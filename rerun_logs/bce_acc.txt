creating models for obj12...
done

loading annotations into memory...
Done (t=4.35s)
creating index...
index created!
loading annotations into memory...
Done (t=8.40s)
creating index...
index created!
len(val_dataset)):  40137
len(train_dataset)):  82081
lr:  [4.000000000000002e-06, 4.000000000000002e-06]
/raid/ganesh/prateekch/miniconda3/envs/debenv2/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
BCE Train Loss:  tensor([ 90.6522,  84.2833,  89.6053,  90.7873,  85.9224,  91.8206,  85.5741,
         92.9525, 126.1053,  86.3566, 114.8694,  73.5039,  84.1070, 109.5092,
         80.7596,  99.9605,  97.3300,  83.2492,  90.1016,  87.1253,  97.6835,
         95.4703,  72.6303,  82.4801, 107.8711,  77.0514,  73.8811,  91.8941,
        103.6009,  85.3835,  81.0058,  97.8376,  84.6602,  90.2872,  82.7207,
        125.7144,  91.8559,  98.0569,  92.3669, 112.6854, 103.9581,  81.0008,
        122.4906, 101.0042,  90.6710,  73.2494,  94.8213,  65.8217,  85.9755,
         92.1444, 110.2688,  90.9073,  82.5622,  93.9711,  73.8777, 119.3369,
         91.9770,  97.2029,  82.5878, 103.6306,  95.5658, 101.3451,  77.4401,
         96.0478,  86.7432, 113.7234,  75.2180,  99.9743, 105.6255, 103.5480,
         98.5779,  82.3590,  83.0102,  85.8979, 102.6647,  80.2919, 108.5184,
         98.9142,  86.4205,  85.4766], device='cuda:0', grad_fn=<NegBackward0>)
Epoch [0/80], Step [000/642], LR 4.0e-06, Loss: 7414.5
BCE Train Loss:  tensor([89.5293, 70.9517, 76.4885, 79.6245, 70.6057, 77.6729, 69.9899, 78.0597,
        96.4904, 72.5341, 89.1846, 61.1394, 71.6190, 87.7629, 69.3008, 82.2344,
        80.4985, 71.1152, 76.0617, 78.0483, 80.3353, 73.7188, 64.5324, 70.1999,
        94.0586, 65.7785, 64.4742, 76.1275, 90.2244, 69.8903, 71.4678, 84.7096,
        74.1678, 81.8565, 67.6472, 95.0216, 75.1368, 79.5442, 77.9932, 90.0151,
        87.0421, 71.9707, 91.5424, 85.7367, 78.8728, 59.8244, 82.8372, 56.8032,
        70.1849, 78.6806, 87.4911, 76.2792, 69.4595, 73.9309, 65.3479, 98.8833,
        76.7467, 78.0932, 72.3371, 87.1685, 83.7343, 89.3181, 64.5851, 78.7108,
        70.6184, 86.4949, 60.8135, 86.0847, 83.8628, 86.5662, 78.6745, 70.8273,
        71.1589, 77.3379, 85.1902, 68.1691, 84.9122, 76.6760, 73.0362, 75.1456],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [0/80], Step [100/642], LR 4.0e-06, Loss: 6197.0
BCE Train Loss:  tensor([90.5370, 48.7604, 60.6949, 51.9805, 46.7036, 54.2955, 50.0226, 58.2663,
        68.8283, 51.7950, 66.7721, 38.6396, 50.0982, 69.9125, 50.9995, 55.6582,
        55.0687, 48.3126, 49.0681, 56.7704, 52.5740, 57.5984, 46.3233, 46.3400,
        65.3286, 53.0523, 42.8135, 55.2521, 63.2569, 47.6050, 50.1492, 63.3338,
        53.0719, 52.2666, 49.3298, 70.7236, 57.5185, 59.6999, 54.1525, 70.2173,
        58.9180, 50.6077, 61.6010, 60.2327, 57.3473, 45.6854, 56.9697, 38.2669,
        51.6988, 57.1869, 60.5759, 49.0167, 50.5064, 50.5678, 35.6187, 70.9783,
        67.3771, 59.8272, 54.7127, 60.9548, 59.4107, 63.3269, 47.4420, 53.4301,
        47.1562, 60.4607, 37.6505, 64.0190, 59.8525, 58.2077, 53.8779, 50.0641,
        48.6115, 57.7015, 60.9980, 45.9351, 59.5069, 56.9699, 52.3752, 52.6533],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [0/80], Step [200/642], LR 4.1e-06, Loss: 4422.1
BCE Train Loss:  tensor([87.7495, 32.1433, 58.0729, 37.6012, 15.1361, 35.4550, 29.1493, 33.7885,
        40.4699, 29.9862, 37.6864, 27.2197, 17.5088, 38.0039, 23.7916, 36.1095,
        34.8932, 21.8584, 21.8286, 29.7190, 25.3430, 35.0603, 23.7159, 17.9395,
        35.9928, 22.0344, 29.2291, 23.9345, 25.8896, 27.1871, 26.5601, 33.7459,
        29.5599, 23.3991, 27.7601, 39.8367, 37.6191, 35.2074, 26.0668, 49.5665,
        22.9789, 48.6466, 30.9484, 32.7207, 34.3625, 32.5111, 27.2810, 21.4356,
        24.6927, 28.7525, 29.6509, 22.1862, 20.8222, 27.5720, 10.7062, 37.4235,
        46.3680, 37.2303, 31.9889, 34.9279, 37.8662, 31.5391, 38.1511, 29.4950,
        26.3654, 34.4357, 18.3371, 36.8736, 37.2622, 36.7558, 26.9340, 32.4648,
        30.1692, 37.4280, 41.0750, 28.5755, 29.3571, 31.3011, 25.5419, 20.3320],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [0/80], Step [300/642], LR 4.2e-06, Loss: 2517.3
BCE Train Loss:  tensor([88.7194, 23.2886, 43.4130, 22.1262, 33.3025, 22.8628, 23.7269, 33.9616,
        21.5918, 31.6850, 17.6921,  6.1966,  6.9992, 33.9483, 27.1818, 22.0100,
        28.7586, 14.8572,  7.2608, 25.3264, 14.3828, 18.7180,  6.7259, 12.9475,
        27.9716, 12.7978, 32.4625, 14.2205, 16.3108, 15.8804, 20.5390, 13.8851,
        22.0958, 13.2259, 11.3678, 20.7309, 18.0063, 25.2635, 25.1019, 36.3270,
        15.5641, 33.3124, 15.7417, 26.4066, 18.5415, 20.3095, 23.9004, 14.9094,
        16.7457, 18.1285, 15.7486, 14.7063, 11.5469, 20.5718, 11.4361, 19.1645,
        32.9765, 17.8966, 23.4064, 16.3468, 38.8457, 20.5063, 16.6871, 10.7988,
         7.4985, 19.9759,  6.7827, 20.3389, 21.7340, 17.4602, 12.9718, 21.3732,
        15.4385, 17.9151, 31.0517, 26.1279, 16.6316, 20.5456, 13.4768,  8.4741],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [0/80], Step [400/642], LR 4.4e-06, Loss: 1665.9
BCE Train Loss:  tensor([90.3267, 15.8987, 45.5228, 20.0079, 18.5792, 20.0263, 18.8150, 33.2203,
        17.4283, 15.6058, 23.1283,  8.3359, 11.2936, 27.5999, 23.3549, 30.3923,
        18.8894, 12.0393, 20.1654,  7.4238, 13.4110, 14.0478,  9.1474, 12.5158,
        35.2376, 20.8710, 31.0883, 15.9170, 10.0939, 19.3603, 22.9184, 11.8776,
        31.3820, 17.0219, 13.7620, 20.9848, 14.5963, 20.1833, 26.1966, 35.9212,
        17.5174, 25.8834, 16.4709, 21.7328, 22.3461, 26.3999, 17.7603, 10.4593,
        14.7166, 13.4323, 15.5720, 23.4167,  6.0256, 11.0766,  6.9345, 17.5071,
        42.2428, 20.3673, 10.1224, 25.2223, 45.4389, 11.3626, 15.2377, 17.9759,
         5.4207, 16.6256,  7.3761, 27.4355,  9.7375, 11.9285,  8.3332, 13.0623,
        10.4528, 22.6062, 20.1762, 17.2627, 12.4714, 16.9294,  7.2364,  6.0141],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [0/80], Step [500/642], LR 4.6e-06, Loss: 1542.9
BCE Train Loss:  tensor([87.4507, 14.1194, 48.9749, 13.8409, 11.0393, 21.7197, 12.4135, 31.2192,
        21.6936, 19.6816,  9.9579,  7.4956,  3.2057, 27.8147, 26.0773, 22.7551,
        17.6598, 20.2599,  6.7950,  5.2528, 18.3560,  7.7369,  6.4086, 19.7880,
        39.6208, 17.3859, 38.0152,  8.9184,  7.8743, 14.6497, 24.4972, 12.5476,
        18.7738, 21.7603, 19.2134, 34.2456, 27.5772,  9.0373, 27.7121, 24.9196,
        14.9179, 21.7795, 21.2364, 15.7101, 23.4787, 23.2091, 17.8947, 10.0322,
        10.8508,  7.9675, 12.7566, 11.1555, 10.4817, 12.1467,  6.4232, 10.1330,
        38.1642, 17.8606, 12.4073, 20.3052, 36.5532, 12.4451, 17.1972, 17.8135,
         6.9236, 19.3997, 10.6882, 24.9086,  6.2003, 13.5170,  8.4710, 18.6031,
         7.4096, 23.6318, 10.3014,  7.8956,  6.1818, 16.1254,  4.5639,  3.9065],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [0/80], Step [600/642], LR 4.8e-06, Loss: 1420.1
BCE Val Loss:  tensor([ 87.1774,  77.6681,  84.4591,  55.5557,   4.6674,  15.4098,  12.8979,
         26.3915,  14.0469,  15.0567,   9.7352,  10.6297,   8.2629,  22.6110,
          8.6196,  10.3593, 381.8265,   6.6983,   5.0062,   6.8338,   6.1830,
          9.5182,   4.0458,   5.5887,  40.5148,  13.6374,  34.2713,   6.8342,
         11.7412,  10.7801,   6.8593,   5.9244,   9.3048,   5.8560,   6.3101,
          9.9695,   9.5258,  12.4738,   5.6245,  52.3906,  15.0145,  37.3912,
         13.1221,  24.5032,  17.9864,  27.7894,   5.9595,   6.8052,   5.4851,
          8.3449,   7.8325,   5.6976,  10.3322,   7.2858,   3.4343,   8.1327,
         32.1564,  13.3098,  23.3942,   6.8029,  24.1038,  31.2624,  10.5359,
         10.1505,   4.6153,   7.5450,   3.4512,  11.9836,  16.0920,  29.0031,
          6.2455,  23.8116,  23.6124,  13.6203,  16.1393,  15.2026,   6.5244,
          9.9800,   6.8876,   5.2350], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [0/80], Step [000/314], LR 4.9e-06, Loss: 1688.0
BCE Val Loss:  tensor([ 88.3207,  17.0821,  74.0835,  10.7360,   3.4036,  37.6080, 108.1061,
         61.1469,  37.9641,  34.2255,  17.7823, 236.6739,  11.6251,  13.1689,
         14.4327,   9.1980,  11.9616,  18.3367,   3.9304,  22.1652,   4.8851,
          7.8691,   3.5310,   7.8464,  32.1908,  20.7074,  39.6652,  14.1828,
         14.7608,   4.7940,   4.8952,   5.0330,   6.0190,   5.1531,   5.1715,
          8.4009,  11.6934,   6.2113,   4.5275,  11.6758,   4.6547,  13.7540,
          6.8592,   7.4380,   5.5798,  11.0918,   4.3957,   2.5910,   4.6970,
          7.7491,   6.0113,   4.5065,   3.6144,   6.0341,   2.7389,  10.0479,
         22.6453,  10.1602,  12.1448,   5.2126,  12.8660,   6.2883,   6.3395,
          6.0641,   3.6761,   6.5239,   2.6427,  17.2921,   5.5068,   9.3889,
          5.2364,   7.3091,   7.0779,   9.8580,   8.7592,   5.1544,   5.4614,
          5.8306,   4.9677,   3.8723], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [0/80], Step [100/314], LR 4.9e-06, Loss: 1343.2
BCE Val Loss:  tensor([ 85.6193,   6.5288,  21.1023,   6.1944,   4.9449,   9.6845,   7.6073,
         17.2198,  13.5081,   7.2703,   8.4299,   4.7140,   3.9194,  25.1400,
          7.4028,   8.5272,   7.9828,   7.7283,   5.5060,   7.4380,   7.1170,
          9.6554,   4.2644,   6.3188,  13.9633,   5.6212,  25.9699,  13.5898,
          7.9345,   7.4299,  10.0045,   9.1378,  14.3065,   6.8288,   7.2561,
         11.5582,  21.7349,  17.6834,   6.2069,  33.4004,  32.9146,  95.7129,
        103.8301,  99.0416,  73.4092,  92.9433,  12.1829,  10.3136,  45.0094,
         11.5346,  31.9694,  47.8127,  71.4538,  25.0278,  85.1286, 130.4402,
        151.6025,  17.4559,  13.5370,   7.3448, 220.1004,   8.7147,  15.9091,
         16.5600,  15.0004,   8.0651,  10.1781,  17.5236,   9.3396,   8.1143,
          7.0660,  14.6787,   9.8272,  37.7499,   8.3965,  16.0219,  13.2874,
          7.2630,   7.5924,   6.0271], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [0/80], Step [200/314], LR 4.9e-06, Loss: 2122.5
BCE Val Loss:  tensor([ 97.4524,   4.9533,  36.5955,   5.8211,   3.5756,  16.0866,   9.3618,
         23.5552,   9.4565,  22.3782,   9.2426,   6.3847,   2.9723,  20.6622,
         15.8209,   6.5545,   5.4312,   5.3229,   3.6551,   5.4592,   4.8607,
          7.7789,   3.4695,   4.2954,  28.0221,   4.5846,  35.9361,   5.6151,
         15.1700,   4.7663,   5.0262,   5.5525,   5.5625,   4.9731,   4.9164,
          8.6900,   7.0009,   5.9246,   4.7180,  13.9574,   4.4889,  11.2402,
          6.5686,   7.3446,   5.5003,   8.1402,   4.7739,   2.6928,   4.6844,
          4.8435,   6.0317,   4.5007,   3.4696,   5.6497,   2.4898,   6.7849,
         18.6695,   7.5941,  15.6097,   5.3920,  17.4921,   6.0143,   6.2569,
          5.7555,   3.5361,   6.4196,   2.8528,  10.2129,   5.7396,   5.3653,
          4.9655,   6.7394,   3.9972,  12.2886, 393.4010,   8.9639,   5.2568,
          9.9140,   4.8204,   3.7550], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [0/80], Step [300/314], LR 4.9e-06, Loss: 1151.8
starting validation
Accuracy th:0.5 is [54.81292869 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38695922 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.11504489 92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.79300934 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [44.97874051 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38695922 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.11504489 92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.79300934 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [57.08170781  3.02801465 11.99298542  3.64798198  2.66972789  3.52869281
  2.9731049   5.56513047  2.0948586   4.40958679  1.24452187  1.35148292
  0.65039874  5.30433755  2.27437832  3.88955611  3.51376979  2.26417071
  1.21818752  1.34048981  1.69776921  0.90942626  1.13466029  1.88234233
  4.70333587  3.18921282  7.68578363  4.17700381  2.52521157  1.57564686
  2.67744889  1.40348631  3.83733356  1.60012864  1.88595207  2.28299285
  3.17131087  2.06893148  3.43330822  9.64220101  2.87147655 11.8999497
  4.35497624  4.15340925  3.84285953  9.38131031  2.5043026   1.78352057
  2.8463277   1.76689553  2.36069673  2.01440275  1.41090428  3.27929441
  1.74700464  3.04519064 14.86307967  5.63286384  4.6350726   3.76848116
 13.25918661  2.76089057  5.54315756  4.15430919  2.3467638   3.08932897
  2.41992666  5.20142213  1.83955089  3.33400162  0.28012046  5.2791037
  3.1912333   5.71872722  4.19288329  4.07107841  1.12654821  1.89044882
  0.20082284  1.09802161]
Accuracy th:0.5 is [51.08855886 82.86570583 28.47674858 74.23398838 97.26733349 34.32828547
 45.07376859 84.31427492  7.58884517 96.4754328   8.19068968 98.52097319
 99.41399349 37.43009954 93.77566063 96.53512993 76.16500774 87.51964523
 94.9428004  94.3433925  73.47863696 19.40400336 98.38695922 97.80460764
 84.37762698 96.65086926 94.0778012  86.85566696 97.39769252 35.15551711
 97.23200253 98.57457877 96.33776392 97.64622751 94.16673773 13.21621325
 29.40753646 58.42034088 83.45902219 37.62381063 96.77026352 92.05540868
 10.77959577 45.53672592 96.44984832 84.4227044  68.04619827 97.6169881
 96.0709543  98.05070601 97.26367856 95.75541234 97.4781009  48.43508242
 98.70615611 79.82846213 87.24918069 72.65262363 88.89146087 75.37310705
 84.89540819 91.65214849 96.1123768  75.93840231 98.40888878  7.60224656
 98.20786784 27.89561531  9.73306855 86.08569584 75.25249449 95.73104616
 97.96176947 95.44961684 33.66552552 94.78685689 91.96281722 31.06199973
 64.69097599 99.14474726]
Accuracy th:0.7 is [50.78519999 97.20276312 42.84304528 95.03417356 97.26733349 43.88591757
 59.94688174 94.33608265 15.05098622 96.4754328  25.9024622  98.52097319
 99.41399349 49.02596216 97.25393209 96.56315103 84.01457097 89.50427017
 98.65255053 98.30655085 79.81993397 27.1975244  98.38695922 97.80948088
 95.18402554 96.65086926 94.0778012  94.29100523 98.01293844 42.83208051
 97.30875598 98.57457877 96.36213009 98.02024829 97.7851147  34.61336972
 34.665757   83.88177532 95.29610994 41.56016618 97.65597398 92.05906361
 23.79478808 50.84855204 96.96031968 93.87068871 79.52997649 98.57336046
 97.99588212 98.51853657 98.32482548 98.55508583 98.99976852 56.45155395
 98.70615611 95.27052546 89.03156638 88.63683435 96.23542598 96.28415833
 89.75036854 97.13697445 96.1123768  95.13163826 98.42838172 17.65085708
 98.20786784 47.07910479 36.12529087 96.81899587 77.62088669 95.99054592
 97.96420609 95.45083515 61.17615526 96.8933127  99.14231064 42.44953156
 70.79348448 99.14718388]
Avg Prec: is [55.54424845  2.3032573  11.95773025  2.42971258  3.44056027  4.09197865
  3.08392646  4.76778128  2.52418055  3.10419161  1.71012483  1.41112064
  0.53885876  4.68180316  2.77913131  3.85801883  3.7994832   2.41435459
  1.39149181  1.57567124  1.63204979  0.94876044  1.29612178  1.77512062
  4.3367147   2.96981853  5.14510775  3.20102797  1.8975959   1.91192597
  2.89562137  1.53606809  3.66726273  2.69135422  2.02189115  2.36262382
  2.97303434  3.06118387  2.93643746  7.27050071  2.02245674  7.70548285
  3.35212553  3.97054315  2.7868007   5.90916711  1.93207305  1.44920242
  2.00339491  1.56588074  1.51472323  1.43019246  1.06241448  3.29001456
  1.26037649  2.43415557 11.1157593   4.75930278  3.52852644  3.64203994
  9.8486475   3.74790453  4.04388458  3.25438197  1.62665385  2.27126674
  1.82190241  4.10531222  1.12164292  2.7989495   0.18528027  5.2863762
  2.33946617  4.44374811  3.92127991  3.17270439  0.8419161   1.88186929
  0.16153973  1.10097153]
mAP score regular 4.26, mAP score EMA 3.73
starting validation
Accuracy th:0.5 is [55.84871814 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.31327703 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.89471062
 97.27931833 96.78102499 97.0276802  92.74484889 97.82744101 92.37362035
 97.07750953 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 89.02758054 96.39235618 96.16314124 96.78102499
 90.13379176 97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [46.0273563  97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.31327703 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.89471062
 97.27931833 96.78102499 97.0276802  92.74484889 97.82744101 92.37362035
 97.07750953 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 89.02758054 96.39235618 96.16314124 96.78102499
 90.13379176 97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [57.88583537  2.78509412 10.99741715  3.66765625  1.71893148  3.15484853
  2.76760462  5.21447796  1.92621933  4.45007106  1.29213856  1.22720363
  0.79244246  5.56626411  2.41657048  4.87770266  3.55880871  2.22012523
  1.21965507  1.16985282  1.72905277  1.19034598  1.0960453   1.69575488
  4.13295247  3.09838081  7.60596139  4.55049881  2.76998253  1.52871271
  2.42647954  1.45741722  4.20496424  1.18986703  1.6226779   2.05384883
  2.66632266  2.26526087  3.17170216 11.00774458  3.72086621 14.61517875
  4.91678703  4.48058374  4.40608458 11.29969497  2.78714175  1.87749104
  3.95465698  2.06020957  3.26161085  2.5039398   2.27719046  3.68528878
  2.18307742  3.27306406 17.30761852  6.45489126  5.15873324  4.5107726
 15.31087076  3.01548957  5.91963525  4.88812747  2.77579086  3.13785186
  2.72051709  6.0937053   2.60207422  4.42370801  0.41450142  6.0417749
  4.13724115  6.3149742   4.62458931  4.1030045   1.12062328  2.01674336
  0.3162631   1.23632303]
Accuracy th:0.5 is [52.11650098 84.48812816 21.67825199 72.79567481 97.90716795 27.29900092
 35.68278646 85.83102873  2.78795127 96.41976231  4.64907691 98.5325261
 99.34723572 43.29172584 91.91269901 96.24785111 78.49864215 83.2872412
 93.39761317 96.07095697 78.71041682 10.59122505 98.31327703 97.88225328
 86.81017515 96.52938685 94.3393876  86.65321275 97.66549568 26.4992401
 97.46368687 98.66955677 96.39484765 98.14385729 95.09679348  6.50023669
 22.1566136  54.68769465 81.33642275 33.87896455 96.69133219 92.37112888
  5.68054414 37.74572091 96.45215138 86.49874181 68.35588111 97.3191818
 96.21297058 98.36808929 97.42880634 93.40508758 97.60071754 44.2459576
 98.6969629  81.90447717 87.92635224 72.37461694 91.05563445 78.45877868
 82.82133692 92.07215288 96.07095697 78.85741336 98.25099036  2.73064753
 98.13139996 17.75170043  4.45474251 84.23399855 81.8870369  95.6648479
 98.02924982 95.44559882 29.27971697 93.73645265 94.272118   21.45152851
 69.75359394 99.11802078]
Accuracy th:0.7 is [52.48772953 97.19460847 36.13872487 92.85447343 97.90716795 38.63268306
 49.12674091 94.24471186  5.10999826 96.41976231 20.58698956 98.5325261
 99.34972718 53.17288288 97.1472706  96.30266338 85.81109699 85.56942472
 98.78167277 98.34068316 84.84689937 17.63460149 98.31327703 97.88474475
 95.38331216 96.52938685 94.3393876  92.73986596 97.81747515 34.64135336
 97.52348207 98.67204823 96.39983058 98.18870369 97.98191195 25.19869447
 27.65029773 78.86488776 93.72897825 37.07053342 97.82494955 92.37362035
 17.80152976 43.2194733  97.01522286 94.01549692 77.56434213 98.77668984
 97.96198022 98.5848469  98.32822583 98.55744077 98.87385704 51.50360017
 98.6969629  95.48047936 88.9628024  85.15334978 96.15068391 95.98375564
 89.92700002 96.99030819 96.07095697 95.02952388 98.32075143 11.42586641
 98.13139996 31.61422129 27.33637292 95.8890799  83.97737748 96.07843137
 98.03174129 95.44559882 58.05864913 96.99778259 99.22017091 33.65722401
 76.33604903 99.15040985]
Avg Prec: is [55.63268467  2.20291286 13.50521814  2.33590902  4.83323786  4.62796031
  3.22727388  3.90925428  7.44711348  2.84910795  2.25887973  1.49592024
  0.54089277  4.00253928  3.33608616  4.65497068  3.94076677  2.55697146
  1.30531428  1.51533124  1.19950557  4.54831743  0.99223333  1.49203387
  3.59114056  2.54444151  4.20744827  3.11606763  1.85530622  3.03724131
  3.03701917  1.6892672   3.2866226   3.71657289  1.66214858  2.16941935
  3.34130968  4.70575578  3.25469676  6.31661924  2.02366976  7.04746019
  2.95226465  3.28546102  2.49599191  5.16016928  1.61138224  1.05193144
  1.88355485  1.45747742  1.2172116   1.17025595  1.14870446  3.30391923
  1.23400788  2.16850055 11.20674925  5.99239833  3.31278991  4.69239448
  8.59521984  5.83930389  4.30917945  3.31291983  1.83272162  1.75862836
  1.96264863  3.6428007   0.84576493  3.31358488  0.14497712  8.80890883
  2.68317005  4.381726    4.13098025  3.18817213  0.84826595  1.54374407
  0.15268015  1.5730726 ]
mAP score regular 4.58, mAP score EMA 3.92
Train_data_mAP: current_mAP = 4.26, highest_mAP = 4.26
Val_data_mAP: current_mAP = 4.58, highest_mAP = 4.58
lr:  [4.922485566185043e-06, 4.922485566185043e-06]
BCE Train Loss:  tensor([89.3780, 11.9697, 47.5249, 21.6088, 21.6852, 30.9491, 22.3126, 34.1164,
        21.9647, 19.1170, 11.8096, 13.3805,  2.6840, 24.7374, 14.5991, 20.9627,
        19.7069,  7.6383,  3.1529,  8.0181,  8.5052,  9.2958, 31.1661, 23.4223,
        39.3912, 18.1991, 31.1754, 15.2324, 11.5190, 13.8709, 22.2499, 19.5050,
        17.9332, 12.1859,  7.8291, 10.4895, 22.9662, 16.7440, 17.8848, 31.3066,
         6.6079, 25.7848, 17.5774, 21.2867, 16.5474, 23.7921,  9.8203,  8.8253,
        25.2102, 10.3132, 11.0702,  9.6442, 17.1075, 12.0855,  9.6571, 27.1280,
        39.9354, 12.3026, 16.7749, 11.8232, 34.1097, 15.0423, 11.1725, 22.6183,
        10.0595,  9.2476,  5.5608, 11.5617,  5.3942,  8.1789,  7.7768,  8.5879,
         3.3718, 20.1596,  9.1584, 14.5462,  7.5731,  9.1548,  3.8242,  7.0594],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [1/80], Step [000/642], LR 4.9e-06, Loss: 1385.6
BCE Train Loss:  tensor([86.4982,  7.2964, 36.6913,  9.8599, 17.0068, 11.2107, 17.9029, 23.3513,
        14.4412, 17.5810,  7.7343, 14.9004,  1.7961, 19.0236, 22.0274, 11.3025,
        13.6690, 10.7627, 16.5009,  8.7373, 11.2919,  7.3617, 22.4811, 14.4732,
        29.0465, 17.9198, 23.4505, 15.4455,  6.2594,  3.3422, 34.0575, 10.7546,
        35.8474, 15.0063, 11.1815, 17.6465, 27.9641, 11.5579, 29.3020, 26.4815,
        13.7023, 19.5501, 23.3215, 22.3610, 22.0669, 24.3243,  6.7352, 10.5497,
         3.1680,  3.1160,  6.7972, 10.6883, 15.4255, 14.8236,  1.6108, 10.9544,
        32.5555, 28.4576,  8.0799,  7.4223, 44.0062, 10.9807, 17.4053, 12.2510,
         9.5404, 28.1778,  1.9828, 11.9506,  7.4668,  9.7859,  2.9604, 11.6501,
         2.6675, 23.3512, 34.7431, 21.2275, 14.0756, 10.6645,  2.5406,  2.2671],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [1/80], Step [100/642], LR 5.2e-06, Loss: 1304.6
BCE Train Loss:  tensor([86.6918, 22.1315, 42.9244, 19.0420, 22.1495, 21.0995, 11.1012, 42.8366,
        16.1163, 29.2890,  8.1329, 10.2089, 12.0917, 32.1031, 25.6619, 14.9597,
        14.3602, 15.3399,  2.5801, 10.2689,  3.5348,  7.0928,  2.8201, 14.4052,
        22.0263, 25.4687, 40.6722, 11.0677,  7.0655, 11.0980, 19.5979, 10.6534,
        22.1940,  7.0648, 14.9066, 14.2208,  7.7780, 11.7960, 17.6658, 28.6622,
        19.5844, 35.1602, 18.1631, 29.3668, 13.9280, 33.5012, 13.9558,  2.1784,
        20.3242, 10.6904,  6.8771, 18.0684,  9.4960, 15.3123,  1.8900, 16.9494,
        40.9950, 23.4738, 24.0784, 24.0801, 44.6421, 11.8815, 20.5832, 16.6792,
        17.7585, 17.5032, 14.5767, 22.8123, 10.7322, 10.1847, 11.6750, 11.8674,
        20.1108, 22.0576, 37.8968, 21.2608,  3.3407, 11.8731,  2.3350,  7.3671],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [1/80], Step [200/642], LR 5.6e-06, Loss: 1474.1
BCE Train Loss:  tensor([87.2490, 23.6869, 39.3428, 16.4726, 10.7314, 40.1716, 16.9626, 22.2142,
         8.1982, 17.7869,  3.5415,  5.9794,  1.5810, 32.2931, 22.9254, 29.3108,
        25.4739, 26.6355, 18.5864, 21.4437, 13.5671,  3.3000,  2.5817, 14.8120,
        12.8868, 18.8777, 32.6021, 16.8019,  7.3505, 26.7596, 21.7503, 10.3708,
        14.7316, 15.0734, 11.6409, 15.7538, 24.3264, 14.2878, 11.1057, 37.4990,
         6.7116, 17.7108, 13.3338, 17.5157, 14.0157, 17.9966, 14.3765, 14.3295,
         3.0276, 10.7020,  7.9717, 12.0994,  2.1177, 15.8542, 10.4020, 15.0383,
        30.3499, 16.6202, 19.4238, 16.7172, 33.9692, 33.0218, 16.3798,  7.1886,
         2.4421, 10.1325,  6.6160, 19.6157,  3.2352,  6.7146,  2.1402, 17.4891,
         7.3445, 23.7784, 24.3987, 16.7006,  6.5735,  6.8376,  1.8642, 10.3798],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [1/80], Step [300/642], LR 6.0e-06, Loss: 1329.8
BCE Train Loss:  tensor([83.9789, 17.7785, 44.6366, 19.7418, 10.7742, 23.6261, 26.7532, 34.5826,
        14.2071, 14.1328,  2.7385,  5.9399,  5.6909, 26.0649, 13.2575,  7.8352,
        29.9815, 14.1644,  5.8545, 15.2466,  6.5688,  2.4901, 12.9697,  2.7552,
        26.5808, 24.5347, 24.1589, 17.1090, 10.4124, 27.9358,  8.0126, 13.1216,
        21.2986, 28.2052, 14.1264, 17.0552, 14.0993, 16.0812,  3.5370, 19.8438,
        14.3013, 34.7790, 23.4833, 17.9517, 10.6015, 29.4135, 18.5001,  9.4449,
        13.0040, 14.5202, 10.2020, 13.6249, 13.7147, 22.8182, 13.8751, 17.9513,
        45.9730, 22.6505, 16.9403, 17.8998, 37.5494, 10.4130, 16.5056, 17.5081,
        19.3549, 10.7079, 25.5627, 27.2901,  2.3923,  2.9874,  1.4714,  7.0888,
         6.1700, 26.2132, 37.7783,  3.5788, 22.0733,  2.7236,  1.2804,  1.4338],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [1/80], Step [400/642], LR 6.4e-06, Loss: 1389.6
BCE Train Loss:  tensor([83.0496, 14.4598, 37.1020, 23.9137, 20.1671, 16.5484,  7.6730, 21.5972,
        23.6498, 19.5199,  2.5141,  6.2302,  1.0996, 18.1049, 14.4671, 10.5609,
        28.6825, 23.5406, 10.5022,  6.9348, 14.9276,  5.6282, 10.9741, 16.5468,
        26.6206, 21.2067, 19.2808, 10.8805,  2.6277,  8.1461, 10.1514, 28.4118,
        16.1889, 13.7987, 18.0935, 10.7347, 18.1532, 25.7250, 13.9651, 22.2859,
        21.0131, 41.1726, 22.3052, 17.3120, 16.6247, 37.2267, 10.3920,  6.2567,
        16.3049,  9.5311,  6.1021,  5.4436,  6.1114, 23.6336, 19.7543, 25.0645,
        36.6819, 20.1913, 12.1432, 14.2607, 35.1577, 17.3590, 26.5940, 16.7338,
        10.2269, 20.9653,  5.9586, 16.6886, 13.9754,  9.8885,  1.3139, 12.0279,
        18.2402, 27.3466, 25.9392, 10.7397,  5.9262, 20.9159,  1.1629,  6.1060],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [1/80], Step [500/642], LR 6.9e-06, Loss: 1375.5
BCE Train Loss:  tensor([88.0642, 22.4071, 33.5326, 30.7125, 13.7219, 21.8508, 10.3882, 25.6404,
        18.0762, 16.9712, 19.0267,  6.3060, 10.9306,  9.1824, 10.5304,  7.5658,
        25.6093, 10.9742,  1.6874,  6.3421, 10.3559,  6.2359, 10.4068, 16.8388,
        21.6375, 18.2066, 24.4056, 17.5943, 11.4896, 10.8118, 28.5370, 10.5844,
        13.9840, 18.9058, 20.6315, 24.2073, 10.1723, 11.6107, 14.7230, 28.1698,
         9.8474, 36.6512,  3.7356, 17.0558, 16.4226, 21.6554,  6.0545,  5.8780,
        10.2158,  6.8748,  2.2793,  9.2260, 10.1807, 14.4668, 13.7341, 13.1230,
        49.0497, 30.9034, 20.7904, 36.6502, 48.9779, 12.4900, 22.8278, 12.5286,
        18.2963, 17.1046, 16.9714, 34.5239, 14.0114, 14.5570,  1.0743, 20.7420,
        12.7613, 25.2764, 17.7134, 19.2789,  1.6193, 19.2706,  6.1053,  1.2096],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [1/80], Step [600/642], LR 7.4e-06, Loss: 1391.2
BCE Val Loss:  tensor([ 83.8355,  80.1106,  82.9153,  55.2489,   3.0287,  13.2253,  11.0901,
         25.9680,   7.9614,  14.1264,   6.0235,   9.8634,   6.6759,  20.2215,
          6.9817,   8.2393, 406.8803,   4.5863,   2.5734,   3.2402,   3.2026,
          2.5218,   2.4132,   4.1731,  38.8456,  13.6634,  32.1623,   4.8003,
          9.5924,   8.8335,   4.0975,   2.0115,   8.2327,   2.4554,   3.6722,
          3.9535,   5.1564,   9.0734,   3.6482,  53.3527,  14.2938,  35.9739,
         10.7161,  23.3201,  17.6325,  27.0683,   3.0894,   6.0499,   3.0733,
          5.6295,   3.0414,   2.5397,  10.4153,   4.3641,   2.1742,   3.8819,
         31.7420,  11.0251,  22.9925,   4.3231,  23.5312,  28.6831,   8.8910,
          7.7119,   2.3049,   3.7865,   2.5265,   9.6369,  14.4144,  28.7062,
          1.3272,  22.8799,  24.2762,  12.6364,  14.4325,  14.0786,   1.7811,
          6.4101,   1.5109,   1.6480], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [1/80], Step [000/314], LR 7.7e-06, Loss: 1543.2
BCE Val Loss:  tensor([ 88.1069,  17.0000,  73.3902,  10.1050,   2.3108,  38.2422, 117.2640,
         64.2936,  41.1356,  35.8432,  17.4873, 263.9250,  11.0918,  10.3373,
         14.7115,   7.1124,  11.4546,  18.1499,   1.8588,  22.7018,   2.3366,
          1.8604,   2.3089,   6.5798,  31.3518,  21.0344,  38.7590,  14.0322,
         14.0937,   2.2695,   2.9726,   1.6005,   5.0171,   2.1373,   2.9569,
          3.1347,   8.7305,   3.4293,   2.9495,   8.8787,   2.6153,  12.3050,
          3.5531,   4.7575,   3.3408,   9.9302,   2.1769,   1.4169,   2.4924,
          5.8552,   2.2533,   1.9011,   1.2645,   3.5520,   1.6637,   7.0017,
         21.2377,   7.7263,  11.0723,   2.9807,  13.3164,   2.7703,   4.6880,
          3.8384,   1.7776,   2.8692,   1.8926,  16.1734,   1.6218,   6.9438,
          0.9643,   5.0365,   5.7636,   8.1485,   7.3009,   3.6700,   1.3349,
          2.2742,   0.9636,   1.0873], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [1/80], Step [100/314], LR 7.7e-06, Loss: 1244.5
BCE Val Loss:  tensor([ 78.9357,   4.8505,  18.7275,   4.9040,   3.1588,   6.7266,   5.0678,
         15.5471,   5.6105,   5.3677,   3.1642,   2.9267,   1.2819,  22.6312,
          5.2630,   5.7706,   6.5579,   5.2957,   2.9157,   3.6424,   3.8483,
          2.6759,   2.5013,   4.7537,  12.4851,   5.1429,  24.9760,  12.1469,
          4.4096,   3.9432,   7.6166,   6.4104,  13.0576,   2.8944,   4.4125,
          4.7653,  20.3593,  15.8213,   4.2855,  33.6987,  34.0529,  90.2100,
        113.1817, 106.0051,  78.0091,  92.2189,  10.2574,   9.8423,  48.0649,
          9.8989,  35.0138,  53.3594,  87.5435,  23.5305,  89.8501, 153.1607,
        147.2658,  15.7390,  12.6026,   4.9526, 190.3587,   4.4813,  15.1866,
         14.5654,  14.4621,   4.3658,   9.7749,  15.4922,   5.9161,   4.8430,
          1.6203,  12.6566,   7.8651,  37.8550,   5.5736,  15.4572,  10.1761,
          3.2769,   1.8100,   2.0731], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [1/80], Step [200/314], LR 7.7e-06, Loss: 1991.1
BCE Val Loss:  tensor([102.2243,   4.0624,  35.7277,   4.7489,   2.8575,  15.2901,   7.8978,
         22.2377,   4.0562,  22.0695,   5.8800,   5.8269,   0.9438,  18.9558,
         14.9993,   4.2735,   4.3689,   3.7874,   1.8778,   2.5897,   2.4545,
          1.9689,   2.2970,   3.4480,  27.5338,   4.5470,  35.8454,   4.1402,
         14.8120,   2.3999,   3.4884,   2.0240,   4.7191,   2.4131,   2.9249,
          3.4336,   3.9744,   3.4904,   3.2951,  11.5492,   2.6920,  10.5276,
          3.4394,   4.8066,   3.4221,   6.9428,   2.5184,   1.5579,   2.5666,
          1.9616,   2.3469,   1.9690,   1.2783,   3.2765,   1.5708,   3.2225,
         18.3103,   5.4363,  14.6337,   3.4698,  16.9872,   3.0692,   5.2161,
          4.0079,   1.8615,   3.0836,   2.2180,   8.5336,   1.8002,   3.0819,
          1.0199,   5.1345,   2.5311,  11.0940, 436.5974,   7.6227,   1.3908,
          6.8447,   1.0379,   1.1813], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [1/80], Step [300/314], LR 7.7e-06, Loss: 1045.7
starting validation
Accuracy th:0.5 is [58.73466454 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38695922 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.11504489 92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.79300934 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [45.59154981 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38695922 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.11504489 92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.79300934 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [64.09360025  3.82991847 15.72915491  5.74760903  5.62283317  4.48910902
  3.32482049  6.67327024  2.13305258  5.44442294  1.30856658  1.40558446
  0.65975297  6.15648075  2.3091039   4.84004853  3.64253216  2.41243386
  1.45176351  1.30680645  2.05850514  0.74913705  2.3725948   2.73284549
  5.62428866  3.72689393  9.71015293  4.89008738  2.67749268  1.64850024
  3.92807311  1.41725824  5.83063796  2.55218095  2.295515    3.10587157
  3.18545277  3.04524264  3.95367702 11.89376635  3.61170637 16.09006502
  6.442418    6.10555152  5.15667051 12.66299687  2.98656329  2.32737762
  3.66103779  2.30329262  2.89570248  2.88585049  1.64070667  5.67122964
  2.04320535  3.43616762 18.02499846  7.42958518  5.48400537  4.55906592
 20.82811178  8.83653318  7.3825775   5.4459368   2.84387603  4.26180632
  2.82155175  5.80833375  2.41826705  4.77155375  0.2890456  11.75071591
  4.28803682  7.49721976  4.60529326  4.80181508  1.21781965  2.06946769
  0.24292929  1.54881627]
Accuracy th:0.5 is [48.5154908  96.93717182 83.3907969  91.37681071 97.26733349 96.30486958
 82.77067775 94.64553307 40.65374447 96.4754328  87.1955751  98.52097319
 99.41399349 39.51706241 97.20032651 96.56558765 67.16779766 97.48053752
 98.51975488 97.79486117 74.08048148 76.45009198 98.38695922 97.80948088
 91.6119443  96.65086926 94.0778012  96.67523544 97.88379771 97.8679597
 97.30875598 98.57457877 96.19887672 97.61089655 97.73029081 96.97859432
 96.67645375 97.06996747 92.18211279 77.07386606 97.69739647 92.05906361
 52.47499421 94.76492733 96.94569998 89.99037536 75.73250813 98.57336046
 97.99100888 98.51853657 98.36746628 98.55508583 98.99976852 97.3111926
 98.70615611 94.21547008 86.358597   76.61821859 90.86633935 93.15675979
 89.04253116 95.69693352 96.1123768  90.70308598 98.42838172 49.7837502
 98.20786784 88.17996857 97.04194637 95.35093383 99.81603538 95.99054592
 97.96420609 95.45083515 92.70842217 96.91767888 99.15571204 98.14451578
 99.82700016 99.14718388]
Accuracy th:0.7 is [46.9134148  97.2137279  86.17950561 97.02489005 97.26733349 96.5997003
 96.12577819 94.73568792 88.6307428  96.4754328  93.36265396 98.52097319
 99.41399349 92.20160573 97.2685518  96.56680596 96.28537664 97.48053752
 98.65376884 98.30776915 97.99831873 84.37275374 98.38695922 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.69374155
 96.93351689 97.14550261 97.09920688 79.69079324 97.84237521 92.05906361
 95.35946199 95.12189179 96.96153799 93.87434364 96.7812283  98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09126351 96.06120783 96.24273583 96.9067141
 89.79300934 97.17717864 96.1123768  96.98468586 98.42838172 88.38098951
 98.20786784 95.89308122 97.86430477 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.14892606 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [54.12507957  2.25003866 10.77689317  2.29503739  4.12836474  2.959049
  3.0261785   4.88196291  2.69723759  3.16680941  1.36490342  1.29580782
  0.56725513  4.0972993   2.860895    3.97111008  3.82957522  2.14743289
  1.53269228  1.61876818  1.62733546  0.96385468  1.29401487  1.82422226
  4.27385704  2.86018364  4.97399201  3.08552427  1.91180159  1.69773044
  2.73550853  1.53080703  3.61395094  3.44231464  2.14062374  2.05249464
  3.21252057  3.50087922  2.74751773  7.42813365  1.96452796  7.74556024
  2.69966547  3.2288514   2.95215043  5.80668566  1.8169004   1.36284017
  2.00135638  1.3948994   1.27959959  1.63826877  1.08688819  2.22852107
  1.26095237  2.26097671 12.78271499  4.19885687  3.43216407  3.28281575
 10.51065089  3.58738576  4.70929384  3.12573851  1.69817273  2.60419753
  1.89799755  3.74362243  1.32553313  2.81227876  0.2031348   6.15447754
  2.28794039  4.69753396  3.76285797  3.2586254   0.88202377  1.73030355
  0.16955556  1.05363816]
mAP score regular 5.49, mAP score EMA 3.69
starting validation
Accuracy th:0.5 is [61.38724867 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.31327703 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.89471062
 97.27931833 96.78102499 97.0276802  92.74484889 97.82744101 92.37362035
 97.07750953 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 89.02758054 96.39235618 96.16314124 96.78102499
 90.13379176 97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [47.61192914 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.31327703 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.89471062
 97.27931833 96.78102499 97.0276802  92.74484889 97.82744101 92.37362035
 97.07750953 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 89.02758054 96.39235618 96.16314124 96.78102499
 90.13379176 97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [66.50966063  3.50077747 18.50636665  7.24376467  6.60642885  4.17681018
  3.19251639  6.99905243  1.99296599  5.91056424  1.33235722  1.30541646
  0.73029206  6.82908073  2.39916536  6.09808745  3.78748584  2.4669807
  1.237459    1.18425304  1.992396    1.14349626  2.82865468  2.71681173
  5.07420368  3.68796081 10.40156653  4.97940844  2.92333586  1.64007662
  4.86195265  1.48414594  6.85112899  2.49692123  2.0077396   3.2521302
  2.76713609  3.68920115  4.17690282 14.19009157  4.92381444 19.68811154
  8.56422725  7.08163259  6.27281887 14.10783946  3.36703801  2.46026747
  5.74522677  2.67199055  4.67106731  3.27244837  2.61248791  8.47198897
  2.56163662  4.07201929 20.66649159  8.49111589  6.00014047  5.56940276
 24.53101807 14.4234088   8.01500007  6.355973    3.51129637  5.16287199
  3.24330603  6.83330799  3.73031827  6.43033426  0.58011424 17.04423913
  5.9734572   8.8213191   5.26919526  4.82468658  1.38776076  2.27801874
  0.42493499  1.73766448]
Accuracy th:0.5 is [47.0164686  96.71624685 83.93502255 90.59969604 97.90716795 96.57672472
 80.27505793 94.61843187 22.70971921 96.41976231 92.27894461 98.5325261
 99.34972718 34.11565389 97.01522286 96.31262924 66.679124   97.50604181
 98.7642325  98.14136582 83.39437427 79.38062137 98.31327703 97.88474475
 93.1036201  96.52938685 94.33689613 96.74614446 97.73525675 98.08406209
 97.52597354 98.67204823 96.13075217 98.16129756 97.95948875 96.21795351
 97.03764606 96.69631512 87.43055036 88.40471386 97.48611007 92.37362035
 53.10063034 93.46488278 97.0202058  89.64297282 72.05321773 98.77668984
 97.95948875 98.5848469  98.33071729 98.55744077 98.87385704 97.2070658
 98.6969629  95.47300496 85.50464659 71.25096544 92.22662381 93.98310786
 88.11321225 96.11829484 96.07095697 93.64426838 98.32075143 45.06814161
 98.13139996 90.05157336 97.65054688 93.61686225 99.81563146 96.07843137
 98.03174129 95.44559882 92.05720408 97.01023993 99.23013678 98.14385729
 99.78822533 99.15040985]
Accuracy th:0.7 is [46.99653686 97.22450607 87.34085756 96.96290206 97.90716795 96.63651992
 95.8890799  94.87754441 83.89765055 96.41976231 98.33320876 98.5325261
 99.34972718 89.54580562 97.2070658  96.31262924 96.17310711 97.50604181
 98.78167277 98.34068316 98.13638289 94.09024092 98.31327703 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.84238981
 97.27682687 96.78102499 96.96539353 89.29416748 97.82744101 92.37362035
 94.6009916  94.32942173 97.03764606 94.02795426 95.35341456 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 89.02508907 95.7620151  96.16314124 96.78102499
 90.13379176 97.04761193 96.07095697 96.92553006 98.32075143 84.66003937
 98.13139996 95.66983083 98.05167302 97.53344794 99.81563146 96.07843137
 98.03174129 95.44559882 95.74208336 97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [52.26014158  2.00907391 10.74279513  2.04187347  8.2389227   2.70658254
  3.11859198  4.12877933  2.76568098  3.00714256  1.22676672  1.13829604
  0.54850714  3.9890172   2.92475045  4.33923853  3.98733032  1.88388777
  1.65598848  1.69232903  1.50973669  0.94241195  1.53426628  1.43614129
  3.69440529  2.65643095  4.30374507  3.05341284  1.96774556  1.6964082
  2.46007207  1.34464589  3.80903498  4.09165891  2.16872587  1.81325755
  2.51306171  4.20284458  2.99089282  7.20777061  2.04381632  7.51870119
  2.24579721  2.88088636  2.81605709  5.29926965  1.53500518  1.05418236
  2.09293203  1.24435434  1.2096421   1.72296614  1.11280965  2.04486858
  1.28635133  2.13672322 14.5201799   5.14918246  3.26250957  3.68516878
 11.04074714  4.62821094  5.17085502  3.09506586  1.84118729  2.45038661
  1.96644725  3.92895239  1.28702728  3.1275494   0.29692299  9.37734519
  2.69335851  4.83489493  4.51905823  3.31979405  0.93770611  1.68786352
  0.28389174  1.09966423]
mAP score regular 6.34, mAP score EMA 3.78
Train_data_mAP: current_mAP = 5.49, highest_mAP = 5.49
Val_data_mAP: current_mAP = 6.34, highest_mAP = 6.34
lr:  [7.654484780581013e-06, 7.654484780581013e-06]
BCE Train Loss:  tensor([87.9753,  8.5082, 24.1171, 10.4578, 14.6207, 11.4269, 19.2731, 20.3843,
        18.4875, 15.1585, 10.5508,  6.4024,  0.9411, 21.4749, 22.7898, 17.9125,
        27.9288, 14.6351, 14.0500, 19.7108, 13.7134,  5.8746, 10.2775,  6.9973,
        27.7051, 18.6987, 15.6247, 36.9801, 13.3346, 10.7021, 18.9157, 27.9368,
        17.5907,  2.6786, 10.3234,  6.7392, 13.6966, 10.9278, 18.4152, 41.3254,
         9.5903, 44.0134, 10.8665, 28.1374, 16.4519, 33.7531,  6.6360,  1.7014,
        18.2137,  6.6374, 14.2116,  6.1650,  5.4430, 13.1446,  1.6066, 21.7270,
        55.4904, 19.7103, 22.5475, 13.1496, 39.6024, 25.8624, 26.4188, 22.6002,
         5.8725, 16.5801, 17.4304, 14.7070, 13.9782, 30.9501,  0.9877, 30.6218,
        35.7038, 28.0859, 20.2129, 11.5853, 14.0509,  6.3195,  5.5914,  9.9654],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [2/80], Step [000/642], LR 7.7e-06, Loss: 1441.6
BCE Train Loss:  tensor([86.5057, 17.5287, 37.1705, 17.3955, 13.6625, 23.6079, 10.3788, 25.6778,
        33.1491, 14.5419, 14.0847,  9.8746,  0.9210, 27.6979, 11.1445, 18.9843,
        26.4044, 10.7533,  9.5222, 10.4456, 15.3542, 10.8197, 10.3422,  7.0249,
        18.3451, 21.2770, 30.3331, 21.0721,  6.0872, 11.2723, 10.5332,  6.5101,
        20.9320, 19.8533, 21.5938, 21.2129,  7.8227,  7.2819, 18.3270, 30.1721,
        17.2227, 36.4437, 13.2254, 15.6306, 25.4881, 29.9091, 15.8453, 13.9676,
         9.2203, 10.0016,  6.6137, 10.4959, 11.5646, 16.8405, 13.4768, 20.2895,
        37.6423, 23.5605, 27.4698, 16.3596, 40.5991, 15.9460, 21.0235,  9.7622,
         5.4348,  9.9307,  6.0177, 27.7304,  1.8509, 13.3912,  0.8943, 12.6176,
        24.2551, 20.6677, 11.7799, 22.4762,  9.8297, 10.8123,  0.7827,  5.7106],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [2/80], Step [100/642], LR 8.2e-06, Loss: 1378.4
BCE Train Loss:  tensor([89.4946,  9.8652, 31.1001, 19.8284, 18.5909, 17.0799,  7.4460, 37.3206,
        12.1468, 12.9675,  1.8815, 10.6006,  0.7418, 20.3453, 18.7752, 10.0519,
        17.8036, 36.3855,  9.9220, 20.5797,  6.5105, 14.7507,  2.2134, 10.3161,
        28.2970, 14.0742, 21.4756, 20.4853, 13.2044,  6.5252, 12.0520,  1.7323,
        24.7001, 10.2778, 28.6523, 21.4515, 18.6158, 28.4031, 14.8268, 25.5306,
        10.0780, 36.2645, 30.6875, 27.4507, 26.2111, 30.9215, 17.3397, 18.6616,
         6.1891,  6.1579, 20.9299, 19.0016,  5.1154, 15.1390, 18.7626, 13.0592,
        45.0631, 13.0894, 23.0918, 16.8802, 42.9963,  6.0729, 16.8746, 20.6130,
        13.8830, 20.1732, 10.3692, 16.6405, 14.6680, 14.3481,  0.6657, 12.7774,
         9.6023, 18.4344, 14.4027,  6.6433,  5.8883, 10.2627,  0.5840,  5.2934],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [2/80], Step [200/642], LR 8.9e-06, Loss: 1388.3
BCE Train Loss:  tensor([88.7383, 11.1732, 36.2469, 33.0405, 13.6881, 13.6132, 10.5978, 26.8559,
        28.3994, 13.8297, 14.8932,  5.3783,  0.7867, 22.7122, 14.2825, 17.2733,
        18.4043,  3.7124, 13.3265, 11.5392,  6.2539, 19.2389, 15.0934, 35.9611,
        28.9679, 13.9237, 26.3260, 22.7214, 13.8892,  6.3046, 31.7515,  9.5506,
         4.7831,  6.6330,  6.3632, 10.8809, 13.8337, 15.2539,  3.7722, 32.4997,
        18.1006, 35.0251,  6.8370, 10.8110, 10.3890, 24.7286,  8.9383, 13.7811,
        13.8213, 17.4091,  5.8575, 13.5131,  5.9528, 14.1290,  5.5707, 12.9937,
        42.9039, 10.5993, 16.9327, 17.4606, 32.9414, 18.1354,  7.7176, 13.2191,
        12.8047,  6.6885,  9.1814, 20.5713, 10.8044, 18.0275,  5.4644, 28.4983,
        12.6789, 22.1895, 18.2363, 10.2557,  5.9447,  2.5394,  0.5795,  5.4954],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [2/80], Step [300/642], LR 9.5e-06, Loss: 1290.2
BCE Train Loss:  tensor([85.5272, 10.6874, 24.8942,  7.4751,  7.1148, 25.0583, 26.7358, 10.2204,
        21.2422, 17.4022, 18.6668, 23.2290, 11.0348, 34.3450, 17.7235, 10.2523,
         8.1096, 15.2686,  6.5486,  2.3564, 10.0521,  7.6136, 15.5938, 16.6883,
        31.9512, 21.1846, 34.6676, 16.4207,  6.0388, 10.8622, 10.4127,  5.6361,
        27.7096,  2.8128, 18.2770, 17.8465, 14.1195, 10.4028, 33.7584, 27.1048,
        16.7594, 36.4502,  7.5935, 17.2826, 19.8667, 35.4623, 18.4979, 10.9616,
        13.4639, 13.6879,  8.9483,  5.8555,  9.8759,  9.8770, 13.7405,  6.5929,
        50.8483, 10.1723, 17.5175, 13.1945, 37.4103, 17.9861, 14.0884, 16.0499,
         2.0284, 11.5018,  6.2261, 20.5217,  5.5918,  6.0344,  0.5951, 19.0944,
        10.7112, 18.8545, 23.3232, 26.3601,  1.2265,  6.4592,  0.5240,  1.1653],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [2/80], Step [400/642], LR 1.0e-05, Loss: 1305.4
BCE Train Loss:  tensor([82.9962,  6.5878, 42.8411, 16.8646, 18.1844,  8.4353, 20.5406, 30.6345,
        21.6430, 17.6984, 13.9073,  1.9361,  5.4647, 18.4607, 24.7459, 19.9744,
        17.1661, 27.8152, 14.6206,  6.2149, 24.6913,  5.8172,  2.4129,  6.1869,
        30.2471, 15.1251, 21.0342,  7.4106, 22.4240,  9.1478, 16.1898, 17.1440,
        14.6382,  9.3836, 10.1606, 17.2982, 23.6582, 22.8383, 10.7877, 37.7831,
         9.0884, 27.0222, 23.4268, 14.0061, 24.4549, 26.0436, 13.6724, 15.6026,
         6.2836,  1.7767,  5.2821,  9.8046,  1.2336, 16.2157,  5.4478, 27.0402,
        41.7843, 12.8409, 18.4777, 16.6706, 42.8851, 15.5225, 17.5396,  7.3578,
         2.1299, 10.1811,  2.2199, 16.6636,  1.5394,  2.8555,  0.4928, 18.2598,
         2.4755, 22.8805, 14.9301, 10.0149,  5.9181,  2.2167,  0.4122, 10.6480],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [2/80], Step [500/642], LR 1.1e-05, Loss: 1264.4
BCE Train Loss:  tensor([82.8345, 19.5332, 40.7999, 17.6721, 13.9679, 27.3998,  7.6097, 32.9501,
        14.2734, 16.3471, 10.4813, 19.1554,  0.9046, 14.2692, 23.6597, 17.0053,
        25.0581, 14.4325,  2.1253, 10.8305,  2.8517,  1.3365,  6.8492, 19.5845,
        17.8162, 19.7224, 13.3693, 21.8561,  2.9016,  8.4042, 19.1017, 10.0052,
        18.5751,  9.3804, 13.6788, 16.8477, 15.7556, 23.9929, 13.6161, 29.9917,
         6.2322, 27.6250, 36.4084, 22.9026, 16.0933, 37.0860,  6.8100, 13.3651,
        13.2840,  5.8097, 17.3365, 23.0046,  1.4237, 15.6602, 17.4973, 22.5625,
        42.7735, 13.6678, 20.3582, 16.4676, 32.5521, 12.1611,  7.9132, 16.5052,
         2.1626, 17.2750,  2.5938, 11.5467, 22.1961, 33.7672,  5.8156, 23.9312,
        16.1372, 11.9858, 21.0135, 13.8759,  1.1905,  2.4188,  0.4463,  1.2254],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [2/80], Step [600/642], LR 1.2e-05, Loss: 1330.0
BCE Val Loss:  tensor([ 84.9725,  78.9623,  82.0980,  52.0508,   1.8174,  12.0612,  10.2114,
         25.7346,   7.3141,  13.7526,   6.0535,   9.9551,   6.4449,  18.9616,
          6.8921,   8.8170, 394.4281,   4.5859,   2.6926,   3.0779,   3.3795,
          1.5048,   2.3887,   4.6977,  37.4559,  13.8450,  31.0456,   4.6498,
          9.3218,   8.3756,   2.9303,   1.4047,   7.5853,   1.6365,   3.1962,
          3.3143,   4.5176,   7.2267,   2.7975,  53.3916,  13.3932,  32.1061,
         10.6554,  22.2608,  17.3897,  28.2229,   2.7799,   5.9231,   2.9542,
          5.1603,   2.6055,   2.1519,  10.6118,   4.7970,   1.9806,   3.8084,
         33.4362,  10.6895,  22.4770,   3.9687,  22.0808,  25.8730,   9.1938,
          7.0227,   2.1908,   3.6238,   2.7206,   9.3475,  14.2720,  27.0725,
          0.4681,  22.9888,  23.5326,  13.0826,  13.9681,  13.5787,   1.1003,
          6.2349,   0.5382,   1.1699], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [2/80], Step [000/314], LR 1.2e-05, Loss: 1493.0
BCE Val Loss:  tensor([ 89.2248,  17.5118,  70.9290,  10.3850,   1.6812,  37.7750, 114.2191,
         64.0293,  40.1858,  36.0343,  17.8159, 262.9473,  11.2877,  10.6758,
         14.9970,   7.2758,  11.9767,  17.8055,   2.0201,  21.6998,   2.4851,
          1.1437,   2.7916,   6.7865,  30.0730,  21.9391,  37.6750,  14.8014,
         13.5398,   2.2657,   2.5416,   1.1984,   4.5805,   1.5926,   2.7574,
          2.7054,   7.4784,   3.0643,   2.4589,   8.1525,   2.5927,  11.4878,
          3.4574,   4.8416,   3.5410,  10.2441,   2.0803,   1.2715,   2.2090,
          5.8065,   1.9263,   1.6343,   1.0732,   3.8399,   1.4453,   6.5788,
         20.5967,   7.1068,  10.3667,   2.4972,  12.3091,   1.8104,   4.3457,
          3.3189,   1.6945,   2.4847,   2.0203,  16.9687,   1.2260,   6.6363,
          0.3188,   3.7161,   5.5745,   7.8813,   7.5743,   3.2185,   0.7976,
          1.8699,   0.3293,   0.7165], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [2/80], Step [100/314], LR 1.2e-05, Loss: 1219.9
BCE Val Loss:  tensor([ 77.5372,   3.9042,  15.7151,   4.4529,   1.6314,   5.1304,   3.8870,
         14.3426,   3.7837,   4.3023,   2.3889,   2.5217,   0.9613,  21.3888,
          4.4627,   6.0288,   6.5586,   4.3620,   2.6413,   3.1773,   3.7157,
          1.5595,   1.7776,   4.0441,  11.6737,   5.0299,  25.6618,  11.6718,
          4.1068,   3.5426,   6.2919,   6.2251,  11.4350,   1.5776,   3.5764,
          3.7020,  20.5213,  15.4707,   3.2631,  34.4853,  32.8587,  80.5842,
        101.2729,  97.9038,  69.1296,  86.3854,   9.9420,   9.7947,  45.2015,
         10.2155,  34.2664,  51.4822,  89.1893,  22.4882,  88.6796, 144.3155,
        137.8716,  16.4437,  12.2353,   4.8614, 157.5400,   3.4206,  15.5279,
         14.1746,  14.6169,   4.5918,  10.1354,  15.1092,   5.7569,   6.0195,
          0.6264,  11.8717,   7.8307,  36.6212,   5.1973,  15.0877,  10.4889,
          3.0401,   0.6868,   1.5475], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [2/80], Step [200/314], LR 1.2e-05, Loss: 1853.5
BCE Val Loss:  tensor([9.8481e+01, 4.1721e+00, 3.4591e+01, 5.3938e+00, 2.5042e+00, 1.4677e+01,
        8.0860e+00, 2.1060e+01, 3.7891e+00, 2.1263e+01, 5.7522e+00, 5.9123e+00,
        7.4181e-01, 1.9023e+01, 1.4357e+01, 4.4211e+00, 4.6688e+00, 4.1305e+00,
        1.9973e+00, 2.5455e+00, 2.6730e+00, 1.2435e+00, 2.7336e+00, 4.3359e+00,
        2.6517e+01, 5.5262e+00, 3.5501e+01, 4.1585e+00, 1.4974e+01, 2.3215e+00,
        3.3954e+00, 1.7864e+00, 4.1016e+00, 2.1522e+00, 2.6105e+00, 2.8322e+00,
        4.0150e+00, 2.9770e+00, 2.7785e+00, 1.1261e+01, 2.7166e+00, 9.9622e+00,
        3.2569e+00, 4.7309e+00, 3.5471e+00, 7.4952e+00, 2.3617e+00, 1.3777e+00,
        2.2294e+00, 1.5967e+00, 1.9758e+00, 1.6505e+00, 1.0902e+00, 3.3002e+00,
        1.4083e+00, 3.1808e+00, 1.7573e+01, 5.5026e+00, 1.4633e+01, 2.9951e+00,
        1.5386e+01, 2.2235e+00, 5.1541e+00, 3.6733e+00, 1.8413e+00, 2.8483e+00,
        2.5210e+00, 8.1179e+00, 1.4254e+00, 3.5352e+00, 3.6581e-01, 4.2309e+00,
        2.3785e+00, 1.0437e+01, 4.2011e+02, 7.2262e+00, 8.6578e-01, 7.1361e+00,
        3.9711e-01, 8.4554e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [2/80], Step [300/314], LR 1.2e-05, Loss: 1008.8
starting validation
Accuracy th:0.5 is [62.0180066  97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38695922 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.11504489 92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.80641074 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [47.7503929  97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38695922 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.11504489 92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.79300934 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [67.86755069  5.05082237 20.72777516  8.3420805  10.90133879  7.50230615
  4.98070259  9.43275938  3.18080846  7.36861793  1.46358044  1.64828021
  0.7230152   7.60738184  2.72532209  5.70928192  3.89073751  3.74511238
  3.32480502  1.77272165  3.58216234  0.89597664  9.08318978  7.41595481
  7.32969799  5.03609667 12.21308624  5.47365327  3.00458453  2.32285688
  8.45045841  2.36320634  9.71826925  5.93405725  4.10440381  8.1612261
  3.73856476 10.8339824   6.29188718 15.08986668  5.28767183 19.59663284
 10.29407477  9.67068215  7.40244317 14.97144857  3.77669257  3.13195274
  6.41785038  3.14823218  5.13668057  4.38012975  1.95467726 12.28685068
  2.42892805  4.74554768 21.16434624 10.56050584  6.70373841  5.60970691
 26.29010684 14.56306301 10.01657226  6.83872607  3.71679967  6.08921948
  3.57698784  6.95020649  3.8141637   7.09442941  0.51513565 18.11674351
  7.37838718 10.25028292  5.33831636  5.93472009  1.24960014  2.2590935
  0.29397739  1.85219753]
Accuracy th:0.5 is [50.45747493 97.2137279  89.39827731 95.07315944 97.26733349 96.57533412
 96.00272901 94.7332513  88.57591891 96.4754328  98.51975488 98.52097319
 99.41399349 53.40456378 97.26977011 96.56680596 91.99083832 97.48053752
 98.63062097 98.28949452 93.45037219 99.18616976 98.38695922 97.80948088
 93.66966777 96.65086926 94.0778012  96.74955227 97.97760749 98.15669887
 97.30875598 98.57457877 96.34751039 98.01781167 97.80095272 97.70470633
 96.94082674 97.14062938 96.89574932 92.70233062 97.82531889 92.05906361
 65.11860236 96.22689782 96.96153799 93.75860431 96.17451054 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.11869982 88.37733458 87.08714562 95.69937013 96.89574932
 89.73453052 97.14915754 96.01613041 88.69287655 98.42838172 96.15623591
 98.20786784 95.722518   98.67326178 97.10651673 99.81603538 95.99054592
 97.96420609 95.40819434 95.53977169 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [45.41854997 97.2137279  89.51158002 97.02489005 97.26733349 96.5997003
 96.9907774  94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.26930715 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38695922 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.11504489 92.72791511 97.84237521 92.05906361
 96.89087609 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.79300934 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [54.88345804  2.7952387   9.41609376  2.45362598  4.92343218  2.98579969
  3.11299811  5.22208934  2.53792141  3.29870067  1.4837388   1.28672032
  0.5425322   4.51190049  2.91391658  4.08279237  3.73550554  2.11803707
  1.26036877  1.56015405  1.56158919  0.69462368  1.33410059  1.88227058
  4.37857307  2.79025188  4.9707395   3.17763963  1.98433729  1.6293241
  2.77662995  1.46162119  3.54758502  2.95068513  2.25130732  2.0944816
  2.98887716  3.25274073  2.74316199  7.57406908  1.93432277  7.75138272
  2.53730998  3.5773513   2.91430341  6.07001415  1.84809467  1.23611166
  1.84446941  1.28458953  1.30370584  1.81505929  1.03537369  2.22331675
  1.31136893  2.25597829 13.68316915  3.89051391  3.43634532  3.3080531
 10.81763845  3.76120276  5.33193959  3.21173457  1.74612537  3.13079139
  1.86804546  4.03316149  1.41445099  2.62819135  0.24587557  6.87323751
  2.54575785  5.14891437  3.76748226  3.26217701  0.88794376  1.73154339
  0.20251936  1.19610957]
mAP score regular 7.62, mAP score EMA 3.75
starting validation
Accuracy th:0.5 is [64.44427835 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.31327703 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.89471062
 97.27931833 96.78102499 97.0276802  92.74484889 97.82744101 92.37112888
 97.07750953 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 89.03505494 96.39235618 96.16314124 96.78102499
 90.09143683 97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [51.2694023  97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.31327703 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.89471062
 97.27931833 96.78102499 97.0276802  92.74484889 97.82744101 92.37362035
 97.07750953 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 89.02758054 96.39235618 96.16314124 96.78102499
 90.1387747  97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [70.06228086  6.11587939 25.88763559 12.36574414 16.95910863  9.55412607
  6.34976208 11.024023    3.58961945  8.49957211  1.56543707  1.60273146
  0.71322516  8.90624832  2.87496783  7.34620215  4.20642856  3.88036518
  3.06807873  1.68794556  3.87320136  1.19828074 15.16529996 10.12632928
  7.91403123  5.39249058 12.93815046  6.10819338  3.24921876  2.67371057
 14.21999063  3.68878096 11.41971334  7.48624256  4.97513934 11.76429142
  3.44215145 21.1557467  11.6206833  17.70023234  7.26025554 21.95250034
 13.02853586 11.87047824  9.29634823 16.86661926  3.82970544  3.36684431
  8.85994711  3.84776216  8.336233    5.40356185  3.20989146 24.44218846
  3.03014392  5.75107458 23.85085813 11.24523865  7.37425938  6.65364576
 30.39948774 26.71896711 11.51321425  8.40212906  4.99556965  7.58045948
  4.27159052  8.00115874  6.16971741 10.38889292  0.78664386 27.81116693
  9.83716395 12.02238732  7.09749984  6.19434501  1.51112293  2.49932255
  0.47188916  2.56100423]
Accuracy th:0.5 is [49.28370332 97.22450607 89.28918454 96.05600817 97.90716795 96.62406259
 96.02611057 94.86259561 90.33809203 96.41976231 98.38054663 98.5325261
 99.34972718 47.83366968 97.20457433 96.31262924 90.4452251  97.50604181
 98.76174104 98.32075143 95.6424247  99.15040985 98.31327703 97.88474475
 94.09024092 96.52938685 94.3393876  96.79099086 97.78757755 98.11395969
 97.52597354 98.67204823 96.26529138 98.18870369 97.99686075 97.89221915
 97.27931833 96.77105912 96.14570097 92.73737449 97.60819194 92.37362035
 63.14871565 96.48703192 97.0351546  93.91832972 92.81460996 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.44624661 87.08672796 80.7110646  95.37334629 96.76607619
 89.85973042 97.00027406 96.02860204 91.92764781 98.32075143 97.08996686
 98.13139996 95.69225403 98.72187757 97.49856741 99.81563146 96.07843137
 98.03174129 95.35839749 95.08184468 97.01023993 99.24508558 98.19368662
 99.82559733 99.15040985]
Accuracy th:0.7 is [46.08964297 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.78600792 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 94.93983108 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.31327703 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.89471062
 97.27931833 96.78102499 97.0276802  92.74235743 97.82744101 92.37362035
 97.0575778  96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 89.02758054 96.38737325 96.16314124 96.78102499
 90.13379176 97.04761193 96.07095697 96.92802153 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [53.78228958  2.41786301  8.06347889  2.1483395  10.28780253  2.7158101
  3.32773923  4.64590736  2.27956954  3.28025575  1.31415762  1.18432581
  0.59024583  4.50884508  2.93842718  4.7110056   3.66776565  1.84528836
  1.37366001  1.59001768  1.6426169   0.79248138  1.90601662  1.81363126
  3.66363803  2.57432274  4.50385441  3.14415306  2.17140669  1.7743757
  2.52982652  1.23327379  3.87009601  2.47563821  1.96532761  1.81675382
  2.52094698  3.39371984  2.70607269  7.51345745  1.94598697  7.16175949
  2.16907667  3.25869545  2.80136194  5.8062897   1.57241508  1.00296961
  1.75709099  1.18803336  1.33128261  3.88354521  1.16069218  2.2909351
  1.27012115  2.0007978  15.09829805  3.3600193   3.35131591  3.33080199
 11.55478378  5.48024129  5.76719645  3.23705685  1.83985759  3.02887309
  2.05554064  4.48530589  1.40403525  2.43696302  0.30708239 10.00896919
  2.89785298  5.41288797  4.45673733  3.11802318  0.79335341  1.56431047
  0.26062755  1.42379663]
mAP score regular 9.64, mAP score EMA 3.85
Train_data_mAP: current_mAP = 7.62, highest_mAP = 7.62
Val_data_mAP: current_mAP = 9.64, highest_mAP = 9.64
lr:  [1.209098806643336e-05, 1.209098806643336e-05]
BCE Train Loss:  tensor([84.7668, 13.4147, 48.7907, 16.2173,  8.6613, 14.2170, 10.6757, 36.3050,
        12.2548, 14.8575, 14.9393, 13.7158, 25.6876, 28.0676, 17.8983, 20.7176,
        17.7978, 22.4884,  4.7931,  6.6179, 14.0455, 10.5823, 10.5457, 15.4696,
        17.5583, 10.4077, 22.3546, 16.7917, 17.7559, 12.5281, 16.1504,  1.9413,
        37.0578, 19.5561, 21.5701, 24.5310, 24.4323, 14.1658, 19.1230, 15.6853,
        16.7402, 24.6284, 10.7127, 16.1420, 16.4548, 25.9191,  2.3470,  9.7875,
         2.4254, 12.2116, 13.1027,  5.4125,  1.2801,  7.5123, 10.3944, 22.1229,
        30.5199, 20.5324, 29.3389, 12.3931, 30.2327, 23.3823, 17.7656, 14.2462,
         6.1225,  9.7204,  6.5720, 29.8397,  6.0137,  3.4847,  0.4095, 13.2945,
         5.7486, 16.5360, 11.3755, 20.3129,  1.0549,  6.1149,  0.3414,  1.0328],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [3/80], Step [000/642], LR 1.2e-05, Loss: 1288.7
BCE Train Loss:  tensor([82.6298,  9.8460, 31.9747,  3.8299, 15.6449,  7.7583, 17.7764, 17.5586,
        11.7275, 18.3005,  1.8973,  5.9789,  5.6416, 36.9331, 11.7535, 20.4240,
        18.3138,  9.8006,  5.7477,  2.5159,  9.5539,  1.0928, 14.5208,  8.0403,
        20.9645, 14.3326, 26.9462, 14.1067,  9.3665, 13.7612,  9.8921,  9.1720,
        25.5141, 13.0213, 17.8160, 13.0916, 11.2738, 10.1686, 28.5882, 40.1486,
        13.4641, 32.9877, 19.2435, 15.5190, 13.3986, 27.1167, 10.7270,  9.7416,
        21.7678,  6.6008, 12.0210, 10.4161, 14.9607, 13.3256, 18.5133, 16.5995,
        59.2270, 20.3533, 20.0983, 24.2589, 59.9847, 14.1576, 15.6689, 20.6716,
        20.9717, 13.1518,  6.0449, 21.0495,  1.6340,  9.9408,  0.3695, 18.5897,
        18.9020, 29.8047, 22.7402, 11.1144,  1.0699, 13.9094, 11.5512,  1.0302],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [3/80], Step [100/642], LR 1.3e-05, Loss: 1340.1
BCE Train Loss:  tensor([82.5044, 13.6872, 48.3692, 28.6974,  3.6038, 23.7871, 11.5390, 26.1446,
         6.9115, 24.6696,  5.9417, 13.8272,  0.7225, 26.4254, 28.7086, 29.2729,
        17.4556, 17.2292, 10.4720, 15.7356, 12.4958,  1.0633,  5.5504,  2.5672,
        27.9819, 13.9753, 23.4582, 26.1931,  5.8886,  6.2033, 14.7167,  5.7646,
        26.4104, 17.7896,  5.9526, 16.2761, 13.4618, 14.6060, 26.0765, 38.3731,
        19.7585, 32.2307,  5.5003, 10.6476, 19.2347, 18.6857,  9.9714,  1.8195,
         5.7648,  1.7786,  1.9104,  1.6303,  1.2379, 14.8967,  5.6042,  5.5423,
        45.6880, 24.7308, 24.1017, 20.6983, 37.2484, 18.6032, 20.9923, 12.6717,
         1.8046, 15.4862,  9.6213, 14.4563, 17.0500, 24.0634,  0.2997, 22.5059,
        24.4957, 19.6079, 17.3513, 17.1184, 12.0533, 10.1486,  0.2562,  6.4193],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [3/80], Step [200/642], LR 1.4e-05, Loss: 1314.2
BCE Train Loss:  tensor([80.3438, 15.4092, 30.3921, 14.2770, 22.5312, 18.8680, 16.8060, 20.9420,
        18.3874, 32.1640,  6.7418,  6.7699, 11.8755, 17.2883, 14.6226, 24.5178,
        18.0636, 16.4094,  1.9123,  2.4165, 20.0190,  1.1041,  6.8014, 11.8757,
        14.0486, 26.2872, 30.9287, 16.7806,  2.6528, 16.1639, 14.0564,  7.3490,
        17.5022,  5.1566,  9.8409, 10.3509,  7.5073, 14.5395, 24.7787, 29.2059,
         3.1017, 33.4820,  4.4215, 22.4697, 18.4086, 23.7297,  9.8859, 14.7306,
        15.0964, 22.6486,  6.2107,  1.9855,  1.3580, 12.2787, 13.0053, 13.6669,
        43.3444, 15.9611, 12.6136, 32.5820, 35.5466, 21.3669,  9.9555, 13.4986,
         9.5278, 13.4502,  9.6185, 29.0006,  5.7365, 19.1542,  0.3011, 20.4563,
         2.4935, 26.5870, 11.6528, 18.5296,  1.0419, 10.5638,  0.2600,  5.4588],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [3/80], Step [300/642], LR 1.5e-05, Loss: 1262.9
BCE Train Loss:  tensor([83.4457, 15.0204, 28.6964, 20.6158, 11.2795, 10.4392, 17.4751, 19.2005,
        16.5190, 10.0692,  1.8583, 22.2799,  0.7139, 20.1546, 24.3930, 15.8105,
        24.4136, 12.2808,  1.5592, 14.1427, 13.3289, 10.6521, 29.6028,  9.1082,
        29.4448, 25.3349, 23.1916, 13.3603,  6.6400, 13.9852, 13.2378,  5.3636,
        29.1243,  7.6600, 11.7646, 12.5403, 10.6051, 17.8497, 15.2840, 32.5841,
         2.6983, 20.5473,  9.5812, 12.7101, 12.4312, 19.6643, 15.8240, 10.5263,
         8.6516,  5.4965,  6.2869,  1.8024, 14.1300, 11.1795,  6.4674,  6.5899,
        27.6335, 18.3501, 22.7987, 13.5119, 32.5216, 14.6954, 19.7565,  8.9150,
         9.4701, 12.1028, 13.2693, 15.5813,  5.1198, 13.3828,  0.2552, 22.6319,
         5.6446, 39.2699, 17.3671, 16.2653,  5.7244,  8.9690,  0.2056,  6.4269],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [3/80], Step [400/642], LR 1.6e-05, Loss: 1215.5
BCE Train Loss:  tensor([75.3217, 16.1212, 28.9577, 28.9845, 12.4085, 22.5764, 19.5831, 14.4458,
         3.5945, 13.5527, 13.9605,  1.7143,  7.0204, 18.0859, 15.1942, 16.1753,
         7.6964, 29.9897,  6.1304, 17.9360, 17.3359,  5.6292,  4.6273,  2.4470,
        27.0089, 21.6484, 22.0621, 14.8281, 12.7837,  8.2581, 12.8038,  9.3811,
        18.5492,  7.7217, 11.7379, 11.7292, 19.5466, 15.7750, 13.0686, 26.7892,
        10.1624, 27.2984,  8.0128,  8.3449, 12.4610, 22.7929,  9.3511, 12.8530,
         9.8552, 14.0144, 12.1512, 10.7815,  1.2502,  4.1486,  1.5755, 15.2505,
        34.1404, 15.2141, 31.1525, 12.7924, 31.6160, 10.4380, 20.9454, 19.2834,
        12.5198, 23.1730,  5.0633,  7.0526,  5.6981, 10.3082,  6.5877, 19.0515,
         5.9937, 20.6049, 21.6792, 27.3100,  1.0065, 19.1644,  0.1871,  9.8063],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [3/80], Step [500/642], LR 1.7e-05, Loss: 1204.3
BCE Train Loss:  tensor([80.6111,  7.9067, 45.7035, 12.4878, 10.5109, 12.1064, 15.9069, 26.6265,
        15.5071, 10.6955,  9.5828, 14.7188,  7.1327, 20.3037, 24.1578, 13.0089,
        16.5136, 28.8966,  8.0473, 12.2932,  6.7931,  1.1947, 13.0524,  7.7434,
        23.1134, 13.8896, 32.9697,  8.0444, 17.8345, 14.6915, 10.7128, 11.6249,
        10.3943,  6.5038, 15.8720, 12.8029,  9.8714, 19.1083,  7.2503, 15.5282,
        10.5388, 28.1481, 20.0345, 12.3550,  9.6538, 21.8502,  6.5035,  5.9133,
         4.6099,  1.9665,  1.9314,  5.4447,  9.8781, 10.7405,  5.0686,  6.6345,
        28.8771,  9.4772, 30.6960, 16.4579, 29.5204, 16.0903, 30.4356, 15.8581,
        15.6432,  6.1065, 16.3983, 21.4243,  8.4807, 11.6189,  0.2340, 25.5690,
         9.4394, 17.0540, 22.1552, 31.3213,  1.0647,  6.1663,  0.2160,  1.1352],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [3/80], Step [600/642], LR 1.8e-05, Loss: 1184.4
BCE Val Loss:  tensor([8.0537e+01, 7.4966e+01, 8.7172e+01, 5.0390e+01, 1.1983e+00, 1.1145e+01,
        8.8822e+00, 2.4651e+01, 6.8131e+00, 1.3799e+01, 6.4438e+00, 1.0248e+01,
        5.7242e+00, 1.7199e+01, 6.8760e+00, 9.2557e+00, 4.2465e+02, 3.7752e+00,
        2.2812e+00, 2.3820e+00, 3.1876e+00, 1.3189e+00, 1.4616e+00, 4.3410e+00,
        3.5261e+01, 1.3033e+01, 3.0722e+01, 4.6128e+00, 9.2914e+00, 8.0895e+00,
        2.4531e+00, 8.2537e-01, 6.3383e+00, 9.5220e-01, 2.9585e+00, 2.5959e+00,
        3.3517e+00, 3.9008e+00, 1.8504e+00, 5.5232e+01, 1.1743e+01, 2.8688e+01,
        9.5477e+00, 2.1222e+01, 1.7503e+01, 2.7344e+01, 2.4321e+00, 5.8164e+00,
        2.3135e+00, 4.4437e+00, 2.3126e+00, 1.9424e+00, 8.3414e+00, 3.6145e+00,
        1.5584e+00, 2.9810e+00, 3.2973e+01, 1.0561e+01, 2.1403e+01, 4.4249e+00,
        1.7681e+01, 2.3304e+01, 8.0635e+00, 6.1805e+00, 2.0797e+00, 3.2571e+00,
        2.2135e+00, 9.8681e+00, 1.3234e+01, 2.5090e+01, 1.7826e-01, 2.3903e+01,
        2.1076e+01, 1.2292e+01, 1.3530e+01, 1.2104e+01, 8.3705e-01, 6.1258e+00,
        2.1107e-01, 1.0076e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [3/80], Step [000/314], LR 1.8e-05, Loss: 1463.6
BCE Val Loss:  tensor([9.0617e+01, 1.9221e+01, 6.8451e+01, 9.8596e+00, 2.0163e+00, 3.8452e+01,
        1.1189e+02, 6.0933e+01, 3.8080e+01, 3.4322e+01, 1.7646e+01, 2.6857e+02,
        1.1245e+01, 1.1620e+01, 1.5155e+01, 6.9836e+00, 1.1791e+01, 1.8113e+01,
        2.6948e+00, 2.2091e+01, 3.2315e+00, 1.3832e+00, 2.5386e+00, 7.6686e+00,
        2.9315e+01, 2.2551e+01, 3.6146e+01, 1.5624e+01, 1.3426e+01, 2.7794e+00,
        3.1159e+00, 9.8958e-01, 3.7781e+00, 1.6535e+00, 3.2940e+00, 2.7287e+00,
        6.6210e+00, 3.3210e+00, 2.2422e+00, 6.9020e+00, 1.9473e+00, 8.7936e+00,
        2.3070e+00, 3.2735e+00, 2.6355e+00, 7.2693e+00, 1.8873e+00, 1.0956e+00,
        1.3788e+00, 6.1846e+00, 1.6308e+00, 1.4269e+00, 8.5876e-01, 2.4833e+00,
        1.0053e+00, 5.1671e+00, 1.9864e+01, 5.4899e+00, 1.0525e+01, 2.4869e+00,
        8.5738e+00, 1.4427e+00, 3.4866e+00, 3.2009e+00, 1.7228e+00, 2.0434e+00,
        1.5799e+00, 1.8655e+01, 1.1395e+00, 4.9985e+00, 1.3572e-01, 3.3510e+00,
        5.0562e+00, 5.7473e+00, 7.3323e+00, 2.7510e+00, 6.3902e-01, 1.7700e+00,
        1.4590e-01, 6.0693e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [3/80], Step [100/314], LR 1.8e-05, Loss: 1191.2
BCE Val Loss:  tensor([ 74.2325,   2.1245,   9.6852,   2.1349,   0.5358,   2.1581,   1.4804,
         13.4616,   1.0500,   1.8921,   1.3130,   1.0796,   0.4834,  20.1078,
          1.9328,   6.3948,   4.0629,   1.7197,   0.9402,   1.2301,   1.8433,
          0.8833,   0.3853,   1.5168,   8.3054,   2.4820,  26.4466,   9.8769,
          2.7041,   1.7705,   3.8597,   5.8198,  10.5681,   0.4462,   1.9391,
          1.8100,  17.3361,  16.0548,   1.4066,  36.0154,  31.0164,  74.3766,
         92.6536,  91.5624,  55.2525,  80.3362,  11.0131,  10.5150,  41.3704,
         11.4162,  30.2022,  44.5040,  81.6498,  24.8273,  88.1513, 132.5632,
        139.4528,  16.1152,  12.2474,   5.4403, 138.9801,   3.0878,  14.5076,
         13.2693,  13.6817,   4.8045,   9.2230,  15.0937,   6.1737,   5.8817,
          0.2381,  10.9570,   8.1325,  36.7334,   3.1380,  14.0624,  11.7469,
          3.5447,   0.2230,   1.3357], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [3/80], Step [200/314], LR 1.8e-05, Loss: 1689.0
BCE Val Loss:  tensor([1.0117e+02, 5.7947e+00, 3.2748e+01, 6.1953e+00, 2.6990e+00, 1.3819e+01,
        8.8798e+00, 1.9644e+01, 3.6215e+00, 2.0512e+01, 5.5689e+00, 5.9754e+00,
        6.5366e-01, 1.8430e+01, 1.4189e+01, 4.5881e+00, 3.8691e+00, 4.5140e+00,
        1.7387e+00, 2.2275e+00, 2.9573e+00, 1.2351e+00, 2.1272e+00, 4.1443e+00,
        2.4693e+01, 5.1923e+00, 3.4956e+01, 4.8487e+00, 1.4629e+01, 2.0147e+00,
        4.4796e+00, 1.9124e+00, 2.7155e+00, 2.1199e+00, 2.3595e+00, 2.2491e+00,
        3.9201e+00, 1.9068e+00, 2.1263e+00, 1.1044e+01, 2.4096e+00, 8.8761e+00,
        2.2733e+00, 3.6739e+00, 2.9805e+00, 6.0131e+00, 2.0674e+00, 1.0970e+00,
        1.4891e+00, 1.2830e+00, 1.6700e+00, 1.4677e+00, 9.1504e-01, 2.4277e+00,
        9.9413e-01, 2.3871e+00, 1.7884e+01, 4.8470e+00, 1.5341e+01, 3.4368e+00,
        1.2195e+01, 2.2361e+00, 4.7823e+00, 3.9472e+00, 2.0575e+00, 2.6087e+00,
        2.2934e+00, 8.6809e+00, 1.4709e+00, 3.4185e+00, 1.6974e-01, 5.2610e+00,
        2.5418e+00, 8.4081e+00, 4.0505e+02, 6.7105e+00, 7.4105e-01, 6.3166e+00,
        1.9703e-01, 7.8696e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [3/80], Step [300/314], LR 1.8e-05, Loss: 971.9
starting validation
Accuracy th:0.5 is [64.81889841 97.2137279  89.5079251  97.02489005 97.26977011 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.39548738 97.80582595
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30631937 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.20519974 97.11504489 92.73644327 97.84237521 92.06515515
 96.9067141  96.22689782 96.9627563  93.87068871 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.35383341
 98.70615611 97.46591781 89.09491843 96.13674297 96.24273583 96.9067141
 89.96113595 97.17717864 96.11115849 96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 96.00760225
 97.96420609 95.44961684 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [55.84361789 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38817753 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.15646739 97.11504489 92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.79544596 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99298254
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [72.13958081  7.88718902 25.96750179 12.76133288 16.45839237 13.92900612
  8.57978673 14.0417621   7.92381878 11.0466087   2.3549265   2.38591714
  0.9992449   9.1823345   4.92894209  7.34973457  4.67994953  5.41549656
  8.7469807   5.47768165  6.39393292  4.29328159 26.13540767 10.60472581
  9.78333503  5.89860821 14.65465207  6.67689019  3.42897596  5.85243365
 13.124057    5.52103907 15.58954497 11.96887036 11.57144662 18.02015614
  6.71813668 25.41727102 16.14853424 20.11937915  7.61588861 23.72522944
 14.72682416 14.84877914 10.95898492 18.61425857  5.05835467  3.88046054
  9.11544932  4.67466045  9.79231642  7.06674283  2.56542965 23.41544356
  3.27470019  7.5987018  26.73914186 14.52382056  9.48845056  7.13306148
 32.97445333 20.60468427 15.65730162  8.91007897  5.98327589  9.85336118
  5.43248197  7.96352538  7.66040639 12.17088164  0.36856523 24.87549418
 13.21671326 13.57770705  7.43357779  7.99466343  1.59332241  2.89002289
  0.28200374  2.61119504]
Accuracy th:0.5 is [51.64167103 97.2137279  89.50914341 96.66305235 97.26733349 96.5997003
 96.92864366 94.73568792 94.74908931 96.4754328  98.53193796 98.52097319
 99.41399349 91.65214849 97.26977011 96.56680596 96.15989084 97.48053752
 98.65376884 98.30776915 97.93983991 99.18616976 98.38695922 97.80948088
 95.07194113 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.10895335 92.72913342 97.84237521 92.05906361
 94.23008979 96.22689782 96.9627563  93.87434364 98.01781167 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.03278469 89.51401664 96.20009503 96.9067141
 89.78935442 97.17717864 95.76515881 94.49933602 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55729097 99.81603538 95.99054592
 97.96420609 95.44474361 95.54099    96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [45.21752903 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38695922 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.11504489 92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.79300934 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.14892606 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [55.92492967  3.43066016  9.5898026   2.59592485  5.08655811  3.10190258
  3.3290963   5.27937147  2.5282653   3.3140893   1.36971781  1.34213155
  0.55494235  4.93839005  2.79531577  4.46089145  3.62822628  2.09720506
  1.14609873  1.44620058  1.46512282  0.68787799  1.30645262  2.01339434
  4.43420371  2.76149126  5.12910829  3.27953819  2.25220114  1.57213905
  2.88130239  1.40487568  3.56193981  2.16313842  2.20947906  2.14280603
  3.23985091  3.50234899  2.8099594   8.12623979  2.14673333  8.26820127
  2.63958949  3.66055019  3.14323149  6.56974585  1.90730224  1.26622339
  1.82843069  1.36061696  1.57072261  1.87625707  1.08411521  2.55219231
  1.52432646  2.24341682 14.66822282  4.24309674  3.65858751  3.53690012
 12.46923082  4.072766    5.62960073  3.24752046  1.83235084  3.38177752
  1.97240676  4.22877504  1.47526119  2.76225645  0.37235829  7.63250932
  2.90460536  5.29501252  3.80370367  3.44352918  0.88240164  1.78608094
  0.22959894  1.47162683]
mAP score regular 11.34, mAP score EMA 3.92
starting validation
Accuracy th:0.5 is [67.21728081 97.22450607 89.60560082 96.96290206 97.91464235 96.63651992
 96.80843112 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.7642325  98.34068316 98.22109276 99.15040985 98.4353589  97.63808954
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.53344794 98.67204823 96.39983058 98.19119516 98.00931809 97.90218502
 97.27931833 97.01273139 97.0276802  92.72242569 97.82744101 92.35867155
 97.0725266  96.49201485 97.03764606 93.98809079 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.2967586
 98.6969629  97.58576874 89.10979894 96.39235618 96.16314124 96.78102499
 90.42778484 97.0575778  96.06846551 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.17061564
 98.02924982 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [60.93380173 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.33570023 97.86730448
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.89471062
 97.27931833 96.88317513 97.0276802  92.74235743 97.82744101 92.37362035
 97.07750953 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.2220146
 98.6969629  97.58576874 89.02508907 96.39235618 96.16314124 96.78102499
 90.18112963 97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.09587164
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [74.56753262  9.38302387 31.11247852 18.00805919 23.86355606 21.3452304
 12.75373777 15.79201482 10.88049417 14.78900909  3.12081484  2.85273049
  1.01624525 11.11006161  5.30895337  9.38192671  5.83003999  5.60540137
  9.25843568  6.78794592  8.08790162  5.79890666 45.90015504 12.88377588
 10.27375335  6.78280524 15.37595809  7.11058087  4.24882786  8.30696145
 22.40586546  7.46291462 19.51074914 15.2879417  21.61671365 24.98468596
  7.40921221 37.87181281 29.40276889 23.28317184  9.93361965 26.95725748
 18.13235308 17.25839    13.18067347 20.86462558  4.84709466  3.71697904
 12.89798898  5.15245754 14.17116008  8.51142897  3.61274646 32.61315635
  3.97538022  9.01488689 30.34065796 16.43256972 10.554985    8.30460482
 37.80403856 33.63133184 19.80897035 12.73493676  9.87050144 11.2122921
  7.53893421  8.81727255 11.0338984  16.69519768  0.51705238 34.17934961
 17.13338457 17.35073587 11.82743208  9.589569    1.36507315  3.23521709
  0.37419338  3.17716227]
Accuracy th:0.5 is [52.54254179 97.22450607 89.55078855 96.81839699 97.90716795 96.63651992
 96.77105912 94.87754441 94.50631587 96.41976231 98.5250517  98.5325261
 99.34972718 88.59655679 97.2070658  96.31262924 95.79689563 97.50604181
 98.78167277 98.34068316 98.13887436 99.15040985 98.31327703 97.88474475
 95.21389242 96.52938685 94.3393876  96.79099086 97.81498368 98.11395969
 97.52597354 98.67204823 96.39733911 98.18870369 98.00931809 97.89471062
 97.27931833 96.78102499 97.00774846 92.74484889 97.82744101 92.37362035
 92.86693076 96.48703192 97.03764606 94.02795426 98.01679249 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58327728 88.693724   88.80085706 96.02860204 96.78102499
 90.05655629 97.04761193 95.90652017 94.66078681 98.32075143 97.40389167
 98.13139996 95.7769639  98.72436904 97.52597354 99.81563146 96.07843137
 98.03174129 95.43314149 95.15908015 97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [46.04977951 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 95.11174228 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.31327703 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.89471062
 97.27931833 96.78102499 97.0276802  92.74484889 97.82744101 92.37362035
 97.07750953 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 89.02758054 96.39235618 96.16314124 96.78102499
 90.13379176 97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.75204923 97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [57.00077173  3.34314229  8.38966214  2.35131954  9.81446596  2.98027451
  3.94493524  4.95990291  2.29048496  3.35710723  1.3036935   1.17314697
  0.59951553  5.08749201  2.88677478  5.42768091  3.47413297  1.86989291
  1.03377469  1.41706762  1.40461809  0.68344798  1.86019368  2.6123639
  3.95386747  2.60237284  4.78825101  3.59431259  2.47238696  1.66519777
  2.7909498   1.35443533  3.51538416  1.58935339  1.77172058  1.79104927
  2.72998819  3.49781852  2.71103144  8.45469755  2.13617812  7.95777479
  2.18041117  3.49946023  3.30205968  6.71449103  1.90268693  1.05250936
  1.76781487  1.29528115  2.05927936  3.70419375  1.35221035  3.18254526
  1.55806378  1.95952771 16.06115482  3.68911384  3.66939616  3.82360709
 14.93706393  5.31074814  6.49838084  3.39595837  1.95349695  3.73015535
  2.25954656  4.96361235  1.64686311  2.79132686  0.34808543 11.36607454
  3.28727713  5.85772012  4.56201427  3.31552416  0.75539196  1.68735057
  0.37180956  1.8348615 ]
mAP score regular 14.56, mAP score EMA 4.15
Train_data_mAP: current_mAP = 11.34, highest_mAP = 11.34
Val_data_mAP: current_mAP = 14.56, highest_mAP = 14.56
lr:  [1.8061469996844952e-05, 1.8061469996844952e-05]
BCE Train Loss:  tensor([81.5003, 12.3449, 48.0066, 13.8553, 10.5355, 12.8899,  7.4310, 25.8080,
         9.5909, 13.9210, 11.0423,  9.3325, 10.4212, 26.8128, 10.7513, 10.9047,
        24.0506, 14.9942,  6.2200, 12.2263, 27.9393,  4.8981,  6.3955,  5.9950,
        26.9051, 33.3021, 31.0029, 16.4984, 12.3777, 22.0029,  7.9935,  1.8871,
        20.4174,  7.4722,  8.4855, 18.6944, 19.3161, 11.0610, 17.0283, 30.1036,
        19.6963, 30.9258, 13.2704, 14.3033,  9.6546, 19.8525, 12.1187,  4.7559,
        12.5045,  6.2012, 10.7714,  6.1311,  1.1687, 13.2870, 12.6207, 17.4525,
        37.3856, 11.7394, 12.2944, 21.4921, 38.1198, 12.0851, 18.7238, 12.9050,
        20.9966, 15.9972, 12.2180, 14.1386,  5.2947, 12.8474,  0.2219, 14.5000,
         8.3375, 21.2105, 33.9163,  9.3195,  5.6202, 13.8310,  0.1981,  5.2714],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [4/80], Step [000/642], LR 1.8e-05, Loss: 1265.8
BCE Train Loss:  tensor([82.2230, 14.8627, 37.3260,  5.7910, 11.2802, 19.6180, 14.3567, 24.0575,
        14.0799, 14.1426, 14.9521,  5.9271,  6.4639, 30.8733, 29.2756, 10.4205,
        20.1877, 12.2164,  9.7399,  9.8761,  2.0046,  4.8105,  1.7272,  2.5459,
        29.3055, 15.3667, 21.3910, 13.6143, 13.2173, 13.2013, 24.5353,  5.5022,
        20.5280, 12.2733, 26.2174, 22.7079, 13.2205, 14.7766, 20.3901, 50.0119,
         8.3008, 33.3994,  5.7670, 23.0459, 13.8154, 40.0262,  9.5606, 16.5361,
        13.0437, 14.8888,  4.5683,  5.9215, 26.1005,  9.0534, 11.4354, 10.9650,
        46.3497, 16.1473, 24.4978, 14.8643, 42.1402, 16.7366, 16.4742, 26.0151,
        12.0455, 16.6313, 10.9037, 16.2149,  9.2394, 12.2918,  6.5826, 11.3097,
        12.5135, 22.8295, 15.3943, 15.5622, 11.6573,  5.8355,  0.1697,  5.8700],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [4/80], Step [100/642], LR 1.9e-05, Loss: 1349.7
BCE Train Loss:  tensor([75.8414, 18.1487, 40.5116, 21.0977, 12.9245, 16.0875, 26.0845, 32.9023,
        11.0663,  7.9132, 14.1657,  2.4423,  6.2762, 23.2912, 11.0793, 28.9518,
        30.8308, 12.7379, 26.6352, 14.7751,  9.4359,  9.8802,  4.7340,  4.6552,
        18.3105, 19.2336, 22.1747, 25.0706,  5.9832, 12.3953, 11.8350,  4.0294,
        13.1827,  8.1640, 11.7694,  9.8327, 20.6275,  7.3038,  9.8184, 30.9523,
        20.9165, 22.4898,  3.7007, 11.0506, 10.9712, 19.4688, 12.0443,  4.8342,
        10.1056, 11.6719,  1.8267,  5.2417,  1.4506,  7.2282,  8.9255, 13.5224,
        44.2028, 18.1686, 14.5530,  9.2793, 36.7365, 13.6634, 14.0534,  9.6095,
         6.0287, 14.2224,  5.5525, 24.2113,  1.9927, 11.9599,  6.8647, 14.7807,
         7.1340, 15.9165, 13.0298, 16.9025,  6.1911,  2.4035,  0.1853,  1.3458],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [4/80], Step [200/642], LR 2.0e-05, Loss: 1167.6
BCE Train Loss:  tensor([79.5466, 16.4285, 42.1131, 12.5332,  8.8688, 10.1496, 10.9274, 25.3658,
         9.5424, 23.0374,  8.7010, 13.4970,  5.5293, 27.5168,  7.1718, 20.9868,
        22.8939,  7.5433,  9.7169,  8.1498,  5.7454,  1.2068,  7.0604,  3.1940,
        26.3875, 12.7454, 16.6159, 19.7790, 19.2168,  5.6915, 12.1132,  9.0019,
        13.4026,  5.9972, 21.8388, 22.0397,  6.5421,  8.2840, 12.9234, 29.8954,
        20.7778, 40.0963,  9.8021, 20.8159, 36.1581, 42.8589, 13.3062,  1.7737,
        16.3628, 13.9677, 20.1743, 11.2257,  7.5005, 16.4116,  6.3978, 20.5450,
        52.9726, 12.6505, 12.7407, 21.2630, 41.4351, 14.1559, 17.2774, 15.5939,
         9.1764, 11.6254, 10.5294, 11.6229,  9.2403, 20.8177,  0.2629, 19.8877,
        10.7420, 25.1185, 20.4655, 27.6045,  6.1382, 13.3048,  6.8247,  8.7047],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [4/80], Step [300/642], LR 2.1e-05, Loss: 1328.2
BCE Train Loss:  tensor([76.6235, 19.1853, 36.8093, 15.9109, 12.5040, 12.2095, 14.1910, 19.2031,
        23.8533, 18.4208,  5.3972,  5.2715,  5.1396, 29.9863,  6.7039, 18.4045,
        15.2506, 19.0977,  6.3720,  6.1745,  8.6992,  1.2356,  6.0948, 13.5442,
        26.1244, 15.1262, 25.1300, 15.0989,  9.0631, 13.5139,  9.6881, 10.6115,
         8.9179, 16.8167,  8.6744,  7.2471, 25.8791,  9.7422,  9.8168, 32.2789,
        16.7449, 27.8134, 19.7231, 16.9968,  8.8998, 27.1392, 18.8758,  2.3623,
         4.1793,  9.0494,  7.6215,  1.8869,  1.2538,  4.8559, 13.6031, 17.6918,
        28.2052, 15.4800, 18.9282, 14.6359, 39.0957, 13.0351, 20.9145, 12.0196,
        12.0884, 12.7959,  8.6055, 25.3396,  4.0706, 10.2273,  0.2320, 15.0549,
         9.1565, 19.3233, 19.8352,  8.1686,  0.9443, 13.2801,  0.1952,  8.6833],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [4/80], Step [400/642], LR 2.2e-05, Loss: 1169.0
BCE Train Loss:  tensor([75.9480, 24.1134, 31.7334,  9.6009, 10.2905,  7.5463, 15.7150, 24.8724,
         5.2241, 25.6064, 10.5358,  7.0492,  5.4222, 30.3018, 13.2955, 20.1550,
         6.8692, 10.4698,  2.5795, 12.1949,  8.2283,  3.9464,  7.3039,  8.9864,
        25.8692, 24.6740, 19.2592,  9.7909,  9.8029,  8.1813, 10.4618, 12.5600,
        12.8852,  9.2589, 15.7585,  6.2397, 19.4464,  9.3300, 15.3085, 19.6403,
        11.4597, 27.6251, 12.3356, 14.7515, 11.2096, 18.7041,  8.4348,  6.1734,
         5.3194,  6.3566,  3.2622,  4.3361,  1.2438,  8.6077,  4.3296, 16.0352,
        39.9899, 22.8076, 18.8923, 25.3126, 23.0820,  4.6040, 20.0310, 18.8304,
        11.7601, 26.2295,  5.0538, 18.9359, 17.5926, 16.4331,  5.8429, 16.2785,
         4.5833, 30.3030, 15.4409, 18.4412,  6.5397, 16.6927,  5.8380,  8.0645],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [4/80], Step [500/642], LR 2.4e-05, Loss: 1164.2
BCE Train Loss:  tensor([75.9657, 24.7353, 36.6343, 28.0211,  5.8760, 23.2408, 21.2936, 36.8321,
        17.6382, 17.3366, 11.3626,  5.2651,  0.8129, 33.4676, 13.7021, 17.6915,
        20.2206, 15.8750,  9.0632,  6.0802,  5.2903,  6.0700,  2.7907, 12.1491,
        20.3382, 26.1181, 33.8918, 15.7842,  5.9429, 14.8410, 14.0775,  5.5701,
        19.3833,  5.2515,  9.3562,  9.7979,  7.0453, 16.0229, 14.1935, 26.9538,
        12.2111, 17.0465, 18.7666, 11.5973, 11.2647, 23.4615,  9.0277,  5.2862,
         8.1880,  4.5576, 11.5250, 10.1809,  1.4516,  3.9541,  1.5007, 10.5821,
        37.8688, 15.3514, 16.4229, 21.6491, 32.7161, 16.1488, 17.2749, 14.4575,
         5.4987,  8.6661,  5.7095, 26.2879, 16.3761,  9.1980,  5.7546, 17.3642,
        12.8131, 35.1435, 16.1440, 25.3494,  1.1754, 13.7084,  0.2243,  4.6983],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [4/80], Step [600/642], LR 2.5e-05, Loss: 1228.6
BCE Val Loss:  tensor([7.5723e+01, 7.5279e+01, 9.2893e+01, 4.7720e+01, 1.0677e+00, 1.2071e+01,
        8.0754e+00, 2.4754e+01, 7.5258e+00, 1.3536e+01, 6.3045e+00, 1.0321e+01,
        4.6944e+00, 1.7884e+01, 6.3518e+00, 9.3576e+00, 3.9941e+02, 3.2763e+00,
        1.8365e+00, 2.3545e+00, 3.5065e+00, 1.4143e+00, 1.0652e+00, 3.8251e+00,
        3.4556e+01, 1.3936e+01, 3.0041e+01, 6.3981e+00, 9.7492e+00, 8.2385e+00,
        1.9630e+00, 7.3427e-01, 6.9166e+00, 6.4489e-01, 2.3971e+00, 2.3518e+00,
        3.8931e+00, 3.1404e+00, 2.1508e+00, 5.4555e+01, 9.7882e+00, 2.4421e+01,
        8.9230e+00, 1.9570e+01, 1.7409e+01, 2.6229e+01, 2.5040e+00, 5.0587e+00,
        2.4863e+00, 4.1829e+00, 1.3754e+00, 1.4349e+00, 6.8982e+00, 1.9481e+00,
        1.6766e+00, 2.8056e+00, 3.2894e+01, 1.0570e+01, 2.0538e+01, 4.5012e+00,
        1.4948e+01, 2.2228e+01, 7.3275e+00, 4.3619e+00, 1.6960e+00, 3.5880e+00,
        1.9680e+00, 9.8622e+00, 1.0135e+01, 2.3153e+01, 1.6710e-01, 2.3399e+01,
        1.8929e+01, 1.2538e+01, 1.3095e+01, 1.0668e+01, 8.8309e-01, 5.7756e+00,
        2.0211e-01, 7.6103e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [4/80], Step [000/314], LR 2.5e-05, Loss: 1402.8
BCE Val Loss:  tensor([8.6921e+01, 1.9173e+01, 6.7873e+01, 9.5534e+00, 2.3438e+00, 4.1983e+01,
        1.0307e+02, 6.3233e+01, 3.4767e+01, 3.3666e+01, 1.7699e+01, 2.6416e+02,
        9.7411e+00, 1.3389e+01, 1.5625e+01, 5.6308e+00, 1.2240e+01, 1.8160e+01,
        2.2807e+00, 2.1321e+01, 3.5483e+00, 1.6226e+00, 2.0822e+00, 6.7590e+00,
        2.8947e+01, 2.2808e+01, 3.5614e+01, 1.6497e+01, 1.3037e+01, 2.4637e+00,
        2.2931e+00, 9.3530e-01, 3.9789e+00, 1.6459e+00, 2.4997e+00, 2.2555e+00,
        6.8892e+00, 3.3375e+00, 3.1017e+00, 5.3093e+00, 1.3468e+00, 6.5363e+00,
        1.3383e+00, 2.0128e+00, 1.6472e+00, 5.8766e+00, 1.5405e+00, 6.8037e-01,
        1.0973e+00, 7.5265e+00, 8.3345e-01, 7.6966e-01, 6.2610e-01, 1.2235e+00,
        7.7978e-01, 3.9860e+00, 1.8581e+01, 4.8118e+00, 1.1002e+01, 1.9663e+00,
        7.3255e+00, 1.3644e+00, 3.2420e+00, 1.7406e+00, 1.2307e+00, 1.7581e+00,
        1.2739e+00, 1.8606e+01, 7.7120e-01, 4.3789e+00, 1.0321e-01, 2.0703e+00,
        4.4320e+00, 5.4698e+00, 6.6015e+00, 2.0177e+00, 5.7624e-01, 1.4440e+00,
        1.1559e-01, 3.3343e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [4/80], Step [100/314], LR 2.5e-05, Loss: 1147.5
BCE Val Loss:  tensor([ 73.0511,   1.3724,   8.2828,   1.4606,   0.3032,   1.1308,   1.1665,
         12.5627,   0.5565,   1.1402,   0.8404,   0.5378,   0.4305,  19.1533,
          1.8863,   7.6725,   5.0697,   1.2119,   0.5510,   0.8564,   1.6433,
          0.8447,   0.2266,   1.0105,   7.1611,   1.9790,  26.8598,  10.5953,
          2.1894,   1.0952,   3.0773,   4.8464,  10.6616,   0.1762,   1.2016,
          1.4182,  16.9203,  16.8239,   0.9852,  35.2231,  31.0196,  74.4219,
         84.0337,  89.3625,  48.3851,  74.5223,  11.8568,   9.4264,  37.5034,
         12.3860,  28.9280,  45.1889,  78.7607,  26.6729,  77.5640, 122.5753,
        138.1562,  16.0207,  10.6282,   6.2718, 124.2790,   2.6808,  14.0419,
         12.0521,  12.7465,   5.4084,   8.2204,  14.3872,   5.9206,   4.3033,
          0.2321,   8.0840,   7.3144,  40.3204,   2.1712,  14.0045,  12.1758,
          4.5838,   0.2500,   1.1677], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [4/80], Step [200/314], LR 2.5e-05, Loss: 1602.2
BCE Val Loss:  tensor([9.2089e+01, 5.4454e+00, 2.9424e+01, 5.1791e+00, 2.5717e+00, 1.3665e+01,
        1.1825e+01, 1.7651e+01, 4.0928e+00, 2.0704e+01, 5.1822e+00, 6.1581e+00,
        9.2563e-01, 1.7568e+01, 1.5874e+01, 4.1578e+00, 4.1364e+00, 3.9763e+00,
        1.1676e+00, 1.8745e+00, 3.0358e+00, 1.0049e+00, 1.4299e+00, 3.6418e+00,
        2.3722e+01, 4.4689e+00, 3.3306e+01, 5.8222e+00, 1.5295e+01, 1.4569e+00,
        3.5200e+00, 1.7055e+00, 2.1032e+00, 1.4902e+00, 1.1559e+00, 1.1073e+00,
        4.0715e+00, 1.3226e+00, 2.1580e+00, 9.5597e+00, 2.1490e+00, 8.2871e+00,
        1.7377e+00, 2.9552e+00, 2.5094e+00, 5.5046e+00, 1.7899e+00, 6.9519e-01,
        1.2778e+00, 9.1796e-01, 9.7271e-01, 8.8363e-01, 7.4695e-01, 1.2997e+00,
        8.4443e-01, 1.9190e+00, 1.5986e+01, 4.1882e+00, 1.4978e+01, 2.8827e+00,
        1.2593e+01, 2.3606e+00, 4.7317e+00, 2.6340e+00, 1.8222e+00, 2.5288e+00,
        2.2238e+00, 8.3806e+00, 1.4552e+00, 3.2231e+00, 1.4978e-01, 4.4057e+00,
        2.2674e+00, 7.6702e+00, 4.1278e+02, 6.4334e+00, 7.1425e-01, 5.1277e+00,
        1.7979e-01, 4.4560e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [4/80], Step [300/314], LR 2.5e-05, Loss: 939.7
starting validation
Accuracy th:0.5 is [68.30326141 97.2137279  89.59686164 97.02854497 97.28073488 96.60944677
 96.99808726 94.7332513  97.44155164 96.47177788 98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65498715 98.30776915 98.15060733 99.18616976 98.77803633 97.80948088
 95.21935649 96.65086926 94.07658289 96.75077058 98.01293844 98.15913549
 97.31362922 98.57336046 96.3633484  98.01902998 97.8265372  97.83506536
 96.94082674 97.30753768 97.14672092 92.73400665 97.84237521 92.02860589
 96.89574932 96.21715135 96.96397461 93.8694704  98.02877645 98.57336046
 97.9934455  98.51853657 98.36868459 98.55508583 98.99976852 97.49393891
 98.70615611 97.46591781 89.21674931 96.13552466 96.24273583 96.9067141
 90.12317101 97.20276312 96.09653878 96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.5621642  99.81603538 96.01978533
 97.96664271 95.43865206 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [60.63644449 97.2137279  89.52132649 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.66717023 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.81069919 97.76440346
 96.94082674 97.22591099 97.11869982 92.72913342 97.84237521 92.06028192
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.47200936
 98.70615611 97.46591781 89.11928461 96.13796128 96.24273583 96.9067141
 89.92945992 97.17474202 96.11481342 96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99907409
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [77.63197534  9.38647987 31.62426575 17.58854072 23.36930905 23.71636227
 15.55052984 18.79397116 11.8222036  15.81519965  3.15377106  3.38082304
  1.44379676 11.07845771  5.86139102 10.68560092  6.35952897  6.97542876
 12.13822275  7.57536533 10.13322937  7.17245007 55.05047078 14.07423668
 11.82432943  7.18440459 16.9083332   9.30377082  4.23707982  8.93490986
 22.97659965  9.47382477 23.58340961 17.18772818 21.79361129 31.79331591
 11.25659482 32.05607678 25.42157322 22.99118532  8.62358438 27.98361361
 20.08108121 19.39529957 13.98137653 22.17825093  7.10829665  6.40466136
 13.46309989  7.8143793  16.57801027  9.6821486   3.78790881 34.65140256
  4.50446008  9.34080081 30.89777708 19.34867799 11.30725749  8.8012966
 38.11806756 26.76224717 21.92459347 12.30264543  8.99394833 12.81422361
  8.43115014  8.80234159 13.01291234 16.99959623  0.40290419 30.62603541
 16.55084273 17.93706728  8.79377654 10.62266696  1.71029164  4.0080684
  0.34943049  3.43306976]
Accuracy th:0.5 is [52.52128995 97.2137279  89.51401664 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.3806362  96.4754328  98.53193796 98.52097319
 99.41399349 95.11214532 97.26977011 96.56680596 96.28537664 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38695922 97.80948088
 95.21082833 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.11504489 92.72913342 97.84237521 92.05906361
 96.80072124 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.08760858 92.96914024 96.24273583 96.9067141
 89.73331222 97.17717864 95.88089814 96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.5475445  99.81603538 95.99054592
 97.96420609 95.45083515 95.91988402 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [45.00797992 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38695922 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.11504489 92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.79300934 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [56.46941158  3.83732898 10.55722815  2.6607678   4.86336067  3.47843948
  3.4255565   5.71348468  2.42811941  3.35966541  1.4766206   1.31879771
  0.56190647  5.39039038  2.85497412  5.0696125   3.85738276  2.31126563
  1.23923646  1.53300077  1.69696591  0.78677535  1.30066633  2.50954187
  4.71060677  2.81912913  5.56227745  3.61774833  2.38145844  1.62760147
  2.79751162  1.47226783  3.8869955   2.21068563  2.60329687  2.55139625
  3.38117665  3.59292943  3.07951225  9.27986639  2.49494477  9.42256489
  2.93857376  3.80581539  3.51584178  7.77428437  2.33202258  1.40748003
  2.01683413  1.44428654  2.45858397  1.7477614   1.43819992  3.08472948
  1.81441962  2.27540202 15.75135855  4.89465713  4.38320619  3.84908117
 15.47373217  4.3072379   6.22430703  3.45982914  1.92731266  4.29269759
  2.12226504  4.55694485  1.62436287  3.36176333  0.33124063  8.69202849
  2.9975862   6.15366769  3.8997613   3.6934146   0.90492386  2.02450486
  0.32146364  1.5174445 ]
mAP score regular 15.45, mAP score EMA 4.26
starting validation
Accuracy th:0.5 is [70.9021601  97.22450607 89.84478162 96.96041059 97.93457408 96.68385779
 96.80843112 94.87505294 97.38894287 96.41727085 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.75924957 98.34068316 98.22109276 99.15040985 99.08812318 97.88972768
 95.43563296 96.52938685 94.34437053 96.79099086 97.81747515 98.11395969
 97.56832847 98.66955677 96.32259511 98.18372076 98.10150235 98.10150235
 97.27931833 97.2220146  97.11239006 92.72740863 97.82744101 92.21914941
 97.04761193 96.43720258 97.0202058  94.00054812 98.18621222 98.77668984
 97.94453995 98.5848469  98.37058076 98.55993223 98.87385704 97.55337967
 98.6969629  97.58576874 89.17457707 96.39235618 96.16314124 96.78102499
 90.4601739  97.11488153 96.08839724 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.55088821 99.81563146 96.23290231
 98.03174129 95.43563296 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [65.63519944 97.22450607 89.61058375 96.96290206 97.90965942 96.64150285
 96.80843112 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 99.02334504 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.37989885 98.18870369 98.05914742 98.06413035
 97.27931833 97.12733886 97.03017166 92.74484889 97.82744101 92.40600942
 97.0725266  96.48204898 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33320876 98.55993223 98.87385704 97.54341381
 98.6969629  97.58576874 89.11229041 96.39235618 96.16314124 96.78102499
 90.50502031 97.05259486 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.09338017
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [80.00854452 11.50223197 36.13776808 22.13024216 30.44335398 30.71537068
 18.37212959 19.89540636 16.22431286 18.92187264  4.56505958  4.92539706
  1.96188245 12.97959008  6.01233375 14.1114273   7.5454389   7.76600735
 12.34792683  9.88704302 13.83974098  9.07430783 72.58517032 17.83341059
 13.0419147   8.26191318 18.09631428  9.93262534  5.50848225 11.61189
 34.17343769 12.9983937  29.11315935 21.06961538 31.9771295  42.00380973
 11.69315801 43.50748415 36.58001046 25.69216015 11.26384858 30.26928662
 22.53323839 20.53731589 15.80939403 24.10778683  7.22572843  5.36363812
 16.73606182 10.81757326 24.34963939 11.44298146  6.1420759  46.11854246
  6.16737712 10.79987675 33.71121191 22.67770844 12.55770999 10.67468582
 42.36035686 37.05329861 28.34296982 17.87443344 16.31200556 13.18433453
 14.42804013 10.02721583 15.15188156 22.6967076   0.51424491 39.78632606
 20.18736338 21.53853193 14.40346944 12.75214414  1.59893117  4.50333459
  0.42846782  3.87863974]
Accuracy th:0.5 is [52.92871914 97.22450607 89.58317762 96.96041059 97.90716795 96.63651992
 96.80843112 94.87754441 97.08996686 96.41976231 98.5250517  98.5325261
 99.34972718 94.01798839 97.2070658  96.31262924 96.16064977 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.31327703 97.88474475
 95.40573536 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.89471062
 97.27931833 96.78102499 97.0276802  92.74484889 97.82744101 92.37362035
 96.77355059 96.48703192 97.03764606 94.02795426 98.18372076 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 88.94287067 92.68256222 96.16314124 96.78102499
 89.69031069 97.04761193 95.96880684 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53344794 99.81563146 96.07843137
 98.03174129 95.44559882 95.36836336 97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [46.06472831 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.31327703 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.89471062
 97.27931833 96.78102499 97.0276802  92.74484889 97.82744101 92.37362035
 97.07750953 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 89.02758054 96.39235618 96.16314124 96.78102499
 90.13379176 97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.75204923 97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [57.82098404  4.34586439  9.42923736  2.5756236   6.83145231  3.18961993
  3.98254797  5.46472823  2.27325308  3.37661761  1.35347711  1.16614824
  0.60927104  5.7497125   2.94199135  6.7269094   3.88680045  2.03464593
  1.05136344  1.60003452  1.94437578  0.99254267  1.6500658   4.4124451
  4.21888633  2.64545117  5.34386648  4.30684743  2.85183407  1.7073444
  2.70343029  1.48999356  4.18959347  1.46022898  2.42774926  2.35012117
  3.11364501  3.86490157  3.10314091 10.27867526  2.84057001 10.02341459
  2.63836824  3.86689043  4.11982199  8.60135408  2.60158866  1.27255995
  2.05010531  1.55268926  3.73117888  2.68299776  1.56181529  4.71638001
  2.1187151   2.13728208 17.67442672  4.71909336  4.62746683  4.95021699
 20.15867981  7.13517948  7.68134287  3.71314853  2.15637483  5.01145762
  2.53742201  5.66257646  1.99830879  3.79763836  0.34646684 14.44775112
  4.06137284  6.57985916  4.83837389  3.60050044  0.8744695   1.91094164
  0.48560936  2.18105018]
mAP score regular 19.02, mAP score EMA 4.74
Train_data_mAP: current_mAP = 15.45, highest_mAP = 15.45
Val_data_mAP: current_mAP = 19.02, highest_mAP = 19.02
lr:  [2.533644376331692e-05, 2.533644376331692e-05]
BCE Train Loss:  tensor([73.3468, 15.1622, 26.1464, 12.2024,  6.0852, 10.1675, 26.4232, 14.2136,
        10.7635, 24.0725, 18.6579, 12.1529,  0.8073, 17.4929, 16.0310, 20.3194,
        11.0946,  6.2003,  2.0233,  9.5767,  5.2831,  9.8157,  6.2988,  5.3270,
        31.0037, 10.9934, 38.2011, 14.6124,  6.1089, 14.3977,  5.7468,  4.5226,
        20.0643, 14.3583,  8.0258,  6.8388, 12.2116,  8.2235, 16.4628, 18.0127,
        12.0510, 28.9129, 12.2940, 20.4657, 15.4730, 29.8001,  9.5965, 12.6484,
         6.8037,  4.0403, 10.5541,  6.6553,  1.2844, 15.3525, 12.8232, 18.0745,
        36.2649, 20.5811,  8.3425, 10.0399, 34.8452, 23.1423, 14.2460, 13.8459,
        14.6860, 12.8027, 14.8873, 19.6964,  4.3724, 14.5129,  0.2339,  7.6656,
         9.6267, 30.6014, 20.6730, 15.0825,  1.1067, 14.6177,  0.2212,  9.9749],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [5/80], Step [000/642], LR 2.5e-05, Loss: 1158.3
BCE Train Loss:  tensor([77.7586, 13.7149, 40.3760, 12.9886, 14.4168, 19.2989, 15.9168, 26.5811,
         6.0197, 28.1901,  9.7780,  9.1987,  6.2495, 19.1238,  6.2107, 24.2534,
        24.7357, 17.8777,  7.5046,  8.5257, 17.5053,  5.0606,  1.9101, 22.2005,
        21.9250, 28.3960, 34.4304, 21.3300,  9.0500, 12.9969,  7.3995, 11.4283,
        11.1247,  7.6786, 11.5181,  5.9333, 13.7732,  4.4483,  8.5001, 24.1425,
         8.4315, 33.3042, 10.6438, 13.8719, 22.9408, 30.7976,  9.3270, 12.3579,
         4.5477, 16.5876,  1.6091,  5.1695,  1.2362,  9.7129, 13.4945, 23.0040,
        46.2022, 17.8332, 26.3884, 20.4139, 35.9687,  6.6494, 39.5985, 26.0764,
        27.4742, 23.5237, 22.2592, 21.0254,  4.7166, 12.8361,  5.5315, 23.0211,
         5.7400, 32.7683, 14.8317, 12.7048, 10.4381,  5.9996,  0.2202,  4.6005],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [5/80], Step [100/642], LR 2.7e-05, Loss: 1333.3
BCE Train Loss:  tensor([71.7528, 17.6970, 30.4822,  9.7498, 12.3907, 16.0852, 19.5308, 16.9980,
        23.7689,  9.8599,  5.5360, 10.2241, 10.8276, 15.2748, 18.6345, 19.3879,
        21.0028, 11.5297,  5.8550,  2.3581, 12.7971,  5.5846,  1.1954,  9.3167,
        25.8844, 12.3670, 26.4291, 22.6799, 17.5493,  7.9907,  8.2084,  4.7505,
         9.0277, 13.4981,  6.4494,  9.9838,  8.7945,  3.0345,  8.5035, 29.7001,
        15.9701, 36.3566, 22.9019, 14.2961, 14.3227, 14.8144, 19.4112,  1.6526,
         5.0265,  4.7124,  4.6077, 15.6649,  5.1249, 17.3978, 14.8131, 23.7842,
        50.5084, 22.4555, 29.1070, 19.1601, 36.4963,  9.1413, 10.2647, 25.8247,
         6.0025,  9.4769,  5.1686, 11.5711,  3.2307,  7.3731,  0.2111, 15.1563,
         9.8336, 18.5529, 12.3398, 16.4609,  9.2554, 10.9695,  6.1168,  1.0126],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [5/80], Step [200/642], LR 2.8e-05, Loss: 1169.2
BCE Train Loss:  tensor([71.5026, 19.8430, 41.9278, 14.0981, 11.8198, 15.8103, 14.2900, 15.4665,
         4.3379, 17.1787, 14.1399,  1.8358,  0.6942, 35.4619,  9.7063, 11.0293,
        25.5475, 22.2911,  6.5603, 15.0187,  8.4532,  7.4771,  5.3886,  2.6966,
        24.1462, 22.8360, 19.5175, 11.6560, 25.1273,  9.7070,  9.7122, 14.5820,
        14.5027, 13.2311, 15.6450, 11.1899, 26.3455,  9.3515, 13.2454, 14.5905,
         9.0224, 26.9889, 12.7997, 14.3230, 12.6211, 15.2834, 12.8363,  1.8651,
         8.4161,  5.3371, 14.1901,  3.8164,  1.4392, 13.8366,  6.0597,  5.2578,
        45.2073, 12.1002, 12.8243, 23.1550, 33.8129, 12.6545, 10.2294, 16.0814,
         4.4758,  5.9834,  6.4343, 15.1269,  3.4546,  8.5090,  0.1764, 14.5349,
         7.0309, 29.8289, 36.3881, 16.1813, 10.8586,  8.3129,  0.2102,  0.8913],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [5/80], Step [300/642], LR 2.9e-05, Loss: 1146.5
BCE Train Loss:  tensor([82.0316, 16.7334, 33.1419, 25.3008,  9.0038, 14.4232, 17.5841, 20.8145,
         5.5308, 13.3178,  9.6997,  2.0326,  0.8184, 21.0460,  9.6416, 27.6832,
        14.2454,  8.8284,  7.5252,  4.3160, 12.8921,  2.7962,  3.6837, 10.2145,
        27.3092, 13.9001, 28.3514, 33.1314, 18.0111,  2.2057, 10.5621,  3.9881,
        11.4362,  9.8153, 12.8163,  6.4576,  4.7129, 12.1826,  7.4196, 51.0620,
         6.7043, 33.0926, 26.7424, 27.1155, 14.8518, 30.3607, 14.6371, 11.2904,
         9.2095, 21.6440,  8.2352, 18.2593, 16.1803, 26.7168,  6.1210, 16.8616,
        31.6644, 21.3493, 18.4384, 15.7776, 49.5162, 13.6942, 20.4092, 21.1497,
        13.2326, 16.0358, 20.3537, 23.8852,  6.1838, 17.1142,  0.2594, 23.6856,
        17.7378, 19.8699, 16.7033, 24.1946,  1.2249,  3.1051,  6.4010,  1.4374],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [5/80], Step [400/642], LR 3.0e-05, Loss: 1318.1
BCE Train Loss:  tensor([80.2631, 14.3161, 46.7597, 10.6311, 20.6493, 17.2576, 25.3598, 24.7103,
        16.6528, 17.6189,  9.5190,  1.6952,  0.8201, 27.7484, 21.2139, 11.0351,
        16.3267,  9.8190,  4.3621, 14.1664, 15.5731,  1.8044,  1.4668, 24.0925,
        32.0724, 26.8038, 43.9119, 12.4372, 12.5288,  7.4716,  3.4311,  9.3647,
        21.1129,  9.9179,  7.5276,  3.0383, 27.2420, 21.0683, 12.8777, 24.1549,
         7.4393, 28.1022,  9.6777,  9.4673,  9.7870, 20.5528, 11.4994,  7.9426,
         9.3962,  2.3538,  7.0627,  1.8718,  1.3562,  4.7485, 12.6859,  8.4407,
        29.6220, 12.9016, 14.6214,  6.3413, 29.2506,  6.7357,  4.8844, 12.0336,
         1.6905,  6.0232, 11.3612, 19.9547,  7.0644, 13.1160,  0.2695, 12.4427,
         9.8035, 11.9055, 20.2308, 12.6289,  0.8792, 12.2456,  0.1974, 11.2637],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [5/80], Step [500/642], LR 3.2e-05, Loss: 1128.7
BCE Train Loss:  tensor([75.2213, 17.0596, 34.3816, 21.7436,  5.4905, 16.8188, 19.9148, 25.3274,
        20.3460, 14.5150, 10.7711,  8.2818, 10.6399, 27.5442, 15.2358, 15.9332,
        13.9010, 15.2327,  6.3771,  1.6203,  1.9382,  0.7852,  5.6647,  9.6100,
        16.8889, 23.5970, 49.7674,  3.4565, 13.5352,  4.3087,  7.0868,  3.9445,
        10.9495,  7.3098,  9.7784,  5.2009, 18.3344, 10.8506,  9.3290, 34.7648,
        21.8708, 13.4568,  3.8165,  6.4994, 16.2220, 19.9201,  5.8957,  8.9654,
         7.5492,  1.8519,  2.7967,  6.3698,  4.9173,  6.2267,  5.4501, 13.9364,
        38.5521, 17.7081, 19.3876, 18.4404, 39.8250, 10.4479, 13.1986, 15.1943,
         5.3578,  3.6397, 12.5551, 38.4424, 14.0024,  7.8911,  0.2821, 16.6656,
        20.4126, 15.1376, 25.4450, 19.8289, 10.6004,  8.6971,  6.0004,  3.7814],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [5/80], Step [600/642], LR 3.3e-05, Loss: 1150.7
BCE Val Loss:  tensor([6.7771e+01, 6.9658e+01, 8.9632e+01, 4.5911e+01, 1.1070e+00, 1.2207e+01,
        6.9655e+00, 2.4744e+01, 7.6952e+00, 1.2937e+01, 6.0109e+00, 1.0100e+01,
        4.6446e+00, 1.8460e+01, 5.6979e+00, 9.4176e+00, 4.0533e+02, 3.3838e+00,
        1.2460e+00, 2.1741e+00, 2.7060e+00, 1.0895e+00, 1.3014e+00, 2.5911e+00,
        3.1029e+01, 1.5550e+01, 2.9987e+01, 6.4693e+00, 9.7647e+00, 7.7260e+00,
        2.0194e+00, 7.4577e-01, 6.1424e+00, 7.7760e-01, 2.9007e+00, 3.1941e+00,
        3.8662e+00, 3.4664e+00, 2.2152e+00, 4.9837e+01, 1.1011e+01, 2.5636e+01,
        9.4702e+00, 1.9098e+01, 1.7064e+01, 2.3416e+01, 2.3322e+00, 5.3959e+00,
        1.5372e+00, 4.5280e+00, 1.0469e+00, 1.0428e+00, 7.2304e+00, 1.4470e+00,
        1.6350e+00, 2.4817e+00, 3.0780e+01, 9.9074e+00, 1.9238e+01, 4.5205e+00,
        1.5334e+01, 1.9523e+01, 7.9586e+00, 6.0690e+00, 2.8608e+00, 4.2539e+00,
        2.6497e+00, 1.1996e+01, 7.9887e+00, 2.1535e+01, 2.4943e-01, 2.2318e+01,
        1.5645e+01, 1.4143e+01, 1.2860e+01, 1.0708e+01, 1.0050e+00, 5.8717e+00,
        2.2145e-01, 1.0824e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [5/80], Step [000/314], LR 3.4e-05, Loss: 1371.6
BCE Val Loss:  tensor([8.5792e+01, 2.0103e+01, 6.3204e+01, 1.0651e+01, 3.4701e+00, 4.4189e+01,
        9.2018e+01, 5.8225e+01, 3.4007e+01, 3.1782e+01, 1.7678e+01, 2.2910e+02,
        9.1927e+00, 1.2810e+01, 1.5423e+01, 4.6600e+00, 1.2191e+01, 1.8862e+01,
        1.9922e+00, 2.0014e+01, 2.5917e+00, 1.2026e+00, 2.5288e+00, 5.3581e+00,
        2.8403e+01, 2.3985e+01, 3.4010e+01, 1.6512e+01, 1.3665e+01, 2.2796e+00,
        1.8053e+00, 8.6017e-01, 2.5798e+00, 2.5571e+00, 1.4865e+00, 1.3087e+00,
        6.2079e+00, 2.2824e+00, 2.2357e+00, 5.7398e+00, 1.5648e+00, 6.8846e+00,
        1.4757e+00, 1.9288e+00, 1.5397e+00, 4.7213e+00, 1.3111e+00, 7.0838e-01,
        6.5943e-01, 6.6806e+00, 6.0360e-01, 5.6076e-01, 4.7365e-01, 1.1418e+00,
        6.8552e-01, 3.8722e+00, 1.6956e+01, 4.7340e+00, 1.0255e+01, 1.5298e+00,
        7.1124e+00, 2.0969e+00, 3.1855e+00, 2.0735e+00, 1.3840e+00, 1.8468e+00,
        1.3156e+00, 1.7362e+01, 8.0136e-01, 4.3325e+00, 1.0956e-01, 2.6480e+00,
        4.1998e+00, 6.0784e+00, 7.6172e+00, 1.8120e+00, 5.2171e-01, 1.1603e+00,
        8.8942e-02, 3.6704e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [5/80], Step [100/314], LR 3.4e-05, Loss: 1077.4
BCE Val Loss:  tensor([5.6970e+01, 1.4251e+00, 7.7625e+00, 1.3671e+00, 2.0435e-01, 9.4797e-01,
        7.9468e-01, 1.3098e+01, 3.4658e-01, 1.0137e+00, 5.5237e-01, 4.2915e-01,
        2.3009e-01, 1.7817e+01, 1.4350e+00, 7.2134e+00, 4.6885e+00, 9.0000e-01,
        3.4976e-01, 5.5802e-01, 1.1679e+00, 8.1983e-01, 1.4190e-01, 4.4042e-01,
        6.6728e+00, 2.1515e+00, 2.6488e+01, 9.8467e+00, 2.4520e+00, 8.2604e-01,
        2.3151e+00, 5.3978e+00, 1.0584e+01, 1.2320e-01, 9.0508e-01, 1.0562e+00,
        1.8374e+01, 1.7705e+01, 7.1496e-01, 3.7641e+01, 3.0439e+01, 6.9572e+01,
        7.9733e+01, 8.4971e+01, 4.6837e+01, 6.9322e+01, 9.5956e+00, 8.9840e+00,
        3.6341e+01, 1.1178e+01, 2.6595e+01, 4.7308e+01, 7.9701e+01, 2.4553e+01,
        7.5680e+01, 1.2373e+02, 1.2308e+02, 1.8229e+01, 1.1934e+01, 5.8561e+00,
        1.1566e+02, 2.2377e+00, 1.5117e+01, 1.3817e+01, 1.3883e+01, 7.2366e+00,
        9.4233e+00, 1.4517e+01, 6.4495e+00, 4.4356e+00, 3.0893e-01, 8.2008e+00,
        8.5882e+00, 4.0847e+01, 2.8999e+00, 1.4236e+01, 1.1736e+01, 4.0341e+00,
        2.4113e-01, 1.4473e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [5/80], Step [200/314], LR 3.4e-05, Loss: 1542.9
BCE Val Loss:  tensor([8.8263e+01, 6.1128e+00, 3.0808e+01, 3.9655e+00, 3.0173e+00, 1.5013e+01,
        1.6218e+01, 1.8816e+01, 4.0360e+00, 2.1289e+01, 5.2627e+00, 6.5035e+00,
        8.1563e-01, 1.7428e+01, 1.7383e+01, 4.0488e+00, 3.4061e+00, 3.3915e+00,
        8.4756e-01, 1.5732e+00, 2.1666e+00, 6.2642e-01, 1.8495e+00, 3.0018e+00,
        2.4499e+01, 5.1896e+00, 3.1226e+01, 4.4589e+00, 1.6643e+01, 1.1716e+00,
        2.8533e+00, 1.7926e+00, 1.2674e+00, 1.5928e+00, 6.5773e-01, 6.0422e-01,
        3.1215e+00, 1.0614e+00, 1.3139e+00, 9.2238e+00, 2.1720e+00, 8.2334e+00,
        1.7173e+00, 2.8599e+00, 2.3214e+00, 6.1055e+00, 1.4759e+00, 7.3997e-01,
        7.2787e-01, 6.7718e-01, 5.2668e-01, 5.2021e-01, 5.0282e-01, 1.1072e+00,
        7.7668e-01, 1.4216e+00, 1.3538e+01, 3.7199e+00, 1.4320e+01, 2.5519e+00,
        1.1939e+01, 4.1546e+00, 4.6488e+00, 3.3728e+00, 2.4679e+00, 2.5295e+00,
        2.3827e+00, 8.6164e+00, 2.0988e+00, 4.0839e+00, 1.9719e-01, 6.7645e+00,
        3.2899e+00, 8.0792e+00, 3.3998e+02, 6.2433e+00, 7.4106e-01, 5.1062e+00,
        1.6410e-01, 5.3630e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [5/80], Step [300/314], LR 3.4e-05, Loss: 865.9
starting validation
Accuracy th:0.5 is [70.91897029 97.2137279  89.74427699 97.05656607 97.38916436 96.77026352
 97.06996747 94.7332513  97.44642487 96.46446803 98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65498715 98.30655085 98.15060733 99.18616976 99.13500079 97.81069919
 95.21813818 96.65086926 94.08023781 96.75077058 98.01293844 98.15913549
 97.41840377 98.56117737 96.38405965 98.05801586 97.92156528 98.0214666
 96.94082674 97.41596715 97.36357988 92.74862636 97.83750198 92.19064095
 96.92498873 96.23664429 96.95788307 93.87190702 98.02877645 98.57336046
 97.9934455  98.51853657 98.38817753 98.55508583 98.99976852 97.63282611
 98.70615611 97.46591781 89.42995334 96.14770775 96.24517245 96.9067141
 90.52277628 97.32703062 96.10506695 96.98468586 98.42838172 97.34286863
 98.20786784 95.95277835 98.6756984  97.56703744 99.81603538 96.1269965
 97.97151594 95.3740817  96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [68.0230504  97.2137279  89.57615039 97.02732667 97.30022782 96.73127764
 97.00296049 94.73568792 97.44398826 96.47786942 98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 99.14596557 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.32703062 98.57457877 96.38893288 98.02024829 97.83750198 97.88988926
 96.94082674 97.30022782 97.22225606 92.72791511 97.84237521 92.06393684
 96.9201155  96.22811613 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.50490369
 98.70615611 97.46591781 89.25208026 96.14161621 96.24273583 96.9067141
 90.10367807 97.25758702 96.12212327 96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 96.05389798
 97.96420609 95.44961684 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [81.66873111 11.9903227  36.70459234 21.16147773 31.64668485 33.79855566
 27.41129418 22.40699617 16.33758001 20.78039533  3.93107784  5.96728227
  2.45751506 12.70471717  7.55773132 15.32629203  7.40900606  9.22813187
 15.2109117  11.07249133 14.776302   12.38192435 70.28801136 22.39076558
 13.18525726  8.64819943 19.11834595 12.50569817  5.23005266 12.73114988
 33.68128007 13.9481635  30.6281483  23.8588564  34.81547262 44.0940064
 14.60862571 40.44493459 38.93801376 25.97860826 11.66185835 32.28423751
 24.66992421 22.40676956 16.87454208 25.38252139 10.63576359  8.67624601
 16.88293004 11.052429   25.07057432 12.0771063   5.45068665 43.15304603
  5.7176895  11.33418224 35.88403211 25.1627252  14.03415032 13.88442887
 43.97581791 34.68421712 26.93718591 16.43334436 15.70645331 16.46970354
 14.62245864  9.8141504  15.78110437 20.92163679  0.86365486 36.50849047
 20.62802564 21.66566849 11.8420388  12.28993783  1.99350434  5.49355325
  0.42742804  4.06061464]
Accuracy th:0.5 is [53.47888062 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44276995 96.4754328  98.53193796 98.52097319
 99.41399349 95.30098318 97.26977011 96.56315103 96.2939048  97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38695922 97.80948088
 95.21570156 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.11504489 92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 95.82241932 96.24273583 96.9067141
 89.70407281 97.17717864 96.11115849 96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.14161621 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [45.01163485 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38695922 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.11504489 92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.79300934 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [58.11252185  3.77129846 12.25932584  2.9717164   5.20063813  3.71631327
  3.47477772  6.04058666  2.5933646   3.54124786  1.84653723  1.29172838
  0.64313201  5.62038429  3.07849249  5.21228777  4.00237965  2.53452837
  1.51999638  1.93423882  2.92803304  1.38017637  2.00252716  5.058387
  4.68257318  2.84986517  6.53583939  4.06859759  2.58543087  2.20494981
  3.03457863  1.76639021  5.41233177  2.629995    3.34558965  3.48712013
  3.59303143  5.35978188  3.87353039 10.65618884  2.90592227 11.62911393
  3.99311013  4.47278666  4.3094547   8.9380766   2.97822957  1.73012259
  2.69468407  1.77130505  3.85031234  2.09493823  1.51261005  5.05809968
  1.96819822  2.39723165 17.28412767  5.59191108  5.12306597  4.53980191
 18.3990131   6.07248358  6.90091192  4.20116153  2.00398448  4.66551742
  2.37437761  4.9335867   1.88958675  3.82109513  0.24791033 10.4096626
  3.57136091  6.32586007  4.04691445  3.85957327  0.89868758  2.1744125
  0.26525729  1.63625147]
mAP score regular 19.88, mAP score EMA 4.88
starting validation
Accuracy th:0.5 is [74.22826818 97.22450607 89.98679523 97.02269726 98.11146822 96.69631512
 97.00774846 94.83518948 97.378977   96.37242445 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.30764631 96.21047911 97.50604181
 98.75177517 98.33320876 98.23355009 99.14791838 99.27996612 97.89720208
 95.43812442 96.52938685 94.34437053 96.79846526 97.81747515 98.10897675
 97.76515435 98.65709943 96.32757805 98.20614396 98.26843063 98.32573436
 97.27682687 97.3565538  97.45870394 92.75232329 97.81249221 92.50068515
 97.0874754  96.44218551 97.02269726 94.04290306 98.18870369 98.77419837
 97.94952288 98.58982983 98.42539303 98.55993223 98.87385704 97.73276528
 98.6969629  97.58576874 89.44365548 96.48454045 96.13324364 96.78102499
 91.01577098 97.3939258  96.15317537 96.93051299 98.32324289 97.41136607
 98.13139996 95.7769639  98.71689464 97.58576874 99.81563146 96.38488178
 98.04669009 95.40075242 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [71.45028278 97.22450607 89.81239256 96.96788499 97.97692902 96.84580312
 96.85327752 94.88003588 97.39890874 96.41228791 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78416424 98.34068316 98.22109276 99.15040985 99.34225278 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11146822
 97.57829434 98.66955677 96.41976231 98.19119516 98.14385729 98.24600742
 97.27931833 97.1771682  97.2743354  92.74983183 97.82744101 92.39853502
 97.0949498  96.46959165 97.03764606 94.03044572 98.18621222 98.77668984
 97.96198022 98.5848469  98.35314049 98.55993223 98.87385704 97.57580288
 98.6969629  97.58576874 89.34648828 96.43221965 96.16314124 96.78102499
 90.66696564 97.1397962  96.11829484 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.54092234 99.81563146 96.40979645
 98.03174129 95.46802202 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [84.1931447  12.46613752 40.77786873 27.37948501 38.47432744 37.29179907
 36.1743718  22.61640363 19.91144484 21.8077353   5.84108945  9.06926247
  2.96778595 14.4483057   8.52223907 19.16527965  8.90906631 10.6775128
 14.72821324 12.88124253 22.63390079 18.97331087 83.19296041 26.94393086
 14.24008407 10.31370346 19.60157468 14.17330842  6.65880125 15.36246593
 47.36337081 19.1546449  35.45079032 27.17107772 44.12516526 52.50012807
 15.76509526 49.40398939 50.4246078  28.5596435  13.40292271 34.50798132
 26.02365301 23.5237695  18.99431084 27.86587138 11.47275981  7.14000795
 19.7752787  15.96174108 34.85620245 14.31882906  9.01510306 51.8318062
  7.43696968 13.0122419  38.18838432 30.19721675 15.20951465 17.06934397
 47.16799215 42.95972823 33.62014323 23.20018612 25.05011551 18.34705802
 22.27097898 12.21039536 17.15890613 26.70117116  1.41833111 46.45228196
 24.48486347 25.30045462 20.56443428 16.24604446  1.76914262  6.70050793
  0.6004622   4.48486315]
Accuracy th:0.5 is [53.38465755 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.38395994 96.41976231 98.5250517  98.5325261
 99.34972718 94.81525774 97.2070658  96.26279991 96.21047911 97.50604181
 98.7791813  98.34068316 98.21860129 99.15040985 98.31327703 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.89471062
 97.27931833 96.78102499 97.0276802  92.74484889 97.82744101 92.37362035
 97.07501806 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 89.0225976  95.35092309 96.16314124 96.78102499
 89.32157361 97.04761193 96.06846551 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.7171687  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [46.06472831 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.31327703 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.89471062
 97.27931833 96.78102499 97.0276802  92.74484889 97.82744101 92.37362035
 97.07750953 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 89.02758054 96.39235618 96.16314124 96.78102499
 90.13379176 97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [59.62373875  4.80674265 11.66467775  3.19337288  6.70480415  3.52764996
  4.03061437  5.99740992  2.41945964  3.40069214  1.49324759  1.211472
  0.63686546  6.66028078  3.4172608   7.0736277   4.60165677  2.36652819
  1.39609835  2.22411072  5.38240976  2.54641669  3.52729966  7.63135295
  4.35804946  2.83245845  6.2954791   4.80011848  3.15069613  2.63965133
  3.28538649  3.10351621  6.94598181  2.17157691  3.96138179  5.56058655
  3.65042889  9.29327761  4.7394613  12.20336622  3.46152544 13.39647851
  4.26640537  4.66964704  5.29753858 10.43098004  3.35933402  1.65287772
  3.63410817  1.95214932  6.26261428  2.70332377  2.03260014 11.0572736
  2.79719612  2.49038007 20.04486453  5.93854934  6.01993725  5.76146911
 24.08080415 12.97398456  9.08365558  4.48696469  2.42501855  5.79067583
  2.84922254  5.9654772   2.66667024  5.50991968  0.39464593 19.1796941
  4.83079959  7.43078881  5.19727979  4.02042136  0.9733586   2.21416133
  0.53512792  2.45291005]
mAP score regular 23.71, mAP score EMA 5.94
Train_data_mAP: current_mAP = 19.88, highest_mAP = 19.88
Val_data_mAP: current_mAP = 23.71, highest_mAP = 23.71
lr:  [3.3636281936934846e-05, 3.3636281936934846e-05]
BCE Train Loss:  tensor([68.7565, 15.1572, 33.2929, 18.3143,  9.4097,  7.1591, 27.1725, 12.9440,
         5.8029, 22.4448,  1.8349,  2.1555,  0.5757, 15.7255, 11.4324, 18.6335,
        18.5067, 13.8046,  1.0677,  7.6636,  7.4289,  0.7093,  1.1504, 18.7137,
        22.7057, 23.5296, 35.7944, 17.7074, 12.6185, 14.4817,  4.0938,  2.1510,
         7.0455, 12.6973,  6.6244,  3.6001, 14.1173, 12.9653,  7.6109, 33.2551,
        22.5369, 26.0375, 18.0419, 27.2983, 19.6345, 26.8843, 12.0330, 14.3653,
         4.8483,  4.3876,  4.1572,  5.5222,  5.5597,  8.2613, 21.6982, 25.9491,
        31.3837, 17.5032, 13.6098, 13.0366, 37.1175,  8.2572, 13.0264, 19.3651,
         9.6777, 11.4082, 15.2294, 29.6165,  4.3013,  8.7216,  0.2313, 12.3489,
         4.7705, 28.2605, 21.0150, 22.6514,  4.4632,  9.8704,  5.8217,  6.2446],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [6/80], Step [000/642], LR 3.4e-05, Loss: 1166.0
BCE Train Loss:  tensor([68.8358,  7.5997, 32.0572, 13.8641, 12.8699, 13.5588, 12.9901, 21.1358,
         6.0352,  7.2304,  4.7526,  6.9231,  6.1786, 19.3644,  6.0487, 22.1054,
        17.4957, 14.1746,  5.5950, 13.9483,  7.7789,  6.6393,  0.9220,  3.2204,
        22.9217, 14.4458, 24.4380, 28.0798, 10.8975,  7.7556, 11.7743,  8.5278,
        18.8329,  7.4353, 10.0183, 15.6673, 15.9276, 10.1511,  5.9225, 30.3214,
         5.6117, 23.5215, 11.7406, 24.0205, 17.8659, 20.8202, 16.5524,  9.7847,
        19.1851, 13.1615,  5.3272,  7.3427,  3.6803, 12.3225,  4.0550, 12.1094,
        35.1967, 12.0752, 18.7280, 11.0012, 30.4182,  8.8584, 17.6632, 10.5040,
        10.9889, 21.2888, 10.2559, 18.8627, 10.7628, 21.8282,  0.2871, 18.3779,
         6.8808, 14.4708, 11.5086,  7.7659,  0.9759,  5.4556,  0.2245,  1.1662],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [6/80], Step [100/642], LR 3.5e-05, Loss: 1087.1
BCE Train Loss:  tensor([71.8211, 12.4681, 30.6456, 23.4198,  9.6267,  9.8870, 13.6081, 18.6689,
        16.6284, 19.3389,  5.5630,  2.3804,  9.6757, 16.3241,  8.9177, 17.8857,
        12.0772, 10.8030,  3.9133, 10.4534,  8.5705,  3.1960,  0.8288,  4.7070,
        13.1193, 14.9922, 25.6746,  7.0765,  9.8748,  7.1188, 10.5588, 11.6348,
        13.9689, 11.2120,  8.1944, 10.9405, 22.7861, 24.1760,  6.0018, 27.7830,
         6.6211, 27.1908, 11.9724, 10.3859, 12.3033, 15.1190, 10.8261,  1.9951,
        19.7217,  1.9550,  2.0832,  6.5316,  8.5921, 11.2352,  9.6591, 15.8600,
        30.9473, 12.3552, 13.6097, 16.7116, 21.4401, 14.4565, 17.7983,  9.9626,
         7.6162, 12.9999,  8.3588, 25.0524, 11.4401, 20.9251,  0.2198, 19.1657,
         8.2178, 14.9616, 15.4851, 15.9072, 19.0035,  9.5463,  5.9443,  1.2972],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [6/80], Step [200/642], LR 3.6e-05, Loss: 1072.0
BCE Train Loss:  tensor([66.7583,  5.3779, 42.3512,  8.8183,  6.3073, 19.4827, 11.6561, 33.0926,
         6.2788, 15.3269,  5.4758, 16.0059,  6.0332, 23.4188, 12.5548,  9.7195,
        12.1411, 15.8154,  1.3085,  2.0039, 11.2365,  0.9182,  7.7784, 12.6758,
        10.6505, 21.4143, 18.2108, 13.2615,  5.5567,  7.4590, 12.1916, 10.4207,
        15.3812,  8.4113,  8.5620, 15.3236, 18.5624,  6.5329,  6.3258, 27.5236,
        10.5156, 27.0126,  8.2699,  9.5086, 23.6219, 27.0052, 15.5910, 16.1716,
        16.7410, 10.0885,  9.5998, 14.1989,  8.0786, 11.5724,  1.4242, 17.3489,
        25.8419,  7.2734, 22.2240, 11.5464, 18.4525, 16.1376,  7.6651, 10.2655,
         5.5079,  2.8638,  8.1922, 15.7437,  2.8562, 12.4830,  9.1616, 15.0878,
         7.3060, 11.0949, 16.2289, 18.2339,  4.9425,  7.1040,  0.1598,  4.5782],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [6/80], Step [300/642], LR 3.8e-05, Loss: 1046.0
BCE Train Loss:  tensor([76.5837, 18.4272, 34.9506, 17.4388, 15.3143, 17.7791, 19.2830, 17.4095,
        14.5951, 11.2362,  2.0698,  9.9164,  9.2301, 21.3987, 29.6006, 19.8189,
        12.8840, 16.3139,  5.8187, 15.9209, 13.3233,  6.5789,  2.1734, 10.5742,
        14.2628, 25.1582, 18.9489, 22.1972, 12.8031,  8.7169, 11.5677,  1.7709,
        16.8790, 11.7761,  3.2836,  2.7699,  7.4183, 17.0599,  8.5307, 19.4648,
        10.1571, 20.1430,  8.1586, 10.7718,  7.6679, 15.5645,  5.4576,  8.5767,
         5.3779,  6.1499,  1.4257,  1.7709,  1.0593,  7.4309,  6.1926,  8.1724,
        26.6640, 13.1332,  7.7088,  7.4172, 26.1917,  3.9221, 18.7265, 18.5633,
         1.7587, 15.0569,  9.0595, 13.8499,  4.2874,  3.2542,  0.2023,  8.1852,
         7.6505, 11.7914, 20.4489,  6.9374,  6.1319, 14.2465,  0.2003,  9.6629],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [6/80], Step [400/642], LR 3.9e-05, Loss: 1000.4
BCE Train Loss:  tensor([69.0942, 12.7649, 32.1141, 12.9011,  9.4271,  9.0711, 12.5917, 17.1007,
        13.0239, 12.5703,  5.3402,  4.4668,  4.5761, 16.1089, 13.1286, 19.8595,
        26.9389, 14.7468,  8.5487,  1.7788, 24.3738,  3.7895,  0.6587,  7.4453,
        13.7631, 15.8672, 21.6669, 12.0757,  2.4628,  4.3286, 14.5558, 13.5681,
        17.3198,  4.7300, 11.4115,  7.1588, 12.9178, 17.8436, 10.1938, 24.6611,
        10.0384, 30.1845,  9.0275, 13.2567, 17.4054, 18.4583,  7.3631,  8.1076,
         2.4519,  6.9841,  6.2707,  3.8012,  5.4211, 10.3065,  5.4276,  6.8828,
        44.7349,  9.7146, 25.0130,  9.3202, 32.1100,  9.3946, 18.1539, 20.7081,
        14.5805, 21.8167, 12.3688, 33.7404,  7.8975,  9.6480,  5.0247,  9.0965,
         7.6930, 18.3251, 18.2432, 18.2734, 12.4138, 18.7445,  0.1668,  9.1195],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [6/80], Step [500/642], LR 4.1e-05, Loss: 1104.6
BCE Train Loss:  tensor([64.6711, 11.0944, 39.3473, 12.1532,  5.7085, 11.4497, 13.3601, 17.2127,
        14.8777,  9.9209,  9.4615,  9.5533,  3.8990, 17.4830, 12.4450,  7.1189,
        24.8123,  8.7069,  8.7574, 11.1339,  7.1929,  3.5318,  0.8339,  8.1318,
        21.5132, 15.1873, 20.6118, 22.3702, 18.1227,  7.6681,  3.4158,  3.7827,
        17.0681, 11.4016, 19.9266, 17.6698, 21.2926,  5.7855,  5.0769, 20.9006,
         5.5760, 25.2502, 14.7224, 18.9807, 16.2162, 16.1057,  6.4845,  5.0538,
         4.9428,  1.6552,  5.5908,  1.5443,  5.3485,  5.0838, 10.0217, 23.0623,
        28.0207, 14.2793, 11.4491, 20.8681, 23.6957, 12.8151,  9.0474,  7.3523,
         5.4964,  9.3905,  8.0399, 20.6157,  2.0980,  4.9312,  0.2069,  8.2108,
         2.7137, 21.0862,  7.7830,  7.6888,  6.2639,  9.8364,  0.2177,  1.2635],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [6/80], Step [600/642], LR 4.2e-05, Loss: 973.7
BCE Val Loss:  tensor([6.8084e+01, 6.7954e+01, 8.9800e+01, 4.1690e+01, 7.4006e-01, 1.1632e+01,
        7.4308e+00, 2.4486e+01, 7.2558e+00, 1.4107e+01, 5.8256e+00, 1.1126e+01,
        5.1229e+00, 1.8015e+01, 5.7549e+00, 1.0879e+01, 4.1205e+02, 4.1203e+00,
        1.1849e+00, 2.2122e+00, 2.8393e+00, 7.1992e-01, 1.1970e+00, 1.6574e+00,
        2.9529e+01, 1.7654e+01, 3.1237e+01, 6.2551e+00, 9.5708e+00, 8.7795e+00,
        1.4792e+00, 6.0378e-01, 5.4073e+00, 6.5281e-01, 3.2138e+00, 3.4602e+00,
        5.3889e+00, 2.9936e+00, 2.1294e+00, 5.0145e+01, 1.0905e+01, 2.4497e+01,
        1.0445e+01, 1.8361e+01, 1.6925e+01, 2.1381e+01, 1.9408e+00, 5.0221e+00,
        1.6675e+00, 4.1000e+00, 9.3204e-01, 8.8733e-01, 7.3252e+00, 1.4496e+00,
        1.6287e+00, 2.8125e+00, 2.9765e+01, 8.6501e+00, 1.9041e+01, 4.7856e+00,
        1.4909e+01, 1.7051e+01, 6.6171e+00, 6.5702e+00, 2.2231e+00, 3.7318e+00,
        2.6776e+00, 1.4371e+01, 8.4597e+00, 2.0909e+01, 3.1633e-01, 2.1384e+01,
        1.5127e+01, 1.4175e+01, 1.2708e+01, 1.0028e+01, 1.0149e+00, 5.9818e+00,
        3.1379e-01, 1.4377e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [6/80], Step [000/314], LR 4.3e-05, Loss: 1366.9
BCE Val Loss:  tensor([7.9182e+01, 2.0422e+01, 5.8040e+01, 1.0714e+01, 2.2646e+00, 4.2616e+01,
        7.9736e+01, 5.1738e+01, 3.4164e+01, 3.1355e+01, 1.6361e+01, 2.3023e+02,
        7.9829e+00, 1.2929e+01, 1.5003e+01, 4.1711e+00, 1.1859e+01, 1.7847e+01,
        2.5460e+00, 1.8823e+01, 3.0572e+00, 9.0001e-01, 7.6679e-01, 4.2404e+00,
        2.8083e+01, 2.3659e+01, 3.1788e+01, 1.6408e+01, 1.2949e+01, 1.6035e+00,
        1.0750e+00, 5.5671e-01, 1.4999e+00, 2.1258e+00, 1.0921e+00, 9.7138e-01,
        6.2456e+00, 2.4144e+00, 1.5582e+00, 4.7965e+00, 9.1815e-01, 6.1385e+00,
        7.5537e-01, 1.4819e+00, 1.0673e+00, 4.9592e+00, 1.1191e+00, 7.7119e-01,
        6.2977e-01, 6.5590e+00, 4.3260e-01, 4.8332e-01, 6.2179e-01, 1.1152e+00,
        6.1990e-01, 3.4528e+00, 1.4620e+01, 4.6173e+00, 8.6299e+00, 1.2180e+00,
        5.9812e+00, 2.2314e+00, 2.4153e+00, 1.8961e+00, 1.0476e+00, 1.1518e+00,
        1.3037e+00, 1.7013e+01, 5.1882e-01, 4.1977e+00, 1.0193e-01, 2.3660e+00,
        4.0527e+00, 5.6744e+00, 9.0437e+00, 1.3806e+00, 4.5711e-01, 1.0221e+00,
        9.0582e-02, 3.9890e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [6/80], Step [100/314], LR 4.3e-05, Loss: 1016.3
BCE Val Loss:  tensor([5.3381e+01, 1.2887e+00, 7.3845e+00, 1.4921e+00, 1.3105e-01, 7.8738e-01,
        5.9032e-01, 1.4448e+01, 2.5543e-01, 9.2720e-01, 4.7696e-01, 2.3249e-01,
        2.3803e-01, 1.6319e+01, 1.2892e+00, 6.7503e+00, 4.0761e+00, 9.5693e-01,
        3.1668e-01, 4.7246e-01, 8.1055e-01, 3.7058e-01, 5.4067e-02, 2.7376e-01,
        6.2383e+00, 2.2406e+00, 2.5639e+01, 9.2817e+00, 1.8563e+00, 6.7998e-01,
        1.8300e+00, 5.9668e+00, 8.8381e+00, 7.8170e-02, 8.3934e-01, 1.0792e+00,
        1.6077e+01, 1.8430e+01, 5.2513e-01, 3.9351e+01, 2.9928e+01, 6.6592e+01,
        8.8291e+01, 8.3809e+01, 5.3335e+01, 7.2064e+01, 9.2032e+00, 8.9299e+00,
        3.6564e+01, 1.2064e+01, 2.7078e+01, 4.7986e+01, 7.5096e+01, 2.3874e+01,
        7.3594e+01, 1.2282e+02, 1.2105e+02, 1.6913e+01, 1.0928e+01, 5.1034e+00,
        1.1401e+02, 2.1293e+00, 1.3736e+01, 1.4548e+01, 1.3811e+01, 6.2093e+00,
        9.2264e+00, 1.4137e+01, 6.3748e+00, 4.9353e+00, 3.8202e-01, 8.1255e+00,
        8.2163e+00, 4.1008e+01, 3.3551e+00, 1.3951e+01, 1.0447e+01, 3.5603e+00,
        3.0536e-01, 1.6801e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [6/80], Step [200/314], LR 4.3e-05, Loss: 1527.6
BCE Val Loss:  tensor([7.6403e+01, 5.2368e+00, 3.0441e+01, 4.0897e+00, 1.6317e+00, 1.5118e+01,
        2.5241e+01, 1.9755e+01, 3.4264e+00, 2.5056e+01, 5.2414e+00, 5.9528e+00,
        1.0499e+00, 1.7649e+01, 1.7306e+01, 3.7371e+00, 2.5267e+00, 3.3330e+00,
        7.7852e-01, 1.3936e+00, 2.5477e+00, 4.2642e-01, 5.3833e-01, 3.0421e+00,
        2.4708e+01, 5.3166e+00, 2.9250e+01, 3.3073e+00, 1.6782e+01, 8.9477e-01,
        2.1205e+00, 1.1845e+00, 7.8233e-01, 1.0788e+00, 4.8735e-01, 4.3895e-01,
        3.2621e+00, 7.0697e-01, 8.9614e-01, 7.7017e+00, 1.2556e+00, 6.6767e+00,
        8.2251e-01, 2.0193e+00, 1.4987e+00, 4.8650e+00, 1.3084e+00, 6.9474e-01,
        5.9812e-01, 5.9930e-01, 4.8384e-01, 3.8337e-01, 4.9396e-01, 9.3348e-01,
        6.1650e-01, 1.3517e+00, 1.1030e+01, 2.1118e+00, 1.3104e+01, 1.9153e+00,
        9.1897e+00, 4.1319e+00, 2.8989e+00, 2.8102e+00, 1.4000e+00, 1.5589e+00,
        1.8699e+00, 8.3862e+00, 1.1090e+00, 3.3643e+00, 1.9536e-01, 6.0740e+00,
        2.3903e+00, 7.0083e+00, 2.8263e+02, 4.7326e+00, 5.9777e-01, 4.8571e+00,
        1.9314e-01, 5.4086e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [6/80], Step [300/314], LR 4.3e-05, Loss: 769.5
starting validation
Accuracy th:0.5 is [74.16941801 97.2137279  90.07809359 97.1296646  97.51221355 96.88722116
 97.36479819 94.74543439 97.44886149 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56558765 96.29512311 97.48053752
 98.67082516 98.30776915 98.18350166 99.18616976 99.2751063  97.88745264
 95.21813818 96.65086926 94.04856179 96.74955227 98.01293844 98.15669887
 97.51586847 98.56726892 96.52294685 98.08481865 98.17131858 98.25416357
 96.94691829 97.61333317 97.8119175  92.74497143 97.84481183 92.26983102
 96.91402395 96.24151753 96.9627563  93.89992812 98.02999476 98.57214215
 97.98613565 98.51975488 98.44178312 98.55386752 98.99976852 97.81435411
 98.70615611 97.46591781 89.61879119 96.21227812 96.23298936 96.9067141
 90.80176898 97.40622068 96.20618657 96.99199571 98.43081834 97.34408694
 98.21030446 95.95277835 98.67326178 97.59627685 99.81603538 96.30608789
 97.98735396 95.45205346 96.18303871 96.91280564 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [69.23161268 97.2137279  89.72722067 97.04072806 97.35505172 96.82874234
 97.31362922 94.73568792 97.44155164 96.48761589 98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65498715 98.30776915 98.15426225 99.18616976 99.21784579 97.82531889
 95.21935649 96.65086926 94.07658289 96.75198889 98.01293844 98.15913549
 97.38916436 98.57457877 96.42060891 98.03121307 98.04583277 98.20908615
 96.94082674 97.43302348 97.61455148 92.73035173 97.84237521 92.08830302
 96.90915072 96.22933444 96.9627563  93.87799856 98.02877645 98.57336046
 97.99588212 98.52219149 98.40036062 98.55508583 98.99976852 97.68034015
 98.70615611 97.46591781 89.36172805 96.14770775 96.24273583 96.9067141
 90.15241042 97.3806362  96.14405283 96.98468586 98.42838172 97.34408694
 98.20908615 95.95277835 98.67326178 97.55972759 99.81603538 96.168419
 97.9654244  95.45205346 96.1537993  96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [85.03722914 12.62179495 41.40192783 28.01043816 43.6052421  40.08592072
 40.23538715 27.06592881 18.81709962 24.82502375  5.54069231 11.39176503
  3.35730958 13.76003528  9.05321852 19.18719792  8.57873625 11.52786924
 18.71177835 12.70189031 22.75673056 15.43198391 77.80659214 37.19052211
 15.04126186 10.06020925 21.32419802 15.00661429  6.03467443 18.45694976
 39.81496734 18.99940262 38.63832671 30.67940154 46.39166987 54.72365482
 19.13813259 48.15581048 55.53483785 27.7378368  13.03199301 35.83883672
 28.0090968  25.6199555  19.59523084 28.81959026 13.45240753 11.17063028
 20.33593369 15.33847565 33.50908922 15.49631135  7.48255776 51.17297138
  6.07576348 13.82290964 39.37181111 29.93108811 15.63719155 18.92764845
 48.60252772 41.84253745 33.21019684 19.5789936  19.69760814 20.50577162
 18.38203436 11.53025835 18.85828861 26.54214811  2.89436753 42.87035496
 23.39260822 24.63045844 16.21132254 14.38401941  2.47350096  7.54671724
  0.80777919  4.8264389 ]
Accuracy th:0.5 is [55.35994932 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56436934 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38695922 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.11504489 92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 96.13674297 96.24273583 96.9067141
 89.69310803 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [44.9495011  97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38695922 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.11504489 92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.79300934 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [61.07373189  4.43831858 15.63678187  4.40625722  7.17534638  5.33665234
  4.48296557  7.62237283  3.29708112  4.26847663  1.75821545  1.37732376
  0.61161655  6.34070416  3.58312116  5.89663198  4.46525604  3.01274208
  2.68805572  2.54969014  5.52281608  1.86807479 10.48022239  7.63953312
  4.95053893  3.27225371  8.45468644  4.66338672  2.74847888  3.13278258
  5.28609425  3.45737904  9.3978251   4.75619303  4.62158663  7.60868779
  4.2277638  10.95520926  6.53210351 12.77740238  3.63129937 15.1222448
  6.92084865  5.73615853  5.4703168  10.03339063  3.76416776  2.30070233
  4.32523931  2.59101519  7.06186445  2.74043567  1.76462823  9.79357829
  2.65688545  2.83959284 19.6991433   7.11914244  6.2028442   5.29575956
 21.7833364  10.11409292  8.48639037  4.90218929  2.2833347   5.43012759
  2.70922796  5.15540163  2.39182528  4.8896222   0.26245475 13.9258049
  4.19739144  7.30139654  4.63588701  4.64902648  1.05065641  2.33821152
  0.43372604  1.81929257]
mAP score regular 24.20, mAP score EMA 6.33
starting validation
Accuracy th:0.5 is [76.80693624 97.22450607 90.29075417 97.17467673 98.22358422 96.86573486
 97.33163914 94.85013828 97.41136607 96.31013778 98.5250517  98.5325261
 99.34972718 95.11921668 97.20955727 96.31512071 96.21047911 97.50604181
 98.7193861  98.33071729 98.31825996 99.14791838 99.49921519 98.05665595
 95.43563296 96.52938685 94.22228866 96.81092259 97.81747515 98.12641702
 97.95699728 98.62720183 96.62406259 98.24600742 98.54249197 98.57488103
 97.26935247 97.52846501 97.94952288 92.79716969 97.82744101 92.62774996
 97.1024242  96.51443805 97.03764606 94.09273239 98.19119516 98.76672397
 97.93955702 98.61723597 98.52256023 98.54996637 98.87385704 97.94453995
 98.6969629  97.58576874 89.54331415 96.52440392 96.11331191 96.78102499
 91.24498592 97.53095647 96.26030844 96.95542766 98.34815756 97.4238234
 98.14385729 95.7769639  98.72436904 97.64307248 99.81563146 96.43720258
 98.04419862 95.48795376 95.8218103  97.00774846 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [73.6726711  97.22450607 90.0864539  97.0351546  98.06413035 96.99778259
 97.39641727 94.87007001 97.39641727 96.43221965 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.75426664 98.34068316 98.27092209 99.14791838 99.44938585 97.92211675
 95.43563296 96.52938685 94.3393876  96.79846526 97.81747515 98.11146822
 97.76764581 98.66955677 96.50945512 98.19866956 98.42539303 98.5923213
 97.27931833 97.37399407 97.72030795 92.74235743 97.82744101 92.49321075
 97.080001   96.48952338 97.03764606 94.03792012 98.18870369 98.77419837
 97.95948875 98.5997957  98.49017116 98.55993223 98.87385704 97.84986422
 98.6969629  97.58576874 89.44116401 96.45962578 96.16314124 96.78102499
 90.61215337 97.52846501 96.11082044 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.55088821 99.81563146 96.52938685
 98.03174129 95.45307322 95.76450657 97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [87.18427315 14.25808138 45.95160853 35.96264941 47.63142605 44.73604829
 49.56701893 28.10886215 24.36429755 26.27731647  8.19762444 16.20119813
  3.6947035  15.69512373 12.17334847 24.20975918 11.19246112 14.34730737
 17.09165751 15.51536771 32.28842029 25.24153701 86.79542499 47.38498926
 16.06897148 12.14942805 21.78899545 18.29013318  8.0726257  21.67860157
 55.09048295 23.05074688 43.27510209 35.29823039 55.63731495 62.92485816
 21.05629679 56.89491556 67.45785595 31.50408406 15.6326908  38.69767017
 28.36737563 26.00773819 21.57137756 31.36249231 14.66248609  9.05701922
 23.01515433 20.53043252 43.68886483 17.2024465  10.81101245 58.57670785
  7.46247372 14.99775212 41.01235361 32.63476584 16.90081629 23.42918594
 50.27534594 51.88847324 38.4898193  28.35392065 30.16984947 21.63071123
 27.72367876 13.2284011  20.3993093  31.68956622  5.38010984 50.37263319
 27.01248889 27.76571896 26.13046539 18.274712    2.14730659 10.20265518
  0.79416068  4.92106131]
Accuracy th:0.5 is [55.6792984  97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.3864514  96.41976231 98.5250517  98.5325261
 99.34972718 95.07935322 97.2070658  96.25283404 96.21047911 97.50604181
 98.78167277 98.34068316 98.21610982 99.15040985 98.31327703 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39733911 98.18870369 98.00931809 97.89221915
 97.27931833 96.79597379 97.0276802  92.74484889 97.82744101 92.37362035
 97.07501806 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 89.02758054 96.35996711 96.16314124 96.78102499
 89.57072028 97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [46.08964297 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.31327703 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.89471062
 97.27931833 96.78102499 97.0276802  92.74484889 97.82744101 92.37362035
 97.07750953 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 89.02758054 96.39235618 96.16314124 96.78102499
 90.13379176 97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [63.87223366  6.22486256 16.93873015  6.44076687 12.02730818  6.38135576
  5.79775373  7.50983452  3.81394587  4.29931716  1.69691631  1.42158885
  0.71638667  8.39175344  3.90960771  8.31711027  5.10351909  3.04687959
  3.20364741  3.605971    9.68015669  6.59015658 23.57164501 10.74025574
  4.83000371  3.23872365  9.23278446  5.66256375  3.40107561  4.59929206
  9.89436774  7.13482072 12.2908425   4.62780024  8.32905848 18.80921765
  4.59568525 23.10554396 10.39596663 16.20439145  4.7672447  17.47570756
  8.94947295  6.74949703  7.85247051 12.45438571  4.56523525  2.39257901
  7.61374995  3.68352987 10.49205901  3.47015659  3.10649113 18.53614967
  3.20017875  3.01802362 23.34481312  8.13505159  7.34445593  6.6903412
 27.8123474  24.01486952 11.04510998  6.04596153  3.17549801  6.74379436
  3.61781318  6.61434462  3.95147558  8.74756877  0.4804692  26.62956587
  6.57144152  8.56812005  6.55339431  4.80302306  1.05161716  2.40676674
  0.59470764  2.75607733]
mAP score regular 28.33, mAP score EMA 8.70
Train_data_mAP: current_mAP = 24.20, highest_mAP = 24.20
Val_data_mAP: current_mAP = 28.33, highest_mAP = 28.33
lr:  [4.2641964479497305e-05, 4.2641964479497305e-05]
BCE Train Loss:  tensor([71.7837, 18.2205, 31.1422,  7.1504, 16.9898,  9.5033,  9.4237, 14.7224,
        15.4443,  7.7287,  8.7423,  1.5250,  4.4484, 27.7794, 10.4149, 11.1443,
        16.4387, 13.8934,  7.0040, 20.0540,  5.6078,  0.7557,  1.0539,  4.5519,
        22.2014, 14.0429, 25.4100, 20.6476, 13.5013, 11.1552, 13.1545,  6.3973,
        19.8145, 12.4752,  8.4347,  9.2869, 17.0836, 15.3404,  6.7044, 15.2581,
         2.5825, 27.4924, 17.8315, 20.9593,  7.6779, 14.1653,  4.9853,  7.7873,
         9.6273,  8.1281,  6.4573,  9.7077, 12.8155,  5.5224, 19.9936,  9.6737,
        37.4793,  6.6368, 22.5651, 14.9717, 29.2707,  9.5009, 11.4367, 12.6632,
        10.8059, 12.7784, 10.4872, 38.5287, 12.6047, 11.5688,  0.2681,  5.2819,
        16.7100, 22.2321, 10.6320, 19.2386,  5.8476, 12.0073,  0.2380,  7.9775],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [7/80], Step [000/642], LR 4.3e-05, Loss: 1093.6
BCE Train Loss:  tensor([72.9132,  6.7059, 39.0517, 15.7253, 18.4843, 17.3668, 29.4089, 24.7793,
         7.9927,  7.6505,  4.6033,  9.6095,  3.4627, 29.4035, 24.6619, 17.2277,
        22.0720, 31.3892,  5.6516, 15.2082,  2.6015,  0.8564,  5.9557,  8.0117,
        34.6260, 16.3515, 31.5141, 13.7197,  9.0928, 14.4381, 11.0641, 10.2523,
         9.8019,  6.5029,  5.7866,  4.5217, 13.9712,  6.3529,  3.4359, 31.0060,
         9.2928, 15.5223,  8.3415, 15.0072,  7.4168, 18.5123,  3.5498,  5.9987,
         1.6696, 10.1025,  3.1901,  4.2965,  1.1723,  1.7030,  1.3834,  8.3029,
        33.4306, 25.4868, 15.6951,  9.6497, 14.7030,  3.6730, 13.2239, 11.0041,
        10.4152,  9.6676, 11.4403, 17.3041, 12.6487,  9.4548, 12.5911, 27.3104,
        10.6299, 22.3762, 11.5858, 17.5211,  8.5634, 19.6004,  0.1366, 11.6385],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [7/80], Step [100/642], LR 4.4e-05, Loss: 1098.4
BCE Train Loss:  tensor([65.0035, 15.8449, 30.6691,  7.4867,  4.3453, 10.7558,  8.0892, 26.6884,
        26.6870, 13.2616, 11.1936,  5.5774,  9.6832, 13.8324, 11.1864, 22.4635,
        14.9530, 18.6337,  6.2355,  5.7837,  3.7508,  1.0342,  1.1410,  3.6264,
        11.9502, 18.7942, 24.1569, 10.6414,  8.5191, 12.9658,  3.9960,  4.2513,
        21.5798,  9.7575,  3.8290,  9.4962,  7.2580, 16.3456, 19.1328, 23.1267,
         5.4007, 25.1751, 16.0458, 27.7887, 14.4353, 16.3050, 14.6991, 11.0950,
        11.7399, 10.2004,  7.8488, 13.9304, 23.5613,  6.2100,  5.4175, 10.5308,
        44.7200, 15.8090, 19.8226, 17.8020, 37.4174, 16.1020, 17.0286, 12.3816,
         1.7576, 16.1798,  2.0128, 18.1634,  4.9801, 11.3691,  6.0935, 13.2110,
         2.7324, 14.3758,  9.9800, 19.3384,  1.1157, 11.4224,  0.1815,  6.4326],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [7/80], Step [200/642], LR 4.6e-05, Loss: 1084.5
BCE Train Loss:  tensor([71.0789,  7.6616, 22.3534,  7.2915, 16.8592, 17.1331, 15.1847,  9.8567,
        16.2851, 17.1918,  8.0966,  9.6418,  5.9161, 21.0274, 11.4626, 16.1200,
        14.6906, 14.3887, 13.2991,  2.2528, 16.4222, 12.6226,  1.0085,  4.9054,
        15.0325, 13.2288, 16.7524,  6.4583, 14.2546, 10.8516,  4.8656,  7.7764,
         7.1978,  7.5860,  6.9280,  4.6701,  8.8479, 17.1962,  9.0681, 29.1597,
         7.6062, 22.4052,  8.6673, 17.0935,  9.2259, 24.4014, 18.6343, 12.2016,
         8.3350,  9.8384,  3.7404,  1.7374,  4.4565, 17.2498,  5.6897,  9.0430,
        25.6250, 13.4575, 10.3347, 20.7354, 23.4911, 12.0060, 13.1404, 10.0108,
         9.0843,  7.7366,  8.1130, 15.8454,  5.6090, 12.8920,  0.2744, 16.3155,
        15.8968, 16.9791, 11.6211, 10.9779,  4.9926, 11.3765,  0.1731,  4.4259],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [7/80], Step [300/642], LR 4.7e-05, Loss: 994.1
BCE Train Loss:  tensor([67.7642, 15.7284, 33.4307, 10.2691,  4.1349,  9.4633, 11.9956, 24.9419,
        11.1939, 16.1431, 14.3339,  4.9221,  0.7147, 10.8712, 14.9435, 13.9269,
        19.3859, 17.7407,  8.4611,  8.8563,  8.1916,  0.9965,  2.3518,  8.9755,
        13.6762,  7.8961, 14.6173, 10.3912, 12.9775, 12.2782,  4.3137, 12.8275,
        14.5784,  7.5300,  3.8009,  1.7317,  7.9420, 12.6867, 10.9680, 20.2804,
        15.9769, 22.1039,  6.9790, 13.8842, 15.3254, 23.0851,  6.2427,  1.7962,
         3.3397, 17.8276,  6.5264,  5.5473,  1.3025,  3.4055,  8.6352, 12.1454,
        31.4282, 13.7552, 18.2153,  6.3373, 32.6077, 16.3476,  8.2694, 16.2342,
         2.7075,  3.8414,  5.5602, 15.2766, 12.1631, 17.5769,  3.1862, 24.0909,
        18.1799, 14.3975, 30.4069, 21.9446, 13.0823,  5.1893,  0.2650,  8.2247],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [7/80], Step [400/642], LR 4.8e-05, Loss: 1011.6
BCE Train Loss:  tensor([59.3948, 14.9540, 26.1766, 16.9013, 10.6221, 13.9561,  4.2515, 12.0121,
        20.9977, 11.5621, 14.9206,  8.6448,  0.7773, 29.2796, 16.0436, 21.8237,
        19.8050,  5.0271,  3.9837, 11.2599,  5.9473,  0.8598,  0.4317,  9.2621,
        20.4995, 15.2066, 22.2993, 12.2582, 10.0694,  2.4537, 17.4448,  3.7355,
         8.3364, 13.5112, 12.4829,  4.2986, 11.0631,  5.9783,  9.2887, 21.0776,
         8.1380, 28.2494,  5.5418, 15.6424, 11.0617, 15.8745,  7.1070,  5.2749,
         7.3975,  7.1418,  4.9607,  9.7357,  2.8091,  7.1397,  4.7967, 12.9054,
        25.7648, 13.0556, 22.8543, 13.2034, 29.1693,  6.8029,  4.9537, 15.4052,
         1.7423,  9.1889, 10.0999, 14.5937,  6.2620,  5.7275,  4.2739, 15.4733,
         9.5744, 23.6962, 15.2955, 16.9094,  5.0965,  9.1529,  5.7793,  9.3679],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [7/80], Step [500/642], LR 5.0e-05, Loss: 976.1
BCE Train Loss:  tensor([51.0649,  9.9834, 35.4546, 19.8213, 10.4544, 10.7345,  8.0192, 16.6985,
         3.9077,  6.9307,  8.3666, 15.7332,  0.8192, 28.2176, 14.7504, 15.2405,
         9.8431, 20.2646,  2.3085,  2.2381,  1.8779,  7.9002,  1.1144,  6.6396,
        28.3094, 10.3445, 16.3190, 16.1337, 15.5591,  4.9158,  5.3082,  8.9984,
         7.1507,  4.8205,  8.4049,  2.4097, 25.1229,  6.2393,  6.2499, 28.7048,
         9.2383, 20.3748,  8.3399, 13.0368, 16.2987, 24.9876,  6.2895,  5.7075,
        12.2186, 15.5815,  4.9333,  2.9039,  5.2774,  9.8009,  6.0317, 15.8672,
        27.6195, 11.1711, 21.1649, 12.4652, 25.0433,  5.0198,  9.7479, 20.7032,
        13.3885,  5.9093, 14.1553, 26.1755,  7.9741, 10.7901,  0.1752,  7.5321,
        16.2854, 18.5753, 26.7311,  8.8048,  4.4890,  4.0525,  0.2898,  1.1935],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [7/80], Step [600/642], LR 5.1e-05, Loss: 979.7
BCE Val Loss:  tensor([6.1897e+01, 6.5873e+01, 8.5122e+01, 3.7565e+01, 1.7757e+00, 1.2238e+01,
        7.5780e+00, 2.1144e+01, 7.8178e+00, 1.3226e+01, 6.3586e+00, 1.1331e+01,
        5.7755e+00, 1.8074e+01, 6.4131e+00, 1.4322e+01, 3.6761e+02, 4.5628e+00,
        1.1955e+00, 2.1463e+00, 2.3917e+00, 1.0535e+00, 1.2421e+00, 2.0947e+00,
        2.9979e+01, 1.7206e+01, 2.8335e+01, 5.3627e+00, 9.7966e+00, 9.6541e+00,
        1.4624e+00, 8.0579e-01, 5.5375e+00, 9.4560e-01, 2.1748e+00, 1.3088e+00,
        7.9863e+00, 3.0943e+00, 2.5851e+00, 5.3743e+01, 1.0261e+01, 2.3859e+01,
        9.4736e+00, 1.6995e+01, 1.5713e+01, 2.0799e+01, 2.2351e+00, 4.9794e+00,
        1.8363e+00, 4.0398e+00, 7.0348e-01, 5.3197e-01, 6.8393e+00, 9.6008e-01,
        1.2003e+00, 2.2087e+00, 2.6033e+01, 9.3130e+00, 2.0543e+01, 6.7055e+00,
        1.2439e+01, 1.7281e+01, 6.9734e+00, 5.8610e+00, 1.6277e+00, 3.3317e+00,
        1.9474e+00, 1.2625e+01, 9.1165e+00, 2.1782e+01, 2.1939e-01, 1.9611e+01,
        1.6080e+01, 1.3538e+01, 1.1878e+01, 9.8016e+00, 7.0926e-01, 6.3539e+00,
        3.2055e-01, 1.1185e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [7/80], Step [000/314], LR 5.2e-05, Loss: 1296.6
BCE Val Loss:  tensor([7.3400e+01, 1.9625e+01, 5.7404e+01, 1.0388e+01, 4.7249e+00, 4.4035e+01,
        9.0970e+01, 4.8763e+01, 3.3080e+01, 3.1430e+01, 1.5705e+01, 1.6685e+02,
        8.0026e+00, 1.2696e+01, 1.4253e+01, 3.8348e+00, 1.2435e+01, 1.6915e+01,
        2.4927e+00, 1.5938e+01, 2.3322e+00, 9.2556e-01, 9.4685e-01, 3.8204e+00,
        2.8737e+01, 2.2725e+01, 3.1541e+01, 1.5929e+01, 1.3130e+01, 2.1016e+00,
        9.3844e-01, 5.4482e-01, 1.7949e+00, 2.8149e+00, 1.1781e+00, 6.3367e-01,
        7.0724e+00, 3.5283e+00, 1.1645e+00, 2.5506e+00, 6.2006e-01, 2.9938e+00,
        7.2942e-01, 1.4985e+00, 7.9029e-01, 3.6740e+00, 1.1445e+00, 8.6631e-01,
        5.9411e-01, 6.1023e+00, 2.9988e-01, 2.8977e-01, 5.6966e-01, 1.3985e+00,
        3.8785e-01, 2.8235e+00, 1.2290e+01, 3.7250e+00, 9.1438e+00, 9.5144e-01,
        4.5500e+00, 1.0688e+00, 1.5528e+00, 9.7345e-01, 4.6496e-01, 5.8503e-01,
        6.0323e-01, 1.6190e+01, 3.0877e-01, 3.1529e+00, 4.4137e-02, 1.1175e+00,
        3.2749e+00, 4.3124e+00, 7.4904e+00, 9.5942e-01, 3.1554e-01, 9.5737e-01,
        5.4307e-02, 2.4308e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [7/80], Step [100/314], LR 5.2e-05, Loss: 926.5
BCE Val Loss:  tensor([4.8606e+01, 1.1826e+00, 6.2110e+00, 1.0934e+00, 2.5077e-01, 4.9828e-01,
        1.8350e-01, 1.5047e+01, 3.1180e-01, 5.0259e-01, 5.5999e-01, 2.2903e-01,
        1.7478e-01, 1.6651e+01, 1.0647e+00, 5.5426e+00, 4.8914e+00, 8.7174e-01,
        3.9966e-01, 4.8464e-01, 5.8354e-01, 4.5441e-01, 4.5691e-02, 2.6895e-01,
        5.5401e+00, 1.5895e+00, 2.4656e+01, 8.8739e+00, 1.3413e+00, 9.2016e-01,
        1.1788e+00, 5.8075e+00, 7.9545e+00, 8.8805e-02, 7.8662e-01, 4.9400e-01,
        1.5717e+01, 1.6792e+01, 6.8096e-01, 3.6983e+01, 3.1926e+01, 6.7711e+01,
        7.5970e+01, 8.3611e+01, 4.4984e+01, 7.0355e+01, 1.0247e+01, 9.2522e+00,
        4.0053e+01, 1.1776e+01, 2.6381e+01, 5.1028e+01, 7.1833e+01, 2.9574e+01,
        7.3005e+01, 1.1523e+02, 1.2352e+02, 1.9357e+01, 9.5352e+00, 4.8791e+00,
        9.5361e+01, 9.8558e-01, 1.2714e+01, 1.4848e+01, 1.6120e+01, 5.5822e+00,
        1.0307e+01, 1.3423e+01, 6.5203e+00, 3.8948e+00, 2.4592e-01, 6.8778e+00,
        7.6482e+00, 4.0862e+01, 2.6365e+00, 1.3382e+01, 1.1089e+01, 3.8598e+00,
        3.0090e-01, 1.1670e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [7/80], Step [200/314], LR 5.2e-05, Loss: 1473.6
BCE Val Loss:  tensor([7.1448e+01, 5.7870e+00, 2.7861e+01, 3.3748e+00, 2.7018e+00, 1.3361e+01,
        1.4386e+01, 1.8038e+01, 5.4659e+00, 2.4495e+01, 5.3102e+00, 7.5140e+00,
        1.1046e+00, 1.7124e+01, 1.8117e+01, 3.6796e+00, 2.4715e+00, 3.5155e+00,
        7.0505e-01, 1.1694e+00, 2.2852e+00, 4.9044e-01, 6.5778e-01, 7.6153e+00,
        2.7230e+01, 3.8352e+00, 2.9799e+01, 2.4744e+00, 1.6808e+01, 1.0145e+00,
        1.9615e+00, 1.1923e+00, 8.4260e-01, 1.2147e+00, 4.9449e-01, 2.1833e-01,
        4.5517e+00, 7.9630e-01, 9.3448e-01, 5.6015e+00, 9.6538e-01, 3.4383e+00,
        8.3569e-01, 2.3643e+00, 1.3900e+00, 3.7099e+00, 1.4955e+00, 6.9127e-01,
        7.4184e-01, 5.1052e-01, 4.0990e-01, 2.6962e-01, 4.3374e-01, 6.7023e-01,
        4.5328e-01, 1.0352e+00, 8.9272e+00, 1.6435e+00, 1.3270e+01, 1.9548e+00,
        9.5131e+00, 2.7264e+00, 2.2919e+00, 1.8360e+00, 8.6812e-01, 1.1076e+00,
        1.0797e+00, 7.4229e+00, 1.0081e+00, 1.8126e+00, 1.1828e-01, 3.4609e+00,
        1.3258e+00, 6.4893e+00, 2.9718e+02, 4.1548e+00, 3.9955e-01, 4.5709e+00,
        1.7491e-01, 3.7336e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [7/80], Step [300/314], LR 5.2e-05, Loss: 750.8
starting validation
Accuracy th:0.5 is [76.27343721 97.20885467 90.33272012 97.24540393 97.7424739  97.06509424
 97.42571362 94.830716   97.50368538 96.51320038 98.53193796 98.55874076
 99.41399349 95.31316626 97.27464334 96.5728975  96.29512311 97.47931921
 98.65255053 98.31264239 98.2297974  99.18860638 99.40668364 98.23954387
 95.21935649 96.65086926 94.08998428 96.76051705 98.01293844 98.15426225
 97.76318515 98.52219149 96.49005251 98.16400872 98.35284658 98.45640282
 96.97006615 97.80338933 98.06898064 92.76933761 97.84115691 92.32587322
 96.89818594 96.168419   96.9201155  93.86094224 98.03974123 98.55995906
 97.93131175 98.55264921 98.51731826 98.55508583 98.99976852 97.93253006
 98.70615611 97.46591781 89.84661493 96.23908091 96.24273583 96.93351689
 91.13193065 97.50490369 96.25857385 97.0175802  98.47467745 97.35505172
 98.24198048 95.95277835 98.67326178 97.59262192 99.81603538 96.43766523
 97.98979057 95.47885625 96.20253165 96.91402395 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [73.03029934 97.2137279  89.76376993 97.143066   97.66206552 96.9907774
 97.25393209 94.75883578 97.45738965 96.49127082 98.53193796 98.53437458
 99.41399349 95.31682119 97.27098841 96.56558765 96.29512311 97.48053752
 98.65498715 98.30776915 98.19690306 99.18616976 99.36160622 98.133551
 95.21935649 96.65086926 94.07901951 96.75077058 98.01293844 98.1603538
 97.60967824 98.57457877 96.51441868 98.07629049 98.27365651 98.34431842
 96.94691829 97.64988243 97.9374033  92.72791511 97.84237521 92.15043676
 96.91402395 96.25857385 96.96519292 93.89992812 98.04095954 98.57336046
 97.99588212 98.53193796 98.46005775 98.55508583 98.99976852 97.83872029
 98.70615611 97.46591781 89.38609422 96.17451054 96.24273583 96.90793241
 90.61414944 97.34774186 96.18425701 96.98590417 98.4393465  97.34530525
 98.21030446 95.95277835 98.67448009 97.5621642  99.81603538 96.09288386
 97.9654244  95.45449008 96.16963731 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [87.36157107 14.86633584 45.30525621 35.94070404 50.43848262 46.32976718
 48.77296008 31.32923931 24.47998142 28.67700378  7.63526623 19.85662113
  3.92056211 15.17845946 12.13134495 22.3732241  11.5704539  14.74223958
 21.39252142 17.73628124 30.17747795 20.57539693 82.42412753 52.91889708
 16.85377947 11.89435553 23.71843029 18.55149102  7.74395524 23.90129904
 50.22016388 20.91553477 41.419464   37.47005286 54.2467998  62.68711066
 23.4301385  55.02330197 64.04908442 30.14599925 15.06780807 38.04410105
 30.08003543 27.53845319 21.94586666 32.24774761 16.63335463 13.89659879
 24.35564847 19.51852955 40.10272807 17.53423716  8.48923861 55.18585839
  7.47460386 16.31907458 42.72678052 32.17464294 17.42972607 24.30474394
 51.32872666 47.83679656 36.49927584 23.33855594 24.16534409 21.68049078
 23.52233972 12.29626009 21.87823478 31.96371004  4.73852242 47.22842865
 28.77495305 27.36279416 20.70581517 17.20468113  3.06866067 10.11530004
  1.08943652  6.39918825]
Accuracy th:0.5 is [57.94276386 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31560288 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.14938902 99.18616976 98.38817753 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36578502 98.02024829 97.80338933 97.70714294
 96.94082674 97.15403077 97.11504489 92.72913342 97.84237521 92.05906361
 96.90793241 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.32337569
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.73818545 97.17839695 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [45.05183904 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.38695922 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70470633
 96.94082674 97.14550261 97.11504489 92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.79300934 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [65.8697657   5.84659771 20.52769676  8.3164442  12.34416346 10.2496726
  7.79434468 10.68479256  5.94428798  6.79085459  2.06021769  1.77356507
  0.81576498  7.35025175  4.08595474  7.06853822  4.69931999  3.80992588
  5.6358673   4.25190601  7.24472086  3.26351877 34.80775736  9.81730112
  5.82189766  4.02955888 11.17881577  5.69465309  2.95166769  4.68244355
 13.20863295  6.83836374 13.7054742  10.08635673  7.5606877  14.93686004
  5.82522083 19.5327866  12.13419425 15.40496573  4.91824275 18.36171706
 10.28011466  8.51899707  7.1453015  12.85327138  5.31683564  2.98483029
  7.1981831   4.01241457 11.14912318  4.25510815  2.40855223 16.61689104
  3.08620599  3.8499717  23.11836239  9.42249127  7.74901259  6.29009301
 25.87668981 16.60835368 11.27682553  6.43551778  3.03435513  6.44743469
  3.42854025  5.88218949  3.5154456   7.48923721  0.35983057 19.34321884
  5.80960747  8.8204232   5.87564944  5.69157687  1.16702085  2.71937281
  0.43430359  2.14432612]
mAP score regular 28.13, mAP score EMA 8.96
starting validation
Accuracy th:0.5 is [78.58584349 97.22699753 90.86379151 97.41136607 98.29832823 97.080001
 97.67297008 94.84017241 97.52348207 96.42474525 98.5250517  98.60228717
 99.34972718 95.11921668 97.23198047 96.34252685 96.21047911 97.50853327
 98.73184344 98.32075143 98.4652565  99.20273065 99.56897626 98.4951541
 95.43065002 96.52938685 94.34187906 96.81341406 97.81747515 98.03672422
 98.19866956 98.54249197 96.59167352 98.36808929 98.6296933  98.7941301
 97.341605   97.66798714 98.30580263 92.82955876 97.81249221 92.78471236
 97.00276553 96.22044498 96.96041059 94.04788599 98.15382316 98.7418093
 97.75269701 98.6446421  98.53501756 98.55993223 98.87385704 98.11146822
 98.6969629  97.58826021 89.85973042 96.60413085 96.16064977 96.85327752
 91.6735182  97.72279941 96.44716845 97.0276802  98.40047836 97.42880634
 98.23355009 95.7769639  98.72436904 97.62812368 99.81563146 96.73368712
 98.08655355 95.52283429 95.93143484 97.00774846 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [76.88168025 97.22450607 90.12880883 97.2220146  98.29583676 97.19460847
 97.42133194 94.94232255 97.44126367 96.43471111 98.5250517  98.57238957
 99.34972718 95.11423375 97.2145402  96.31761218 96.21047911 97.50604181
 98.7567581  98.34068316 98.38552956 99.15040985 99.55402746 98.33071729
 95.43563296 96.52938685 94.3393876  96.79846526 97.81747515 98.14385729
 98.02675835 98.67204823 96.63651992 98.26095622 98.5997957  98.6745397
 97.28430127 97.65054688 98.12641702 92.73986596 97.82993248 92.58041209
 97.09993273 96.49948925 97.03017166 94.11515559 98.18870369 98.75177517
 97.94952288 98.6222189  98.52256023 98.55993223 98.87385704 98.05665595
 98.6969629  97.58576874 89.51341655 96.51443805 96.16314124 96.80095672
 91.43433739 97.46866981 96.21795351 96.93798739 98.35314049 97.40389167
 98.14884022 95.7769639  98.72436904 97.54092234 99.81563146 96.49201485
 98.03423275 95.45805616 95.82430177 97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [89.38200981 15.79554635 50.23840103 45.55877961 52.69620833 50.56825397
 60.03530115 32.77453951 30.94925536 29.87446887 11.81896779 24.69784844
  4.12191736 16.61913867 15.78871743 28.31251267 14.76341103 17.6569644
 20.63377685 18.85180291 42.86880204 32.76068792 88.97561802 62.93372273
 17.69617905 15.29395458 23.40726769 22.668936   10.57245057 25.7036503
 62.24494415 25.09903404 46.65062389 42.63767983 61.84741486 70.12300969
 28.77715729 62.21842915 74.39045909 32.61218508 16.53242643 40.94122021
 31.43568683 27.92683139 24.10059795 34.44310991 16.75485912 11.98167625
 26.97279355 24.29848135 45.97069928 18.25070621 11.61569754 64.49623671
  9.90399905 17.50651646 44.27932549 36.44201394 18.57789291 29.6848207
 54.34556971 57.45632196 43.67162638 31.89293821 36.46152344 23.47824416
 34.36197534 15.08425259 23.41070094 37.1850769   6.19953874 53.9422965
 30.5525392  30.66621129 31.62591041 21.96116798  3.17473995 12.36950034
  0.98338649  6.26941801]
Accuracy th:0.5 is [58.22806886 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.38395994 96.41976231 98.5250517  98.5325261
 99.34972718 95.09679348 97.2070658  96.26778284 96.21047911 97.50604181
 98.78167277 98.34068316 98.12890849 99.15040985 98.33071729 97.87976182
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.37989885 98.18870369 98.00931809 97.92959115
 97.27931833 96.98781673 97.0276802  92.74484889 97.82744101 92.37362035
 97.06754366 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.24194633
 98.6969629  97.58576874 89.02758054 96.38737325 96.16314124 96.78102499
 89.81239256 97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07593991
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [46.41104218 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.31327703 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39983058 98.18870369 98.00931809 97.89471062
 97.27931833 96.79099086 97.0276802  92.74484889 97.82744101 92.37362035
 97.07750953 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.21703167
 98.6969629  97.58576874 89.02758054 96.39235618 96.16314124 96.78102499
 90.13628323 97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [68.90046009  8.67395099 25.19555486 13.53462227 22.75698129 16.45554596
 13.75097541 11.22465203  9.43123761  7.78831668  2.05541075  2.65840055
  0.85413985 10.16038991  4.64331589 10.50675351  5.65798171  4.55517634
 10.01944705  5.41584144 12.48552358  9.87085743 52.22563037 14.32514435
  6.35590953  4.35771773 12.61825929  7.24489578  3.75558937  7.69210278
 22.79773881 11.7595282  17.29049584 11.58247613 17.40036053 28.38704641
  7.08068567 33.64710851 22.42298488 20.67410391  6.55716141 21.55815839
 13.36693772 10.63455508 10.60171995 15.91733688  6.27969927  3.36563388
 11.10729547  7.34744556 16.49785314  5.16351466  4.14979491 25.44575478
  3.94018859  4.73990095 26.86590215 11.97291821  9.37399847  8.02918526
 31.85581035 32.16735677 14.90571186  8.2552514   5.03443239  7.89679654
  5.36623946  7.6697905   6.72714252 13.2434714   0.71480502 33.17506179
  9.62145229 10.48905562  9.41496986  6.40657857  1.15664131  2.68265406
  0.63721543  3.06240528]
mAP score regular 32.35, mAP score EMA 12.65
Train_data_mAP: current_mAP = 28.13, highest_mAP = 28.13
Val_data_mAP: current_mAP = 32.35, highest_mAP = 32.35
lr:  [5.200734088437272e-05, 5.200734088437272e-05]
BCE Train Loss:  tensor([65.2801, 18.0525, 32.7792, 10.4247,  6.9932, 10.1169, 17.7985, 26.2445,
         8.7012, 24.3978, 15.4437,  4.2781,  8.3116, 34.9949, 12.7909, 22.2345,
        29.7740, 17.1591,  4.2820,  5.3272, 10.5460,  1.3239,  0.6506,  4.5086,
        14.2459, 12.5108, 26.9388, 15.8968,  6.3620,  9.4366,  8.2299,  5.3891,
        13.7605,  1.7616,  6.7674,  7.9850, 17.4957, 15.9067, 14.3110, 33.3734,
         5.4727, 18.3367,  7.7275, 15.0161, 10.6083, 10.1061,  9.6678,  2.1541,
         8.8304,  8.2010,  3.3119,  3.1167,  8.6598,  4.2183, 11.6964,  8.6545,
        31.3266, 16.7025, 17.8171, 28.0432, 26.1687,  5.2514, 11.5111, 12.0112,
         4.0292, 16.8569, 11.8041, 15.7118,  7.4637, 12.4038,  3.7623, 12.9464,
         9.1178, 16.9646, 17.0534,  7.6752, 19.5389,  8.5296,  0.2827,  0.9392],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [8/80], Step [000/642], LR 5.2e-05, Loss: 1052.5
BCE Train Loss:  tensor([71.6236,  8.4838, 29.0219, 11.6803,  5.1742, 14.0429,  4.8801, 10.3191,
        15.0686, 19.1059,  9.6637, 13.4268,  6.2753, 21.2498, 12.4426, 16.0681,
        27.0217, 16.1358,  1.6327,  2.0856,  6.5877, 10.0726,  8.9789,  6.7644,
        20.9254, 14.6819, 20.3751, 11.2306, 17.8588,  3.9325, 12.7623, 13.3574,
         6.0787,  4.1635,  3.0469,  2.4138,  7.0156,  4.9836, 10.3955, 31.8206,
        10.3028, 29.4615, 23.5784, 10.7577, 21.4281, 32.0765, 20.6596, 15.2264,
         7.1006, 11.5832,  2.5427,  6.3622,  6.2079, 16.7569,  2.4213, 13.2042,
        33.8284, 28.7160, 23.5648,  9.0774, 37.5770,  9.0986, 11.7048, 10.5059,
         8.3905, 14.0796,  6.3255, 28.6071,  6.4670,  5.7275,  2.9751, 15.4718,
        13.1142, 28.4808, 16.6798, 30.8149,  1.4112, 11.1714,  0.2134, 11.7176],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [8/80], Step [100/642], LR 5.3e-05, Loss: 1128.2
BCE Train Loss:  tensor([59.7267, 17.0338, 30.4613, 11.0051, 10.6341,  5.6425,  9.7716, 18.0212,
        12.8417, 10.3586,  8.1958,  1.5573,  3.9830, 23.6178,  4.6871, 26.1909,
        10.8811, 17.5835,  3.6317, 10.4694, 10.7681,  7.2106,  0.6995,  4.0114,
        14.7821, 22.3131, 26.4242, 21.4884, 12.7029, 10.5313,  7.2905,  7.0019,
         6.8231,  7.0271, 15.6730, 11.1270,  8.6903,  4.3189,  3.3007, 31.6599,
        13.6260, 26.4743,  8.4916, 18.2532, 18.8627, 30.1222, 11.7744, 11.4661,
        10.3089,  5.2505,  1.3748,  5.6894, 16.9121, 13.1629, 15.8208, 15.9018,
        29.0208, 24.7073, 20.6576,  6.6967, 31.5046,  9.2915,  9.1434,  9.0153,
         7.6759, 11.4604,  9.9063, 13.5245,  1.9514,  7.7214,  0.2558, 11.0063,
         7.8406, 16.1668, 11.1051, 13.7044,  4.3524, 13.4025,  0.1705,  0.8714],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [8/80], Step [200/642], LR 5.5e-05, Loss: 1024.8
BCE Train Loss:  tensor([62.5750, 29.3551, 42.9768, 11.2819,  4.3254, 19.6362,  9.8439, 22.7502,
        10.2993, 17.7122,  9.2391, 18.4432,  5.8746, 24.2226,  6.2936,  8.9448,
         8.9627, 13.2830,  2.3148, 11.6526,  5.2922,  8.7148,  1.0061, 12.8102,
        18.5480, 18.1263, 28.6183, 29.1556,  9.7610,  1.8678,  6.3280,  9.8817,
        10.3423,  5.2926,  2.3822,  3.4763, 12.3117, 13.2885,  4.6442, 27.9742,
        26.4525, 26.5174, 13.7015,  8.2506,  9.2727, 18.0870,  5.9988,  7.1512,
         4.9261,  1.0559,  3.8587,  8.3252,  0.9394, 11.6169, 10.3725, 14.1041,
        43.9669, 12.0279, 27.0804,  5.7803, 43.6686,  8.1125,  5.7176,  2.7141,
         1.1075,  7.2297,  1.4452, 17.7662,  8.8722,  9.1032,  0.1408, 14.5924,
         6.6737, 10.1774, 19.8075, 23.0795,  4.5291, 11.6258,  0.1966,  3.6970],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [8/80], Step [300/642], LR 5.6e-05, Loss: 1029.6
BCE Train Loss:  tensor([65.5685, 16.7650, 41.4696, 14.5960,  7.3636, 20.7177, 16.9042, 27.1615,
        13.9860, 28.4385,  7.0716,  5.7097,  8.2842, 23.0559, 19.0581, 12.0228,
        14.2690,  5.4135,  4.9400,  4.6371, 14.9248,  1.8560,  0.4975,  7.6512,
        19.7743, 25.0893, 29.2947, 12.1687, 14.8084,  8.8540,  9.5468,  9.9749,
        11.1111, 12.9251, 12.0132, 10.5256,  7.8713, 12.6741,  5.2557, 16.5566,
        16.0092, 17.8359,  4.6711,  8.6781,  7.1530, 19.9895, 11.0051, 17.2427,
        12.1763,  6.0379,  2.5940,  4.5573,  3.5793,  2.5749, 13.3306,  2.8258,
        30.8549, 13.8964, 11.8369,  8.5808, 16.7137,  6.3977,  6.7737, 12.5071,
         8.9851,  4.0216,  7.1861, 20.6666,  6.3698,  8.1871,  6.4700,  9.1026,
         8.8235, 10.3776,  9.6663,  7.9979, 12.0681, 14.3713,  0.1622,  3.8747],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [8/80], Step [400/642], LR 5.8e-05, Loss: 997.0
BCE Train Loss:  tensor([52.3727, 19.6358, 22.8369, 13.3908,  7.5209, 12.8409, 11.7378,  8.0513,
        12.7099,  3.5165,  9.1806, 11.0976,  6.6462, 29.9993, 16.1601, 17.1766,
        20.4742,  5.0545,  7.2870,  5.0211,  9.0070,  5.1751,  1.3228,  2.2072,
        18.1355, 12.7417, 16.7653, 10.4845, 15.3508, 10.3856,  9.7727,  5.5326,
        21.7356,  8.0990,  7.3491,  9.6130, 16.7821, 15.7101, 14.3845, 35.5908,
        10.3438, 41.0712, 15.1597, 22.7980, 12.4912, 15.0037,  8.2931,  2.0502,
        10.4128,  3.9909,  5.8039,  4.8496, 20.9030,  7.8174,  6.3029,  5.0187,
        28.5419, 23.3161, 20.9626, 12.0253, 18.6965,  6.8810, 13.8849,  8.4401,
         8.2910, 10.7775,  6.4227, 21.2722,  5.3842, 14.0774,  0.2066, 13.8188,
         9.1562, 14.3839, 22.5953, 14.0412,  1.1306,  9.1536,  0.2431,  4.3496],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [8/80], Step [500/642], LR 5.9e-05, Loss: 1019.2
BCE Train Loss:  tensor([59.8308,  9.7729, 28.9703, 26.7009,  7.4188, 11.6081, 13.0530, 12.2733,
         5.0306, 20.8612,  9.1544,  8.9367, 14.3290, 24.5357, 15.7810,  9.5201,
        13.8296,  3.1658,  2.1575,  2.4235,  5.5609,  8.9573,  3.7255,  1.0123,
        21.9492, 20.0629, 26.7119, 10.8581,  9.2558, 16.8098, 10.9607, 10.8985,
        14.7971,  3.4976,  8.4113,  5.3655, 14.8750,  3.3545,  2.4870, 22.1243,
        11.8253, 25.5072,  8.7001,  8.4648,  5.7314, 16.6747,  1.7975,  1.8344,
         5.9964,  2.2774,  4.3019,  2.4975,  6.1697, 11.6438,  4.7918,  8.0757,
        23.1548,  9.4387, 18.7646, 14.3967, 26.9177,  3.2463, 15.2753, 10.7776,
        12.5897, 11.3250,  8.1591, 22.8802,  6.9653, 11.0516,  0.1116,  9.8580,
        15.6851, 26.6422, 20.2187, 16.2357,  0.9872,  1.5999,  0.1730,  5.9663],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [8/80], Step [600/642], LR 6.1e-05, Loss: 939.7
BCE Val Loss:  tensor([5.7997e+01, 6.5141e+01, 7.8412e+01, 3.4626e+01, 1.7531e+00, 1.1505e+01,
        8.2845e+00, 2.0063e+01, 7.4449e+00, 1.2372e+01, 5.5730e+00, 1.2517e+01,
        6.1151e+00, 1.8563e+01, 6.2592e+00, 1.6713e+01, 3.6713e+02, 6.9630e+00,
        2.0971e+00, 3.0636e+00, 2.1242e+00, 1.2449e+00, 7.9623e-01, 3.6857e+00,
        2.9391e+01, 1.6836e+01, 2.8689e+01, 5.0556e+00, 1.0432e+01, 9.3448e+00,
        6.7459e-01, 5.3059e-01, 6.0623e+00, 1.6885e+00, 1.6836e+00, 2.0618e+00,
        4.9648e+00, 2.4875e+00, 1.6533e+00, 4.9656e+01, 9.4721e+00, 2.5525e+01,
        9.5921e+00, 1.6217e+01, 1.4472e+01, 1.8797e+01, 1.5728e+00, 5.0748e+00,
        7.8460e-01, 4.3126e+00, 3.4525e-01, 7.1239e-01, 6.7978e+00, 1.1158e+00,
        1.3596e+00, 1.7687e+00, 2.5030e+01, 8.8048e+00, 1.8108e+01, 6.6640e+00,
        1.2331e+01, 1.4374e+01, 6.2036e+00, 4.4055e+00, 4.6234e-01, 2.1917e+00,
        6.8485e-01, 1.0206e+01, 9.0479e+00, 2.0206e+01, 2.7353e-01, 1.9802e+01,
        1.7262e+01, 1.2449e+01, 1.2174e+01, 8.9276e+00, 1.0670e+00, 5.9590e+00,
        2.7177e-01, 1.1190e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [8/80], Step [000/314], LR 6.1e-05, Loss: 1257.6
BCE Val Loss:  tensor([7.6724e+01, 1.8344e+01, 5.3731e+01, 1.0864e+01, 6.2020e+00, 4.4226e+01,
        7.3710e+01, 4.6408e+01, 3.6844e+01, 3.1067e+01, 1.6034e+01, 1.2948e+02,
        8.8754e+00, 1.3431e+01, 1.3474e+01, 3.4567e+00, 1.2646e+01, 1.6977e+01,
        3.4215e+00, 1.4196e+01, 1.7733e+00, 7.8923e-01, 6.9882e-01, 3.7530e+00,
        2.7226e+01, 2.2827e+01, 3.2407e+01, 1.5449e+01, 1.2648e+01, 1.3519e+00,
        4.3592e-01, 3.1533e-01, 1.1806e+00, 5.0533e+00, 1.0711e+00, 1.1873e+00,
        4.1256e+00, 4.9185e+00, 4.9721e-01, 2.7476e+00, 5.9994e-01, 2.7298e+00,
        5.7996e-01, 9.6172e-01, 6.0539e-01, 2.7781e+00, 7.4260e-01, 3.8660e-01,
        2.0063e-01, 6.1775e+00, 1.3536e-01, 3.3656e-01, 3.6366e-01, 1.9063e+00,
        4.0109e-01, 2.9042e+00, 1.2242e+01, 3.8278e+00, 9.0736e+00, 6.0438e-01,
        3.2279e+00, 6.4028e-01, 8.4749e-01, 3.8909e-01, 1.0996e-01, 2.8569e-01,
        1.6844e-01, 1.5857e+01, 1.3720e-01, 3.1904e+00, 3.6542e-02, 5.9267e-01,
        3.9920e+00, 4.2978e+00, 8.2303e+00, 4.2894e-01, 4.5094e-01, 5.2389e-01,
        3.1117e-02, 2.0602e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [8/80], Step [100/314], LR 6.1e-05, Loss: 861.8
BCE Val Loss:  tensor([4.4403e+01, 9.1804e-01, 6.2187e+00, 1.3398e+00, 1.8328e-01, 3.9413e-01,
        2.0813e-01, 1.4354e+01, 2.2933e-01, 2.9645e-01, 3.1152e-01, 1.4714e-01,
        1.4078e-01, 1.6133e+01, 7.3099e-01, 5.4500e+00, 4.3156e+00, 1.1357e+00,
        6.1823e-01, 6.3488e-01, 4.4958e-01, 3.8942e-01, 5.3007e-02, 2.3164e-01,
        5.5590e+00, 1.5142e+00, 2.7556e+01, 9.2920e+00, 1.7968e+00, 8.9569e-01,
        8.4296e-01, 6.2977e+00, 7.8082e+00, 1.7441e-01, 1.1804e+00, 1.3912e+00,
        1.7029e+01, 1.4046e+01, 5.1591e-01, 4.0434e+01, 3.1662e+01, 7.2403e+01,
        7.8979e+01, 8.4128e+01, 4.4605e+01, 6.9192e+01, 9.8448e+00, 9.0373e+00,
        4.1482e+01, 1.0300e+01, 2.5157e+01, 4.5299e+01, 7.2415e+01, 3.6093e+01,
        6.7227e+01, 1.1426e+02, 1.2656e+02, 1.8534e+01, 1.0782e+01, 4.3899e+00,
        9.4327e+01, 1.6172e+00, 1.1491e+01, 1.4385e+01, 1.7512e+01, 3.3460e+00,
        1.1440e+01, 1.2874e+01, 7.4118e+00, 4.6849e+00, 2.9341e-01, 7.3036e+00,
        7.6041e+00, 4.1380e+01, 2.3480e+00, 1.2636e+01, 9.9924e+00, 2.0573e+00,
        2.5883e-01, 1.2946e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [8/80], Step [200/314], LR 6.1e-05, Loss: 1472.2
BCE Val Loss:  tensor([6.6658e+01, 5.6246e+00, 3.0021e+01, 5.4540e+00, 2.2000e+00, 1.2017e+01,
        1.8130e+01, 1.7634e+01, 3.2804e+00, 2.1415e+01, 4.6216e+00, 8.3667e+00,
        8.4175e-01, 1.8315e+01, 1.8653e+01, 4.2498e+00, 1.8382e+00, 3.9755e+00,
        8.4199e-01, 1.1551e+00, 1.3863e+00, 3.4935e-01, 5.6326e-01, 1.2285e+01,
        2.5805e+01, 4.1832e+00, 2.6516e+01, 2.3191e+00, 1.5273e+01, 6.4533e-01,
        9.9152e-01, 7.5144e-01, 5.8192e-01, 1.7029e+00, 3.1503e-01, 2.6586e-01,
        2.6191e+00, 9.6169e-01, 4.4242e-01, 5.3052e+00, 9.3299e-01, 2.7215e+00,
        6.9279e-01, 1.6017e+00, 1.2781e+00, 2.8978e+00, 1.1041e+00, 3.3218e-01,
        2.6179e-01, 3.1300e-01, 2.0583e-01, 3.2313e-01, 2.8153e-01, 6.6825e-01,
        5.1912e-01, 7.2439e-01, 7.5785e+00, 1.3693e+00, 1.3336e+01, 1.4708e+00,
        8.4811e+00, 2.4100e+00, 1.4740e+00, 9.3451e-01, 2.8344e-01, 6.9940e-01,
        4.0892e-01, 7.2188e+00, 5.6700e-01, 2.1198e+00, 1.1889e-01, 2.7743e+00,
        1.0254e+00, 5.8709e+00, 2.6707e+02, 3.7959e+00, 6.0055e-01, 4.5567e+00,
        1.3203e-01, 3.3327e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [8/80], Step [300/314], LR 6.1e-05, Loss: 698.0
starting validation
Accuracy th:0.5 is [77.35651369 97.21129129 90.71405075 97.4086573  97.9093822  97.20519974
 97.74612882 94.82584277 97.52196002 96.54731302 98.53193796 98.69884626
 99.41399349 95.30829303 97.28195319 96.5997003  96.29024988 97.48906568
 98.70737442 98.31020577 98.38695922 99.19835285 99.40546533 98.52950135
 95.22544803 96.65086926 94.12775185 96.79097477 98.01293844 98.19690306
 97.85699492 98.53802951 96.64599603 98.29558607 98.44665635 98.60138156
 97.0321999  97.82531889 98.34066349 92.79126716 97.83384705 92.44526748
 96.95057321 96.25613723 96.97981262 94.08267443 98.04217785 98.58067031
 97.99466381 98.54290274 98.62696605 98.55752245 98.99976852 97.99100888
 98.70615611 97.45860796 90.06712881 96.32436252 96.27197524 97.02123512
 91.38168395 97.69495986 96.39258781 97.04925622 98.46614929 97.34408694
 98.26025511 95.95277835 98.68178994 97.73272743 99.81603538 96.57655243
 97.99222719 95.50200412 96.30486958 96.92864366 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [76.86188034 97.2137279  90.107333   97.29169966 97.83019213 97.19301665
 97.62795288 94.76980056 97.45860796 96.49492574 98.53193796 98.64280406
 99.41399349 95.3180395  97.27342503 96.60213691 96.29512311 97.48297414
 98.68422656 98.30533254 98.31264239 99.19713454 99.36282453 98.44056481
 95.21935649 96.65086926 94.07901951 96.75564382 98.01293844 98.15913549
 97.67424861 98.57214215 96.41817229 98.21395938 98.35406489 98.55752245
 96.95179152 97.94471315 98.17619181 92.74253481 97.84846676 92.21378882
 96.92986197 96.24395414 96.97128446 93.92916753 98.03364969 98.57457877
 97.99588212 98.52097319 98.51853657 98.55508583 98.99976852 98.03364969
 98.70615611 97.46591781 89.5079251  96.24639076 96.24517245 96.92986197
 90.86512104 97.58287545 96.24029922 97.00661542 98.43812819 97.34286863
 98.22736078 95.95277835 98.67326178 97.65475567 99.81603538 96.26222877
 97.96420609 95.45205346 96.23177106 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [89.33188932 16.34621802 49.14813923 41.07822641 56.1033488  52.16449955
 57.32367782 33.21038818 29.98188332 32.53474544 11.48014943 33.83048878
  5.18068844 15.88599327 15.02358528 26.59674317 13.92436065 19.08258867
 28.69365913 19.92797034 41.65977136 27.52644463 83.9745893  63.72716466
 18.43595606 14.1192766  25.87455031 21.66261781  8.91257544 25.72948618
 56.58639457 23.11647995 44.85836865 45.32376438 61.10108125 68.90881208
 33.33799345 60.07060667 70.87161831 31.24278235 17.06922486 40.31476326
 33.69583824 30.81514572 25.71798259 36.14186425 21.04675659 18.59449442
 26.36175057 24.3483287  46.81798762 22.11306234  8.66500963 58.8650714
  8.23886334 17.87526568 44.6086865  36.58199256 20.20343345 30.52221634
 54.3927243  53.42071907 40.91810269 28.49155056 31.92550119 23.8393343
 30.0382615  14.01122605 24.35785076 34.8900439   4.56379097 50.50764052
 28.79863384 29.8021498  26.67671084 21.46606454  4.69508148 12.96680412
  1.37831947  7.72422961]
Accuracy th:0.5 is [59.99439578 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44155164 96.4754328  98.53193796 98.52097319
 99.41399349 95.31560288 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.1469524  99.18616976 98.44300143 97.80217103
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.3111926  98.57457877 96.38040472 98.02024829 97.80460764 97.75100206
 96.94082674 97.24662224 97.11869982 92.72791511 97.84237521 92.05906361
 96.9067141  96.22811613 96.9627563  93.87312533 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.35505172
 98.70615611 97.46591781 89.09979167 96.13796128 96.24273583 96.9067141
 89.83443184 97.18327018 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [45.54647239 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.39548738 97.80948088
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.70592464
 96.94082674 97.15281247 97.11504489 92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.31728415
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.80153751 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [70.50084102  7.63313907 26.28070026 12.67424018 18.62910884 18.58079963
 14.9876962  15.11293138  9.55601264 10.61941623  2.3724717   3.4853351
  0.96327042  8.99308534  4.85942663  8.65250355  5.43418112  5.38777519
 10.46375557  5.93852763 10.27688404  5.83422855 53.19345416 13.85080422
  7.60396256  5.05486256 13.66293956  7.05605731  3.09189547  7.28087098
 19.93792814  9.28653168 18.53014892 15.41743665 14.1161429  23.14729788
  8.98580804 27.15280495 20.99372515 18.56353107  6.02931785 21.64225854
 14.28871675 12.30031302  9.98511494 16.86395472  7.20963119  4.19742521
  9.97135303  6.3222303  15.84163253  6.7301974   3.39117889 22.18547459
  3.78732598  6.33340954 27.16719535 13.9661364   9.58866121  8.15649034
 30.97908154 20.33416692 15.51842066  8.38864792  4.4326593   8.54473356
  5.00253335  6.57942126  5.52994308 10.10294057  0.38914535 24.11970818
  7.86929012 11.49144007  7.55623986  7.68646335  1.40971222  3.35210056
  0.56580594  2.69729035]
mAP score regular 32.09, mAP score EMA 12.16
starting validation
Accuracy th:0.5 is [80.26010913 97.23198047 91.18768219 97.61566634 98.4428333  97.12235593
 98.02426689 95.02703241 97.56583701 96.49948925 98.5250517  98.78914717
 99.34972718 95.10925082 97.23945487 96.43969405 96.21546204 97.51849914
 98.58733837 98.31327703 98.59481277 99.16535865 99.58143359 98.82901064
 95.43563296 96.52938685 94.3767596  96.87320926 97.81747515 98.09153649
 98.33071729 98.58235543 96.83085432 98.5624237  98.68699704 98.88880584
 97.42880634 97.81498368 98.60477863 92.80962703 97.80750928 92.83205023
 97.04013753 96.42474525 96.97037646 94.16747639 98.19866956 98.7567581
 97.96696315 98.63467623 98.63218477 98.5698981  98.87385704 97.98440342
 98.6969629  97.58576874 90.09891123 96.64648579 96.17809004 96.95293619
 91.74327927 97.91464235 96.49450632 97.06754366 98.37805516 97.43628074
 98.22109276 95.7769639  98.7044373  97.82993248 99.81563146 96.89563246
 98.11894262 95.50539403 96.10334604 97.01522286 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [79.47778857 97.22450607 90.61713631 97.49856741 98.52754316 97.3640282
 97.87477888 94.99215188 97.42631487 96.46460872 98.5250517  98.7567581
 99.34972718 95.11423375 97.229489   96.35000125 96.21047911 97.51102474
 98.8016045  98.34317463 98.50013703 99.20273065 99.53907866 98.76921544
 95.43563296 96.52938685 94.35682786 96.81341406 97.81747515 98.15880609
 98.06413035 98.67204823 96.54931858 98.44034183 98.61225303 98.83648504
 97.2967586  97.90716795 98.39300396 92.77474649 97.81996661 92.55798889
 97.08249246 96.47457458 97.03017166 94.09522386 98.19119516 98.76921544
 97.96198022 98.62471037 98.5474749  98.55993223 98.87385704 98.15631462
 98.6969629  97.58576874 89.61805815 96.55679298 96.16064977 96.85576899
 91.49164113 97.83491541 96.27525724 96.96290206 98.34317463 97.40389167
 98.16378902 95.7769639  98.7268605  97.73276528 99.81563146 96.65146872
 98.03672422 95.45058176 95.96133244 97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [91.041734   16.99396876 53.96523072 51.5368906  60.48039984 54.18150904
 67.21489486 35.63305661 36.65460751 34.81295909 17.20333087 40.03725929
  5.2049658  16.70861679 18.52278088 33.53651483 16.94641512 22.33557639
 25.40998282 22.11023951 52.5062357  37.64050658 89.4776771  73.37905301
 18.96656856 17.51682922 25.05726769 25.78701614 13.35453267 28.88551932
 68.97029065 25.78065232 50.4059057  50.13811644 64.18174383 73.92485107
 36.82212093 67.07587265 82.07714064 33.61818946 18.5949889  42.92316171
 32.12545145 29.46158025 24.23359713 36.42844568 19.40674478 15.10292559
 28.23914839 28.99527341 52.91139831 21.80509115 11.72090789 65.80574863
 11.6353167  19.44178363 45.93120415 38.23702088 20.44344563 35.42147677
 56.13898505 63.12526798 47.30438227 35.69590837 43.26674314 24.66007225
 40.49888199 16.48272768 26.11047102 42.45810256  6.31072151 57.02235155
 34.20014534 31.26568883 37.23797917 24.23175357  3.92610807 16.50219614
  1.02406424  7.4660608 ]
Accuracy th:0.5 is [60.70458679 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.36651967 96.41976231 98.5250517  98.5325261
 99.34972718 95.09928495 97.2070658  96.25283404 96.21047911 97.50604181
 98.78416424 98.34068316 98.18870369 99.15040985 98.5997957  97.89471062
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.53344794 98.67204823 96.38239031 98.18870369 98.03174129 98.08904502
 97.27931833 97.24194633 97.03764606 92.74484889 97.82744101 92.37112888
 97.03266313 96.48204898 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.27184393
 98.6969629  97.58576874 89.0450208  96.38986471 96.16314124 96.78102499
 89.95191469 97.07003513 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.08590577
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [47.75394275 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.38894287 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.38552956 97.88474475
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39733911 98.18870369 98.00931809 97.91962528
 97.27931833 96.91307273 97.0276802  92.74484889 97.82744101 92.37362035
 97.07750953 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.24942073
 98.6969629  97.58576874 89.02758054 96.39235618 96.16314124 96.78102499
 90.1910955  97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [73.40981765  9.82484093 31.51351589 20.15679966 31.06396469 26.3542445
 25.95911644 16.01719114 14.52509932 12.75314748  2.6793955   7.05672629
  1.16062329 11.74126794  5.84709283 12.81365734  6.62733582  6.4859698
 15.38403358  8.76866383 17.09711537 12.35910738 69.71745517 19.79023823
  9.19073647  6.17298343 14.81579581  9.02355129  4.33910258 11.14670323
 34.16465051 14.76979395 23.283465   18.86971292 27.25220915 37.33470044
 10.55826418 41.5679617  37.4885136  23.46600053  8.56542963 25.32970243
 17.47290931 14.97718301 13.01793829 20.07767346  8.27414001  4.71303677
 14.3423387  11.0816333  22.37032003  7.71679233  5.51659285 32.99256718
  4.97190592  7.64134522 30.82875544 16.58908629 11.27994934 10.09291211
 36.6120521  37.40522413 21.10488522 11.41854923  8.87826109  9.54607119
  9.16135885  8.86079228 11.41065907 18.72036503  1.2647722  38.4321663
 14.66247364 13.52676751 13.31262451  9.22278519  1.32397118  3.28630663
  0.70860035  3.34150687]
mAP score regular 35.87, mAP score EMA 16.78
Train_data_mAP: current_mAP = 32.09, highest_mAP = 32.09
Val_data_mAP: current_mAP = 35.87, highest_mAP = 35.87
lr:  [6.137243512841993e-05, 6.137243512841993e-05]
BCE Train Loss:  tensor([50.3546,  9.1475, 23.9319,  9.0164,  5.2374,  7.1987,  7.8099, 20.3819,
         8.7799, 12.7875,  1.3189,  6.1678,  0.6499, 21.6747,  8.4876, 19.2380,
        24.1036, 12.6850,  7.5833, 19.0434,  4.4763,  4.0508,  0.4442,  1.7271,
        16.8949,  8.8246, 16.5076, 23.3819,  6.7645,  8.8039, 12.3774, 10.9936,
        10.6768, 12.4235,  2.3711,  3.4047,  6.4249, 12.0696,  6.3026, 29.2573,
        13.6433, 44.6857, 10.2010, 25.7400, 20.3128, 27.7506, 13.0740,  1.3539,
        13.7896,  3.0674,  6.3002,  5.2986,  7.2916,  6.3631,  6.6572, 20.6749,
        32.6907, 32.1124,  8.8586,  9.9590, 26.2814,  5.8116, 20.5110, 22.6071,
        11.7910, 17.0061, 11.3613, 25.9765, 11.1059, 11.1467,  0.3678, 11.6555,
        15.6624, 20.5483,  7.8783, 13.2727,  5.4043, 12.5337,  6.6835,  1.1584],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [9/80], Step [000/642], LR 6.1e-05, Loss: 1042.4
BCE Train Loss:  tensor([43.8503, 14.1972, 32.9516, 10.1537,  6.9944, 25.9858,  6.0687, 16.2730,
         7.1394, 18.1949, 19.5561,  9.9363,  0.5698, 27.3023, 21.1373, 14.4696,
        16.2609,  6.2728,  7.7608,  6.5759,  5.4510,  3.0923,  5.4970,  4.8558,
        14.6086, 12.3527, 30.7924, 14.4872,  8.9828, 12.4605,  6.4926,  6.7399,
        21.9778,  7.6846, 12.2688,  1.8435, 13.8425,  5.9956, 13.1505, 21.3514,
         2.3326, 19.9431,  6.5336,  6.9359,  4.7423,  9.9910,  6.4893, 13.3342,
         9.5087,  5.5862,  3.2851,  3.4798, 11.0214,  5.7615,  8.6166,  5.7244,
        33.1239, 16.4880, 16.0026,  5.1252, 38.2038,  5.0921, 15.2394, 17.8507,
         8.2025,  7.8393,  9.6853, 19.0537,  7.7478,  5.2454,  9.2442,  7.1376,
         5.4501, 14.2528,  7.1983, 13.5297,  7.9890, 11.6521,  0.2520,  4.6488],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [9/80], Step [100/642], LR 6.3e-05, Loss: 945.1
BCE Train Loss:  tensor([55.1290, 13.7938, 28.9722,  9.7623,  4.2414, 14.0750, 11.4246, 21.0952,
        20.0125, 23.3572, 15.0625,  1.6390,  7.0393, 16.9179, 12.2872, 10.4013,
        10.3915, 11.6957,  8.0284,  3.8962,  1.6343,  6.5658,  0.5700,  5.2354,
        21.4385, 21.3834, 30.7916, 12.9622, 10.0746,  9.5667,  3.5330, 11.8457,
        11.7253,  3.5993, 12.2007, 16.3609, 12.5713,  8.7690,  5.6371, 42.0880,
        24.4337, 21.8129, 15.7806, 17.1264, 19.6116, 21.9168, 19.3787, 13.7477,
        21.4764,  8.4706,  6.9463,  8.9334,  5.6781,  8.4846,  9.3648,  5.5367,
        28.3328,  8.5908, 11.9706,  4.8634, 21.8112,  6.1612,  8.4102,  3.9620,
         3.9088, 10.3419,  4.0030, 27.6715,  8.0176, 13.0124,  0.1885,  4.7936,
         9.0110, 24.6287, 11.8186, 16.2202,  9.1088, 17.0844,  0.1304,  7.2300],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [9/80], Step [200/642], LR 6.4e-05, Loss: 1037.7
BCE Train Loss:  tensor([78.3101, 16.0322, 29.8050,  3.6057,  9.2763, 10.9906,  8.5396, 12.5932,
        14.5656, 11.5415,  1.7624,  1.4128,  7.5556, 19.3140, 21.6573, 14.6201,
        17.9680, 17.7075,  1.5171, 24.5433, 13.0321,  6.6903,  1.2972,  2.3024,
         7.5721, 14.0370, 18.8356, 10.0082, 11.4447,  7.8501,  2.9365,  4.8446,
         8.1147,  8.4160,  1.5983,  4.0516,  2.4004,  5.0812,  5.9780, 18.7310,
         2.7015, 45.7624, 12.3087, 14.0166,  9.1159, 26.2731, 12.8569, 10.8473,
         8.4803,  5.9817,  3.0508,  9.8017,  6.4384,  9.4194,  4.8935, 11.7972,
        42.1714, 11.0962, 12.5569, 16.3768, 37.4912,  5.3409,  9.8868, 16.2435,
        12.4746, 11.1762,  7.0050, 15.2455, 15.8169, 10.6381,  9.2036, 24.3537,
        17.3363, 22.7338, 30.1729, 19.2544, 10.8415, 20.1010,  0.1463,  8.6953],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [9/80], Step [300/642], LR 6.6e-05, Loss: 1058.6
BCE Train Loss:  tensor([55.4770,  7.5835, 19.0368, 14.6660,  3.9784,  3.6737,  4.9291, 13.3946,
        16.7151,  7.4231,  1.5557,  0.9350,  0.4828, 21.2940, 12.6974, 21.7059,
        13.0354, 11.3733,  7.9623,  4.9069,  7.1429,  0.6908,  6.2781,  6.1753,
        21.2703,  7.9076, 25.7036, 17.7502,  7.8894, 12.5129,  4.6863,  2.6781,
        12.3146,  9.8750,  5.1433,  5.6181, 10.9282,  1.8176,  5.7450, 36.4827,
        12.6842, 45.2571, 19.4523, 18.1994, 13.5875, 23.1381,  9.0986,  6.8672,
        11.6489,  7.0416, 12.7057, 10.6761,  8.0566, 13.4085,  7.8933,  3.5012,
        45.1592, 22.6275, 18.3328, 14.0115, 37.0204,  6.6947, 10.2599, 13.0178,
         2.5976, 19.5198,  3.1778, 16.6925,  5.9588,  7.0977,  0.3723, 11.0620,
         7.7729, 25.5317, 11.3749, 15.1191,  8.9806,  1.9191,  0.1793,  4.3307],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [9/80], Step [400/642], LR 6.7e-05, Loss: 983.5
BCE Train Loss:  tensor([47.7919, 11.9154, 45.8765, 11.9225,  1.9980,  6.1814, 12.1578, 22.0391,
         2.1373, 11.4067, 10.0956,  1.6388,  0.7655, 36.2211,  4.9811, 10.3075,
        29.1733,  6.8664,  2.8396,  7.9356,  2.4534, 13.5462,  1.6895,  5.3391,
        17.0196, 13.7434, 28.6297, 19.5087, 18.2897, 16.2585,  5.6861,  3.7588,
         8.3845,  2.5433, 16.8171, 11.1552, 10.5964,  1.5330,  3.5529, 20.8415,
         9.1004, 29.8430, 14.2916, 16.5233, 13.6207, 21.8015,  4.2657,  6.4345,
         8.0713,  1.8536,  3.6832,  2.6258,  6.5761,  4.5937,  7.1342, 18.3575,
        39.8993, 20.7234, 10.1399, 14.8172, 27.5496,  7.9662, 22.2240,  9.0179,
         7.5673,  8.6689, 15.2903, 23.5318,  2.6197, 10.5584,  0.5132, 13.0563,
         3.5375, 20.5936,  7.7033, 13.8178,  1.4991,  7.9236,  0.1858, 10.5902],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [9/80], Step [500/642], LR 6.8e-05, Loss: 974.4
BCE Train Loss:  tensor([52.8047,  3.3601, 23.7578,  7.8998,  9.1556,  5.9455, 10.3423, 12.0121,
         4.7120, 12.4421,  2.1331,  5.8596,  0.8807, 26.5980, 11.6873, 11.6535,
        27.2948,  7.7310,  4.2187,  6.4741, 12.4317,  5.1036,  4.0472,  7.3177,
        17.3251,  6.4841, 20.5842, 10.8058, 17.1074,  8.3547,  9.6632,  5.5090,
        10.7968, 11.1472,  8.5976,  4.7110, 14.4512, 10.2030,  3.0049, 20.5548,
         2.9145, 20.3813, 10.3758, 10.8449, 10.7300, 19.4248,  9.6026,  5.1046,
         5.2074,  7.0284,  9.4236,  7.2450,  4.4668,  5.3225,  1.5782, 15.8089,
        28.3677, 15.9643,  9.0901,  9.1327, 27.4637,  9.2412, 15.8702, 23.2358,
        11.8307, 13.0046,  8.6867, 16.1109,  9.6308,  3.1477,  0.2087,  8.8808,
         3.2243, 19.5755, 12.1562, 12.7289,  0.7780, 16.5827,  0.2563,  0.8245],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [9/80], Step [600/642], LR 7.0e-05, Loss: 876.6
BCE Val Loss:  tensor([5.5766e+01, 6.5342e+01, 8.5780e+01, 2.8425e+01, 4.8844e-01, 1.0794e+01,
        7.9536e+00, 1.8378e+01, 7.3827e+00, 1.2653e+01, 5.5338e+00, 1.2341e+01,
        6.3071e+00, 1.7442e+01, 6.8389e+00, 1.3263e+01, 3.5164e+02, 4.9418e+00,
        8.3860e-01, 3.6799e+00, 1.8967e+00, 7.1713e-01, 1.1964e+00, 4.8506e+00,
        2.5844e+01, 1.6625e+01, 2.8767e+01, 5.4950e+00, 8.7097e+00, 9.3182e+00,
        1.0948e+00, 9.1801e-01, 6.7643e+00, 1.5927e+00, 1.3179e+00, 1.4091e+00,
        6.5905e+00, 2.4419e+00, 9.9911e-01, 4.8125e+01, 1.0441e+01, 2.4103e+01,
        9.2972e+00, 1.5401e+01, 1.4089e+01, 1.9826e+01, 2.8985e+00, 5.6905e+00,
        2.0209e+00, 4.3792e+00, 6.8277e-01, 8.7366e-01, 7.3688e+00, 1.6636e+00,
        1.7438e+00, 2.6592e+00, 2.9887e+01, 9.7380e+00, 1.7124e+01, 7.1853e+00,
        1.6288e+01, 1.5082e+01, 5.8546e+00, 5.0636e+00, 9.2632e-01, 3.9693e+00,
        8.1524e-01, 1.3644e+01, 9.1498e+00, 1.9783e+01, 1.4189e-01, 1.9029e+01,
        1.5124e+01, 1.2705e+01, 1.2337e+01, 7.9231e+00, 1.3660e+00, 7.3243e+00,
        3.1778e-01, 9.6195e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [9/80], Step [000/314], LR 7.0e-05, Loss: 1245.3
BCE Val Loss:  tensor([7.6895e+01, 1.9366e+01, 5.1299e+01, 1.3087e+01, 2.4220e+00, 3.5731e+01,
        7.8982e+01, 4.4587e+01, 3.5059e+01, 3.2197e+01, 1.7101e+01, 9.5354e+01,
        9.0674e+00, 1.0411e+01, 1.3487e+01, 3.5197e+00, 1.1038e+01, 1.8003e+01,
        1.4843e+00, 1.3699e+01, 2.1955e+00, 4.0403e-01, 1.8548e+00, 2.0229e+00,
        2.7510e+01, 2.2304e+01, 3.4126e+01, 1.4805e+01, 1.3636e+01, 1.0830e+00,
        4.6992e-01, 4.9041e-01, 6.7280e-01, 4.3894e+00, 4.1711e-01, 3.2786e-01,
        3.8523e+00, 3.5015e+00, 2.2521e-01, 4.2613e+00, 6.5661e-01, 5.2102e+00,
        1.4505e+00, 2.0243e+00, 1.1008e+00, 2.8214e+00, 1.8599e+00, 9.6475e-01,
        4.7093e-01, 5.3115e+00, 2.5813e-01, 3.9002e-01, 3.0917e-01, 2.1780e+00,
        5.1992e-01, 3.0167e+00, 1.3604e+01, 4.8602e+00, 9.1538e+00, 7.1017e-01,
        8.3744e+00, 5.1745e-01, 1.4829e+00, 6.4275e-01, 2.2660e-01, 5.4224e-01,
        2.2463e-01, 1.5633e+01, 4.3701e-01, 4.4538e+00, 2.7996e-02, 7.1598e-01,
        5.6740e+00, 5.2351e+00, 1.0672e+01, 1.0873e+00, 5.4547e-01, 8.6788e-01,
        4.6787e-02, 1.6281e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [9/80], Step [100/314], LR 7.0e-05, Loss: 835.8
BCE Val Loss:  tensor([4.2867e+01, 5.7225e-01, 4.3205e+00, 9.4503e-01, 9.7280e-02, 1.2857e-01,
        1.0967e-01, 1.6272e+01, 1.6057e-01, 3.0008e-01, 1.4298e-01, 6.8650e-02,
        6.7645e-02, 1.7036e+01, 6.4450e-01, 1.9899e+00, 2.5961e+00, 5.2028e-01,
        2.8683e-01, 6.3874e-01, 3.0852e-01, 2.2573e-01, 8.9505e-02, 1.4767e-01,
        4.5498e+00, 1.1982e+00, 2.6610e+01, 8.8133e+00, 6.4463e-01, 5.9613e-01,
        4.9804e-01, 6.8216e+00, 7.6401e+00, 1.4455e-01, 5.2643e-01, 5.3515e-01,
        1.6480e+01, 1.4261e+01, 3.4791e-01, 4.1609e+01, 3.1453e+01, 7.5671e+01,
        7.4893e+01, 8.3543e+01, 4.5312e+01, 7.0294e+01, 1.2650e+01, 8.6914e+00,
        4.2802e+01, 1.1588e+01, 2.4287e+01, 4.3868e+01, 7.2788e+01, 3.0727e+01,
        6.2422e+01, 9.8207e+01, 1.0064e+02, 1.9554e+01, 1.0453e+01, 2.6396e+00,
        7.6694e+01, 1.0018e+00, 1.1959e+01, 1.4383e+01, 1.6532e+01, 4.5430e+00,
        1.2597e+01, 1.4616e+01, 6.6685e+00, 3.9440e+00, 1.2305e-01, 6.0798e+00,
        7.0574e+00, 3.8217e+01, 3.6473e+00, 1.3095e+01, 9.9879e+00, 2.5464e+00,
        2.5247e-01, 9.7318e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [9/80], Step [200/314], LR 7.0e-05, Loss: 1389.2
BCE Val Loss:  tensor([5.3993e+01, 3.4785e+00, 2.4707e+01, 5.0990e+00, 8.1167e-01, 9.6411e+00,
        1.2342e+01, 1.6755e+01, 2.2966e+00, 2.2804e+01, 4.6276e+00, 8.4424e+00,
        6.3780e-01, 1.6490e+01, 1.7180e+01, 2.8367e+00, 1.6056e+00, 2.1955e+00,
        3.7416e-01, 1.0618e+00, 1.3885e+00, 1.9489e-01, 1.9172e+00, 7.5965e+00,
        2.5436e+01, 4.9607e+00, 2.4886e+01, 2.4541e+00, 1.7519e+01, 3.4571e-01,
        1.0606e+00, 8.6812e-01, 3.6589e-01, 1.0318e+00, 2.0999e-01, 1.3640e-01,
        3.1104e+00, 5.1543e-01, 2.5716e-01, 5.3944e+00, 9.1643e-01, 4.2717e+00,
        1.4368e+00, 2.6149e+00, 1.7872e+00, 4.8838e+00, 2.1409e+00, 5.1535e-01,
        5.8047e-01, 7.0636e-01, 4.4739e-01, 3.8433e-01, 2.4133e-01, 1.3927e+00,
        7.0034e-01, 1.3193e+00, 9.8433e+00, 1.6339e+00, 1.3530e+01, 1.4724e+00,
        9.9305e+00, 2.2680e+00, 1.9096e+00, 1.2647e+00, 6.2099e-01, 1.0739e+00,
        5.8488e-01, 8.0901e+00, 1.1547e+00, 2.9233e+00, 5.8903e-02, 2.1812e+00,
        1.6130e+00, 7.1110e+00, 1.6711e+02, 4.1117e+00, 8.3223e-01, 3.7538e+00,
        1.3693e-01, 2.4472e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [9/80], Step [300/314], LR 7.0e-05, Loss: 574.8
starting validation
Accuracy th:0.5 is [79.73099743 97.21616452 90.91141677 97.51221355 97.91547374 97.19301665
 97.97151594 94.91965254 97.59627685 96.63137632 98.53193796 98.80362081
 99.41399349 95.3180395  97.29779121 96.65330588 96.2939048  97.52074171
 98.68422656 98.31264239 98.50513517 99.20444439 99.40790195 98.76707155
 95.19986355 96.65086926 94.10704061 96.80315786 98.01293844 98.22126923
 98.0628891  98.55386752 96.63746787 98.3699029  98.55752245 98.69153641
 97.2405307  98.10309329 98.47589576 92.82172488 97.84846676 92.42942947
 96.92620704 96.2244612  96.97128446 94.0778012  98.08969189 98.60381818
 98.02512153 98.60016325 98.63671252 98.57092384 98.99976852 98.13111439
 98.70615611 97.46957274 90.16824844 96.44984832 96.251264   97.04803791
 91.25619815 97.82531889 96.4742145  97.10895335 98.5514309  97.35505172
 98.33091702 95.95277835 98.70493781 97.7985161  99.81603538 96.64843265
 98.02390322 95.51906044 96.43644692 96.98955909 99.18007822 98.16279041
 99.84405648 99.14718388]
Accuracy th:0.7 is [78.52365346 97.2137279  90.23891034 97.48175583 97.72176265 96.96762954
 97.86674139 94.78076534 97.4915023  96.5168553  98.53193796 98.77559971
 99.41399349 95.31682119 97.29169966 96.58020736 96.29512311 97.48784737
 98.65620546 98.31264239 98.44787466 99.19713454 99.48100048 98.68788148
 95.21935649 96.65086926 94.09120259 96.77879168 98.01293844 98.16522703
 97.9240019  98.57457877 96.54000317 98.30776915 98.42472679 98.60138156
 97.13088291 98.02268491 98.29924099 92.73644327 97.84237521 92.43673932
 96.94935491 96.25979216 96.97737601 94.07170965 98.05557924 98.58067031
 97.99953704 98.59041678 98.59894494 98.55630414 98.99976852 98.18350166
 98.70615611 97.46713612 89.8283403  96.29755973 96.24882738 96.94569998
 91.3609727  97.63648104 96.25370061 97.05169284 98.50635348 97.34896017
 98.26634666 95.95277835 98.68544487 97.69008662 99.81603538 96.25004569
 97.97029763 95.45449008 96.38893288 96.95910138 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [90.85668423 18.7340073  52.56502096 47.40391038 63.91936573 54.23406438
 62.97425985 37.1958668  33.6037131  36.41551352 12.69224184 41.62958055
  7.36621328 18.43895874 18.57361079 32.6543156  16.2400684  22.46400055
 31.65406112 23.39736548 48.65062466 31.06862333 86.0394993  71.24846076
 19.06288417 16.63616312 26.70415836 25.15238261 11.45719478 29.53683882
 61.02511354 28.36846792 46.85349446 50.92809837 64.87313611 72.30816124
 39.25294789 65.38441952 76.49475392 33.03227168 18.61332577 42.43953105
 33.84714233 31.67506335 26.20891929 39.71903296 24.40949399 22.21564322
 29.53236121 29.40890059 50.01966618 26.34421088  9.92370678 63.78016972
 11.62527971 21.93858505 46.84048387 40.99617731 22.01252618 35.37658042
 56.31492579 59.59622642 43.67361386 31.97859929 37.31325674 27.06127657
 35.83878044 16.50459811 28.60479214 41.05027634  5.83355674 55.52758656
 33.18017742 32.06578899 30.94488598 28.25130649  4.83369515 16.24462713
  2.06739848  9.34954401]
Accuracy th:0.5 is [62.17395012 97.2137279  89.51645326 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.43058686 96.4754328  98.53193796 98.52097319
 99.41399349 95.31560288 97.26977011 96.56436934 96.29512311 97.48053752
 98.65620546 98.30776915 98.15182564 99.18616976 98.7037195  97.84481183
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30997429 98.57457877 96.37431318 98.02024829 97.81679073 97.84237521
 96.94082674 97.4086573  97.1710871  92.72791511 97.84237521 92.06271853
 96.89696763 96.22567951 96.9627563  93.87434364 98.02877645 98.57336046
 97.99466381 98.51853657 98.3699029  98.55508583 98.99976852 97.35017848
 98.70615611 97.46591781 89.11075645 96.13552466 96.24273583 96.9067141
 90.03179786 97.20398143 96.11115849 96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99420085
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [46.59178129 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44398826 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.53437458 97.8119175
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.80217103 97.73394574
 96.94082674 97.20398143 97.1162632  92.72913342 97.84237521 92.05906361
 96.90915072 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.38916436
 98.70615611 97.46591781 89.09613674 96.13796128 96.24273583 96.9067141
 89.83686846 97.17717864 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [74.59230406  9.11341901 30.76972685 18.00940507 24.58308775 25.95831985
 23.38244446 18.96374574 12.42555954 14.51619433  2.89314617  7.58635234
  1.65651852 10.33262118  6.3354566  10.5523904   6.33514915  6.98942877
 12.67629606  8.43250626 14.22902616  7.52439587 65.58782766 20.35946989
  9.64990066  6.8859006  15.72083086  9.64811917  3.56231149 11.10477056
 26.64637978 12.79319505 24.27410609 20.49042322 21.35733236 31.48257462
 12.11339653 35.75472408 32.77965993 21.96971067  7.86954784 26.32923795
 18.80221859 16.40788255 12.77412909 21.63765946 10.06177378  6.03827224
 12.48588184  9.47475742 20.21100067 10.17040141  4.14987528 30.49226047
  4.66883146  8.74566704 31.06183248 17.94342599 11.3777067  10.54724488
 36.7476961  25.67475034 20.31530379 10.40412219  7.71289083 11.0770732
  7.95298624  8.14018788 10.80108774 15.66308411  1.29706108 29.19652398
 12.66835014 14.14128099 10.51664167  9.86985751  1.59435522  4.43969569
  0.70080869  3.20363761]
mAP score regular 35.63, mAP score EMA 15.79
starting validation
Accuracy th:0.5 is [81.98918703 97.2369634  91.33717019 97.79006901 98.57986397 97.34658794
 98.12890849 95.03201535 97.65303834 96.61658819 98.5250517  98.90126317
 99.34972718 95.11174228 97.2593866  96.49201485 96.22044498 97.54590527
 98.7941301  98.26344769 98.6969629  99.23511971 99.49423225 99.07566584
 95.41570122 96.53436978 94.33440466 96.95293619 97.81747515 98.16877196
 98.52256023 98.62471037 96.69382365 98.55245783 98.78416424 98.97600718
 97.65054688 98.06662182 98.76921544 92.91177716 97.84986422 92.78222089
 96.99529113 96.26778284 96.98034233 94.07778359 98.10150235 98.76174104
 97.94703142 98.58733837 98.63467623 98.5624237  98.87385704 98.12641702
 98.6969629  97.58327728 90.0789795  96.67389192 96.21795351 96.99529113
 91.62618033 98.10150235 96.55430152 97.1846426  98.54498343 97.46368687
 98.30580263 95.7769639  98.73184344 97.91962528 99.81563146 97.04512046
 98.14884022 95.46553056 96.34501831 97.1098986  99.24757705 98.21112689
 99.82559733 99.15040985]
Accuracy th:0.7 is [81.17447741 97.22450607 90.77659018 97.76017141 98.4204101  97.12983033
 98.04170715 94.97471161 97.48361861 96.51942098 98.5250517  98.89877171
 99.34972718 95.11423375 97.2369634  96.33505245 96.21047911 97.51849914
 98.78416424 98.34068316 98.7268605  99.18030745 99.59887386 99.00839624
 95.43563296 96.52938685 94.3692852  96.85826046 97.81747515 98.16378902
 98.40795276 98.66955677 96.72870419 98.4951541  98.66457383 98.85392531
 97.51600767 97.98689489 98.59730423 92.74983183 97.82744101 92.85447343
 97.05259486 96.44467698 97.04761193 94.26962653 98.23105862 98.7642325
 97.96696315 98.6745397  98.67703117 98.55993223 98.87385704 98.27341356
 98.6969629  97.58576874 89.96188056 96.60413085 96.16064977 96.88068366
 91.96751127 97.87976182 96.29768044 97.06256073 98.45279916 97.42880634
 98.23604156 95.7769639  98.71689464 97.76764581 99.81563146 96.66641752
 98.07160475 95.44310736 96.26529138 97.05508633 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [92.43358971 18.42439231 56.38679438 58.9802648  66.85600474 56.72229118
 70.99536707 37.29177418 41.71352136 39.40997891 19.16081244 48.04005316
  6.50371545 19.8259208  22.3694694  40.91899562 18.92121225 26.02982865
 29.54933412 25.16446089 60.41501862 42.62651275 90.61040453 81.81191756
 19.65502764 19.96901183 26.13260402 30.61564244 13.28676688 31.4171154
 72.26497867 31.0119598  50.71615957 55.08612369 68.03087856 77.98174005
 43.92666106 70.95513644 84.99043204 35.81560214 22.54106522 44.00630531
 32.38508094 31.01476822 26.29199313 40.92457239 21.94418762 18.16136715
 29.22314503 30.88034947 56.21795132 24.69186804 13.04712923 69.6515007
 14.86027299 21.63503579 47.34374204 42.00678191 23.47081678 41.09420626
 57.92237526 69.37240429 48.81962479 40.16407091 46.58262892 27.32704075
 44.11252355 18.0019813  29.9694792  47.97843602  7.45190496 61.22980098
 36.78191062 32.42659075 42.12106864 32.5667629   4.13790517 19.12893109
  1.16895246  8.81041835]
Accuracy th:0.5 is [63.17113885 97.22450607 89.58816055 96.96539353 97.91962528 96.63651992
 96.80843112 94.87754441 97.3490794  96.41976231 98.5250517  98.5325261
 99.34972718 95.08682762 97.2070658  96.25781698 96.21047911 97.50604181
 98.79662157 98.34068316 98.27590503 99.15788425 99.00092184 97.91464235
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11146822
 97.54590527 98.6670653  96.37740738 98.18870369 98.14884022 98.23105862
 97.27931833 97.3341306  97.2070658  92.73986596 97.82744101 92.38856915
 97.05508633 96.47706605 97.03764606 94.04539452 98.18372076 98.77668984
 97.96198022 98.5923213  98.35563196 98.55993223 98.87385704 97.08996686
 98.6969629  97.58327728 89.17706854 96.40979645 96.15815831 96.78102499
 90.33809203 97.1397962  96.07344844 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.12826071
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [49.8617236  97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.3864514  96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 98.7492837  97.91464235
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39484765 98.18870369 98.02177542 98.08904502
 97.27931833 97.1846426  97.0351546  92.74484889 97.82744101 92.37362035
 97.07003513 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.5848469  98.33071729 98.55993223 98.87385704 97.42631487
 98.6969629  97.58576874 89.02758054 96.39235618 96.16314124 96.78102499
 90.35802377 97.04761193 96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.07843137
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [77.74714577 10.40156951 36.34392829 26.49420864 36.55167031 33.91946763
 37.10663646 20.00164497 18.05158559 17.17213714  3.60490032 14.26716694
  1.70990159 13.17451866  7.7340659  15.62385633  8.08846386  8.14185974
 17.79100783 12.06259378 23.96291124 16.50327747 79.23070271 28.28589649
 12.12821343  8.0254309  16.68516096 11.28971132  5.09041064 14.51023795
 43.92546544 17.34939704 29.7749758  25.19714826 35.72245815 46.54211742
 14.25676893 48.3077129  50.22673644 25.64561871 10.71254974 29.0535947
 21.58816641 18.83690544 15.21129726 23.9640531  10.65914917  6.18346359
 17.61037084 14.2973202  28.51714069 10.53655806  6.9927579  41.07494819
  6.04408613  9.90056015 34.57443089 22.14536396 12.87394134 13.21863211
 41.6204246  41.53865804 27.59307899 15.71888345 16.23694605 11.80324128
 15.66295493 10.20734851 15.40844227 24.24867619  2.73666995 43.29316597
 21.12004202 17.8463183  16.93143412 11.88541176  1.5666182   4.48729995
  0.86293296  3.64609643]
mAP score regular 39.13, mAP score EMA 20.84
Train_data_mAP: current_mAP = 35.63, highest_mAP = 35.63
Val_data_mAP: current_mAP = 39.13, highest_mAP = 39.13
lr:  [7.037728203388494e-05, 7.037728203388494e-05]
BCE Train Loss:  tensor([64.0566,  9.7327, 32.2064, 18.5028,  1.2607, 10.0724,  8.7186, 26.5098,
         9.7729, 12.2904, 21.1080, 11.5745,  0.5583, 16.1484,  5.6201, 13.3461,
         9.7659, 12.8815,  4.7620,  8.7195,  5.1941,  4.8974,  1.2972,  2.9866,
        30.8786, 14.9402, 21.2273, 15.4883,  5.1837,  5.2872,  1.3276,  8.4314,
         4.5576,  4.3712,  6.1204, 10.9021, 19.3464,  6.2302,  2.1812, 14.9379,
        11.3927, 26.3930, 11.8757, 12.8523, 14.5115, 20.9189,  9.4810,  4.8195,
         6.7622,  4.8709,  4.6730,  3.8560,  4.0762,  3.7509,  1.6557, 11.0071,
        31.9948,  9.0751, 14.0697,  8.9235, 27.1065, 11.3795,  9.9620,  4.2947,
         5.6182,  4.6544,  9.2486, 11.1769,  5.1779,  3.7144,  3.6773,  7.8281,
         8.0443, 15.0998, 14.3199, 23.7053,  4.5047,  8.0164,  8.5022,  0.9500],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [10/80], Step [000/642], LR 7.0e-05, Loss: 887.3
BCE Train Loss:  tensor([48.1780,  9.2799, 25.8903,  7.8218,  7.4137,  7.6476,  3.1893, 20.7227,
        14.5381, 17.6602,  2.2694,  0.9016,  0.5297, 16.8365, 14.3248, 13.6580,
        19.2985, 12.9338,  1.5697, 10.2351,  2.0296,  4.0524,  7.6088,  3.1878,
        19.3011, 11.9997, 32.8935, 12.8362,  3.9075, 12.0005,  9.8794,  1.7558,
        13.1076,  9.3964, 10.4726,  1.2642, 23.2243, 13.7333,  4.2089, 30.1716,
         9.7936, 20.5872, 17.6239,  6.9171, 21.1342, 24.8169,  5.3207,  8.5497,
         7.7190,  5.1540,  7.1373, 10.7636,  7.7371,  3.2130,  1.4579, 23.9895,
        37.7720, 15.9047, 12.4446,  7.1459, 30.5779,  4.8819, 13.2588, 14.7408,
         4.0448, 13.3482,  4.4304, 19.1970,  3.6563,  7.6446,  0.2053, 12.6746,
        12.0902, 17.8773, 18.9243,  6.8280,  9.5047, 17.5086,  7.1468,  1.1226],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [10/80], Step [100/642], LR 7.2e-05, Loss: 956.8
BCE Train Loss:  tensor([48.6332, 11.5352, 36.5908, 11.2447,  4.3226, 10.1131,  2.3790, 25.2447,
         7.1045, 15.1839,  2.3372, 11.3598,  4.9123, 20.1759,  8.5382,  9.7527,
        18.6667,  7.3535, 10.6601,  9.3702,  1.9329,  5.4788,  8.0975,  3.7701,
        18.7354, 14.7481, 16.3052, 11.2482, 10.4323,  9.0815,  7.3403, 14.1435,
        19.0183,  5.4807,  9.2264,  5.8181, 14.4017, 11.8883,  6.0707, 22.2735,
        17.5733, 24.5586,  8.6340, 13.6226,  7.6108, 13.5493, 10.6288,  2.5396,
         4.4041,  7.4078,  0.8801,  2.8833,  8.8458,  7.4416,  9.6598,  2.7172,
        21.5760,  5.0228, 10.6008,  8.7012, 23.3823,  5.5102,  6.0692, 11.8552,
         4.0428,  4.5947,  5.8860, 12.7234,  4.1630,  2.8266,  2.3388,  7.1924,
         8.5360, 12.0381, 18.3779, 10.3619,  4.1470,  7.5763,  5.7232,  2.0252],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [10/80], Step [200/642], LR 7.3e-05, Loss: 839.2
BCE Train Loss:  tensor([46.2706, 25.2438, 31.4116, 13.4155,  2.8424, 14.0359,  9.5466, 23.0080,
        11.6764,  7.2743,  1.7382, 13.1238,  0.7610, 17.9782, 27.3625,  5.8398,
        22.4270, 20.9915,  2.0357,  5.9434,  5.2787, 10.4655,  0.3826,  2.3919,
        24.9998, 25.6831, 37.0841, 24.3967, 10.8672,  8.6694,  2.9028,  3.4701,
         7.1454,  8.1261,  6.0658,  5.7351, 15.2039,  5.9855,  5.5031, 23.6989,
        14.9412, 20.1015,  9.4428, 11.5020,  5.2550, 14.8839,  7.6848,  5.6227,
         9.7914,  5.5068,  7.1670, 14.6297,  7.4105,  3.6806,  4.8344,  6.9254,
        27.4858, 15.0602, 13.0910, 10.5138, 19.4613,  4.5208, 13.6392, 19.4768,
         3.5364,  9.0018,  5.7555, 19.1039,  5.5253,  5.2193,  0.2589,  6.4924,
        15.2641, 18.4282, 21.3197, 11.9742,  1.3652,  6.5615,  0.3740,  8.6661],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [10/80], Step [300/642], LR 7.4e-05, Loss: 948.5
BCE Train Loss:  tensor([46.3904, 19.8880, 47.4871,  8.6559,  3.7670, 11.5515,  2.6388, 27.0453,
         5.2748, 16.5316,  9.3781,  1.4701,  0.7561, 25.8024, 12.3112,  7.1268,
        28.1898,  8.6988, 12.7248,  5.9001,  5.2102,  5.1149,  4.7648,  1.8378,
        29.0266, 18.3911, 39.0102, 21.9118, 11.9778, 15.4024, 10.0273,  9.0998,
         6.4458,  9.9745,  4.0658,  8.2123, 18.9469, 11.3780, 18.1185, 30.5045,
         4.2293, 18.9350,  8.2586,  8.8215,  6.1945, 10.4270, 14.0962,  7.5790,
         8.5106,  2.7673,  1.7998,  2.3972,  3.7304,  2.6678,  4.1483, 20.3431,
        33.0933, 12.7854, 16.0439,  7.9584, 20.8545,  6.2622, 10.2631,  6.1598,
         2.3132,  5.6067,  6.5559, 15.6543,  1.1464, 11.1700,  0.1038,  6.9192,
        14.3881, 13.2716, 11.2539, 12.8365,  4.4050,  8.2333,  0.2691,  6.8228],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [10/80], Step [400/642], LR 7.6e-05, Loss: 940.3
BCE Train Loss:  tensor([39.7778,  5.0434, 22.3768,  7.7540,  3.8933, 18.3343,  3.6876, 12.7103,
         4.4407,  9.9337,  1.8496,  1.0736,  3.7576,  9.3836, 15.9289, 12.2190,
        11.6818, 14.1941,  3.6565,  7.7479,  4.4322,  2.8906,  3.5656,  3.1769,
        30.7393, 12.1731, 24.2406,  6.8277,  7.5394,  3.3459,  3.6882,  4.1699,
         6.6574,  6.7010, 10.7304,  2.1936, 10.6277,  6.2876,  3.8203, 17.9444,
        10.4349, 21.3345,  8.1695, 10.3968,  7.6972, 20.4861, 11.8997,  3.3373,
         9.8601,  8.5240, 10.3117,  4.0242,  9.0874, 12.3894,  1.2518,  8.0416,
        30.0794, 12.5830, 22.8221, 17.0915, 16.2419,  5.3003, 16.6780,  8.3882,
         8.4976, 12.1956,  8.8513, 12.7611,  2.1048,  4.4661,  0.1853, 10.8936,
         2.9870, 13.6417, 22.3016, 13.8207,  5.1758,  7.4185,  6.1320,  5.5732],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [10/80], Step [500/642], LR 7.7e-05, Loss: 804.6
BCE Train Loss:  tensor([45.6590, 13.9734, 32.3661,  8.6676,  5.7433, 22.6939, 16.3889, 36.4456,
        13.1409,  9.3208,  9.3300, 16.5635, 17.0927, 30.6228, 19.6514,  6.7348,
        19.3359, 17.8183,  1.5496,  2.0560,  1.8646,  0.6674,  0.9272,  4.3978,
        21.1792, 30.9010, 34.9644,  5.9509, 13.9103,  7.7128,  4.0119,  4.4675,
        11.2836, 10.9826,  4.7534,  8.1529,  3.9766,  8.2353,  8.5576, 21.8902,
         8.2635, 17.0007,  4.7248,  9.2538,  6.3727, 21.3480,  3.7897,  4.8732,
         6.5095, 12.1988, 20.7682,  4.8954, 11.4015,  4.8660,  9.8536,  2.4724,
        29.4001,  4.8007,  8.7202, 10.2539, 28.1407,  3.3289,  8.5634,  8.9381,
         7.7604,  6.5454, 10.3261, 20.3328,  3.1971,  3.3795,  0.1552, 10.6229,
         4.2185, 10.6154, 18.1205,  3.8695,  0.6435,  8.3964,  0.2104,  1.3943],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [10/80], Step [600/642], LR 7.8e-05, Loss: 914.5
BCE Val Loss:  tensor([5.4835e+01, 5.6858e+01, 7.5965e+01, 3.2464e+01, 1.0735e+00, 1.1981e+01,
        6.9226e+00, 1.9520e+01, 6.9697e+00, 1.1550e+01, 6.4656e+00, 1.2186e+01,
        6.8722e+00, 1.6574e+01, 6.5728e+00, 1.3806e+01, 4.0092e+02, 6.0463e+00,
        7.9367e-01, 1.8561e+00, 1.5701e+00, 5.9045e-01, 3.4491e-01, 3.9031e+00,
        2.6585e+01, 1.5870e+01, 2.8967e+01, 7.7961e+00, 1.2489e+01, 9.9744e+00,
        9.2645e-01, 3.2502e-01, 6.9407e+00, 1.3557e+00, 1.7062e+00, 1.4967e+00,
        6.3058e+00, 1.5875e+00, 1.1609e+00, 4.6738e+01, 1.0283e+01, 2.1063e+01,
        8.9408e+00, 1.3483e+01, 1.3034e+01, 1.9271e+01, 2.5116e+00, 5.5456e+00,
        1.0910e+00, 4.1045e+00, 3.4214e-01, 8.9629e-01, 6.9682e+00, 8.9013e-01,
        1.2211e+00, 1.1403e+00, 2.5969e+01, 9.7956e+00, 1.5605e+01, 8.2649e+00,
        1.3157e+01, 1.0896e+01, 5.2047e+00, 4.8681e+00, 6.0334e-01, 3.9632e+00,
        7.1503e-01, 1.1406e+01, 8.4509e+00, 1.8089e+01, 3.6611e-01, 1.8683e+01,
        1.4556e+01, 1.2114e+01, 1.2635e+01, 7.6004e+00, 7.8907e-01, 6.9616e+00,
        2.6929e-01, 1.4212e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [10/80], Step [000/314], LR 7.9e-05, Loss: 1250.0
BCE Val Loss:  tensor([6.5195e+01, 1.9481e+01, 4.9592e+01, 9.6461e+00, 7.4980e+00, 3.3195e+01,
        7.2996e+01, 3.9987e+01, 3.4265e+01, 3.0795e+01, 1.5299e+01, 7.1201e+01,
        8.2576e+00, 9.3918e+00, 1.3181e+01, 3.1076e+00, 1.1024e+01, 1.7951e+01,
        1.7241e+00, 1.4370e+01, 1.2047e+00, 2.1171e-01, 2.9909e-01, 2.7609e+00,
        2.5206e+01, 2.3173e+01, 3.4793e+01, 1.3931e+01, 1.2682e+01, 1.1352e+00,
        4.2607e-01, 1.6542e-01, 4.4057e-01, 2.0646e+00, 3.5974e-01, 2.7441e-01,
        3.0530e+00, 1.6952e+00, 2.8141e-01, 4.0971e+00, 9.1311e-01, 4.7141e+00,
        1.9094e+00, 3.0686e+00, 1.1617e+00, 2.3221e+00, 1.2602e+00, 5.1126e-01,
        5.1595e-01, 4.4882e+00, 1.9468e-01, 4.8340e-01, 3.5653e-01, 1.6325e+00,
        4.3948e-01, 2.0775e+00, 1.2807e+01, 4.7770e+00, 7.9234e+00, 4.2893e-01,
        8.0832e+00, 5.9728e-01, 1.0219e+00, 4.5352e-01, 1.7133e-01, 3.6980e-01,
        2.2000e-01, 1.6622e+01, 3.4412e-01, 4.5309e+00, 5.7317e-02, 8.8195e-01,
        4.9384e+00, 5.2656e+00, 8.9742e+00, 7.9943e-01, 4.4990e-01, 5.7600e-01,
        3.1231e-02, 2.5420e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [10/80], Step [100/314], LR 7.9e-05, Loss: 763.0
BCE Val Loss:  tensor([3.6440e+01, 5.9555e-01, 3.9346e+00, 2.7041e-01, 1.3731e-01, 1.4645e-01,
        7.6483e-02, 1.7184e+01, 1.9642e-01, 2.3070e-01, 2.2478e-01, 1.0386e-01,
        1.1571e-01, 1.6362e+01, 4.8191e-01, 1.4184e+00, 1.3389e+00, 7.3858e-01,
        3.0053e-01, 3.5961e-01, 2.0544e-01, 1.1614e-01, 3.4941e-02, 1.1553e-01,
        4.8598e+00, 1.5363e+00, 2.7988e+01, 9.0545e+00, 1.5713e+00, 7.1981e-01,
        4.0341e-01, 7.6836e+00, 7.9680e+00, 1.2014e-01, 1.3435e+00, 9.2237e-01,
        1.6748e+01, 1.2693e+01, 3.7061e-01, 4.3960e+01, 3.3974e+01, 6.9399e+01,
        6.9650e+01, 8.5041e+01, 4.2238e+01, 6.8218e+01, 1.3158e+01, 6.8989e+00,
        4.3736e+01, 1.0881e+01, 2.0983e+01, 3.8463e+01, 7.1705e+01, 2.2404e+01,
        6.0984e+01, 1.0161e+02, 1.0956e+02, 1.7863e+01, 8.8761e+00, 2.8436e+00,
        7.1503e+01, 1.0534e+00, 1.2034e+01, 1.3268e+01, 1.5110e+01, 5.9597e+00,
        1.2537e+01, 1.3984e+01, 6.6614e+00, 3.8064e+00, 3.0912e-01, 6.4610e+00,
        6.7982e+00, 3.8600e+01, 2.7079e+00, 1.2506e+01, 1.0636e+01, 1.9271e+00,
        2.4082e-01, 1.4485e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [10/80], Step [200/314], LR 7.9e-05, Loss: 1355.1
BCE Val Loss:  tensor([4.7114e+01, 4.6329e+00, 2.6771e+01, 2.7496e+00, 2.4500e+00, 8.9024e+00,
        9.0192e+00, 2.1240e+01, 2.4471e+00, 2.1090e+01, 4.0908e+00, 9.3640e+00,
        2.0468e+00, 1.5767e+01, 1.7317e+01, 2.8429e+00, 9.3025e-01, 1.9032e+00,
        3.7447e-01, 5.0302e-01, 5.6341e-01, 7.1574e-02, 2.6192e-01, 1.7643e+00,
        2.6685e+01, 4.3438e+00, 2.8649e+01, 3.5513e+00, 1.5539e+01, 3.5363e-01,
        4.7057e-01, 2.1818e-01, 2.7632e-01, 5.9867e-01, 2.0488e-01, 1.2873e-01,
        1.6265e+00, 4.4217e-01, 2.9268e-01, 5.2531e+00, 8.3662e-01, 3.5818e+00,
        1.1751e+00, 2.6016e+00, 1.0853e+00, 3.0464e+00, 1.3740e+00, 2.9896e-01,
        3.0822e-01, 3.2438e-01, 2.1894e-01, 2.7924e-01, 1.4422e-01, 7.2224e-01,
        3.5674e-01, 6.4002e-01, 8.1787e+00, 1.0586e+00, 1.2251e+01, 1.6214e+00,
        9.3843e+00, 1.8654e+00, 1.5396e+00, 1.0924e+00, 4.9126e-01, 1.3540e+00,
        5.9750e-01, 7.8416e+00, 9.3589e-01, 1.6514e+00, 1.1454e-01, 2.7951e+00,
        1.1748e+00, 6.5150e+00, 1.5942e+02, 2.5420e+00, 5.1737e-01, 4.1528e+00,
        9.8589e-02, 2.9966e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [10/80], Step [300/314], LR 7.9e-05, Loss: 537.3
starting validation
Accuracy th:0.5 is [81.19174961 97.241749   91.33904314 97.66084721 98.2858396  97.37941789
 98.13598762 94.83315262 97.63038949 96.7251861  98.53559289 98.91448691
 99.4152118  95.32169442 97.34286863 96.75564382 96.2939048  97.53048818
 98.7463603  98.33091702 98.59894494 99.20931763 99.53095113 98.89133904
 95.22788465 96.65939742 94.13506171 96.85920006 98.01293844 98.18593828
 98.17862843 98.58798017 96.73736918 98.46249437 98.579452   98.70128288
 97.41109392 98.19933968 98.65133222 92.88264032 97.8131358  92.63897857
 96.95910138 95.99907409 96.97493939 94.21547008 98.10187498 98.60138156
 98.04339616 98.61234634 98.71224766 98.51853657 98.99976852 98.21517769
 98.70615611 97.47200936 90.23403711 96.5582778  96.2658837  97.18448849
 91.84464127 98.09822005 96.56924258 97.16255894 98.60138156 97.39647421
 98.39548738 95.94912343 98.71590258 97.8679597  99.81603538 96.89940425
 98.06167079 95.5690111  96.53634824 97.060221   99.18007822 98.17619181
 99.84405648 99.14718388]
Accuracy th:0.7 is [79.40083576 97.21616452 90.87243089 97.48175583 98.29802268 97.31728415
 97.93496668 95.02320878 97.54145296 96.61310169 98.53193796 98.88159257
 99.41399349 95.31682119 97.30144613 96.6557425  96.29512311 97.50246708
 98.68300825 98.31264239 98.50513517 99.18982469 99.52973282 98.81336728
 95.21935649 96.65086926 94.08267443 96.86772822 98.01293844 98.17741012
 98.11527637 98.57457877 96.52172854 98.33091702 98.49051547 98.54290274
 97.23565746 98.07629049 98.65620546 92.76080944 97.84846676 92.43673932
 96.96397461 96.26832032 96.98834079 94.12287862 98.10674821 98.60990972
 98.02390322 98.63914913 98.65255053 98.57092384 98.99976852 98.04461447
 98.70615611 97.46591781 89.83199522 96.3633484  96.24273583 97.0456013
 91.73255686 97.9106005  96.30486958 97.09067872 98.53559289 97.36845311
 98.32969871 95.95399666 98.6903181  97.73150912 99.81603538 96.86650991
 97.9800441  95.46301824 96.46568633 96.98346755 99.18007822 98.16157211
 99.84405648 99.14718388]
Avg Prec: is [92.18640984 21.22528753 55.5587728  53.8591646  69.48649228 57.02307646
 69.23740392 39.96926099 38.64292222 40.59826532 15.80348275 47.85155883
 10.49858595 19.62383352 21.82177732 37.22755393 18.13031833 25.88346651
 34.95153818 26.79372031 54.60257674 35.10811839 88.2150525  76.71347571
 21.02650066 19.1061396  28.81318688 29.48528272 13.11886907 30.21778829
 65.88976182 31.33938519 49.61779258 56.39635511 67.22457865 75.11632596
 48.08604542 67.51544184 79.48116834 35.14625543 21.36451989 45.02903192
 36.84706141 33.90197871 29.88155735 42.42921948 27.87357806 24.51266555
 32.23357993 33.56823504 54.45025336 27.24431185 12.14147816 66.47652986
 13.44400661 25.20927481 48.24820788 43.4472742  23.48594523 41.95464625
 60.16370947 66.34330709 47.60282466 36.02458848 42.17295419 29.95788231
 40.97613541 17.72189743 30.5294312  45.92402185  5.7279313  60.48771228
 39.47250647 33.63729659 34.7565133  31.78684634  7.11471138 19.61114221
  2.1337652  10.84016204]
Accuracy th:0.5 is [64.60691268 97.2137279  89.52863635 97.02854497 97.31850245 96.5997003
 97.00539711 94.73568792 97.38916436 96.4754328  98.53193796 98.52097319
 99.41399349 95.31438457 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.17375519 99.18251483 99.00829668 97.93009344
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.32337569 98.57457877 96.39867935 98.02877645 97.8679597  97.95080469
 96.94082674 97.46226289 97.32337569 92.73035173 97.84237521 92.08342978
 96.88356623 96.23055275 96.96397461 93.87921687 98.03121307 98.57336046
 97.99100888 98.5234098  98.38452261 98.55508583 98.99976852 97.30022782
 98.70615611 97.4646995  89.23258732 96.16232746 96.24395414 96.90793241
 90.33759335 97.24296731 96.11481342 96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 96.04049658
 97.96420609 95.45083515 96.1537993  96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [48.58493439 97.2137279  89.51523495 97.02489005 97.26733349 96.5997003
 96.99808726 94.73568792 97.44276995 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15060733 99.18616976 98.82676868 97.86186815
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.30875598 98.57457877 96.36213009 98.02024829 97.82410058 97.82531889
 96.94082674 97.34774186 97.13941107 92.72913342 97.84237521 92.05906361
 96.90793241 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.51853657 98.36746628 98.55508583 98.99976852 97.57800222
 98.70615611 97.46591781 89.10100998 96.13917959 96.24273583 96.9067141
 89.96966411 97.18327018 96.1123768  96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99054592
 97.96420609 95.45083515 96.15136268 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [78.68831587 10.99207989 35.63713559 23.91957817 32.32278743 33.69706509
 32.21117547 22.73918634 15.49197721 18.15424124  3.63573375 14.1945895
  2.37688485 11.86884745  7.65737728 13.23817186  7.77799615  8.60143928
 13.64202143 12.19092383 20.10728435  9.97519346 72.28417833 29.04081829
 12.51772082  8.62028168 17.50330164 12.98918814  4.19869838 13.09605896
 35.67327787 15.33380945 30.29872611 25.44970917 30.34034579 41.90925738
 15.93944366 41.05307726 43.51616866 24.22814008  9.44465688 30.26716298
 22.08328646 20.42846106 14.93921972 25.14876574 12.18833325  7.44777616
 15.47955452 13.00240979 25.28464264 11.77385674  5.70610671 38.43863519
  5.31842878 11.25318802 34.12601433 23.02902883 12.98394366 13.91257067
 41.56470855 32.58179568 25.8839147  14.64513843 14.29611134 14.43093058
 13.75220759  9.34884292 14.79110504 21.35146903  2.08591665 37.37954506
 20.4785391  19.00288409 12.48398012 11.70525397  1.92115675  5.76983315
  0.74331969  3.75387224]
mAP score regular 38.94, mAP score EMA 19.67
starting validation
Accuracy th:0.5 is [83.64102947 97.22699753 91.7482622  97.87976182 98.75426664 97.51849914
 98.31078556 94.68071854 97.72778235 96.64150285 98.54498343 98.96853278
 99.35471012 95.10177642 97.30174154 96.65146872 96.21546204 97.56583701
 98.84146797 98.35563196 98.86638264 99.26750878 99.64122879 99.25505145
 95.42815856 96.54433565 94.46146947 96.99279966 97.81498368 98.03423275
 98.59730423 98.6371677  96.77105912 98.67204823 98.86139971 99.01088771
 97.72778235 98.18372076 98.91122904 92.96658943 97.81747515 93.0214017
 96.99529113 95.91648604 96.98781673 93.99805666 98.01928395 98.72935197
 97.99935222 98.60477863 98.77419837 98.5549493  98.87385704 98.33570023
 98.6969629  97.59075168 90.4452251  96.84829459 96.22791938 97.2145402
 92.21665795 98.35812343 96.63153699 97.23198047 98.54249197 97.50853327
 98.35812343 95.7620151  98.7193861  97.96945462 99.81563146 96.93300446
 98.17873782 95.56020629 96.53436978 97.1622194  99.24757705 98.22856716
 99.82559733 99.15040985]
Accuracy th:0.7 is [82.88362359 97.23447193 91.55641926 97.64058101 98.78416424 97.44873807
 98.12392555 95.14911428 97.56334554 96.63402845 98.5250517  98.98846451
 99.35221865 95.11672522 97.27682687 96.44218551 96.21047911 97.54839674
 98.82901064 98.33570023 98.82402771 99.20273065 99.64122879 99.17532451
 95.43563296 96.53187832 94.3767596  97.05259486 97.81747515 98.18870369
 98.52006876 98.6745397  96.63901139 98.52754316 98.77668984 98.81157037
 97.61317488 98.04918155 98.94112664 92.81460996 97.83989835 92.91925156
 97.1024242  96.37242445 97.080001   94.38174253 98.16877196 98.77419837
 97.97942048 98.70942024 98.7642325  98.5848469  98.87385704 98.20365249
 98.6969629  97.58576874 89.91952562 96.70129805 96.17809004 97.03017166
 92.17679448 98.17873782 96.34750978 97.08249246 98.43785036 97.46119541
 98.29832823 95.77945537 98.7343349  97.82744101 99.81563146 97.229489
 98.06163889 95.44559882 96.40730498 97.09744126 99.24757705 98.20116102
 99.82559733 99.15040985]
Avg Prec: is [93.78313979 20.38567649 60.36834878 63.13966854 71.38055828 59.86436419
 76.31653336 39.94652423 45.78467691 42.28003358 24.46054916 53.18218888
  9.96000882 20.96601945 25.43139099 45.46609561 20.58543803 30.75186189
 35.78449223 27.85145161 66.78111566 46.0540584  91.64563701 86.05944318
 21.52278779 23.10326066 28.80512611 35.82206665 15.5608789  32.67588189
 74.26212413 32.46318768 51.8547492  60.78348071 70.78376651 80.27676566
 50.62692454 74.04422487 86.48172798 37.52390279 23.3074078  46.60188769
 36.20331664 32.74517777 30.59917864 42.80343716 25.27244016 20.68592796
 34.18014887 34.74194681 63.38042494 29.79252045 16.28260134 72.65099103
 18.53378525 27.33932335 49.42046953 45.79322185 25.83628447 46.77015446
 61.17356758 75.79343511 51.47472252 42.47065699 48.26217857 30.76508747
 46.63593755 20.16305949 32.65914936 52.24972266  9.53825987 65.12455751
 40.9226521  34.27114342 47.49939548 35.84246183  6.96855773 22.8672691
  1.29978207 11.65086369]
Accuracy th:0.5 is [66.24810026 97.22450607 89.63798988 96.98034233 98.00184369 96.63651992
 96.84331166 94.87754441 97.3266562  96.41976231 98.5250517  98.5325261
 99.34972718 95.05693001 97.2070658  96.26778284 96.21047911 97.50604181
 98.79662157 98.34068316 98.34317463 99.08064878 99.28993198 98.02426689
 95.43563296 96.52938685 94.3393876  96.79348232 97.81747515 98.10399382
 97.58327728 98.66457383 96.43969405 98.19368662 98.28836236 98.37805516
 97.27931833 97.49607594 97.4088746  92.72242569 97.82744101 92.43341555
 97.0501034  96.48454045 97.03764606 94.06034332 98.19368662 98.77668984
 97.94204848 98.60228717 98.39798689 98.55744077 98.87385704 96.72870419
 98.6969629  97.58078581 89.37638588 96.46710018 96.14320951 96.78102499
 90.71928644 97.28679273 96.09587164 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.38737325
 98.03174129 95.44559882 95.75703216 97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [52.54503326 97.22450607 89.58566908 96.96290206 97.90716795 96.63651992
 96.80843112 94.87754441 97.39890874 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.22109276 99.15040985 99.12300371 98.03921569
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.39733911 98.18870369 98.14634876 98.29085383
 97.27931833 97.35157087 97.12983033 92.74484889 97.82744101 92.37362035
 97.07501806 96.48703192 97.03764606 94.02795426 98.18621222 98.77668984
 97.96198022 98.58733837 98.33071729 98.55993223 98.87385704 97.57331141
 98.6969629  97.58576874 89.05498667 96.40232205 96.16314124 96.78102499
 90.59720457 97.0725266  96.07095697 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.08341431
 98.03174129 95.44559882 95.7545407  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [81.82750554 11.32595541 40.27976976 33.32727233 42.70401175 40.16768706
 45.85874386 23.20567324 21.53655759 21.08715086  5.00560879 22.29250811
  2.52977398 14.5973922  10.65847514 19.07032436  9.9187633   9.813147
 20.10824696 15.04017905 31.40037208 22.286418   84.58058946 39.16036612
 14.4349856   9.82325454 18.65970149 14.5473943   6.31776383 18.41609368
 53.09069653 19.6803058  35.460132   31.62990627 43.41278495 54.85739033
 18.72480018 53.39614719 60.83976774 27.90258318 12.96797942 32.89288589
 26.03157501 22.56255773 17.5502373  27.51010694 12.99694903  8.10498278
 20.78485625 17.61124622 35.15895451 13.19274681  8.51298361 48.59167125
  7.05314464 12.22392464 38.12788842 27.36197497 14.41761866 17.43727922
 46.61138246 45.74373895 32.89689139 21.43965933 24.15858234 15.36382205
 23.28462597 11.69376434 19.07461988 29.24917341  5.23590621 48.4520424
 24.99624422 22.64355937 21.01282538 14.5083067   2.04187615  6.60971735
  1.08105949  4.24564641]
mAP score regular 42.44, mAP score EMA 24.88
Train_data_mAP: current_mAP = 38.94, highest_mAP = 38.94
Val_data_mAP: current_mAP = 42.44, highest_mAP = 42.44
lr:  [7.86757632134345e-05, 7.86757632134345e-05]
BCE Train Loss:  tensor([51.6442, 10.0349, 21.3872, 12.3768,  3.5370,  9.0733,  9.2947, 13.1432,
         7.0548, 11.5952,  5.0689,  2.3158,  1.1598, 23.6680,  7.6239, 19.1293,
        31.9290, 10.0040,  3.4951, 12.3578,  7.0358,  2.7713,  0.9716,  6.5448,
        28.7667,  9.9330, 27.7968, 24.4226, 13.1930, 21.7347,  3.6410,  7.7366,
         8.0660,  7.9615, 12.0338, 13.9400,  4.2149, 10.6102,  4.6353, 36.2709,
         9.1893, 21.7646, 15.7262, 14.3227,  8.8606, 13.3726,  4.3478,  2.3070,
         9.7861,  2.5525,  4.7457,  3.5301,  6.6372,  8.2769, 10.2022,  5.6614,
        31.3953, 20.0899, 14.3699,  6.0601, 25.5850,  4.1065, 12.7587, 10.2751,
         5.5933, 15.6538,  7.7875, 13.8853,  8.3803,  5.8577,  0.3674, 11.7871,
         5.4338, 14.1667, 14.6567, 19.4381,  0.8780,  4.7165,  0.2195,  1.4093],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [11/80], Step [000/642], LR 7.9e-05, Loss: 914.3
BCE Train Loss:  tensor([48.0291, 21.9290, 21.7808,  3.0622,  2.0619,  7.6830,  8.5314, 11.9401,
        14.0325,  9.0012, 10.9116,  7.0273,  4.7961, 20.1369, 16.9573,  9.7624,
        14.5701,  6.8837,  9.4381,  9.2048,  2.4758,  3.6577,  1.4614,  6.1102,
        33.5741, 18.9929, 21.6260,  5.9070,  8.7095,  1.7927,  8.5388, 12.8970,
         3.6874,  3.0669,  5.5279,  8.3865,  6.3279,  8.0418,  1.7218, 18.6554,
         9.4609, 17.3297, 14.2833, 16.9631, 11.4817, 23.7555, 16.9878,  5.7774,
        11.1837,  2.8430,  5.3256,  3.5050,  3.3728,  2.0970,  2.4302, 15.6565,
        27.5464,  7.8350, 15.2346, 15.4860, 26.9410,  8.9316,  8.0937,  9.2076,
         3.0238,  9.4064,  4.9547, 10.8947,  3.3425,  2.5019,  3.9913, 11.4551,
         2.6384, 15.1838, 13.4869,  4.4608,  8.9266,  3.9672,  4.8258,  5.3147],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [11/80], Step [100/642], LR 8.0e-05, Loss: 829.0
BCE Train Loss:  tensor([54.1868, 11.2766, 30.5938, 13.3502,  3.4856, 12.9099,  6.4000, 18.9649,
         2.5602,  8.1329,  5.9224, 10.8450,  7.0690, 24.7008, 17.3638, 19.6303,
        18.0453,  8.4430,  3.7793,  9.6388,  8.2840,  0.7680,  4.3225,  1.6974,
        31.1159, 12.2981, 34.9217, 10.2517, 19.7641,  5.4411,  6.4720,  3.7065,
         8.6698,  3.6390,  1.3734,  3.8853, 11.7142,  3.4287,  2.4104, 25.4183,
         4.8885, 26.3722,  6.6971,  5.7143,  9.2210, 17.3115, 12.6720,  3.8657,
        12.7057,  3.8352,  4.9043,  2.4136,  6.8568,  7.1516, 12.0763,  2.0648,
        29.3688,  5.2072, 18.3823, 10.1024, 25.1793, 10.8629, 17.2089, 11.6069,
         8.0501,  6.6530,  5.3828, 12.3172,  6.3351,  3.4207,  3.9218,  8.6433,
         9.0795, 19.4988, 15.0474,  5.5285,  5.5703,  2.2216,  4.8268, 11.7739],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [11/80], Step [200/642], LR 8.1e-05, Loss: 881.8
BCE Train Loss:  tensor([45.0431,  9.8892, 26.7086,  4.4377,  8.0428,  8.2238,  6.6342, 18.1866,
        10.1030, 10.1116,  1.3935,  6.3836,  0.9276, 22.0827, 26.8955, 15.8956,
         5.9702,  7.9809,  4.3557, 12.8080,  5.1583,  1.2154,  3.2301,  4.5091,
        22.1333, 13.2675, 22.1187,  5.0693,  8.4241,  9.6846,  3.9517,  5.8770,
         9.0878,  7.0938,  3.3902,  1.4581, 14.6377, 10.1369,  6.2003, 30.9926,
         2.5890, 29.1819,  6.5235, 11.8010, 10.4023, 22.9184,  7.4704, 11.1866,
         7.3613,  7.6207,  3.5387,  2.1204,  1.5697, 11.3224,  3.2979, 10.4457,
        21.9289, 13.5483,  7.7711, 14.6689, 27.2984,  3.0972, 15.7344, 10.6817,
         8.1159,  7.6378,  6.3138, 12.9304,  2.5791,  9.9857,  0.2955, 10.4550,
         3.1183, 37.4662, 10.0412, 19.2881,  0.9126, 14.7242,  0.2307, 13.1672],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [11/80], Step [300/642], LR 8.2e-05, Loss: 861.1
BCE Train Loss:  tensor([56.7881, 13.1245, 29.4781, 25.4651, 12.9612, 23.9986,  9.8417, 18.8563,
         5.9809, 10.7301,  9.2006,  7.9418,  6.9680, 42.7330, 23.3950, 14.6821,
        21.7265, 15.0455,  8.2763,  3.0096,  5.1722, 12.3637,  2.6700, 10.7013,
        13.2035, 14.6077, 11.5613, 17.4244,  5.2214,  9.4231,  3.2719,  9.1776,
         6.0825,  5.2866,  4.7487,  1.2663, 10.8015,  2.4765,  1.8669, 22.2905,
         9.4020, 21.2595,  5.2569, 14.3026, 11.1742, 13.9971,  4.5170,  1.8287,
         4.4339,  9.1139,  2.4111,  2.8259,  0.9998,  8.3421,  7.0857,  6.9340,
        21.3131, 10.4627, 16.6469, 13.2506, 32.1941,  9.5424, 13.6125,  7.6353,
        11.1887, 12.2838,  4.4626, 13.8349,  5.8530,  9.4158,  0.4216, 13.2282,
         7.1491, 12.8827, 12.9101, 11.7807,  4.1382, 12.8329,  0.1809,  4.7941],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [11/80], Step [400/642], LR 8.3e-05, Loss: 915.7
BCE Train Loss:  tensor([46.8941, 15.6272, 25.6546, 11.1434,  7.9520,  8.8307, 12.6214, 22.0870,
         8.9601, 13.8869,  7.1500,  7.4669,  5.6152, 19.2371,  8.6050, 12.8597,
        20.6150, 11.8124,  6.6556,  4.0241, 11.6679,  8.6720,  1.9954,  7.8456,
        19.5882, 14.0675, 19.9053,  4.6742,  7.2521,  4.7591, 11.2618,  5.0518,
         8.1922, 12.4150,  1.1499,  4.8469,  5.2538,  4.7971,  9.6615, 16.6837,
        10.1748, 16.8909, 11.1558,  8.5877,  7.7246, 21.1129,  5.8149,  7.3450,
         8.4633, 12.0907,  4.5340,  3.6179,  1.8123,  4.2088,  1.0695, 16.0164,
        22.4590, 12.2769, 15.7769, 10.7187, 21.1296,  4.2065, 11.3490, 11.5950,
         3.4902,  6.7691,  6.1681,  8.9501,  7.5015,  6.0481,  0.1947,  9.1249,
         6.7236, 14.8786, 20.2660, 14.2443,  5.0422, 10.6798,  0.1793,  0.8358],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [11/80], Step [500/642], LR 8.4e-05, Loss: 828.7
BCE Train Loss:  tensor([62.6223, 17.7510, 29.6645, 16.0962, 10.1302, 14.6644,  8.9826, 18.6617,
         6.9258,  7.4409, 11.3525,  3.6863, 10.5373, 29.6812, 19.8029, 10.7043,
        21.0393, 22.4087,  6.1155, 19.0829,  3.1759,  0.7604,  1.2865,  6.3677,
        25.1173, 12.0266, 36.8535, 11.3207,  9.0469, 10.5613,  9.4318,  5.6095,
         5.8119,  6.6094,  2.2980,  7.4088,  8.6294, 12.3985,  2.1538, 19.7767,
        12.6331, 24.2167,  6.4761, 20.7069,  8.2745,  9.3746,  4.0795,  3.4120,
         2.5527,  2.8718,  7.1085,  5.8716,  8.3183,  1.4911,  6.2887, 10.1798,
        35.0908,  7.8488,  8.3082,  6.8945, 26.2345,  1.8703,  8.5966,  3.3953,
         2.7292, 13.4593,  5.9396,  9.6181,  1.8532,  7.0016,  2.3328, 11.4053,
        11.7533, 22.5838, 25.7792, 10.1356,  5.2886,  5.8111,  5.3586,  7.8172],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [11/80], Step [600/642], LR 8.6e-05, Loss: 925.0
BCE Val Loss:  tensor([5.3320e+01, 6.1863e+01, 7.8205e+01, 2.8761e+01, 9.3737e-01, 1.2423e+01,
        6.2576e+00, 1.8398e+01, 7.0559e+00, 1.1702e+01, 8.4699e+00, 1.3563e+01,
        6.5316e+00, 1.5931e+01, 7.5814e+00, 1.6039e+01, 3.4322e+02, 3.9064e+00,
        1.7855e+00, 2.1600e+00, 1.4994e+00, 1.0856e+00, 1.1443e+00, 3.5128e+00,
        2.6329e+01, 1.6851e+01, 3.0906e+01, 8.0785e+00, 1.0266e+01, 8.6637e+00,
        8.8937e-01, 1.0884e+00, 7.5254e+00, 1.1745e+00, 9.8246e-01, 1.2023e+00,
        7.8776e+00, 2.6961e+00, 1.4566e+00, 5.0585e+01, 1.0688e+01, 2.3420e+01,
        7.1051e+00, 1.2439e+01, 1.2586e+01, 1.8913e+01, 2.1512e+00, 5.6046e+00,
        1.2194e+00, 4.6219e+00, 2.1061e-01, 7.7178e-01, 5.6391e+00, 5.5176e-01,
        1.1331e+00, 2.8126e+00, 2.5837e+01, 8.4755e+00, 1.4059e+01, 7.1595e+00,
        1.2375e+01, 1.5458e+01, 5.4782e+00, 5.6752e+00, 4.9328e-01, 2.7977e+00,
        7.1675e-01, 1.0449e+01, 9.6877e+00, 1.9852e+01, 1.1043e-01, 1.6731e+01,
        1.7836e+01, 1.2188e+01, 1.2257e+01, 7.1529e+00, 8.8479e-01, 8.6665e+00,
        3.0589e-01, 8.6740e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [11/80], Step [000/314], LR 8.6e-05, Loss: 1207.3
BCE Val Loss:  tensor([6.8789e+01, 1.8236e+01, 5.1484e+01, 9.1415e+00, 6.9377e+00, 3.3401e+01,
        5.7486e+01, 4.6869e+01, 3.1595e+01, 3.1660e+01, 1.7824e+01, 6.4736e+01,
        8.2297e+00, 8.3727e+00, 1.3850e+01, 2.7683e+00, 1.0498e+01, 1.6507e+01,
        1.8901e+00, 1.6360e+01, 1.8770e+00, 4.1945e-01, 3.5503e-01, 3.7082e+00,
        2.5998e+01, 2.2294e+01, 3.3365e+01, 1.4161e+01, 1.4120e+01, 7.8125e-01,
        3.9449e-01, 4.0082e-01, 5.1652e-01, 2.5059e+00, 3.4172e-01, 3.6145e-01,
        3.0327e+00, 1.8395e+00, 2.4202e-01, 2.1933e+00, 4.0879e-01, 3.0198e+00,
        1.0249e+00, 1.6284e+00, 6.7732e-01, 2.3187e+00, 8.9549e-01, 5.6443e-01,
        3.4182e-01, 5.5449e+00, 9.3233e-02, 3.4406e-01, 4.7795e-01, 1.4973e+00,
        3.5540e-01, 1.8838e+00, 1.0990e+01, 4.7399e+00, 7.9455e+00, 3.9708e-01,
        3.4154e+00, 4.4821e-01, 5.6403e-01, 3.4240e-01, 7.0423e-02, 2.3254e-01,
        1.1047e-01, 1.8257e+01, 1.8264e-01, 4.4176e+00, 1.2862e-02, 4.3566e-01,
        5.8389e+00, 5.0293e+00, 8.5869e+00, 6.4523e-01, 5.5710e-01, 8.9090e-01,
        3.1888e-02, 1.2899e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [11/80], Step [100/314], LR 8.6e-05, Loss: 740.9
BCE Val Loss:  tensor([3.3779e+01, 5.0166e-01, 5.3333e+00, 4.1991e-01, 1.9181e-01, 1.9315e-01,
        1.2190e-01, 1.9196e+01, 2.8494e-01, 2.0677e-01, 3.2960e-01, 7.1994e-02,
        9.2052e-02, 1.6715e+01, 4.1057e-01, 1.1075e+00, 2.4539e+00, 4.4196e-01,
        4.1936e-01, 3.1339e-01, 3.0428e-01, 3.1084e-01, 3.0958e-02, 1.2577e-01,
        4.8103e+00, 1.3651e+00, 2.5438e+01, 8.7401e+00, 7.6738e-01, 6.5154e-01,
        3.2016e-01, 6.5436e+00, 7.7969e+00, 8.6352e-02, 3.2432e-01, 2.9285e-01,
        1.3103e+01, 1.1791e+01, 3.2482e-01, 3.5350e+01, 2.8783e+01, 6.9012e+01,
        6.7388e+01, 6.9855e+01, 4.6084e+01, 6.8925e+01, 1.2204e+01, 8.6118e+00,
        4.2511e+01, 9.8963e+00, 2.2031e+01, 4.0075e+01, 6.3493e+01, 1.9366e+01,
        5.7382e+01, 8.3708e+01, 1.1005e+02, 1.5098e+01, 9.8275e+00, 2.3149e+00,
        9.8599e+01, 4.9279e-01, 1.1346e+01, 1.3185e+01, 1.4232e+01, 3.7663e+00,
        1.1126e+01, 1.3871e+01, 6.5548e+00, 3.3539e+00, 1.2431e-01, 6.2622e+00,
        6.3065e+00, 4.1070e+01, 3.2805e+00, 1.3663e+01, 1.0311e+01, 2.9964e+00,
        3.4506e-01, 9.6300e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [11/80], Step [200/314], LR 8.6e-05, Loss: 1309.5
BCE Val Loss:  tensor([4.2825e+01, 1.9155e+00, 1.9776e+01, 1.6945e+00, 2.3649e+00, 9.1325e+00,
        9.8295e+00, 1.5413e+01, 1.9812e+00, 2.1436e+01, 4.3503e+00, 8.0423e+00,
        1.2034e+00, 1.5761e+01, 1.6821e+01, 3.0867e+00, 1.4282e+00, 7.9775e-01,
        4.1311e-01, 3.6599e-01, 1.3158e+00, 1.7852e-01, 2.8747e-01, 3.7657e+00,
        2.7171e+01, 4.2815e+00, 2.6034e+01, 3.3379e+00, 1.8193e+01, 3.1417e-01,
        2.8727e-01, 3.4930e-01, 2.9549e-01, 6.6034e-01, 2.5946e-01, 1.6147e-01,
        2.4590e+00, 4.2009e-01, 2.7438e-01, 3.8852e+00, 4.5785e-01, 2.2563e+00,
        8.2266e-01, 1.6600e+00, 9.6686e-01, 3.2405e+00, 1.1886e+00, 3.4826e-01,
        3.4688e-01, 2.1887e-01, 2.3540e-01, 3.5142e-01, 2.2354e-01, 4.1000e-01,
        4.0127e-01, 1.5082e+00, 7.4058e+00, 7.1369e-01, 1.1118e+01, 9.1156e-01,
        8.1601e+00, 1.4580e+00, 1.0461e+00, 9.3220e-01, 3.4698e-01, 8.2739e-01,
        3.8273e-01, 8.0481e+00, 5.1072e-01, 8.3458e-01, 3.2537e-02, 1.8559e+00,
        4.3678e-01, 6.6750e+00, 1.3281e+02, 2.0838e+00, 6.8864e-01, 3.9391e+00,
        1.0861e-01, 1.8532e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [11/80], Step [300/314], LR 8.6e-05, Loss: 478.7
starting validation
Accuracy th:0.5 is [82.30041057 97.21738283 91.62900062 97.74125559 98.45152959 97.46835443
 98.30533254 94.97569474 97.72298096 96.82752403 98.54168443 98.93763478
 99.41399349 95.3180395  97.38307282 96.88478454 96.31705267 97.60602332
 98.76950817 98.33091702 98.72808567 99.27997953 99.55653562 99.00951499
 95.23884943 96.70569316 93.93160415 96.86772822 98.01293844 98.22614247
 98.21030446 98.4673676  96.82021418 98.579452   98.51000841 98.78047295
 97.60967824 98.31873393 98.78169126 92.95086561 97.86552308 92.73644327
 96.97981262 96.1964401  97.03585483 94.30318831 98.13111439 98.63914913
 98.1055299  98.68057163 98.75245185 98.59529002 99.00342345 98.21274107
 98.70615611 97.47688259 90.58491003 96.46934126 96.32070759 97.33434047
 91.95063413 98.21517769 96.61675662 97.1991082  98.67204347 97.45373473
 98.42350849 95.91501078 98.73905045 97.99100888 99.81603538 97.02610836
 98.08360035 95.58484911 96.66427066 97.12844629 99.18007822 98.21274107
 99.84405648 99.14718388]
Accuracy th:0.7 is [81.30383402 97.2137279  90.8042056  97.57312898 98.42350849 97.35139679
 98.2297974  94.78685689 97.58043883 96.69472838 98.53315627 98.91570522
 99.41399349 95.31682119 97.33555878 96.69107345 96.29512311 97.52561494
 98.74148707 98.31629732 98.69153641 99.2336838  99.54922576 99.02657131
 95.22666634 96.66548897 94.26785736 96.97006615 98.01293844 98.16766365
 97.88379771 98.60747311 96.51441868 98.50269855 98.25903681 98.59529002
 97.47688259 98.2858396  98.65376884 92.74375312 97.85212168 92.23084514
 96.93960844 96.27075694 96.98103093 94.15333634 98.13111439 98.59772664
 98.05070601 98.61478296 98.66960685 98.58432524 98.99976852 97.96786102
 98.70615611 97.49272061 89.71138266 96.2939048  96.29634142 97.18936173
 90.89436045 97.98491734 96.34385546 97.1857068  98.61112803 97.3806362
 98.37843106 95.95034174 98.70006457 97.86308646 99.81603538 96.85189021
 97.97760749 95.45936331 96.61066507 97.06143931 99.18007822 98.18228335
 99.84405648 99.14718388]
Avg Prec: is [93.16468994 23.59661183 58.46486194 56.42408967 73.61680112 59.49715929
 71.71304457 43.68459652 45.82801809 44.27889623 20.379827   50.84270845
 14.61340814 22.02054343 25.32199803 42.77972737 20.99705795 33.16977874
 39.30184051 30.75231576 61.37518081 41.95911028 89.47771603 81.14313907
 23.28798861 22.33283522 31.72821773 34.33791118 15.49270425 34.73702239
 70.58708033 35.09144979 52.29169005 60.19083491 70.79444629 77.43498376
 54.02717709 71.06428394 82.85990663 37.95147383 22.05854464 47.2351528
 38.95549808 34.76543513 32.79726225 45.31378534 31.22256699 28.82651333
 37.32666465 38.45685706 59.06563364 32.63525078 15.94394538 69.14219164
 17.49982421 29.5507588  51.06845157 47.67728735 27.1373284  47.20752408
 62.07446386 70.72100875 49.77555593 38.01382049 46.03774112 33.85140657
 43.33399849 18.93039947 34.53338967 51.35217642  6.94800624 62.75695419
 43.00215151 35.85866798 39.47327849 36.51187914  7.99110288 22.5713999
  3.7100464  13.51794395]
Accuracy th:0.5 is [68.06934613 97.2137279  89.57371377 97.06387593 97.47079105 96.60579184
 97.11017166 94.73690623 97.34896017 96.47665111 98.53193796 98.5234098
 99.41399349 95.31560288 97.2685518  96.56924258 96.29512311 97.48053752
 98.66107869 98.30776915 98.1883749  99.17033175 99.18251483 98.06532571
 95.21935649 96.65086926 94.07901951 96.7532072  98.01293844 98.15791718
 97.42327701 98.57579708 96.44375678 98.05557924 98.00441028 98.18593828
 96.94326336 97.63769935 97.54145296 92.72913342 97.84237521 92.1272889
 96.9213338  96.23908091 96.9627563  93.87921687 98.02999476 98.57457877
 97.99831873 98.52462811 98.42107187 98.55630414 98.99976852 97.22591099
 98.70615611 97.46591781 89.43238996 96.20253165 96.23177106 96.91524226
 90.61049451 97.37454466 96.16232746 96.98712248 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.5621642  99.81603538 96.1818204
 97.96420609 95.45083515 96.168419   96.92255211 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [51.94746653 97.2137279  89.51523495 97.02732667 97.30144613 96.5997003
 97.00783373 94.73568792 97.45982627 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.15304394 99.18616976 99.0521558  97.97882579
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.31362922 98.57457877 96.36822163 98.02024829 97.89963573 98.0214666
 96.94082674 97.49393891 97.2831715  92.72913342 97.84237521 92.05906361
 96.91524226 96.22689782 96.9627563  93.87434364 98.02877645 98.57336046
 97.99588212 98.52097319 98.37233952 98.55508583 98.99976852 97.65475567
 98.70615611 97.46591781 89.13390431 96.15745422 96.24273583 96.9067141
 90.17190336 97.22103776 96.11481342 96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.55972759 99.81603538 95.99785578
 97.96420609 95.45083515 96.15258099 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [82.8013062  12.16853628 38.5793104  29.57934555 40.56137426 39.57538874
 39.23175428 25.56613644 18.69154987 21.92687677  5.35891946 21.82701957
  2.92743903 13.44903823  9.79642589 16.43373039  9.26090551 10.77978923
 19.37146056 14.28540126 26.15113079 16.0286875  76.77680588 39.7061482
 14.23767334 10.154985   20.53089855 16.73207282  5.60408467 17.27934236
 45.73454566 18.62914232 35.62104402 30.78970738 38.98169663 50.53760897
 20.44786187 48.11311148 53.84306765 26.72839939 11.56510009 34.51231746
 27.07509877 23.81097641 17.98518624 28.30415043 14.20071457 11.13326351
 21.00091157 16.00401302 33.20762204 16.30694596  7.50813415 44.83040276
  6.30346901 13.73952402 37.60939285 28.08845667 15.3285421  18.16560892
 46.946465   40.47918457 29.25082301 17.4072326  19.39695836 17.85665962
 17.85293551 10.60078373 17.81879793 25.59429814  3.40857361 42.09710364
 22.75590006 21.56164683 17.28695375 15.0154636   2.46132156  8.09946801
  1.46082171  4.61231681]
mAP score regular 42.42, mAP score EMA 23.67
starting validation
Accuracy th:0.5 is [84.15676309 97.229489   92.13443954 98.00184369 98.86638264 97.65552981
 98.4876797  95.20143508 97.82245808 96.69382365 98.54249197 99.00839624
 99.35221865 95.10925082 97.31669034 96.77105912 96.23539378 97.63310661
 98.88631437 98.35812343 98.98597304 99.24757705 99.62627999 99.34474425
 95.42068416 96.60662232 93.76136732 96.91058126 97.81747515 98.18870369
 98.4951541  98.49266263 96.85327752 98.76174104 98.65460797 99.06320851
 97.86979595 98.22607569 99.07566584 93.01143583 97.86730448 93.0363505
 97.0501034  96.31761218 96.99529113 94.2646436  98.18621222 98.83648504
 98.05167302 98.7492837  98.83150211 98.60976157 98.87634851 98.38802103
 98.6969629  97.60320901 90.4228019  96.90559833 96.26030844 97.31419887
 92.47577049 98.41791863 96.74614446 97.32914767 98.63467623 97.48860154
 98.45529063 95.74955776 98.78167277 98.02426689 99.81563146 97.21703167
 98.19368662 95.54774896 96.69382365 97.27682687 99.24757705 98.26843063
 99.82559733 99.15040985]
Accuracy th:0.7 is [84.44826469 97.22450607 91.43433739 97.82245808 98.89877171 97.54590527
 98.4278845  94.95976281 97.64556394 96.76607619 98.54996637 99.01836211
 99.35221865 95.11423375 97.2892842  96.54682712 96.21297058 97.55587114
 98.88133144 98.33570023 98.92617784 99.31733812 99.64372026 99.37215038
 95.43812442 96.54433565 94.46396093 97.11239006 97.81747515 98.14136582
 98.20614396 98.6745397  96.61658819 98.64215063 98.39051249 98.87634851
 97.77761168 98.19866956 98.95358397 92.79716969 97.84238981 92.60283529
 97.07501806 96.47208312 97.03764606 94.30450706 98.25099036 98.78416424
 97.99436929 98.7119117  98.73682637 98.58235543 98.87634851 98.20116102
 98.6969629  97.61815781 89.86222189 96.66392605 96.21546204 97.1995914
 91.54396193 98.23105862 96.31013778 97.2818098  98.53501756 97.47614421
 98.34815756 95.77198097 98.75177517 97.89221915 99.81563146 97.2444378
 98.05416449 95.44559882 96.58419912 97.2220146  99.24757705 98.25099036
 99.82559733 99.15040985]
Avg Prec: is [94.43326961 23.43519058 61.99595479 66.0207097  75.18212444 62.57319776
 78.97817833 43.56973817 53.00718298 46.41276842 27.34110216 56.60140266
 13.88136862 22.57262473 27.90575539 50.50787636 22.87322205 38.24843413
 42.13482037 30.91419982 72.18729431 52.03348508 92.29861288 88.80672794
 22.93613253 25.23245108 30.39216383 38.70746221 18.67474972 34.70869932
 75.08526264 36.75904362 53.02233056 62.74436164 69.58686589 80.29242787
 57.37211341 75.11876311 88.42129643 39.35667606 25.42517268 47.15302831
 35.66839159 32.72593371 29.24559061 44.84688266 30.86931104 26.22648895
 36.94294214 38.50869202 65.88027235 31.36326135 18.31946816 74.2660053
 20.39776024 29.61145812 50.77266605 48.87105123 28.13147511 51.50994273
 62.06643409 78.47473329 54.25590011 45.16880917 52.11580939 32.28148301
 51.00141406 21.74974763 36.5955831  55.71403444  8.65041993 67.35475607
 44.91643329 35.99913109 50.29363922 39.86800046  7.72222686 26.13228741
  1.60465266 13.53573333]
Accuracy th:0.5 is [70.27181902 97.22450607 89.80740962 97.09744126 98.16877196 96.64399432
 97.11239006 94.88501881 97.1771682  96.42225378 98.5250517  98.5325261
 99.34972718 95.01208361 97.21204873 96.31013778 96.21047911 97.50604181
 98.7717069  98.34068316 98.37805516 98.75924957 99.46433465 98.27341356
 95.43563296 96.52938685 94.3393876  96.79846526 97.81747515 98.11894262
 97.69041034 98.64713357 96.49201485 98.26593916 98.41044423 98.48269676
 97.2818098  97.57829434 97.68044448 92.78222089 97.82744101 92.51065102
 97.0575778  96.48703192 97.03266313 94.07778359 98.18870369 98.77668984
 97.95201435 98.6222189  98.46027356 98.55245783 98.87385704 96.65396019
 98.6969629  97.57081994 89.61805815 96.44467698 96.10085457 96.79099086
 91.26740912 97.51600767 96.20798764 96.93300446 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.56832847 99.81563146 96.66143459
 98.03174129 95.45556469 95.79689563 96.99030819 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [56.14769415 97.22450607 89.58816055 96.97286793 97.98191195 96.63651992
 96.87819219 94.87754441 97.45122954 96.41976231 98.5250517  98.5325261
 99.34972718 95.11423375 97.2070658  96.31262924 96.21047911 97.50604181
 98.78167277 98.34068316 98.23105862 99.16286718 99.33228692 98.26095622
 95.43563296 96.52938685 94.3393876  96.79099086 97.81747515 98.11395969
 97.52597354 98.67204823 96.43720258 98.19368662 98.30081969 98.4951541
 97.27931833 97.50105887 97.3715026  92.74484889 97.82744101 92.37611182
 97.08498393 96.48952338 97.03764606 94.02795426 98.18621222 98.77668984
 97.96447168 98.5997957  98.35314049 98.55993223 98.87385704 97.61068341
 98.6969629  97.58576874 89.18952587 96.46959165 96.16314124 96.78102499
 90.82891098 97.18962553 96.07843137 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.53593941 99.81563146 96.19802178
 98.03174129 95.44559882 95.75952363 97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [85.47797547 12.75225632 44.1332502  40.60352885 50.05903476 45.48184949
 53.45803442 26.27033384 25.85533049 25.12078404  7.27683325 30.52548095
  3.43828424 15.90723419 13.68895247 23.43066906 11.84441416 11.97705648
 22.86422226 17.78572754 38.89373201 27.82508917 87.3289982  51.45309343
 16.24293243 11.83185752 20.69076952 19.04075457  8.02401288 22.68486655
 59.84774768 21.65089412 40.27247995 38.53796933 50.57400297 61.98388694
 24.57161799 57.65158308 69.31784392 30.02105767 15.18629259 36.46746422
 29.60797137 25.46105003 19.79907221 30.83540412 15.33209217 10.29965933
 23.67337986 21.34727252 42.24913407 15.97809748 10.59860172 54.91125168
  8.45945028 14.79714904 41.12364008 31.76114735 16.12387291 22.69473441
 50.89645057 51.49334289 37.96888409 27.81887325 32.13311283 18.85672496
 31.17035385 13.12842468 22.11407653 34.50441238  6.35316762 52.8792055
 28.11288946 26.76617786 26.02836023 17.47816661  2.80292178  9.56307955
  1.16690685  5.09390582]
mAP score regular 45.06, mAP score EMA 28.87
Train_data_mAP: current_mAP = 42.42, highest_mAP = 42.42
Val_data_mAP: current_mAP = 45.06, highest_mAP = 45.06
lr:  [8.59489107875106e-05, 8.59489107875106e-05]
BCE Train Loss:  tensor([44.9396, 12.5883, 17.5238, 11.2468,  2.7021,  6.2525,  5.8391,  6.6765,
         5.9251, 12.9705,  2.8577,  1.0233,  1.0351, 12.1529, 30.7201, 10.2338,
        23.5791, 16.9823,  5.7197,  5.3936,  3.3639, 14.4444,  5.7974,  2.6077,
        28.0818,  9.7384, 27.3276, 14.6948,  9.4400,  3.5132,  4.6852,  2.9535,
        10.0671,  3.5563,  2.8191,  4.1257,  5.6415,  4.3846,  7.6027, 17.7870,
         7.4852, 27.7085, 14.7626, 14.2594,  9.5486, 24.6677, 10.4104, 14.3662,
         3.5676, 17.1266, 14.7626,  9.9688,  5.9402,  8.9167,  3.4435,  6.4771,
        29.3050,  7.1046, 10.9723, 10.6816, 24.5297, 13.1878, 12.5842, 14.9287,
         4.9717, 12.9598,  2.1791, 20.0740,  2.1577,  6.9781,  5.7822,  5.1892,
         6.6195, 11.6374, 11.0939,  9.3791,  1.0458,  6.2613,  0.2245,  0.6604],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [12/80], Step [000/642], LR 8.6e-05, Loss: 842.9
BCE Train Loss:  tensor([57.1651, 15.1626, 28.0875, 12.9543,  3.5447,  8.6462,  6.3355, 17.9931,
         5.1702,  9.2773,  5.3089,  6.2905,  3.5454, 14.5674, 16.1572, 15.5709,
        14.6910,  7.8360,  2.9625, 24.2687,  8.3259,  1.7767,  0.4071,  0.9598,
        10.6486, 14.4921, 23.9137, 17.3245, 11.8918, 16.1781,  5.2344, 12.6686,
         5.0282,  1.8194,  2.7963,  4.0581,  7.5756, 13.4556,  1.0320, 27.2320,
         6.6065, 33.5020, 12.2867, 20.0062, 10.2976, 19.4986, 12.4882,  4.0152,
        10.6234,  7.7949,  4.8459,  8.2367,  5.9736,  1.4223,  1.6057, 14.6499,
        33.7925, 21.4844, 22.9530,  9.1532, 27.8950,  7.4277, 11.4853, 13.8995,
         2.2410,  7.0789,  4.4765, 16.7274,  8.9552,  7.5835,  5.2791,  8.6694,
         5.4454,  8.4173, 13.3441, 15.5921,  4.6936, 21.1463,  7.5191,  0.8313],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [12/80], Step [100/642], LR 8.7e-05, Loss: 922.3
BCE Train Loss:  tensor([48.5365, 16.9110, 27.3328, 13.1228,  6.0235,  9.7273,  8.9964, 16.1916,
         9.4477, 11.7647,  9.0376,  5.6751,  1.3830, 22.5629, 11.8724, 16.6578,
        14.6977, 11.5590,  9.2980,  5.4023,  4.8808,  2.9495,  5.1926,  0.8152,
        24.1953, 11.5881, 23.2405, 16.8149, 12.4123,  8.3368,  8.6693, 15.3740,
        13.0487,  5.0583,  1.9303,  2.1991,  9.6061, 12.8898,  9.5821, 22.4607,
        13.1416, 24.0876,  8.8418, 18.1342, 14.0016, 12.8341,  4.5419, 10.2568,
         3.4819, 11.8018,  1.9386,  4.2740,  5.4548,  4.2350,  3.2715, 10.9871,
        18.4348,  7.8576, 12.8683,  8.2826, 18.0212,  3.2313, 16.2000,  4.9770,
         2.4176, 11.8993,  7.3154, 19.2175, 12.7785, 10.0048,  0.1923,  6.5822,
        13.0719, 13.8322, 13.2346,  9.8722,  0.6289,  3.0727,  0.1299,  9.4543],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [12/80], Step [200/642], LR 8.8e-05, Loss: 862.3
BCE Train Loss:  tensor([48.6109,  8.3270, 29.3777, 10.0954,  1.5853, 13.6876,  4.1743, 26.8827,
         4.6235,  6.2749, 10.9596, 10.2283,  3.9812, 16.2829,  5.9231, 12.9632,
         8.7644, 12.4101,  2.8002, 10.6036, 10.9670,  0.6102,  0.3485,  3.5551,
        18.1370, 26.9947, 30.4658,  6.2078, 15.7685, 12.8891,  8.7485,  7.1960,
         5.6884,  3.5616,  1.8607,  2.9674,  4.7628,  7.3406,  3.9934, 26.5959,
        10.5591, 27.4249, 14.5127,  7.8551, 12.0796, 16.9248,  6.3038, 10.1947,
        11.8527,  2.6009,  4.4495,  2.0236, 11.1681,  1.5025, 11.8337,  8.8811,
        44.7774,  6.7399, 12.8562,  5.8370, 23.5085, 10.0737, 11.3776, 16.2102,
         7.4238,  7.3171, 13.9435, 16.6549,  1.7888, 16.0860,  0.2445, 10.2090,
         8.1709, 24.6050, 15.2840, 23.0212,  4.4083, 15.2347,  4.7553,  3.8678],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [12/80], Step [300/642], LR 8.9e-05, Loss: 911.8
BCE Train Loss:  tensor([49.0420,  6.6930, 23.1000,  7.4544,  6.1254,  4.8711, 10.7133, 10.4273,
         5.6579,  8.4937,  0.9868,  1.0848,  0.4223, 19.9167,  7.5229, 12.4353,
        20.1036,  8.7444,  2.8048,  3.4752,  7.3001, 12.1645,  2.7917,  9.8063,
        12.6821,  6.3236, 17.9981,  5.9039,  5.5249,  5.6481,  2.2724,  3.1020,
        13.5569,  3.5856,  1.1860,  6.7625,  3.7492,  2.2909,  1.2202, 26.8982,
         6.9375, 22.4570,  8.5129, 11.9402, 19.0480, 27.0426,  8.9872,  7.7680,
        13.2028,  8.1496, 16.0495, 11.8782,  5.2378, 12.6796,  4.9486,  9.4382,
        34.7657, 13.6791, 26.7133,  6.0751, 32.7366, 10.8854, 17.1834, 12.0786,
         6.1811, 12.7688,  5.5763,  8.4568,  2.4806, 11.4671,  0.2096, 17.8476,
         9.6834, 20.3944, 12.1303, 11.8648,  0.9379,  6.3826,  0.3124,  2.7020],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [12/80], Step [400/642], LR 9.0e-05, Loss: 838.6
BCE Train Loss:  tensor([57.1196, 12.5789, 20.5955, 10.5167, 20.1676,  3.5149,  3.3462, 14.7580,
         5.3041, 17.1691,  2.1674,  6.3200,  4.9682, 13.9003, 11.1548, 10.6307,
        22.8565, 10.6466,  1.1378,  3.7790,  3.7689,  2.3096,  0.2633,  3.0882,
        24.2117, 13.7120, 20.5618, 20.3698,  8.0736,  7.6876,  4.1682,  2.9151,
         8.5171,  5.6331,  1.9213,  1.8426,  5.1481, 13.1940,  8.7190, 26.2637,
         7.2964, 29.0723, 20.6690, 30.3450, 20.8090, 28.2647,  9.0626,  6.5349,
         8.2316,  2.3860,  6.0858,  7.3379,  1.7390, 11.4650,  9.1622, 20.0340,
        31.6442, 12.4228, 16.1685, 11.8237, 29.4070,  9.8104, 12.5209,  7.7891,
         4.5456,  9.1171,  7.7047, 13.2803, 12.4150,  9.2499,  0.2557, 14.2067,
         3.8621, 13.4770,  2.6905,  4.3304,  1.6014, 11.4655,  4.1601,  5.2157],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [12/80], Step [500/642], LR 9.1e-05, Loss: 902.7
BCE Train Loss:  tensor([49.4127, 26.3630, 34.0317,  5.2297,  4.5473,  3.6576,  5.4395, 17.1101,
         8.6823,  3.9190, 11.6428,  9.7827,  1.3051, 14.9729,  8.7021,  5.9200,
        12.3012,  9.7895,  2.3452,  4.7154,  2.7686,  2.1189,  0.3146,  2.6322,
        19.8347, 18.5691, 25.6387,  4.2482, 12.4809,  8.6529,  9.1125,  1.3854,
         6.7441,  6.0585,  7.9880,  8.6419,  8.5374,  8.9877,  5.9494, 25.3903,
        20.2744, 29.2175, 16.0438, 20.6990,  8.8421, 19.2268, 10.9586,  4.9447,
        14.7312,  2.9145,  3.6283, 10.9067,  8.3029, 12.1219,  5.1012, 13.2485,
        25.1196,  8.8909, 16.8512, 13.4328, 29.9181,  7.6098, 11.8818,  8.7696,
         1.3026, 11.7474,  3.0659, 19.0647,  0.7936,  6.4703,  0.1271,  7.0510,
         3.9859,  9.8639,  6.7981,  9.4921,  1.4665,  7.3162,  0.1449, 12.4660],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [12/80], Step [600/642], LR 9.2e-05, Loss: 850.7
BCE Val Loss:  tensor([5.1048e+01, 5.1219e+01, 6.4606e+01, 2.3780e+01, 1.4338e+00, 1.2403e+01,
        7.6885e+00, 1.8410e+01, 6.7429e+00, 1.0834e+01, 7.5242e+00, 1.3038e+01,
        7.0012e+00, 1.6054e+01, 7.6733e+00, 1.4111e+01, 2.9728e+02, 2.3595e+00,
        1.7718e+00, 3.1473e+00, 1.9939e+00, 6.0757e-01, 2.6802e-01, 1.3420e+00,
        2.5542e+01, 1.5617e+01, 2.8807e+01, 2.8541e+00, 1.3125e+01, 1.0545e+01,
        3.0664e-01, 6.9429e-01, 7.7992e+00, 8.7707e-01, 1.5467e+00, 9.8299e-01,
        7.6466e+00, 2.3416e+00, 1.7992e+00, 4.8089e+01, 9.9563e+00, 2.3382e+01,
        6.5837e+00, 1.1083e+01, 1.3374e+01, 1.7597e+01, 1.3979e+00, 5.0324e+00,
        8.9080e-01, 4.2024e+00, 1.9100e-01, 4.1320e-01, 5.4969e+00, 7.9885e-01,
        1.9303e+00, 1.4028e+00, 2.5317e+01, 9.0462e+00, 1.4121e+01, 8.5143e+00,
        1.4288e+01, 1.0486e+01, 5.0132e+00, 5.6724e+00, 4.5517e-01, 1.8009e+00,
        4.2878e-01, 1.0337e+01, 8.8636e+00, 1.6246e+01, 2.0551e-01, 1.6447e+01,
        1.3846e+01, 1.2914e+01, 1.3393e+01, 7.0837e+00, 1.0166e+00, 8.3162e+00,
        1.6460e-01, 1.0783e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [12/80], Step [000/314], LR 9.2e-05, Loss: 1099.7
BCE Val Loss:  tensor([6.2860e+01, 1.8038e+01, 5.0432e+01, 1.2793e+01, 7.1512e+00, 3.2416e+01,
        6.0345e+01, 3.7585e+01, 2.6882e+01, 2.8294e+01, 1.5668e+01, 5.8702e+01,
        8.9714e+00, 9.5593e+00, 1.3948e+01, 3.0747e+00, 1.1239e+01, 1.7968e+01,
        2.7852e+00, 1.4922e+01, 1.7490e+00, 1.9143e-01, 1.0762e+00, 4.2269e+00,
        2.5308e+01, 2.2237e+01, 3.4046e+01, 1.4277e+01, 1.3775e+01, 1.2310e+00,
        9.9614e-02, 1.6666e-01, 1.0473e+00, 1.2908e+00, 5.7587e-01, 2.2893e-01,
        2.9986e+00, 8.3641e-01, 3.9148e-01, 2.6799e+00, 1.0060e+00, 4.0339e+00,
        2.1830e+00, 1.6917e+00, 1.3873e+00, 1.7806e+00, 5.4251e-01, 3.9066e-01,
        3.8628e-01, 4.9436e+00, 9.9690e-02, 2.2301e-01, 5.5745e-01, 2.0153e+00,
        6.5340e-01, 1.9702e+00, 1.0599e+01, 4.8021e+00, 9.3419e+00, 4.0327e-01,
        5.9488e+00, 8.0083e-01, 5.5777e-01, 2.1747e-01, 6.7412e-02, 1.3916e-01,
        6.8063e-02, 1.7075e+01, 8.7198e-02, 4.5795e+00, 1.0381e-02, 2.9163e-01,
        4.3754e+00, 4.3720e+00, 6.7926e+00, 4.1144e-01, 6.5525e-01, 5.2000e-01,
        1.7128e-02, 2.3591e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [12/80], Step [100/314], LR 9.2e-05, Loss: 718.3
BCE Val Loss:  tensor([3.1833e+01, 4.8270e-01, 4.8427e+00, 7.3658e-01, 8.7938e-02, 1.5447e-01,
        1.0781e-01, 1.6830e+01, 4.3172e-01, 1.6586e-01, 1.9425e-01, 5.0336e-02,
        5.7051e-02, 1.6446e+01, 3.8697e-01, 7.2930e-01, 1.8809e+00, 3.1252e-01,
        5.3179e-01, 3.3100e-01, 2.9898e-01, 8.0131e-02, 2.4940e-02, 5.7793e-02,
        4.5529e+00, 1.6802e+00, 2.6572e+01, 6.3992e+00, 9.6505e-01, 6.5213e-01,
        1.2874e+00, 6.9428e+00, 7.9670e+00, 1.1321e-01, 5.9749e-01, 3.3916e-01,
        1.4848e+01, 1.1692e+01, 9.5760e-01, 4.1067e+01, 2.5200e+01, 7.0065e+01,
        6.4575e+01, 6.6066e+01, 4.8330e+01, 7.0581e+01, 1.1488e+01, 9.3438e+00,
        4.8130e+01, 9.9118e+00, 2.2944e+01, 4.4058e+01, 6.0973e+01, 2.0105e+01,
        5.1526e+01, 9.4013e+01, 1.1135e+02, 1.4054e+01, 7.6893e+00, 2.1527e+00,
        8.0776e+01, 1.0544e+00, 1.1534e+01, 1.2918e+01, 1.4306e+01, 1.7826e+00,
        1.1268e+01, 1.4326e+01, 5.5817e+00, 2.1038e+00, 1.0753e-01, 6.4862e+00,
        6.8030e+00, 4.3274e+01, 1.8887e+00, 1.4153e+01, 1.0602e+01, 1.6674e+00,
        1.5449e-01, 1.2367e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [12/80], Step [200/314], LR 9.2e-05, Loss: 1298.3
BCE Val Loss:  tensor([4.0691e+01, 3.1712e+00, 2.9663e+01, 4.9860e+00, 1.4235e+00, 8.7388e+00,
        7.5435e+00, 1.7226e+01, 3.7937e+00, 2.2290e+01, 4.6186e+00, 7.9563e+00,
        9.4379e-01, 1.7107e+01, 1.7736e+01, 1.4811e+00, 1.9007e+00, 4.7643e-01,
        3.9675e-01, 3.7941e-01, 3.5985e+00, 6.5100e-02, 2.3933e-01, 1.0712e+00,
        2.6277e+01, 4.0847e+00, 2.8989e+01, 1.0833e+00, 1.6132e+01, 4.6318e-01,
        2.2138e-01, 2.7517e-01, 8.0124e-01, 3.0586e-01, 4.4929e-01, 1.5503e-01,
        1.5731e+00, 3.7932e-01, 8.0499e-01, 4.4257e+00, 7.1989e-01, 2.9060e+00,
        1.6971e+00, 1.6053e+00, 1.6067e+00, 2.4374e+00, 4.9381e-01, 1.9732e-01,
        3.6194e-01, 1.9863e-01, 1.8920e-01, 1.7010e-01, 2.1907e-01, 1.3377e+00,
        7.0657e-01, 1.2584e+00, 7.3784e+00, 6.1649e-01, 1.0994e+01, 9.0285e-01,
        9.5157e+00, 1.4997e+00, 9.7401e-01, 4.6932e-01, 2.5228e-01, 6.1333e-01,
        1.8767e-01, 7.7866e+00, 2.4577e-01, 6.5562e-01, 2.6975e-02, 9.4369e-01,
        4.6441e-01, 7.8052e+00, 1.4393e+02, 1.5678e+00, 7.8196e-01, 4.1560e+00,
        4.9150e-02, 1.7666e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [12/80], Step [300/314], LR 9.2e-05, Loss: 502.0
starting validation
Accuracy th:0.5 is [84.08645119 97.25758702 91.97865523 97.93374837 98.53924782 97.62795288
 98.42350849 95.30341979 97.90694558 96.89940425 98.57701539 98.99124036
 99.41764842 95.33387751 97.40134745 96.95666476 96.35360193 97.61820641
 98.84991655 98.41985356 98.82067714 99.30921894 99.6101412  99.15936697
 95.24372266 96.75929874 94.26176582 96.95300983 98.0214666  98.28949452
 98.02024829 98.47955069 96.81655925 98.64036744 98.76707155 98.83042361
 97.74491052 98.36502967 98.83529684 93.08366126 97.86674139 92.94842899
 96.7398058  96.33410899 96.92377042 94.51517404 98.22736078 98.65742376
 98.00319197 98.70250119 98.7877828  98.579452   98.99245867 98.38939584
 98.70981104 97.54998112 90.60562128 96.66548897 96.33410899 97.49272061
 92.4477041  98.37843106 96.77391845 97.241749   98.69397303 97.43789671
 98.41741694 95.94790512 98.72930398 98.00562859 99.81603538 97.08336887
 98.16644534 95.61408852 96.80193955 97.17230541 99.18007822 98.23954387
 99.84405648 99.14840219]
Accuracy th:0.7 is [81.04067933 97.21860114 91.61925415 97.94471315 98.50635348 97.46957274
 98.27365651 95.01346231 97.83506536 96.76660859 98.5514309  98.96443757
 99.41399349 95.3180395  97.32824892 96.76417198 96.33167237 97.53901634
 98.81336728 98.33579026 98.81945883 99.23246549 99.59308488 99.08992337
 95.2205748  96.66792559 94.14115325 96.84579866 98.01537506 98.24807203
 97.62795288 98.59163509 96.67158051 98.4539662  98.68422656 98.6342759
 97.64379089 98.17619181 98.89377566 92.79492209 97.8545583  92.71938695
 97.08093225 96.29024988 97.01392527 94.11922369 98.15669887 98.59894494
 98.12745946 98.63549421 98.72443075 98.55630414 99.00098683 98.35040996
 98.70859273 97.49028399 89.86610787 96.38527796 96.27441186 97.39160098
 92.0164228  98.15060733 96.56802427 97.19788989 98.62574774 97.36845311
 98.30898746 95.95399666 98.68422656 97.83262874 99.81603538 96.71422132
 98.034868   95.47032809 96.66427066 97.0882421  99.18007822 98.2029946
 99.84405648 99.14718388]
Avg Prec: is [94.32184902 28.07487648 61.74961247 61.9914151  76.27716156 63.05296467
 75.61474917 46.8535229  50.02821963 48.2040947  26.47335784 54.31928574
 18.39959109 24.63962909 28.33104887 46.41165357 23.95578836 40.11881176
 45.27789877 36.61777872 66.44406014 47.86179666 90.93164932 85.0615114
 25.02748396 27.27630316 33.2396462  37.461106   18.79262508 39.13813497
 72.88264775 35.9506781  53.43372089 65.61361038 73.43878385 78.81111384
 59.80083487 73.90097542 84.65924554 39.37028967 25.10026819 49.70142928
 42.66868278 38.12041796 34.16691127 48.5240845  37.55516232 31.2062379
 39.48094622 39.61593615 62.11233714 31.71693661 17.65961276 71.53685309
 21.06561397 33.21685856 52.45312776 51.31038605 30.29502758 52.7057901
 64.44385164 75.04634824 52.64875828 41.95092895 51.64920836 34.98807602
 48.31808537 20.66999347 36.5400609  54.68614107  7.78831988 65.95467149
 45.86644179 37.20988651 44.77730472 40.01182238  8.83662657 26.2324905
  4.64541517 16.40492359]
Accuracy th:0.5 is [71.85706802 97.2137279  89.70163619 97.18814342 97.70957956 96.64843265
 97.32581231 94.75396255 97.27464334 96.47665111 98.53193796 98.53193796
 99.41399349 95.31925781 97.27464334 96.58386228 96.29512311 97.48053752
 98.67204347 98.30776915 98.2297974  99.15693035 99.33602173 98.28705791
 95.21935649 96.65086926 94.08023781 96.76417198 98.01293844 98.16644534
 97.57922053 98.56605061 96.49979898 98.13842424 98.14086086 98.24563541
 96.96884785 97.72663588 97.7851147  92.74497143 97.83750198 92.20038742
 96.97006615 96.25004569 96.96884785 93.90480135 98.034868   98.57579708
 97.99953704 98.53924782 98.47224084 98.55386752 98.99976852 97.27829827
 98.70615611 97.46835443 89.69432634 96.25857385 96.21349642 96.92742535
 91.13071235 97.48906568 96.25004569 96.99443233 98.42960003 97.34896017
 98.21030446 95.95277835 98.67326178 97.5901853  99.81603538 96.40964413
 97.9654244  95.47032809 96.19887672 96.878693   99.18007822 98.16157211
 99.84405648 99.14718388]
Accuracy th:0.7 is [56.59531438 97.2137279  89.52010819 97.05534777 97.45738965 96.60579184
 97.11748151 94.73568792 97.49028399 96.4754328  98.53193796 98.52097319
 99.41399349 95.31682119 97.26977011 96.56680596 96.29512311 97.48053752
 98.65376884 98.30776915 98.16644534 99.18860638 99.25195843 98.2297974
 95.21935649 96.65086926 94.0778012  96.75077058 98.01293844 98.15913549
 97.34530525 98.57457877 96.39502443 98.03974123 98.04095954 98.1603538
 96.94082674 97.70348802 97.48662906 92.72913342 97.84237521 92.06393684
 96.91889719 96.22811613 96.9627563  93.87434364 98.02999476 98.57457877
 97.99588212 98.52584642 98.37599444 98.55508583 98.99976852 97.80460764
 98.70615611 97.46591781 89.25817181 96.20374995 96.24273583 96.9067141
 90.31079056 97.30144613 96.12334158 96.98468586 98.42838172 97.34408694
 98.20786784 95.95277835 98.67326178 97.56094589 99.81603538 96.06242614
 97.96420609 95.45083515 96.15867253 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [85.96977749 13.76512702 42.85658834 35.31985138 48.68805663 45.27169229
 47.70891482 29.06644673 23.39382106 26.07488253  7.61186406 29.16114817
  4.24374926 15.13880979 12.48202179 20.78156942 11.05827538 14.14355871
 22.19569047 18.22855656 33.23333055 20.1975881  81.39941131 51.38513977
 16.69215854 12.3894518  21.91188644 19.70458771  7.80099005 22.17543915
 51.95565725 20.4314811  40.2174729  38.20842003 46.7428119  56.085895
 26.73406801 54.0192455  62.63269939 29.08176367 13.54725155 37.5748064
 30.51732969 26.57308668 22.00821366 32.59274579 16.89824952 14.55946771
 23.15985588 20.53900891 39.14319018 19.26374649  8.40500316 50.54774253
  7.99280654 15.62327117 41.21326403 32.24633975 17.55802658 23.38050409
 50.80636033 46.60804914 35.35436641 22.59339618 27.95786137 20.94587953
 24.9021709  11.78377484 20.31547241 30.85561777  3.97614124 46.84170911
 26.80055141 26.07307907 21.14198719 17.58299979  3.94008673 10.96558658
  3.22594928  5.99989846]
mAP score regular 45.61, mAP score EMA 27.73
starting validation
Accuracy th:0.5 is [86.0278546  97.26187807 92.18426888 98.13139996 98.89129731 97.69539328
 98.5698981  95.38580362 97.98938635 96.90559833 98.65460797 99.07815731
 99.35471012 95.13416548 97.41385754 96.88815806 96.22542791 97.71532501
 98.92617784 98.4204101  98.98846451 99.34972718 99.64372026 99.44440292
 95.39078656 96.71126392 94.53621347 97.1397962  97.81996661 98.10897675
 98.34068316 98.5400005  96.87071779 98.7941301  98.93116077 99.11552931
 98.04419862 98.25099036 99.04327678 93.09365423 97.88225328 92.96409796
 96.52191245 96.48454045 96.77105912 94.53123054 98.37556369 98.85143384
 97.89720208 98.77419837 98.92368637 98.58733837 98.85641677 98.4129357
 98.72436904 97.59822608 90.54488377 97.00276553 96.26279991 97.34409647
 92.30635075 98.61972743 96.86324339 97.38395994 98.67204823 97.52099061
 98.39549543 95.76450657 98.76174104 98.06413035 99.81563146 97.3715026
 98.25597329 95.58013803 96.80843112 97.32416474 99.24757705 98.29334529
 99.82559733 99.16286718]
Accuracy th:0.7 is [84.07952762 97.23945487 92.26150435 98.19368662 98.92119491 97.64556394
 98.46027356 95.22884122 97.96447168 96.85078606 98.58733837 99.06071704
 99.35221865 95.11921668 97.3191818  96.65645165 96.29518898 97.57081994
 98.96853278 98.35314049 99.03331091 99.27249172 99.65119466 99.40453945
 95.45556469 96.56177592 94.4515036  96.98034233 97.81996661 98.23105862
 97.91713382 98.6521165  96.69631512 98.6296933  98.82651917 98.88631437
 97.94703142 98.04170715 99.05822558 92.84699903 97.84238981 93.1559409
 97.20955727 96.48454045 97.03266313 94.34437053 98.33071729 98.80409597
 98.08157062 98.76672397 98.7343349  98.56740663 98.88631437 98.4278845
 98.70692877 97.62314074 90.00423549 96.67887485 96.18556444 97.3715026
 92.42344968 98.41044423 96.58918205 97.24194633 98.53501756 97.45122954
 98.27839649 95.77447243 98.72436904 97.89221915 99.81563146 97.07003513
 98.12890849 95.45058176 96.65894312 97.23447193 99.24757705 98.27341356
 99.82559733 99.15040985]
Avg Prec: is [95.27194121 26.1226943  65.13781251 70.07666172 76.85338417 64.69343202
 81.19493242 46.69610709 55.79098713 52.24934474 34.14162889 59.09588241
 16.66454607 26.63585041 30.49036737 55.04651626 27.10275776 45.14186027
 48.44033917 33.90372877 74.82893926 56.59248872 93.17081673 90.69448052
 23.34968603 31.12509514 32.05769759 43.57327127 20.06605251 37.09194309
 77.54896816 36.05136653 52.88383442 68.06674729 73.47891261 83.09723557
 61.69702487 77.39841179 88.8840348  39.88758691 27.17223911 48.34553163
 41.79769135 36.81108582 30.57932129 45.77509048 38.29694077 26.92304778
 39.11068162 40.67753956 69.13214827 31.73298918 21.91714872 75.84114608
 23.35124144 31.43941093 51.63424926 50.80564891 30.38107579 54.86683714
 62.86725526 81.84838093 56.10948561 48.80441496 56.29869766 33.17457922
 53.63174397 22.26522865 36.59575101 58.74132469  7.78737851 69.51045765
 45.398565   35.93526435 54.04736194 41.98644159  7.09403895 27.34831026
  1.53723274 15.44233952]
Accuracy th:0.5 is [74.14854125 97.22450607 90.1313003  97.36901114 98.37556369 96.72122979
 97.50853327 94.92488228 97.05508633 96.44467698 98.5250517  98.5848469
 99.34972718 95.01208361 97.2220146  96.36744151 96.21047911 97.50604181
 98.7343349  98.34317463 98.4428333  98.5923213  99.55901039 98.54249197
 95.43563296 96.52938685 94.36430226 96.82337992 97.81747515 98.14634876
 97.95201435 98.61225303 96.55679298 98.35812343 98.5175773  98.5923213
 97.3490794  97.68044448 98.02426689 92.85198196 97.82993248 92.65017316
 97.0874754  96.48703192 97.03764606 94.09024092 98.19617809 98.77419837
 97.92211675 98.64962503 98.5325261  98.55245783 98.87385704 96.85576899
 98.6969629  97.57580288 89.75010589 96.45713431 95.99870444 96.85327752
 91.70839873 97.76266288 96.37740738 96.96041059 98.32822583 97.40389167
 98.13389142 95.7769639  98.72436904 97.69041034 99.81563146 96.79846526
 98.04669009 95.49044523 95.91648604 96.97037646 99.24757705 98.19617809
 99.82559733 99.15040985]
Accuracy th:0.7 is [61.44455241 97.22450607 89.62553255 97.07501806 98.17624636 96.64150285
 97.13730473 94.87754441 97.55088821 96.41976231 98.5250517  98.53501756
 99.34972718 95.11672522 97.21204873 96.31512071 96.21047911 97.50604181
 98.78416424 98.34068316 98.27341356 99.20273065 99.50419812 98.49764556
 95.43563296 96.52938685 94.3393876  96.79348232 97.81747515 98.11395969
 97.58576874 98.67204823 96.44467698 98.22358422 98.50013703 98.6894885
 97.2818098  97.66798714 97.61815781 92.74484889 97.82744101 92.38607768
 97.0949498  96.48703192 97.03764606 94.03044572 98.18372076 98.77668984
 97.95948875 98.62471037 98.38552956 98.55993223 98.87385704 97.68791888
 98.6969629  97.58576874 89.41874081 96.53187832 96.16812417 96.79099086
 91.09051499 97.43877221 96.11331191 96.93051299 98.32075143 97.40638314
 98.13139996 95.7769639  98.72436904 97.54341381 99.81563146 96.42723671
 98.03174129 95.44559882 95.7844383  97.01023993 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [88.31652351 14.45875293 48.15338351 47.50576443 57.07387777 50.2905054
 60.52353907 29.7085745  31.18702517 29.35689671 11.08559464 38.25372402
  4.27372626 17.34288562 16.81763711 29.11964829 13.89543019 15.86199758
 25.54828267 20.44412778 46.0606756  32.66464988 89.04749797 62.96022738
 17.82488851 14.25707099 22.60514653 24.2267509  10.05799377 26.26636165
 65.19799521 23.59628109 43.96609948 45.25902764 57.20548799 67.76362848
 31.44845544 61.6933477  76.21597366 32.2543205  17.44819738 39.76828876
 32.37024136 27.81144794 22.07676168 33.97421531 17.84659531 12.82665237
 26.41362249 25.07340995 48.66236121 19.34068575 12.49445517 59.94224141
 10.78479589 17.59785138 43.53230686 35.75164672 17.85919883 28.84586962
 54.44378915 58.16194329 42.61307354 33.57584275 38.53139868 22.55977675
 37.26906808 14.58218267 25.18975919 39.56881055  7.05842625 56.27157066
 31.34679025 29.97865805 31.60438953 20.55435178  3.90326593 12.81267563
  1.16726128  6.42532326]
mAP score regular 47.57, mAP score EMA 32.72
Train_data_mAP: current_mAP = 45.61, highest_mAP = 45.61
Val_data_mAP: current_mAP = 47.57, highest_mAP = 47.57
lr:  [9.191716752037077e-05, 9.191716752037077e-05]
BCE Train Loss:  tensor([42.8066,  9.0505, 24.6258,  4.0704,  6.5593, 18.1169,  6.2319, 18.6897,
         7.5886,  8.0760,  8.3706,  7.8811, 11.7280, 20.2998,  4.7267,  6.1592,
        15.0271,  2.2533,  7.7042,  2.5917,  3.1691,  0.4811,  0.3532,  2.6511,
        11.0464, 10.3387, 16.2322,  3.2315,  2.8073, 10.9683, 26.7720, 22.0148,
        13.5652,  4.0155,  2.6683,  6.5925, 22.7826,  3.6090,  1.9446, 16.8942,
         6.0751, 13.5821,  8.2298, 11.1248,  7.1391, 11.5601,  9.0221,  9.9723,
         3.6784,  3.8037,  4.2180,  3.7241,  1.8008, 12.3904,  8.5132,  9.3961,
        29.3237, 12.6672,  7.4074,  7.3874, 23.1398, 11.1229,  6.6827,  8.0044,
         7.3047,  7.9952, 10.7893, 21.3550,  3.0076,  6.8533,  3.1874, 12.4183,
         7.8228,  8.9670, 11.1817,  7.5411,  8.0461,  5.8913,  2.7574,  4.9307],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [13/80], Step [000/642], LR 9.2e-05, Loss: 774.7
BCE Train Loss:  tensor([37.8876,  9.4059, 32.7082,  9.2460,  3.1214, 14.6146,  8.6692, 12.6071,
         5.4788,  5.7721,  1.7545, 13.7065,  0.4319, 10.0792, 15.4447, 16.1004,
        20.3118,  9.7452,  1.7461,  2.5085,  5.3763,  7.0662,  0.5439,  3.7738,
        28.0704,  9.6980, 25.2804, 16.9994, 13.3878,  8.0400, 11.3109,  4.2889,
        13.6754,  7.6600,  4.6308,  5.5422, 10.0929,  1.4996, 11.1454, 23.7144,
         8.6469, 32.0818,  7.2322, 15.7597, 14.0909, 15.6081,  9.0017,  7.0305,
         3.3375,  2.7264,  2.1464, 11.5645,  2.1700,  5.1281,  5.9355,  6.6915,
        32.6637,  8.0021, 19.0859, 13.6382, 20.3854,  6.5555, 13.7902,  7.4387,
         6.7265,  8.7331, 21.7266, 19.9463,  4.5543, 19.8202,  0.3078,  8.2077,
         9.3333, 23.6172, 11.4386,  5.5083,  0.8006,  5.2240,  0.2553,  9.3814],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [13/80], Step [100/642], LR 9.3e-05, Loss: 869.4
BCE Train Loss:  tensor([49.2173, 10.2802, 24.6616, 12.4141,  3.7671,  5.9620,  4.9954, 16.9167,
        12.3307,  8.4072,  8.2416,  1.9165,  4.7462, 15.7891, 15.2068, 19.2034,
        22.9946, 18.1731,  8.3852, 10.0343,  6.7281,  3.5086, 13.8292,  4.5573,
        20.7720, 17.1462, 15.1625, 10.9686,  7.0427,  2.8360,  4.8317,  3.2452,
         7.3535,  2.3329,  3.4591,  2.5390,  6.1597,  5.3059,  1.1345, 37.8008,
         5.8378, 18.1931, 10.7309, 14.3608, 14.8594, 19.4408, 12.9208,  2.4762,
        14.1331,  7.8881,  1.1454,  3.5552,  1.0632,  7.3563,  4.8627,  2.8059,
        29.5115, 11.5663, 13.5946, 18.7281, 32.0604,  3.7389, 13.5866,  8.6774,
         8.6337, 14.5451,  4.3518, 10.9710,  4.3295,  6.9136,  0.2433, 10.7098,
         9.3045, 14.5003, 14.2293,  7.6215,  5.3010, 13.3025,  4.2441, 11.0195],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [13/80], Step [200/642], LR 9.3e-05, Loss: 863.7
BCE Train Loss:  tensor([46.9864, 12.5871, 36.0232,  9.6484, 12.1038,  3.0285,  9.1370, 21.6212,
         5.7563,  5.3004,  8.4312,  0.7417,  0.5966, 18.5559,  9.4650, 11.4631,
        24.9946,  5.7624,  1.9290,  9.4443,  3.8700,  1.6009,  7.6763, 11.9898,
        11.9136, 18.6417, 16.9942,  9.5120, 11.3317,  4.4360,  4.0484,  3.7515,
        10.5458,  6.5726,  4.2741,  4.9442, 14.9034,  5.9054,  7.5029, 21.4498,
        10.9928, 31.3019,  7.9529, 10.5159, 11.0855, 21.0643,  7.0258,  3.2107,
        13.9119,  3.1028,  1.4289,  1.2430,  4.5338,  3.9278,  4.3699,  5.1464,
        25.9995, 19.2335,  8.7283,  6.9833, 16.0232,  6.7391,  7.2500, 12.2743,
         8.5595, 13.2228,  3.9562, 20.7627,  2.5850,  3.7947,  0.4245,  8.5822,
         5.4843,  8.5756, 13.6383,  7.5631,  3.4040,  6.5275,  0.1827,  1.3260],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [13/80], Step [300/642], LR 9.4e-05, Loss: 788.1
BCE Train Loss:  tensor([42.8233, 21.6168, 45.4082,  7.9714,  5.9934, 17.4481, 12.1471, 19.6236,
        19.5558, 14.7943,  9.8241,  1.8909,  0.9655, 27.1463, 11.3040,  6.2845,
        20.9131,  8.8037,  6.8183,  6.2728,  5.7839,  1.7115,  4.5825,  5.5612,
        20.8468, 27.7131, 31.2465, 12.7183, 10.0851,  9.3142,  2.1966,  2.5361,
        25.9790,  4.4473,  5.0989, 10.1925, 21.4530,  5.3921,  0.8044, 30.0023,
         8.0090, 26.3353, 10.1903, 10.5112,  8.2043, 17.8084, 10.9577,  7.0358,
        10.1017, 13.9729,  1.3595,  2.8027,  8.5761, 11.3706,  4.5142,  7.8391,
        39.4968, 16.2523, 25.8797,  6.8371, 36.1410,  2.9878,  9.6267, 11.0093,
         0.9578,  7.0371,  5.6101, 18.5933,  3.9301,  4.7720,  0.1195,  6.2984,
         3.7079, 11.8022, 18.6873, 12.7573,  3.9900,  8.8132,  0.2667,  1.7425],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [13/80], Step [400/642], LR 9.5e-05, Loss: 962.2
BCE Train Loss:  tensor([53.9634,  8.4252, 29.2253, 10.6375,  9.7653, 14.1117,  6.8955, 26.4081,
         9.5882,  7.1846,  4.5231,  1.6511,  0.4434, 16.1179,  5.6452, 10.3454,
        11.4025, 11.1572,  2.0657,  3.5232,  3.4093,  8.8707,  0.9067,  5.1361,
        26.5301, 13.4328, 19.2362, 14.6475, 19.1834,  3.2160,  8.1665,  4.5090,
         5.4563,  9.6646,  2.4238,  1.0967,  7.4040,  6.5559,  5.9202, 23.4313,
        11.6127, 20.9758,  5.5903, 10.0196,  9.2132, 10.0765, 12.9817,  4.6970,
         5.7568,  4.9961,  1.3334,  1.4870,  1.0235,  6.5781,  8.9152, 10.0569,
        24.5800, 10.5188, 13.7668,  6.6487, 24.6012,  6.2597,  7.0420,  8.4639,
         2.9726,  4.8326,  7.8775, 18.4023, 13.1005, 12.0617,  0.1202, 21.1006,
        10.3570, 16.0205, 19.2351,  9.7218,  3.7788, 14.1118,  0.2522,  3.9072],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [13/80], Step [500/642], LR 9.6e-05, Loss: 817.3
BCE Train Loss:  tensor([48.6125, 19.0006, 23.5328, 10.1775,  1.7243,  5.8980,  4.1395, 11.0496,
        11.7985, 13.0415,  6.6084,  4.4564,  2.5499, 22.5054, 13.5308, 13.3880,
        15.3000,  4.0997,  1.9224,  2.8195,  1.9692,  3.1265,  4.8544,  1.0395,
        21.8135, 15.4334, 13.3422, 12.2751, 13.0891,  8.9274,  9.0147,  1.3068,
         4.6619,  3.1195,  1.2296,  4.0911,  4.5539,  8.4573,  0.7675, 26.4448,
        19.5772, 19.5512,  7.2618,  7.3973, 12.1032, 16.6566,  7.0342,  3.1135,
         5.3025,  7.1998,  4.3402,  8.2241,  3.5960,  9.4235,  3.6877,  5.0419,
        29.2969,  9.9271, 23.7360, 21.0492, 27.1246, 20.5931, 17.7080,  4.5355,
         3.7778, 11.0299,  6.0365, 27.1012,  4.6464,  6.4513,  0.1503, 23.2349,
         6.5174, 17.1446,  7.9514,  7.8037,  3.1717,  2.3474,  0.1449, 10.3715],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [13/80], Step [600/642], LR 9.6e-05, Loss: 827.0
BCE Val Loss:  tensor([4.8734e+01, 4.6814e+01, 6.9288e+01, 2.2970e+01, 2.6312e-01, 1.3166e+01,
        8.3734e+00, 1.6332e+01, 7.3833e+00, 1.0417e+01, 6.0080e+00, 1.4458e+01,
        6.7758e+00, 1.5658e+01, 8.2200e+00, 3.0641e+01, 3.0530e+02, 4.3634e+00,
        7.6397e-01, 2.9387e+00, 8.0671e-01, 1.0063e+00, 7.3146e-01, 4.1076e+00,
        2.7254e+01, 1.4353e+01, 2.8999e+01, 1.1697e+01, 1.1697e+01, 1.1083e+01,
        1.4808e+00, 3.2164e-01, 7.4853e+00, 1.3352e+00, 1.5593e+00, 1.0606e+00,
        5.0400e+00, 3.0971e+00, 1.6665e+00, 5.5545e+01, 9.7323e+00, 2.4885e+01,
        6.5374e+00, 1.1179e+01, 1.3139e+01, 1.7703e+01, 1.2106e+00, 5.5611e+00,
        4.2579e-01, 4.4894e+00, 2.2083e-01, 2.7683e-01, 5.7535e+00, 9.6374e-01,
        1.3785e+00, 2.7621e+00, 2.4601e+01, 8.3738e+00, 1.3157e+01, 6.7906e+00,
        1.5456e+01, 1.2178e+01, 4.8735e+00, 4.9264e+00, 2.4726e-01, 1.2863e+00,
        3.2390e-01, 8.9590e+00, 9.1422e+00, 1.5088e+01, 1.7765e-01, 1.6914e+01,
        1.5497e+01, 1.1192e+01, 1.5723e+01, 5.8365e+00, 5.0188e-01, 7.4714e+00,
        2.3109e-01, 8.8726e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [13/80], Step [000/314], LR 9.6e-05, Loss: 1135.2
BCE Val Loss:  tensor([6.5213e+01, 1.7899e+01, 4.8194e+01, 1.2008e+01, 2.6906e+00, 3.3708e+01,
        6.0307e+01, 3.9031e+01, 3.2770e+01, 2.5709e+01, 1.4184e+01, 6.0598e+01,
        1.0408e+01, 7.2306e+00, 1.5056e+01, 2.3686e+00, 1.0190e+01, 1.3902e+01,
        2.1040e+00, 1.4205e+01, 6.5275e-01, 4.5648e-01, 4.2112e-01, 3.6216e+00,
        2.7217e+01, 2.0601e+01, 3.5191e+01, 1.3323e+01, 1.5424e+01, 1.1420e+00,
        8.3908e-01, 2.2986e-01, 8.2845e-01, 4.8487e+00, 4.1694e-01, 2.0103e-01,
        1.9167e+00, 1.9022e+00, 4.6956e-01, 1.2517e+00, 4.6149e-01, 3.1827e+00,
        8.2566e-01, 1.1564e+00, 8.5572e-01, 2.1894e+00, 5.6666e-01, 2.7858e-01,
        1.9322e-01, 5.7392e+00, 9.2242e-02, 1.2231e-01, 3.2252e-01, 1.1470e+00,
        6.9071e-01, 1.1901e+00, 9.4978e+00, 4.4021e+00, 7.0034e+00, 4.5744e-01,
        5.1657e+00, 4.4800e-01, 3.1413e-01, 2.7076e-01, 4.5885e-02, 1.2333e-01,
        6.3673e-02, 1.9994e+01, 6.2072e-02, 4.3536e+00, 1.1749e-02, 4.0024e-01,
        5.8964e+00, 4.0077e+00, 6.4127e+00, 4.3208e-01, 2.8114e-01, 7.1567e-01,
        2.4832e-02, 2.1288e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [13/80], Step [100/314], LR 9.6e-05, Loss: 708.3
BCE Val Loss:  tensor([3.2818e+01, 5.3875e-01, 4.9146e+00, 3.3846e-01, 6.4973e-02, 9.0645e-02,
        6.3341e-02, 1.7988e+01, 2.4923e-01, 6.6111e-02, 1.0277e-01, 2.7527e-02,
        3.4415e-02, 1.6847e+01, 1.9736e-01, 1.1177e+00, 1.8815e+00, 3.4048e-01,
        2.4808e-01, 1.8215e-01, 1.3051e-01, 8.2075e-02, 1.8388e-02, 5.3246e-02,
        3.7831e+00, 6.6193e-01, 2.5969e+01, 1.1762e+01, 4.0531e-01, 7.8517e-01,
        2.4368e-01, 6.7397e+00, 7.9962e+00, 1.6786e-01, 3.6939e-01, 2.8588e-01,
        1.3856e+01, 1.0899e+01, 4.8080e-01, 3.3052e+01, 2.5109e+01, 6.3762e+01,
        6.9790e+01, 7.0580e+01, 4.7804e+01, 7.0945e+01, 1.1311e+01, 6.4291e+00,
        4.0285e+01, 1.1493e+01, 2.2040e+01, 4.8802e+01, 6.3414e+01, 2.6817e+01,
        4.7232e+01, 7.3473e+01, 1.0552e+02, 1.4004e+01, 7.7118e+00, 1.7580e+00,
        8.4377e+01, 6.5710e-01, 1.0948e+01, 1.3413e+01, 1.6362e+01, 2.0886e+00,
        1.1699e+01, 1.3880e+01, 7.0240e+00, 2.5664e+00, 8.4212e-02, 6.9919e+00,
        6.4616e+00, 4.2599e+01, 1.9172e+00, 1.5723e+01, 1.1280e+01, 1.8019e+00,
        2.5331e-01, 1.1498e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [13/80], Step [200/314], LR 9.6e-05, Loss: 1275.4
BCE Val Loss:  tensor([4.8924e+01, 4.4216e+00, 2.8744e+01, 4.9275e+00, 5.6635e-01, 8.8795e+00,
        6.9523e+00, 1.5069e+01, 1.3006e+00, 1.8651e+01, 3.6426e+00, 7.1769e+00,
        8.0431e-01, 1.6801e+01, 1.8127e+01, 2.3665e+00, 1.4556e+00, 9.6572e-01,
        2.3995e-01, 2.9922e-01, 1.6140e+00, 9.6537e-02, 3.1122e-01, 1.3147e+00,
        2.5681e+01, 3.8645e+00, 2.6637e+01, 4.1153e+00, 1.8081e+01, 5.6092e-01,
        4.3866e-01, 1.3474e-01, 4.9389e-01, 7.2227e-01, 2.6644e-01, 1.1762e-01,
        6.7755e-01, 5.6497e-01, 4.8509e-01, 3.1165e+00, 7.5922e-01, 2.1711e+00,
        1.0833e+00, 1.7145e+00, 1.4568e+00, 2.4917e+00, 5.8680e-01, 1.9374e-01,
        2.0136e-01, 1.5092e-01, 2.0297e-01, 1.1647e-01, 1.6177e-01, 9.9914e-01,
        8.5522e-01, 3.5182e+00, 7.5436e+00, 6.5214e-01, 1.1406e+01, 7.3759e-01,
        1.0564e+01, 8.5710e-01, 7.0717e-01, 4.6125e-01, 1.3388e-01, 6.2369e-01,
        1.4075e-01, 6.6361e+00, 2.6515e-01, 1.5277e+00, 4.0038e-02, 1.1838e+00,
        5.7939e-01, 6.7641e+00, 1.4638e+02, 1.9904e+00, 3.9235e-01, 5.4083e+00,
        7.0802e-02, 1.2381e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [13/80], Step [300/314], LR 9.6e-05, Loss: 501.5
starting validation
Accuracy th:0.5 is [84.12300045 97.34043201 92.11876074 98.04339616 98.69884626 97.63648104
 98.4393465  95.31316626 97.93983991 97.06387593 98.59894494 99.01438823
 99.42739489 95.33996905 97.46591781 97.2271293  96.349947   97.81800904
 98.91448691 98.43569157 98.91083198 99.34942313 99.63328907 99.20931763
 95.23397619 96.78731984 94.36897699 96.48274266 98.02390322 98.34431842
 98.4393465  98.59407171 96.95057321 98.72321244 98.81214897 98.91205029
 97.78755132 98.52584642 98.8158039  92.95086561 97.83384705 93.02761906
 97.02123512 96.30852451 96.97128446 94.56390639 98.28462129 98.7037195
 98.10918483 98.71346597 98.86453625 98.57579708 99.0107333  98.51731826
 98.73661383 97.01514358 90.82491685 96.73615088 96.42060891 97.58774869
 92.38922528 98.48807885 96.52903839 97.20763636 98.60259987 97.47079105
 98.35893812 95.96374313 98.70859273 98.14451578 99.81603538 97.2685518
 98.23467063 95.60190543 96.88112962 97.30510106 99.18007822 98.29558607
 99.84405648 99.15693035]
Accuracy th:0.7 is [84.91124621 97.26367856 91.72159209 98.01415675 98.59650833 97.39891083
 98.30167761 95.01589893 97.75831191 96.82996065 98.55264921 98.97662066
 99.4152118  95.3180395  97.39647421 97.12113644 96.33167237 97.7010514
 98.78047295 98.37112121 98.82555037 99.31165556 99.62841583 99.27754291
 95.21935649 96.68620022 94.1618645  97.04681961 98.01537506 98.27609313
 98.46371267 98.57579708 96.58751721 98.66351531 98.62574774 98.72077582
 97.57191067 98.35893812 98.93885308 92.75593621 97.88988926 92.72547849
 96.98346755 96.26466539 96.98468586 94.12653355 98.24319879 98.64645899
 98.02633984 98.72808567 98.75123354 98.55630414 98.99855021 98.49051547
 98.72564905 97.57191067 90.21332586 96.49858067 96.33410899 97.44886149
 92.23450007 98.28827621 96.25491892 97.07240409 98.50635348 97.38916436
 98.25294526 95.95277835 98.67448009 98.04826939 99.81603538 97.23809408
 98.10796652 95.46179993 96.72274948 97.1991082  99.18007822 98.26025511
 99.84405648 99.14840219]
Avg Prec: is [94.97427312 31.10082808 63.32489679 64.46188443 81.71382544 66.06770373
 77.4162616  48.39370862 55.36481637 53.04777237 31.45471233 58.02096256
 22.11281772 26.63941133 30.4432725  52.87741396 26.33748663 45.69297188
 51.33094949 37.869023   70.57756406 52.49926365 92.21813774 87.52512687
 24.78112623 29.2809351  36.26783059 40.86104895 21.1815779  41.75149932
 75.35004196 42.51809272 55.06522356 68.79731737 76.72269069 81.10001216
 64.07602133 77.13782501 86.13556368 39.91164285 25.39836202 50.94773794
 41.70643719 37.73096876 34.06204732 49.66649335 40.87651166 34.70832687
 40.73731547 42.42830931 66.62139607 39.85494837 22.45718854 74.95333591
 24.17252064 36.58119099 53.76946605 54.24374924 32.29120769 56.03068245
 64.9286203  78.40452096 55.02334382 45.43516014 55.07454384 39.87980299
 50.90409259 22.50912684 39.08606888 57.64077646  8.03386903 68.9047678
 47.69009557 39.83536036 48.26622419 44.66448914 11.0662084  32.05250047
  3.95057393 19.18467142]
Accuracy th:0.5 is [75.06609325 97.2137279  90.12682594 97.35748833 97.95811455 96.78610153
 97.62186133 94.79538505 97.27586165 96.5022356  98.53193796 98.60016325
 99.41399349 95.32047612 97.28804474 96.60457353 96.29512311 97.48541075
 98.69275472 98.30776915 98.32238886 99.11063462 99.41399349 98.50026194
 95.21935649 96.65086926 94.08511105 96.79219308 98.01293844 98.18350166
 97.76927669 98.53193796 96.55218626 98.21395938 98.26634666 98.38208599
 97.02976328 97.83384705 98.04339616 92.74618974 97.83872029 92.33318308
 96.95422814 96.28781326 96.97250277 93.93282246 98.05192432 98.58188862
 98.0068469  98.57579708 98.52828304 98.56361399 98.99976852 97.506122
 98.70615611 97.46226289 89.90753037 96.26222877 96.21227812 96.97493939
 91.45234585 97.67668523 96.38284134 97.01270696 98.45031128 97.35748833
 98.22370585 95.95277835 98.68666317 97.69861478 99.81603538 96.57411581
 97.98369903 95.49469427 96.28415833 96.87503807 99.18007822 98.1603538
 99.84405648 99.14718388]
Accuracy th:0.7 is [62.01069675 97.2137279  89.59077009 97.17474202 97.72663588 96.63990448
 97.33799539 94.73934284 97.55607266 96.47665111 98.53193796 98.55508583
 99.41399349 95.31682119 97.27342503 96.56802427 96.29512311 97.48053752
 98.65376884 98.30776915 98.20055799 99.19469792 99.35185975 98.41498032
 95.21935649 96.65086926 94.0778012  96.75198889 98.01293844 98.15791718
 97.44520656 98.57336046 96.42182722 98.09334682 98.18593828 98.34797334
 96.95544645 97.8119175  97.70592464 92.73157003 97.84237521 92.0858664
 96.92255211 96.23664429 96.9627563  93.87434364 98.03364969 98.57579708
 98.00441028 98.53924782 98.41376202 98.55508583 98.99976852 97.96786102
 98.70615611 97.46591781 89.42142518 96.24882738 96.251264   96.91280564
 90.54226922 97.40987561 96.15258099 96.98834079 98.43203665 97.34408694
 98.20786784 95.95277835 98.67326178 97.57678391 99.81603538 96.17938378
 97.96420609 95.45205346 96.18060209 96.91767888 99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [88.42356386 16.21911882 47.73977114 41.62737089 57.42086312 49.41221466
 55.22727883 33.37096338 29.63483314 32.3567074  11.03764791 36.58550777
  7.40611684 16.55850718 16.36317962 26.83278586 12.98805464 19.14078638
 27.56486047 21.22895455 40.40518541 24.3029845  83.9808571  60.75241835
 18.14118201 14.30308579 24.89973593 24.33373719 10.07286514 25.63050765
 57.49799117 22.65240897 42.77262456 45.19596011 53.09229776 62.25750047
 32.8380351  57.61579642 68.91631267 31.05247073 15.45941065 40.44820208
 33.43372688 30.14498398 25.02328973 35.51582532 21.39865491 17.63279376
 27.32471953 24.62760139 45.66175979 23.27990535 10.81775017 56.52575193
 10.04457239 18.97023517 43.50701552 35.32158391 19.58626262 28.86268791
 54.22957595 51.93762866 40.44767633 27.84662611 35.90511487 24.67700272
 31.8279711  13.21935263 27.03368823 37.26895008  4.39670127 51.15572265
 31.58395799 28.7864521  26.70563715 21.30452653  4.82799339 12.7563151
  2.59126119  8.32227061]
mAP score regular 48.43, mAP score EMA 31.85
starting validation
Accuracy th:0.5 is [85.14836684 97.2892842  92.52809129 98.21112689 99.07566584 97.78010315
 98.61972743 95.46303909 98.05665595 97.01771433 98.6670653  99.10805491
 99.36467598 95.14163988 97.44126367 97.2145402  96.27525724 97.91464235
 99.00092184 98.39798689 99.14542691 99.38959065 99.64870319 99.45187732
 95.45307322 96.71375539 94.5860428  96.42972818 97.81996661 98.19368662
 98.7567581  98.6894885  96.95044473 98.83897651 98.96604131 99.15040985
 98.07409622 98.35314049 99.01587064 92.9616065  97.85733862 93.35276677
 97.04013753 96.45713431 96.87570073 94.54368787 98.28088796 98.89378877
 98.05665595 98.74679224 98.94361811 98.5848469  98.88382291 98.59730423
 98.67703117 96.86075192 90.77908165 97.01771433 96.33505245 97.53593941
 92.58539502 98.65709943 96.62157112 97.21204873 98.53003463 97.52597354
 98.35064903 95.7844383  98.75426664 98.14884022 99.81563146 97.53843087
 98.30829409 95.56269776 96.83583726 97.38146847 99.24757705 98.43037596
 99.82559733 99.16535865]
Accuracy th:0.7 is [86.79522635 97.26935247 92.38358622 98.29583676 99.01337918 97.53344794
 98.51259436 95.28863642 97.85733862 96.90061539 98.58733837 99.08812318
 99.35221865 95.11921668 97.33662207 97.05508633 96.28522311 97.79256048
 98.92866931 98.39549543 99.07815731 99.36965892 99.66365199 99.53160426
 95.44061589 96.59914792 94.4515036  97.192117   97.81747515 98.24351596
 98.7866557  98.67703117 96.63402845 98.84645091 98.7567581  98.96604131
 97.91962528 98.23355009 99.11802078 92.78720383 97.86979595 92.9541321
 97.10740713 96.48703192 97.03764606 94.25467773 98.38552956 98.84645091
 97.98440342 98.81904477 98.75426664 98.56740663 98.87883997 98.55993223
 98.75177517 97.67795301 90.34556643 96.80843112 96.24535964 97.48361861
 92.59785236 98.4428333  96.30266338 97.06754366 98.41044423 97.47365274
 98.21361836 95.7769639  98.72187757 98.06413035 99.81563146 97.39641727
 98.19368662 95.45058176 96.64648579 97.34409647 99.24757705 98.39798689
 99.82559733 99.15290131]
Avg Prec: is [95.79844789 29.06007452 66.18760175 72.02654817 80.16675841 67.53185658
 83.17118565 48.4533964  60.92827376 54.99810601 38.23126305 60.74519469
 21.74060816 28.24768096 33.66617848 59.02542782 29.36280083 51.37902368
 53.91702494 37.50992953 78.79891055 61.72236789 93.8233338  92.7640555
 23.32910165 32.35138739 33.44953247 46.49496564 23.31824102 39.36796001
 79.86463507 40.55376954 54.84249532 69.71343608 76.63605161 83.85006695
 65.11228682 78.19157283 90.06714507 41.54007357 28.26950463 50.25912604
 36.46646284 34.87321147 29.76761145 47.13243303 40.35655213 32.96414213
 40.22725293 43.27848231 72.72161213 37.86810298 25.11668224 78.96965678
 28.24659162 36.48827712 53.44653194 53.16399734 32.40669338 59.29492572
 64.45168852 83.54956353 58.34717106 49.44896187 57.57404805 35.85757171
 55.40593474 22.05449454 37.46803762 60.78602947  8.35782483 72.30193055
 47.6689235  37.9325832  56.23286444 45.01350761  9.94947178 37.85445347
  1.91481181 17.57408017]
Accuracy th:0.5 is [77.74372773 97.22699753 90.66447418 97.58327728 98.5773725  96.98532526
 97.92959115 94.98218601 97.09993273 96.46710018 98.5250517  98.6894885
 99.34972718 94.99713481 97.26436953 96.45464285 96.21047911 97.50853327
 98.76921544 98.34815756 98.5250517  98.5773725  99.60883972 98.7941301
 95.43563296 96.52938685 94.36679373 96.87819219 97.81747515 98.16129756
 98.18621222 98.5923213  96.67140045 98.47023943 98.5773725  98.7044373
 97.46617834 97.78259461 98.31327703 92.8793881  97.82494955 92.79467823
 97.1098986  96.46211725 97.03764606 94.13757879 98.18870369 98.76921544
 97.88972768 98.68699704 98.60228717 98.55744077 98.87385704 97.17467673
 98.6969629  97.58576874 89.97682936 96.49450632 96.04355084 96.96539353
 91.90024167 97.96696315 96.52440392 97.0276802  98.34815756 97.42631487
 98.17375489 95.7769639  98.7418093  97.84737275 99.81563146 96.91058126
 98.07160475 95.56269776 96.09088871 96.95044473 99.24757705 98.19866956
 99.82559733 99.15040985]
Accuracy th:0.7 is [66.97311707 97.22450607 89.77502055 97.30174154 98.39549543 96.69631512
 97.55337967 94.88252734 97.63808954 96.42723671 98.5250517  98.59730423
 99.34972718 95.11174228 97.22450607 96.32259511 96.21047911 97.50604181
 98.78416424 98.34068316 98.37556369 99.18778185 99.56648479 98.7717069
 95.43563296 96.52938685 94.3393876  96.80344819 97.81747515 98.11146822
 97.77262875 98.6745397  96.52440392 98.31327703 98.63965917 98.82402771
 97.304233   97.80252635 97.96945462 92.75232329 97.82744101 92.41597528
 97.0949498  96.48952338 97.03764606 94.03542866 98.18870369 98.77668984
 97.96447168 98.64215063 98.43037596 98.55993223 98.87385704 97.89471062
 98.6969629  97.58576874 89.62304108 96.64399432 96.16314124 96.81839699
 91.29481526 97.73774821 96.18307298 96.93549593 98.32573436 97.40638314
 98.13389142 95.7769639  98.72436904 97.64307248 99.81563146 96.69880659
 98.03174129 95.44559882 95.84921643 97.01273139 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [90.44453231 16.58266788 52.22170211 53.467236   63.28753673 54.51571591
 66.80284683 33.38433757 37.19029723 33.77083089 16.36212363 44.94669491
  5.63454474 18.90165323 20.03681745 35.19171421 16.58835595 21.68039716
 29.53588056 23.08314192 53.328031   37.3484275  90.41344479 72.68563242
 19.17638895 17.01527989 24.51614618 29.16333866 12.43667018 29.11320577
 69.50350996 26.02078401 46.51965754 51.70618889 62.3168263  72.38757991
 38.68223391 65.58567726 80.97412141 34.61480328 20.13611535 42.81664766
 34.45366351 29.96476818 24.22493637 36.40007287 20.79569256 15.38933344
 29.14266018 29.07062074 54.75973131 22.48442807 14.41875512 64.02887599
 13.98500363 21.04967801 45.76867338 39.71093959 19.87166349 35.39561108
 57.21234053 64.78850942 46.85559574 38.15355876 43.79466297 25.77321116
 42.01120567 16.10472932 28.10940359 44.76429202  7.72169803 59.40564362
 34.69832974 32.49778834 37.28275512 24.17306853  4.9776337  16.62139569
  1.25709791  8.44604106]
mAP score regular 49.99, mAP score EMA 36.45
Train_data_mAP: current_mAP = 48.43, highest_mAP = 48.43
Val_data_mAP: current_mAP = 49.99, highest_mAP = 49.99
lr:  [9.635113213320874e-05, 9.635113213320874e-05]
BCE Train Loss:  tensor([38.8712,  7.2873, 18.5971,  6.3507,  1.5271,  7.0311,  6.4995, 14.0127,
         9.7440,  7.9178, 18.6764,  0.9017,  0.4919, 22.4717, 10.8411,  8.9163,
        20.9860, 10.0415,  0.4286,  4.3930,  4.0383,  0.9106,  0.3615,  0.9734,
        15.2449, 17.8234, 21.6821, 16.2362, 20.0525,  3.6001,  6.5165,  4.6150,
         8.7085,  3.3277,  3.7379,  4.0720, 12.4030,  4.8486,  3.7551, 36.2405,
         2.7536, 30.4597,  5.9544,  6.3701, 18.5214, 22.6842,  2.6455,  8.6960,
         5.1288,  4.9917,  2.2050,  1.7604,  3.9415,  9.2193,  4.7466,  6.1355,
        43.0020, 19.0371, 31.8116, 16.2247, 27.6224,  5.0993, 24.7371,  9.8464,
         9.7956, 18.8445, 13.9560, 16.7541,  7.6711,  5.6974,  0.1484, 10.7935,
        13.2406, 20.7427, 18.4432, 20.6269,  0.7194,  4.2284,  5.6409, 10.2563],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [14/80], Step [000/642], LR 9.6e-05, Loss: 896.3
BCE Train Loss:  tensor([38.9132,  9.5595, 23.0428,  3.7521,  2.4046, 11.4051,  8.0986, 14.6737,
         7.8964,  7.5528,  4.8622,  2.9842,  0.6595, 22.0620, 15.5449,  8.8490,
        15.0155, 12.4957,  5.9993,  7.7918,  3.7740,  3.6365,  9.7380,  2.3882,
        12.4568,  5.8419, 15.8977,  8.6799,  9.7924, 11.2480,  1.2655,  4.3173,
         8.3821,  1.0654,  0.6775,  0.7085,  7.5667,  3.3947,  2.1382, 17.8745,
         9.1250, 19.2354,  7.7417,  8.6216, 10.8656, 20.5093, 10.3361, 10.9814,
         3.8864,  2.1707,  3.6071, 11.1426,  2.0110,  2.1358,  1.6006,  4.9212,
        21.7004, 12.2492, 16.0758, 11.2037, 10.4106,  4.3643,  9.1398,  6.5077,
         4.9398, 13.8382,  6.2051, 21.6675,  6.8986, 17.4243,  0.0862,  8.8179,
         1.6274, 16.2954, 20.9970, 16.1485,  7.1908,  5.1238,  0.1827,  3.8883],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [14/80], Step [100/642], LR 9.7e-05, Loss: 726.3
BCE Train Loss:  tensor([32.5821,  9.9108, 16.5851,  4.9194,  2.1638,  7.7143,  4.9565, 12.2070,
         2.6903,  9.7152,  3.5104,  0.8995,  0.5685, 10.6991,  6.3326, 12.5443,
         7.4496,  5.1131,  1.3794,  6.4894,  8.3202,  3.4184,  2.9837,  6.6004,
        11.6915, 13.7822, 23.1724, 12.3541, 15.9953,  6.2987,  4.0639,  2.6731,
         9.0276, 10.7051,  4.8523,  6.5318,  7.5048,  7.6076,  0.9626, 29.4240,
        14.1389, 26.8295, 11.0349, 17.1492,  7.6479, 21.4848,  2.8645,  7.3006,
        18.4445,  1.4920,  2.0854,  2.8012,  3.7701,  9.5185,  3.7765,  8.2856,
        29.9936,  7.8494, 13.8785,  6.9143, 39.3213,  4.4201, 11.0871,  4.1488,
         7.5166,  9.8678,  7.5279, 12.4326,  8.3608, 14.5225,  0.2575, 19.3892,
         6.7587, 11.7850,  9.2416, 11.4574,  5.7303,  3.4540,  0.1762,  2.7712],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [14/80], Step [200/642], LR 9.7e-05, Loss: 753.9
BCE Train Loss:  tensor([39.7553,  8.1918, 23.1045,  4.5974,  1.1669,  6.7842,  3.5178, 18.1135,
        11.9337, 15.2350,  1.2752,  7.2124,  4.9303, 11.8928, 13.8628, 19.1472,
         9.3403,  5.1658, 11.6120,  4.5999,  5.4468,  1.6604,  0.2363,  5.7251,
        18.7884,  7.1671, 11.8807, 13.4622, 16.3669,  2.2859,  2.4202,  1.7705,
        13.7517,  1.5354,  1.2968,  0.8336,  4.7998,  4.3826,  3.5943, 19.9071,
        11.3011, 16.5403,  3.4485,  8.0106,  9.5025, 18.9310,  7.3233,  3.1679,
         8.3556,  3.5027,  5.6667,  2.8894,  3.4436,  4.4155, 19.4286, 13.2702,
        33.0181, 16.2854, 20.9600, 13.3413, 26.3474,  5.1273,  9.3282,  7.1979,
         2.8887,  9.5877,  2.6221, 13.3638,  3.8153,  5.7397,  2.9290,  4.7876,
         3.4942, 20.6633,  9.7266, 22.9467,  5.2132, 10.1009,  0.1745,  1.1833],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [14/80], Step [300/642], LR 9.8e-05, Loss: 748.8
BCE Train Loss:  tensor([39.9938, 12.8646, 21.5694, 10.1816,  1.7281, 14.1876,  5.5623, 18.7871,
         7.3621,  9.6497,  2.3716,  3.9860,  3.1971, 23.5587,  6.7111,  7.9204,
         7.3252,  7.1541,  2.0991,  3.5762,  2.9902,  4.7023,  5.8269,  1.3867,
        34.6720, 21.9577, 30.9845, 11.8246,  7.2784,  5.2411,  1.5461,  0.7622,
        16.1240,  9.3194, 11.1512, 17.0342,  3.7450, 13.6265,  3.6611, 28.2462,
         8.9071, 17.1601,  5.0031, 15.6453,  7.0018,  6.8726,  3.9615,  9.8653,
         4.3149,  6.6555, 10.6776,  7.4396,  6.1321,  9.7869,  2.3692,  8.9940,
        28.9619,  9.4968, 10.9734,  6.3684, 21.9819,  8.0076, 14.4260, 11.9030,
         7.2326,  9.8044,  5.9122,  8.6755,  0.8147,  3.5489,  0.0975,  8.7418,
         6.8642, 11.8736, 13.3148, 14.9240,  4.7338,  6.1416,  0.3491,  6.8331],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [14/80], Step [400/642], LR 9.8e-05, Loss: 794.6
BCE Train Loss:  tensor([45.6632,  6.7670, 20.1167,  1.6854,  1.6484,  8.2210,  1.4492,  7.6009,
         7.2175,  7.2366,  7.8730,  3.7075,  0.4268, 27.1684, 12.8708,  4.8726,
        13.8125, 10.7967,  3.8872,  5.7985,  7.4696,  0.4066,  6.6040,  0.6130,
        28.3536,  3.2780, 22.9621, 21.7062,  7.6358,  8.2630,  4.4540,  2.7998,
         7.5118,  3.0315,  7.7963,  5.3026,  8.7068,  5.1874,  2.0206, 25.6173,
         2.1995, 25.3216, 21.8815, 10.3254, 10.7438, 21.9810,  6.2573,  5.1330,
        15.3821, 10.8026,  2.5427,  3.0651,  2.5273,  1.7327,  1.2838,  9.8923,
        29.5869, 10.4626, 15.2593,  8.7226, 26.2931, 12.2502, 11.9987, 17.0652,
         1.1894, 10.1051,  5.6632, 33.7678,  2.7717, 11.0791,  4.2754,  8.0929,
         2.6058, 18.7294, 26.5751, 11.2579,  3.6421, 11.9317,  0.1289,  5.9079],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [14/80], Step [500/642], LR 9.9e-05, Loss: 819.0
BCE Train Loss:  tensor([43.0121, 10.4023, 30.6106, 12.9577,  4.0303,  9.2755,  5.3984, 20.7662,
         4.9974, 18.4158, 15.6403,  1.4995,  3.3751, 24.2501, 19.8211,  7.6914,
         4.0407, 10.8039,  5.5939, 12.8791,  3.2819,  1.9758,  3.0828,  5.9836,
        19.1052, 19.9105, 31.0533, 15.4699,  3.9691, 11.5955,  5.8509,  1.1717,
        13.6146,  4.8485,  4.0351, 12.6994,  8.0723,  9.8543,  5.3491, 19.0325,
         2.2588, 24.9304,  9.8438,  7.0421, 18.1042, 15.8128,  5.8357,  2.2742,
         3.2995,  2.2453,  7.4910, 11.2528,  3.7258,  4.6818,  7.1424,  3.4688,
        39.8551, 10.1946, 11.3781,  3.2386, 19.0325,  9.3708,  8.6476, 17.2529,
         6.4118, 10.1338, 11.4976, 13.7121,  6.9872,  3.2113,  0.2033,  4.9718,
         6.7264, 32.5928, 11.2653,  9.8456,  0.8994,  1.1695,  0.1575,  2.8165],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [14/80], Step [600/642], LR 9.9e-05, Loss: 836.4
BCE Val Loss:  tensor([4.5502e+01, 4.4174e+01, 5.8958e+01, 2.1552e+01, 8.4213e-01, 1.1688e+01,
        8.8436e+00, 2.0757e+01, 6.8967e+00, 8.6750e+00, 9.8669e+00, 1.1903e+01,
        7.1624e+00, 1.6656e+01, 7.8088e+00, 2.4451e+01, 2.8918e+02, 6.8614e+00,
        6.2644e-01, 2.5903e+00, 9.8568e-01, 5.4870e-01, 1.0167e-01, 5.3156e-01,
        2.5851e+01, 1.4348e+01, 2.8419e+01, 3.8020e+00, 1.3179e+01, 1.2908e+01,
        7.1662e-01, 6.0537e-01, 8.8576e+00, 1.6654e+00, 4.1582e+00, 3.1091e+00,
        6.8199e+00, 3.4140e+00, 1.5164e+00, 4.9308e+01, 1.0782e+01, 2.1924e+01,
        6.5410e+00, 1.2394e+01, 1.5745e+01, 1.6729e+01, 1.0508e+00, 5.1750e+00,
        3.9642e-01, 4.2153e+00, 1.3528e-01, 2.7524e-01, 6.5640e+00, 2.5712e-01,
        5.8278e-01, 1.1806e+00, 2.3693e+01, 6.5908e+00, 1.2254e+01, 2.5107e+00,
        1.4634e+01, 8.7813e+00, 4.0609e+00, 5.2297e+00, 7.1462e-01, 9.8945e-01,
        2.8601e-01, 9.8928e+00, 8.1958e+00, 1.3124e+01, 1.7866e-01, 1.4999e+01,
        1.4376e+01, 1.1088e+01, 1.5560e+01, 5.9518e+00, 8.7246e-01, 6.0393e+00,
        1.4581e-01, 7.7127e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [14/80], Step [000/314], LR 9.9e-05, Loss: 1070.7
BCE Val Loss:  tensor([5.8427e+01, 1.8826e+01, 5.5318e+01, 1.0084e+01, 7.4416e+00, 3.3381e+01,
        6.0266e+01, 3.7518e+01, 2.7250e+01, 3.2425e+01, 1.5444e+01, 4.1030e+01,
        1.0335e+01, 8.7724e+00, 1.5223e+01, 3.4018e+00, 9.6848e+00, 1.6474e+01,
        2.8298e+00, 1.5293e+01, 5.9261e-01, 2.4551e-01, 7.8892e-02, 4.8587e+00,
        2.7524e+01, 1.9607e+01, 3.2975e+01, 1.5058e+01, 1.4517e+01, 9.3219e-01,
        1.3696e-01, 1.4905e-01, 5.8458e-01, 3.3133e+00, 5.9116e-01, 2.4989e-01,
        1.8552e+00, 1.0470e+00, 2.7617e-01, 1.6415e+00, 2.1397e-01, 2.4009e+00,
        5.4061e-01, 5.4264e-01, 4.1008e-01, 2.4083e+00, 3.9847e-01, 3.4796e-01,
        1.6524e-01, 4.2221e+00, 4.7685e-02, 1.2958e-01, 3.0187e-01, 4.6666e-01,
        1.9669e-01, 1.3412e+00, 7.2613e+00, 5.6857e+00, 7.7843e+00, 1.3891e-01,
        2.6064e+00, 7.9135e-01, 3.3310e-01, 1.8073e-01, 1.0108e-01, 1.1545e-01,
        4.3529e-02, 1.9472e+01, 5.5859e-02, 3.7874e+00, 4.0284e-03, 2.5122e-01,
        4.2772e+00, 4.5684e+00, 6.3674e+00, 3.9934e-01, 3.2392e-01, 3.7232e-01,
        1.3550e-02, 1.7156e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [14/80], Step [100/314], LR 9.9e-05, Loss: 684.9
BCE Val Loss:  tensor([2.3501e+01, 7.4556e-01, 5.5938e+00, 6.5732e-01, 3.9732e-02, 1.9109e-01,
        8.3351e-02, 1.4538e+01, 3.2600e-01, 1.3494e-01, 2.8699e-01, 6.1427e-02,
        9.1187e-02, 1.4864e+01, 2.8565e-01, 1.0937e+00, 1.8099e+00, 6.1477e-01,
        2.1693e-01, 1.5014e-01, 1.4884e-01, 6.6758e-02, 1.4231e-02, 3.3228e-02,
        4.4642e+00, 1.0670e+00, 2.6767e+01, 6.6095e+00, 5.2567e-01, 7.6265e-01,
        4.2332e-01, 6.3247e+00, 8.3704e+00, 1.6045e-01, 1.0724e+00, 6.1460e-01,
        1.2422e+01, 1.0513e+01, 5.0709e-01, 3.8675e+01, 2.6062e+01, 6.4386e+01,
        6.8067e+01, 6.6009e+01, 4.6502e+01, 7.0661e+01, 1.0012e+01, 8.5789e+00,
        4.3669e+01, 1.0049e+01, 2.0620e+01, 4.5861e+01, 6.0157e+01, 1.4627e+01,
        5.0670e+01, 8.9116e+01, 1.2059e+02, 1.4867e+01, 7.5436e+00, 5.0671e-01,
        9.6394e+01, 1.0266e+00, 1.1937e+01, 1.3545e+01, 1.3308e+01, 1.7464e+00,
        1.0817e+01, 1.3771e+01, 5.9873e+00, 3.3902e+00, 5.9439e-02, 7.2802e+00,
        6.7973e+00, 4.6648e+01, 2.0464e+00, 1.5517e+01, 1.1078e+01, 1.0202e+00,
        1.5921e-01, 1.0047e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [14/80], Step [200/314], LR 9.9e-05, Loss: 1286.9
BCE Val Loss:  tensor([3.8635e+01, 1.9991e+00, 2.7559e+01, 2.7636e+00, 8.0985e-01, 8.4807e+00,
        7.0692e+00, 1.6552e+01, 2.3632e+00, 1.7782e+01, 5.4598e+00, 1.0673e+01,
        8.6374e-01, 1.4994e+01, 1.7106e+01, 1.2994e+00, 1.2228e+00, 5.3964e-01,
        1.9969e-01, 2.0270e-01, 1.2658e+00, 6.7627e-02, 9.3896e-02, 6.2627e-01,
        3.0392e+01, 2.7827e+00, 2.7458e+01, 1.1077e+00, 1.6906e+01, 2.6700e-01,
        1.8256e-01, 1.7089e-01, 3.6048e-01, 4.8195e-01, 5.4855e-01, 3.3179e-01,
        7.8245e-01, 3.5045e-01, 2.7021e-01, 2.9405e+00, 4.2068e-01, 2.0763e+00,
        4.9215e-01, 6.5196e-01, 5.7127e-01, 1.2091e+00, 3.2699e-01, 1.8540e-01,
        1.2565e-01, 1.6462e-01, 7.7814e-02, 6.8061e-02, 1.1659e-01, 2.1646e-01,
        2.6859e-01, 9.9636e-01, 5.1475e+00, 3.6000e-01, 1.1105e+01, 2.7570e-01,
        8.1480e+00, 1.1207e+00, 7.7404e-01, 3.0898e-01, 3.1292e-01, 7.2289e-01,
        1.4746e-01, 7.0260e+00, 2.7934e-01, 1.0368e+00, 1.2982e-02, 7.2852e-01,
        4.5442e-01, 6.8605e+00, 9.1748e+01, 1.7632e+00, 6.5004e-01, 5.4095e+00,
        4.0287e-02, 8.1256e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [14/80], Step [300/314], LR 9.9e-05, Loss: 416.4
starting validation
Accuracy th:0.5 is [86.01747055 97.40012914 92.19916911 98.19202982 98.81945883 97.69252324
 98.44665635 95.36311692 98.14086086 97.00661542 98.69762795 99.08139521
 99.43226813 95.42281405 97.44520656 97.41353054 96.44010185 97.91912867
 98.96200095 98.43569157 99.04971918 99.32993019 99.65278201 99.2336838
 95.26077899 96.87381976 94.43963889 97.18448849 98.03852292 98.38452261
 98.5087901  98.69762795 96.97859432 98.81214897 98.88159257 98.99367698
 98.02999476 98.54290274 99.06433888 93.18843581 97.88745264 93.10924575
 97.17474202 96.38893288 97.04925622 94.57365286 98.37355783 98.74514199
 98.14817071 98.77925464 98.92788831 98.61356465 99.01926146 98.48564223
 98.74757861 97.65475567 90.89192383 96.82508741 96.39867935 97.59140361
 92.86923892 98.64645899 96.81412263 97.35627003 98.78656449 97.54023465
 98.48807885 95.98567269 98.76585324 98.24198048 99.81603538 97.34530525
 98.30776915 95.69327859 97.06753085 97.34408694 99.18616976 98.33335364
 99.84405648 99.15083881]
Accuracy th:0.7 is [84.44341565 97.31362922 92.26861271 98.06167079 98.84138838 97.71688941
 98.23954387 95.36189861 98.034868   96.74467904 98.70615611 99.07530366
 99.42008504 95.33631413 97.38307282 97.23565746 96.36213009 97.87770617
 98.86575456 98.46127606 98.98149389 99.29459924 99.63085245 99.14109234
 95.22301142 96.73249595 94.24714611 97.12479136 98.01902998 98.30533254
 98.13964255 98.6208745  96.53147501 98.7317406  98.87306441 98.95590941
 97.87770617 98.5514309  99.05702903 92.94355576 97.86064985 93.01178105
 97.04681961 96.27563017 96.99808726 94.14968141 98.31020577 98.71102935
 98.04583277 98.71224766 98.83773346 98.56726892 99.01682484 98.21274107
 98.7183392  97.61942471 90.05981896 96.49736236 96.30486958 97.33434047
 92.04078898 98.55508583 96.47908773 97.19545327 98.74148707 97.41840377
 98.35893812 95.96374313 98.69397303 98.18228335 99.81603538 97.17474202
 98.3138607  95.49347596 96.99443233 97.23200253 99.18007822 98.2578185
 99.84405648 99.14718388]
Avg Prec: is [95.55336735 33.71389196 65.69554762 68.62431179 83.49431759 67.50245993
 80.6044114  51.15219177 58.91978491 54.68294249 40.05770539 60.53622857
 25.23005273 28.85831336 33.12806419 57.67220709 28.83762197 49.82854799
 53.9689662  43.07886125 75.92411932 53.2213533  93.64363419 89.72753739
 27.23493011 36.20179575 37.38685931 43.33082878 24.29068852 44.8238245
 78.55787263 47.23219127 56.24376652 71.25697093 78.82991581 82.78696059
 68.90624503 78.73694528 88.71580881 42.09297606 29.00177735 52.62290964
 47.30083102 41.91060479 37.28609271 51.64769636 47.2005272  38.03136902
 43.21409133 46.63598882 69.05606761 43.2480065  23.83679458 76.67952239
 29.61975388 42.08524418 56.24325797 58.54718153 35.02301404 61.08200346
 68.18910815 81.59133359 57.82601853 47.36695301 57.69170175 43.35165175
 53.9415164  24.87635433 41.9992262  61.04518733  9.55361714 69.64975823
 52.81417547 40.46744488 51.62301909 48.68286287 13.53989785 37.44117628
  4.17279815 18.63403304]
Accuracy th:0.5 is [78.04363982 97.21250959 90.52764952 97.49028399 98.1189313  96.98103093
 97.88867095 94.88310328 97.3806362  96.57777074 98.53071965 98.68057163
 99.41399349 95.31560288 97.324594   96.66670728 96.29634142 97.49637553
 98.7183392  98.31264239 98.42716341 99.10697969 99.48952864 98.71590258
 95.22301142 96.65086926 94.09485752 96.83605219 98.01293844 98.18593828
 98.02024829 98.52219149 96.62406647 98.33457195 98.37233952 98.55995906
 97.23931239 97.96176947 98.30898746 92.82294319 97.86308646 92.44648579
 96.95300983 96.28415833 96.97128446 93.97424495 98.08116373 98.59894494
 98.00562859 98.61721958 98.59894494 98.55874076 98.99976852 97.65597398
 98.70615611 97.46591781 90.22550895 96.42913707 96.24151753 97.07240409
 91.63752878 97.86186815 96.48030604 97.06143931 98.49782532 97.39038267
 98.24929034 95.95277835 98.71712089 97.8399386  99.81603538 96.7532072
 98.0360863  95.55317309 96.36213009 96.95179152 99.18007822 98.16279041
 99.84405648 99.14718388]
Accuracy th:0.7 is [67.40780449 97.2137279  89.78082626 97.31850245 98.0068469  96.78731984
 97.60236839 94.76370902 97.63648104 96.49370744 98.53193796 98.62331112
 99.41399349 95.3180395  97.2831715  96.56924258 96.29512311 97.48175583
 98.65864207 98.30776915 98.27731144 99.20200777 99.44688783 98.61965619
 95.21935649 96.65086926 94.0778012  96.77026352 98.01293844 98.16157211
 97.64866412 98.57579708 96.45715817 98.1603538  98.38574091 98.52950135
 97.03341821 98.00441028 97.96298778 92.73766158 97.84359352 92.13581706
 96.92620704 96.24151753 96.96397461 93.88165349 98.04339616 98.58067031
 98.00319197 98.55752245 98.43690988 98.55508583 98.99976852 98.09456512
 98.70615611 97.46591781 89.55543914 96.34629208 96.24760907 96.93839013
 90.74938171 97.61820641 96.21349642 96.99443233 98.44056481 97.34408694
 98.21517769 95.95277835 98.6756984  97.65231905 99.81603538 96.35482024
 97.96664271 95.45449008 96.24151753 96.9347352  99.18007822 98.1603538
 99.84405648 99.14718388]
Avg Prec: is [90.5316258  18.77145611 51.30098082 47.28312178 63.80306426 53.04717673
 62.52290299 36.70164177 35.44909889 35.49643115 15.435172   43.32242912
  8.72502555 17.93036998 19.43616255 31.61877597 16.2288808  23.71390844
 31.53849507 25.37955195 48.12491106 29.47401133 86.89725641 69.42252504
 19.26943425 17.15635127 26.97569384 26.48084795 11.28663433 29.13913696
 63.72966198 27.9246533  46.07627774 51.60873384 59.55834142 68.67685288
 41.33765018 63.36501699 75.68101028 33.57854484 19.28266624 42.80823837
 35.72291569 31.79611964 27.00168869 37.83727568 24.37911293 22.50779563
 29.47566233 30.61323094 51.73772123 26.68474824 12.02183051 61.34112838
 13.94850862 21.93759133 46.30824869 41.11951789 21.91396898 36.44926731
 57.11538231 58.99483075 43.85125697 32.20336199 40.42393199 27.89003078
 35.58146101 15.4555196  30.08484655 43.14776093  7.21777703 55.75826489
 36.30088364 32.07816741 30.83069944 26.39410043  6.83057915 15.98357508
  3.15458752 10.0563778 ]
mAP score regular 51.44, mAP score EMA 35.85
starting validation
Accuracy th:0.5 is [87.37075516 97.3565538  92.28143608 98.35064903 99.07068291 97.80750928
 98.64962503 95.40573536 98.22607569 97.08249246 98.58982983 99.07068291
 99.39955652 95.25126442 97.45870394 97.39641727 96.35249271 98.01430102
 99.05573411 98.41542716 99.25006852 99.43443705 99.70102399 99.52662132
 95.46054762 96.82088846 94.56611107 97.39890874 97.84737275 98.21610982
 98.7343349  98.71689464 96.83334579 98.99344744 98.97849864 99.21767945
 98.27839649 98.44781623 99.07815731 93.35027531 97.86481302 93.25061664
 97.12235593 96.57423325 96.92802153 94.61344894 98.49764556 98.82901064
 98.06662182 98.77668984 99.01337918 98.63965917 98.88631437 98.49764556
 98.7866557  97.75269701 90.77659018 97.06754366 96.31761218 97.53095647
 93.00894437 98.7941301  96.91307273 97.416349   98.7791813  97.58327728
 98.48518823 95.7993871  98.78167277 98.20116102 99.81563146 97.59075168
 98.26095622 95.64740763 97.1098986  97.46866981 99.25505145 98.4577821
 99.82559733 99.16785011]
Accuracy th:0.7 is [86.67812741 97.32167327 92.77723796 98.27590503 99.09559758 97.89221915
 98.4204101  95.52532576 98.15880609 96.80095672 98.7567581  99.12051225
 99.36965892 95.14163988 97.36651967 97.19709993 96.34003538 97.96945462
 98.99095598 98.46276503 99.21020505 99.34972718 99.69354959 99.47679199
 95.43812442 96.65396019 94.50880733 97.31669034 97.81996661 98.26095622
 98.47522236 98.69447144 96.60413085 98.94112664 99.02832798 99.24508558
 98.15382316 98.36310636 99.13047811 92.9765553  97.83242395 93.30044597
 97.17218527 96.49948925 97.07003513 94.34437053 98.49266263 98.89877171
 98.00184369 98.78914717 98.91621197 98.57986397 98.89877171 98.23105862
 98.73931784 97.74522261 90.14874056 96.80095672 96.24785111 97.35904527
 92.52310835 98.73682637 96.55679298 97.2369634  98.7119117  97.49856741
 98.30829409 95.7769639  98.75426664 98.13887436 99.81563146 97.416349
 98.33570023 95.47549642 97.04512046 97.39143434 99.25006852 98.35064903
 99.82559733 99.15539278]
Avg Prec: is [96.08187877 31.91845399 68.11917172 74.22184351 81.71582074 68.8629121
 84.98401084 51.2178924  63.60605921 57.07269649 45.19075275 62.99961145
 23.36949743 31.06754692 35.58760485 63.5358969  32.80443718 55.35612413
 56.10745948 40.84480348 81.77032829 64.61917195 93.83276913 94.08020912
 25.64048944 39.18340424 34.14707148 49.19045915 26.51491217 41.70250329
 81.16347333 44.17005493 52.82837146 74.57426789 77.83364855 84.67272684
 70.17713873 79.89327703 90.1068993  42.66968987 29.37654777 51.50842727
 41.64655138 38.87008545 32.46184139 48.9274773  46.67679387 34.52531224
 41.36198878 43.86323624 74.19500203 41.45753721 26.7601627  79.96858899
 33.94113426 40.28954088 55.01995296 56.32530077 34.83668252 62.43832549
 66.76194808 85.3986524  60.7660243  51.21842476 60.41678778 37.92656958
 60.00124215 25.76586419 38.36895053 62.65248782  8.04070198 72.41520687
 48.52620456 37.8011353  60.00025178 49.33414338 12.14982746 41.50573928
  2.76191876 18.68314132]
Accuracy th:0.5 is [80.46939233 97.23945487 91.30228966 97.79505195 98.73184344 97.2444378
 98.19866956 95.08433615 97.26436953 96.57174178 98.53003463 98.82651917
 99.34972718 94.99962628 97.2593866  96.53686125 96.20549618 97.51849914
 98.80658744 98.35812343 98.6595909  98.7044373  99.63375439 99.04078531
 95.43563296 96.52938685 94.421606   96.97535939 97.81747515 98.16628049
 98.41044423 98.55744077 96.76856766 98.61972743 98.6147445  98.84395944
 97.60320901 97.86232155 98.5624237  92.9690809  97.85733862 92.9018113
 97.0874754  96.43720258 97.0276802  94.19488253 98.21361836 98.76672397
 97.89969355 98.71689464 98.67952263 98.57238957 98.87883997 97.45870394
 98.69945437 97.58576874 90.20853577 96.61907965 96.11580337 97.08996686
 92.11699928 98.13887436 96.62157112 97.1098986  98.40047836 97.46866981
 98.23853302 95.77198097 98.7343349  97.88723622 99.81563146 96.98532526
 98.11395969 95.59508683 96.25034258 97.0351546  99.24757705 98.21112689
 99.82559733 99.15040985]
Accuracy th:0.7 is [72.20270573 97.22450607 90.14874056 97.57829434 98.6147445  96.88068366
 97.92211675 94.92737374 97.73525675 96.46460872 98.5250517  98.73184344
 99.34972718 95.10925082 97.2369634  96.34003538 96.21047911 97.50604181
 98.80409597 98.34068316 98.46027356 99.20023918 99.61382266 98.99593891
 95.43563296 96.52938685 94.34437053 96.84829459 97.81747515 98.13389142
 98.01679249 98.67204823 96.58170765 98.40047836 98.71689464 98.94112664
 97.43628074 97.95201435 98.23853302 92.76727209 97.82993248 92.49570222
 97.0874754  96.50696365 97.03764606 94.05286892 98.19368662 98.7717069
 97.98440342 98.67204823 98.49266263 98.55993223 98.87385704 98.06662182
 98.6969629  97.58826021 89.79993522 96.69631512 96.16812417 96.87071779
 91.48914966 97.94453995 96.30017191 96.98532526 98.33819169 97.41385754
 98.15880609 95.7769639  98.71689464 97.78508608 99.81563146 96.87570073
 98.05914742 95.45307322 96.03607644 97.04013753 99.24757705 98.19617809
 99.82559733 99.15040985]
Avg Prec: is [92.03525741 18.60453376 56.06396168 58.74230538 68.47879615 58.07200627
 71.9937931  37.25277389 43.33107819 38.20537021 21.95600681 49.79070487
  7.80699132 20.48283262 23.23609454 41.01862419 19.36582995 28.35803918
 33.79984729 25.88662319 60.13137027 41.94493902 91.34102351 79.8986307
 20.39179304 19.98253672 26.37590627 33.49739544 15.05552293 31.68289025
 72.75373455 28.24741878 48.93819181 57.16295643 66.38172682 76.012177
 46.04396244 69.03541209 84.29387552 36.91492395 22.78332397 45.35189938
 36.53813432 32.08519542 26.33891728 38.66657153 24.25943285 18.18213696
 31.84048178 32.95929538 60.20152921 25.63756363 16.49803039 67.73461003
 17.86744306 25.14615974 47.91586293 43.29613405 22.10261234 41.63275046
 59.56217592 70.47960934 50.18491498 41.74439828 48.08238129 28.50462151
 45.94767419 17.44449822 30.83582082 49.45163179  8.19199963 62.35607644
 37.91323643 34.22618317 42.68364053 29.02083448  6.62963205 20.63446309
  1.38700946 10.87492836]
mAP score regular 52.35, mAP score EMA 39.92
Train_data_mAP: current_mAP = 51.44, highest_mAP = 51.44
Val_data_mAP: current_mAP = 52.35, highest_mAP = 52.35
lr:  [9.908037677784462e-05, 9.908037677784462e-05]
BCE Train Loss:  tensor([47.6894,  9.8098, 21.4082,  7.3499,  3.8479,  6.3453,  1.0065, 16.8570,
         5.4465,  5.7953,  3.1191,  3.6440,  0.8451, 20.0173, 16.9478, 14.0234,
        17.0470,  8.3452,  7.4113,  2.5360,  6.4373,  1.8547,  0.4239,  0.3218,
         6.5313, 11.0597, 18.2935, 10.8482,  4.9305,  5.7023,  1.0401,  1.3439,
        11.6546,  2.9174,  1.1883,  1.4992,  1.5744,  7.8521,  4.3315, 23.4549,
         9.1727, 24.7070,  7.5339, 16.5248, 17.2485, 15.3984, 12.0727,  2.4651,
        15.7507, 10.2268,  7.1930,  6.9586,  1.2524,  7.9292,  7.2913, 10.7094,
        29.7873, 18.6854, 14.6917, 10.5498, 25.2425,  2.0169, 13.7981,  8.5086,
        13.6048,  6.7469,  9.2089, 11.6044,  5.8029,  7.2886,  0.0965,  4.5556,
         5.6266, 14.2931, 12.5413, 11.7066,  6.0756,  6.6876,  0.1230,  4.0228],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [15/80], Step [000/642], LR 9.9e-05, Loss: 758.5
BCE Train Loss:  tensor([36.7799, 18.7012, 35.8304,  4.5270,  0.9476,  3.3189, 15.8301, 16.7050,
         4.8340, 15.8658,  6.4691, 11.4903,  9.4101, 15.0393, 15.8029,  4.5149,
        11.9654,  6.7139,  5.0056,  1.3429,  2.1481,  1.2246,  1.0645,  4.3664,
        29.6030,  7.0108, 25.9013, 20.8955, 10.4006,  1.3087,  4.1060,  2.8440,
         4.2412,  3.2791,  1.2912,  2.1324,  7.3829,  9.0490,  1.2591, 36.8746,
         8.9279, 18.8463,  6.3939,  6.8827, 16.3632, 21.1736,  8.8391,  4.1880,
         9.3834,  6.8005,  2.3546,  6.6631,  0.9253, 10.0921, 12.3741, 11.3438,
        34.4092,  8.7454, 21.0727,  5.5843, 22.4872,  1.3691,  7.9868,  6.2140,
         0.7922,  7.0569,  2.6562, 10.1758,  4.9177,  7.2601,  0.1234,  5.0884,
         7.6134, 17.2354, 10.7236, 14.6795,  0.5910, 17.2534,  0.2069,  2.3309],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [15/80], Step [100/642], LR 9.9e-05, Loss: 785.6
BCE Train Loss:  tensor([42.8900, 20.1862, 24.5593, 12.3031,  6.3656, 16.1071, 21.8610, 11.5236,
         9.1923, 14.4312, 14.5703,  4.6373,  7.5043, 22.6057,  4.2263,  3.9792,
        11.6862,  5.6977,  1.0914,  8.6374,  3.5057,  0.3646,  0.8451,  1.7028,
        13.8489,  8.9133, 16.3984,  9.7261,  3.7898,  7.0323,  7.5036,  5.1699,
        13.9208,  2.6757,  4.7340,  7.9443, 16.2788,  3.8397,  4.7600, 29.1521,
         6.6500, 12.3593,  6.1366, 14.6350,  6.8903, 17.2710,  8.0377,  4.6239,
         7.9623,  2.8715,  3.7205,  6.9153,  3.3018,  3.5579, 15.0439, 15.6813,
        25.6001, 11.4547, 11.5427,  5.3340, 33.7468,  8.2749, 13.5707, 10.7438,
         2.2988, 10.0433,  8.1244,  8.3095,  3.6429,  2.6352,  0.2265,  7.3969,
         2.1703,  5.6787,  8.3989,  7.0662,  7.0468, 11.4247,  0.1089,  1.1098],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [15/80], Step [200/642], LR 1.0e-04, Loss: 767.8
BCE Train Loss:  tensor([36.7346, 10.9433, 22.8440, 10.1740,  1.2442,  4.3220,  3.8173, 22.2181,
         6.2381,  6.4710,  9.3740, 15.2538,  1.1188, 17.0301,  6.6244,  5.8005,
        15.9840,  8.2943,  4.9958,  5.8299,  4.8046,  6.3063,  5.0999, 12.7749,
        11.9597,  9.7413, 12.4572,  5.5219,  2.6915,  9.1686,  5.9802,  1.6047,
         9.1642, 10.4695, 10.8708,  4.1562,  4.5933,  7.3284,  3.4472, 12.6542,
        12.0887, 27.4766, 10.1693,  6.0449,  6.7116, 14.7968,  6.6182,  9.2133,
         6.8191,  1.6515,  2.1420,  2.8474,  1.5264,  1.0639,  5.1118, 12.2024,
        25.4952,  4.3504,  8.6806,  8.6141, 22.8802,  6.9216,  4.1164,  7.7778,
         1.0915,  3.6539,  1.2378,  9.8146,  7.1872,  2.0726,  0.6987,  5.9394,
        10.8350,  6.2538,  7.1298,  7.2898,  0.8041,  7.3513,  0.3042,  1.3757],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [15/80], Step [300/642], LR 1.0e-04, Loss: 654.5
BCE Train Loss:  tensor([35.7066, 13.8378, 24.2190, 15.9605,  3.1318, 18.6452,  6.6019, 21.0679,
         8.1786, 11.8945,  3.3044,  1.7869,  0.8706, 15.5351,  5.9256, 23.6329,
        31.7712,  8.2366,  1.3922, 16.3575,  1.9703,  1.1847,  0.2151,  2.3069,
        21.3753, 10.1852, 14.4034, 13.6736,  9.2048,  2.9595,  5.5020,  1.7773,
        10.4815,  0.9505,  2.0064,  1.9969,  3.6903,  7.2686,  0.7485, 20.0283,
        11.4521, 32.8631,  8.8320,  9.3644, 11.0245, 17.0206,  1.3487, 12.4762,
        12.8427,  5.1052,  1.5098,  5.0115,  4.2974,  1.7618, 10.0923,  5.6544,
        36.1883,  7.9333,  7.5253,  7.1168, 26.9589,  6.1891, 11.2694,  4.6109,
         6.8421, 11.4147,  5.4017, 14.7412,  1.8092,  3.0079,  0.0970,  4.5939,
         1.5741, 11.2646, 17.9048,  5.7701,  1.0176,  4.8477,  0.1289,  9.5677],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [15/80], Step [400/642], LR 1.0e-04, Loss: 758.4
BCE Train Loss:  tensor([45.4205,  9.7328, 20.8057,  2.2514,  7.0120,  5.6639,  2.6752, 14.8878,
         9.6445, 14.1651, 18.4926,  1.5316,  0.2957, 21.2665, 15.6683,  6.9470,
         7.2934,  4.8610,  4.5263,  6.3897,  2.3304,  9.8490,  0.2247,  1.0958,
        27.9632, 21.4711, 11.8414, 25.2323, 10.5190,  8.6563,  1.3963,  1.1764,
        20.8882,  6.9188,  5.8405,  0.7256,  7.0148,  3.5454,  8.2099, 17.7290,
         2.8415, 24.7634,  8.7056,  9.8555,  7.7574, 14.5357,  3.1596,  6.2415,
        16.7765,  8.8324,  3.7594,  5.2161,  5.5888,  7.2042,  8.7357,  6.1299,
        31.9313,  9.8457,  6.5239,  3.6086, 24.1114,  3.1315,  6.1974,  6.2987,
         8.7535,  5.5429,  6.8523, 21.5516,  0.6448,  2.5443,  5.8897,  5.9696,
         3.9304,  8.6730, 14.8429,  8.9918,  6.0618,  2.7217,  0.2611,  1.0809],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [15/80], Step [500/642], LR 1.0e-04, Loss: 748.2
BCE Train Loss:  tensor([30.8084, 17.5250, 25.2411,  4.6315,  3.0877,  9.4601,  7.1889, 14.7295,
         4.5133,  8.9403,  4.5125,  1.1849,  0.7820, 12.0030,  3.9480,  3.1016,
        14.4245,  4.5101,  2.4026,  8.6087,  0.5902,  0.7155,  0.4863,  4.1575,
        19.7588,  9.7388, 22.7557, 12.1722, 12.2940,  3.5684,  5.7059,  6.2244,
        15.5685,  0.9750,  4.3821,  3.1093, 12.6778,  5.4936,  1.7175, 23.9784,
        11.8481, 27.5995,  5.3547,  6.8485,  5.3993, 13.3329,  8.1209,  7.1622,
        12.0002,  5.5772,  0.5004,  1.1573,  1.0367,  2.2533,  4.6254, 14.4584,
        30.8110, 10.3436, 19.9392,  5.1399, 21.5810,  5.2825,  9.3544,  4.0020,
         2.6608, 13.0037,  2.6883, 12.8386,  1.8426,  5.1872,  0.2952,  8.1295,
         3.4464, 19.8421,  6.7929,  2.0510,  1.0887, 13.6949,  5.2376,  6.9802],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [15/80], Step [600/642], LR 1.0e-04, Loss: 687.2
BCE Val Loss:  tensor([4.6464e+01, 3.6729e+01, 5.5706e+01, 2.2240e+01, 4.9118e-01, 1.1153e+01,
        7.1473e+00, 1.7084e+01, 7.0174e+00, 9.6432e+00, 7.5218e+00, 1.2546e+01,
        7.0189e+00, 1.7398e+01, 1.0020e+01, 2.4615e+01, 3.0436e+02, 5.5611e+00,
        8.1059e-01, 5.0110e+00, 8.3612e-01, 7.5009e-01, 1.1231e-01, 7.9447e-01,
        2.5844e+01, 1.2892e+01, 2.7621e+01, 3.2546e+00, 1.2981e+01, 1.0425e+01,
        1.1579e+00, 5.6691e-01, 8.7770e+00, 6.5558e-01, 1.7852e+00, 2.6488e+00,
        1.6249e+01, 3.4427e+00, 2.0029e+00, 4.6522e+01, 9.5856e+00, 2.6255e+01,
        6.4681e+00, 1.3180e+01, 1.6143e+01, 1.5011e+01, 1.1931e+00, 5.7521e+00,
        5.0801e-01, 4.2317e+00, 1.0741e-01, 6.3457e-01, 6.9232e+00, 7.2787e-01,
        1.0279e+00, 1.9493e+00, 2.6474e+01, 6.3134e+00, 1.2722e+01, 3.2513e+00,
        1.5762e+01, 1.3049e+01, 5.8518e+00, 4.3467e+00, 3.5045e-01, 1.3933e+00,
        4.6935e-01, 7.5956e+00, 8.2999e+00, 1.4884e+01, 2.1044e-01, 1.6859e+01,
        1.4519e+01, 1.1703e+01, 1.5225e+01, 5.7407e+00, 9.9623e-01, 7.9823e+00,
        9.2063e-02, 6.2537e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [15/80], Step [000/314], LR 1.0e-04, Loss: 1092.3
BCE Val Loss:  tensor([5.9918e+01, 1.8655e+01, 4.6435e+01, 9.8899e+00, 3.2583e+00, 3.4269e+01,
        4.4398e+01, 4.1121e+01, 2.1482e+01, 2.8704e+01, 1.8389e+01, 4.3427e+01,
        8.7552e+00, 1.0014e+01, 1.5021e+01, 2.8305e+00, 9.3146e+00, 1.4860e+01,
        2.7949e+00, 1.2584e+01, 5.2393e-01, 2.6637e-01, 2.3211e-01, 4.2142e+00,
        2.7694e+01, 2.0684e+01, 3.3794e+01, 1.2881e+01, 1.5658e+01, 7.2650e-01,
        3.9708e-01, 2.2397e-01, 6.2939e-01, 1.0168e+00, 5.2297e-01, 4.3243e-01,
        4.7302e+00, 1.0716e+00, 2.5262e-01, 2.5248e+00, 6.6001e-01, 3.1207e+00,
        7.1096e-01, 9.7088e-01, 5.7536e-01, 1.7414e+00, 4.1775e-01, 3.0852e-01,
        2.3681e-01, 4.6602e+00, 4.7944e-02, 2.9979e-01, 2.9762e-01, 4.7180e-01,
        5.8086e-01, 1.3471e+00, 9.6481e+00, 4.6924e+00, 7.1661e+00, 2.3169e-01,
        4.7245e+00, 4.3120e-01, 3.4345e-01, 2.0423e-01, 6.0163e-02, 1.1811e-01,
        8.6150e-02, 1.9955e+01, 1.1030e-01, 4.1002e+00, 1.1857e-02, 3.7193e-01,
        4.4070e+00, 3.4511e+00, 6.1969e+00, 7.1673e-01, 7.9518e-01, 6.6549e-01,
        1.1041e-02, 1.9317e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [15/80], Step [100/314], LR 1.0e-04, Loss: 659.7
BCE Val Loss:  tensor([2.2449e+01, 9.0901e-01, 3.7983e+00, 3.2157e-01, 6.5501e-02, 1.2371e-01,
        1.2708e-01, 1.6334e+01, 4.0657e-01, 9.4714e-02, 1.6677e-01, 6.0819e-02,
        5.1644e-02, 1.4017e+01, 6.1499e-01, 1.2399e+00, 1.3635e+00, 6.5620e-01,
        2.2303e-01, 2.0048e-01, 1.7580e-01, 5.3276e-02, 3.6111e-02, 3.4288e-02,
        4.0086e+00, 1.0475e+00, 2.8308e+01, 5.6803e+00, 2.9344e-01, 5.6758e-01,
        3.8134e-01, 6.2423e+00, 8.3008e+00, 7.7875e-02, 4.9248e-01, 9.3634e-01,
        1.0524e+01, 1.0893e+01, 3.1051e-01, 3.8335e+01, 2.4694e+01, 5.9372e+01,
        6.4268e+01, 6.1302e+01, 4.6047e+01, 6.5896e+01, 8.6249e+00, 6.9272e+00,
        4.0994e+01, 1.0970e+01, 2.4124e+01, 3.7554e+01, 6.1250e+01, 1.6538e+01,
        4.1536e+01, 7.4627e+01, 8.9269e+01, 1.4532e+01, 7.8186e+00, 8.7589e-01,
        7.8049e+01, 2.4415e-01, 1.2059e+01, 1.2863e+01, 1.3129e+01, 3.8819e+00,
        1.0102e+01, 1.3043e+01, 6.6516e+00, 3.1513e+00, 1.2323e-01, 9.7084e+00,
        6.0647e+00, 4.1749e+01, 2.8578e+00, 1.4649e+01, 1.0025e+01, 1.6084e+00,
        9.2581e-02, 4.5085e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [15/80], Step [200/314], LR 1.0e-04, Loss: 1177.6
BCE Val Loss:  tensor([3.4945e+01, 4.6128e+00, 1.9233e+01, 1.5053e+00, 1.0227e+00, 9.6272e+00,
        8.4799e+00, 1.5029e+01, 3.4197e+00, 1.7254e+01, 4.3247e+00, 8.0050e+00,
        9.8909e-01, 1.4684e+01, 1.6531e+01, 1.3184e+00, 1.0284e+00, 1.3296e+00,
        2.3396e-01, 3.3629e-01, 1.0555e+00, 6.4043e-02, 1.1999e-01, 8.0269e-01,
        2.4414e+01, 3.8110e+00, 2.2740e+01, 1.3931e+00, 1.6195e+01, 2.9119e-01,
        3.2267e-01, 1.6304e-01, 3.9937e-01, 3.7245e-01, 3.5862e-01, 4.1134e-01,
        1.8706e+00, 4.5130e-01, 1.9717e-01, 3.3366e+00, 1.0980e+00, 1.4742e+00,
        5.8089e-01, 1.1606e+00, 5.3953e-01, 1.8608e+00, 3.6549e-01, 1.9516e-01,
        1.5761e-01, 1.3505e-01, 4.9099e-02, 1.3690e-01, 9.0567e-02, 2.3300e-01,
        5.2487e-01, 1.6384e+00, 6.8183e+00, 1.4251e+00, 1.1615e+01, 3.4042e-01,
        7.4909e+00, 4.9037e-01, 2.0794e+00, 4.4593e-01, 1.8736e-01, 1.5510e+00,
        2.8190e-01, 6.1310e+00, 3.7405e-01, 1.0023e+00, 3.1832e-02, 6.4066e-01,
        4.2419e-01, 5.3855e+00, 9.7882e+01, 3.5568e+00, 7.5386e-01, 6.1836e+00,
        2.2324e-02, 7.7349e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [15/80], Step [300/314], LR 1.0e-04, Loss: 408.1
starting validation
Accuracy th:0.5 is [86.9019627  97.44033333 92.47085196 98.11527637 98.95347279 97.87039632
 98.67204347 95.42281405 98.18106505 97.23687577 98.77194479 99.09845153
 99.45297937 95.50322243 97.55607266 97.55485435 96.50589052 98.05923417
 99.01438823 98.54899429 99.15936697 99.38475408 99.69664112 99.39206394
 95.25346913 96.98834079 94.47618816 97.27220672 98.04705108 98.45762113
 98.5514309  98.62818435 96.9761577  98.8011842  98.90961367 99.03509947
 98.11405806 98.62209281 99.10697969 93.29077375 97.92887514 93.20183721
 97.23078423 96.46812295 97.03950975 94.78563858 98.40645216 98.74392369
 98.22614247 98.7877828  98.88768412 98.74879692 99.04850087 98.75001523
 98.77194479 97.78145978 91.18309962 97.08093225 96.50832714 97.69130493
 93.07756972 98.5928534  97.06874916 97.46104458 98.85357147 97.70348802
 98.57579708 95.99785578 98.79509265 98.28462129 99.81603538 97.54267126
 98.34553673 95.77977851 97.1710871  97.4634812  99.19713454 98.44909297
 99.84405648 99.14840219]
Accuracy th:0.7 is [86.76185719 97.39160098 91.49133173 97.94836808 98.87793765 97.69617817
 98.61112803 95.0402651  98.13598762 96.99930556 98.77316309 99.07774028
 99.42739489 95.38991971 97.4500798  97.3672348  96.36943994 98.04217785
 98.9412897  98.49660701 99.05824734 99.30069078 99.67105664 99.30190909
 95.22788465 96.83483388 94.2593292  97.11382659 98.02024829 98.2578185
 98.09334682 98.58310693 96.69960161 98.64158575 98.8986489  99.02900793
 98.19568475 98.55264921 99.11550785 92.94477406 97.90694558 92.64872504
 97.03950975 96.35847516 96.98103093 94.25201935 98.31751562 98.72564905
 98.11040314 98.71712089 98.72564905 98.69275472 99.02778962 98.63305759
 98.7597617  97.68765    90.77862112 96.8092494  96.41817229 97.506122
 92.55857019 98.28218467 96.92864366 97.324594   98.77316309 97.59627685
 98.54412105 95.95765159 98.72077582 98.10309329 99.81603538 97.21981945
 98.19202982 95.53246184 97.03098159 97.35870664 99.18495145 98.36015643
 99.84405648 99.14718388]
Avg Prec: is [96.18616762 37.98136114 67.87755517 70.0134051  85.88901636 70.54626181
 82.01040607 54.10521449 62.67870262 58.5472887  45.12367657 61.71371698
 28.82616056 31.9378555  36.43301888 61.48175931 33.70330163 56.64473878
 57.54718758 47.38595433 79.12351973 59.15680856 94.34616583 92.04348481
 29.1715422  40.01719686 39.40958485 48.36697961 30.11011969 50.00983002
 80.56837567 50.01015567 58.06512361 75.22402837 79.88046144 83.73156392
 72.75448148 80.27153503 89.62492918 45.12884566 31.36109696 54.35233982
 49.9620017  44.07677725 38.8423342  53.5714073  48.77776694 40.98512334
 46.33174978 48.94583532 71.1158424  47.01813494 30.32155148 79.07107152
 32.36906749 48.0956495  57.92453782 61.21280755 36.96933432 65.22584565
 70.01289696 83.31049672 61.86117355 51.68398841 62.46859713 46.89213747
 56.73638836 27.29132833 43.88560276 63.74008307 12.70890613 73.41211941
 55.75979545 42.97524073 55.00136107 51.5894225  17.25858856 41.98630519
  5.74617882 19.44921148]
Accuracy th:0.5 is [80.28045467 97.22103776 91.06492367 97.6316078  98.3418818  97.26733349
 98.12014961 95.05732143 97.53292479 96.70569316 98.5368112  98.79143773
 99.41399349 95.32778597 97.32337569 96.70325654 96.30121465 97.54388957
 98.74514199 98.33213533 98.58310693 99.12647263 99.5260779  98.86453625
 95.22422972 96.67645375 94.15089972 96.91280564 98.01293844 98.23710725
 98.14573409 98.53559289 96.67767206 98.48320561 98.46127606 98.68666317
 97.44033333 98.02633984 98.48686054 92.92040789 97.86552308 92.61826732
 96.99808726 96.31583436 96.98834079 94.08145612 98.1189313  98.61965619
 97.99831873 98.63793082 98.6488956  98.59041678 99.00342345 97.85821323
 98.70737442 97.49393891 90.35221306 96.56924258 96.29268649 97.20519974
 91.92748626 98.034868   96.60213691 97.12600967 98.55995906 97.43911502
 98.29314945 95.95399666 98.74392369 97.90816389 99.81603538 96.92498873
 98.12989608 95.54708154 96.50954545 97.02610836 99.18007822 98.17253688
 99.84405648 99.14718388]
Accuracy th:0.7 is [71.79493427 97.21494621 90.09514991 97.47444597 98.22736078 96.95910138
 97.88745264 94.79782166 97.73029081 96.53147501 98.53193796 98.71224766
 99.41399349 95.31682119 97.29779121 96.59482706 96.29512311 97.49028399
 98.67448009 98.31020577 98.39183246 99.22759226 99.49196525 98.79874758
 95.21935649 96.65208757 94.08145612 96.81168602 98.01293844 98.16644534
 97.82044566 98.57701539 96.53147501 98.28705791 98.46858591 98.68178994
 97.15646739 98.12867777 98.17619181 92.75593621 97.84846676 92.19916911
 96.92864366 96.24639076 96.96519292 93.90236474 98.06532571 98.58676186
 98.02268491 98.58798017 98.50635348 98.55874076 98.99976852 98.22370585
 98.70615611 97.47444597 89.71625589 96.38040472 96.25613723 97.02123512
 91.08198    97.80948088 96.32679914 97.03707314 98.46371267 97.35992495
 98.24319879 95.95277835 98.6756984  97.75100206 99.81603538 96.58264397
 97.99222719 95.45936331 96.32558083 96.9761577  99.18007822 98.16157211
 99.84405648 99.14718388]
Avg Prec: is [91.99224712 22.45348373 55.29264262 52.24916245 70.04545528 57.50984799
 67.67984981 41.14294562 41.19697781 41.60102764 19.64250814 48.71985342
 12.26204239 20.65148977 22.19137148 36.85248124 18.83864785 31.61081956
 35.55082486 29.13575631 55.89721146 34.70963505 88.79451536 75.73685418
 22.15522354 20.50959251 29.42478678 30.09669435 15.87528038 33.09724359
 66.90033325 31.51309398 48.06498415 59.08448329 64.11072047 73.3419929
 48.04694783 67.14556739 79.27064708 36.43187484 21.47105603 45.45575565
 37.93108853 34.30261011 30.14894885 40.645073   28.72422941 25.50419013
 31.67679107 33.22565213 54.31538586 30.89343935 15.00933865 65.83817436
 16.21298255 27.57136775 48.75616783 45.28223482 25.13820611 42.57007201
 59.94786349 64.23855284 48.60011416 35.85178688 46.82892992 31.6271371
 40.82111594 16.89477226 32.71964708 46.55756942  7.11398792 59.72203935
 39.31512407 33.77490804 37.00104532 32.18704311  7.89877113 19.55663653
  3.3354406  11.41804301]
mAP score regular 54.42, mAP score EMA 39.66
starting validation
Accuracy th:0.5 is [87.84662531 97.416349   92.9018113  98.4054613  99.18030745 97.93208262
 98.77668984 95.52034283 98.33819169 97.19460847 98.67703117 99.16535865
 99.39955652 95.40822682 97.60320901 97.51351621 96.49948925 98.12392555
 99.06819144 98.46276503 99.27996612 99.49174079 99.72344719 99.61880559
 95.46553056 96.96041059 94.608466   97.46368687 97.84986422 98.32324289
 98.72935197 98.70692877 97.07003513 98.96354984 98.95358397 99.14791838
 98.22607569 98.48269676 99.12549518 93.33532651 97.93457408 93.40508758
 97.16471087 96.59914792 97.0351546  94.69566734 98.60976157 98.86638264
 98.17126342 98.81157037 98.94112664 98.75426664 98.90873757 98.71440317
 98.7866557  97.72279941 90.79153898 97.2369634  96.38239031 97.72529088
 92.86693076 98.73184344 97.14976206 97.55088821 98.7941301  97.61566634
 98.59730423 95.8367591  98.76921544 98.28836236 99.81563146 97.65802128
 98.35563196 95.74457483 97.15972793 97.50604181 99.23761118 98.5698981
 99.82559733 99.15788425]
Accuracy th:0.7 is [87.95874131 97.39143434 91.94757954 98.26344769 99.11802078 97.81498368
 98.70194584 95.18897775 98.28587089 97.06754366 98.79662157 99.18030745
 99.37464185 95.21140095 97.47614421 97.32167327 96.33754391 98.11395969
 99.07566584 98.5101029  99.17781598 99.38959065 99.70102399 99.56150186
 95.43563296 96.81341406 94.48389267 97.33163914 97.81747515 98.24102449
 98.35812343 98.67204823 96.79348232 98.82651917 99.00839624 99.25006852
 98.40296983 98.34068316 99.14044398 92.9690809  97.88474475 92.9092857
 97.12733886 96.52689538 97.04013753 94.43157187 98.5549493  98.92368637
 98.05914742 98.81157037 98.75924957 98.67204823 98.90375464 98.6222189
 98.8016045  97.79006901 90.88123178 97.13730473 96.28522311 97.52846501
 92.88437103 98.4503077  96.95044473 97.36651967 98.69197997 97.65552981
 98.57238957 95.78692977 98.75924957 98.16129756 99.81563146 97.416349
 98.25099036 95.56768069 97.0276802  97.48611007 99.24757705 98.5101029
 99.82559733 99.15539278]
Avg Prec: is [96.53602348 36.16286387 69.87716311 76.17641831 83.62755871 70.59078321
 85.18637988 52.62564364 66.32441996 59.75808397 48.44400983 64.58914662
 26.94109177 34.33634995 38.08632179 66.73012524 36.519901   59.66747024
 60.23136647 44.25836755 82.99606024 69.17901081 94.82795672 95.09153423
 26.23434905 42.53659373 34.73716024 52.26211097 30.52092962 45.65392846
 81.20663157 45.63533042 56.07279232 76.46466323 78.2391578  84.48072911
 72.84141956 80.4128108  90.72613606 44.33126226 31.83209128 52.17721034
 42.22803308 39.63983088 33.17048606 50.34976001 50.29275242 36.38112999
 46.3279976  47.39986006 75.78192452 44.95319677 30.00482052 81.33143928
 36.18454169 42.51512454 56.26025595 59.01717199 34.86704796 64.80898977
 67.09809083 87.06264247 63.06683442 54.14851442 62.02958481 40.90823398
 60.73945098 28.72198162 40.06419985 65.56741688  8.86997618 74.87686818
 52.01634612 40.97481615 60.66358173 51.38705989 11.74469811 46.38385927
  2.37322709 20.19425636]
Accuracy th:0.5 is [82.54229265 97.2519122  91.83546354 97.99187782 98.82402771 97.48112714
 98.37307223 95.20143508 97.43378927 96.66143459 98.55744077 98.93365224
 99.35221865 95.01208361 97.31669034 96.63651992 96.21795351 97.58078581
 98.85641677 98.35314049 98.80658744 98.76672397 99.66116053 99.19276478
 95.44310736 96.54433565 94.46146947 97.08996686 97.81747515 98.18621222
 98.5848469  98.5624237  96.79846526 98.70692877 98.6820141  98.92866931
 97.81000075 97.97194608 98.7717069  92.9765553  97.85983008 93.03136757
 97.12983033 96.50447218 97.0351546  94.28208386 98.24102449 98.78167277
 97.91962528 98.7119117  98.76174104 98.59481277 98.87385704 97.70037621
 98.69945437 97.63559808 90.38293844 96.73867006 96.18058151 97.23198047
 92.35618008 98.28088796 96.70877245 97.1995914  98.46774796 97.50105887
 98.29085383 95.77198097 98.7492837  98.02177542 99.81563146 97.09744126
 98.21112689 95.61252709 96.42474525 97.12235593 99.24757705 98.23604156
 99.82559733 99.15040985]
Accuracy th:0.7 is [76.3534893  97.229489   90.61215337 97.79505195 98.77668984 97.14228766
 98.21361836 94.99713481 97.86979595 96.53187832 98.5250517  98.85641677
 99.34972718 95.10426788 97.27184393 96.38239031 96.21047911 97.51351621
 98.83150211 98.34068316 98.61225303 99.22017091 99.63873732 99.17781598
 95.43563296 96.53187832 94.35682786 96.95293619 97.81747515 98.15631462
 98.24102449 98.66457383 96.68136632 98.49266263 98.81904477 99.02583651
 97.54839674 98.03921569 98.49266263 92.83205023 97.83242395 92.56297182
 97.1024242  96.51692952 97.03764606 94.06781772 98.20863542 98.76921544
 97.99935222 98.6969629  98.5549493  98.56491517 98.87385704 98.24849889
 98.6969629  97.59075168 89.95440616 96.79348232 96.18058151 96.99279966
 91.73082193 98.14634876 96.44965991 97.042629   98.37805516 97.4238234
 98.20365249 95.7769639  98.72935197 97.93706555 99.81563146 97.0575778
 98.09153649 95.45805616 96.16064977 97.07750953 99.24757705 98.20365249
 99.82559733 99.15040985]
Avg Prec: is [93.258643   20.73101344 59.39264723 62.95664828 72.70063055 60.98927127
 76.06185601 41.02739782 48.91922075 42.63707246 27.28911533 53.59837596
 10.58253936 22.27018287 25.98606731 46.17135701 22.31688379 34.58588877
 38.86669891 29.13619518 65.96083792 46.38938594 92.05348756 84.85459423
 21.63275612 23.42783959 28.19429264 37.49478773 18.05571011 34.02246525
 75.13378914 30.65819101 50.84258535 61.82077263 69.80026056 78.83549675
 52.70285805 71.83707131 86.60477309 38.84499075 25.23703936 47.31907161
 38.41521576 33.98912756 28.1619611  40.91735685 28.12491423 20.98246613
 34.5499443  36.20230892 64.21286325 28.79443735 18.80304336 70.98415048
 22.15085937 29.26640951 49.83851152 46.61310522 24.58609472 47.23933565
 61.68612203 75.13267882 52.76129961 44.65705393 51.36519318 30.63526205
 48.89563389 18.79021326 33.34181095 53.42314134  8.63687849 65.21482586
 40.95343849 35.416522   47.15213072 34.27640109  8.23359127 24.63144119
  1.55452192 13.04839362]
mAP score regular 54.44, mAP score EMA 43.06
Train_data_mAP: current_mAP = 54.42, highest_mAP = 54.42
Val_data_mAP: current_mAP = 54.44, highest_mAP = 54.44
lr:  [9.999999985384691e-05, 9.999999985384691e-05]
BCE Train Loss:  tensor([41.6921,  6.7826, 30.6008,  6.9509,  8.9852,  3.3137,  2.2881, 17.4553,
        10.3028,  8.4839,  2.1828,  2.3425,  0.4636, 12.2538, 20.2130, 10.8163,
        11.5383,  5.1174,  1.3226,  3.2663,  1.1455,  5.8381,  1.9742,  8.3109,
        15.1769,  4.5819, 21.0526,  7.1794, 19.8318,  3.6608,  0.7806,  6.8964,
         2.6687,  1.9523,  3.1023,  3.6747, 11.7929, 15.4221,  3.8288, 20.2451,
        11.2995, 19.8271,  6.3229, 10.7888, 13.1878, 31.8997,  8.2863, 10.7659,
         7.7100,  4.1935,  9.8392,  6.7355,  8.3665,  6.9322,  1.8967,  2.4064,
        29.9931, 13.3779, 17.3662,  7.8381, 31.4216,  5.0492, 13.8549,  3.8409,
         3.3934, 13.1134, 12.6783, 13.8440,  5.2760,  7.0731,  0.1450,  4.0147,
         5.8298, 11.2038, 28.3622, 24.9321,  5.6055,  5.9964,  0.1024,  0.7540],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [16/80], Step [000/642], LR 1.0e-04, Loss: 791.0
BCE Train Loss:  tensor([41.1011, 19.6418, 21.9023,  5.1165,  5.4751,  8.6617,  5.8602, 10.3764,
         3.6384, 11.3882,  2.8665,  9.6009,  5.0740, 17.1412, 17.5204, 11.6996,
        18.7534,  7.4512,  9.6724,  1.0559,  0.7404,  0.6300,  0.1954,  0.8016,
        20.5570, 16.7225, 17.2255, 15.2740,  9.0733,  4.6260,  2.2153,  9.7248,
        16.8603,  4.5701,  2.2196,  0.7827, 12.2547,  3.9922,  4.7213, 18.1550,
        17.8069, 22.1343, 18.5762, 20.2926, 12.7165, 22.0845,  5.0270,  1.9637,
         6.6337,  3.4277,  8.9673,  5.8161,  6.9551,  6.0379,  4.8122, 11.9360,
        20.4871, 11.0655,  6.0192,  6.8330, 18.8618,  1.4620, 13.1254, 10.2459,
         2.7433,  7.2261, 11.2234, 11.9460,  2.0380,  7.6677,  0.2705,  4.3114,
         3.3839, 24.6892, 10.8425,  7.8961,  5.8904,  6.7773,  0.1331,  3.2852],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [16/80], Step [100/642], LR 1.0e-04, Loss: 769.0
BCE Train Loss:  tensor([38.6195, 10.3857, 17.2966,  4.0496,  2.5719,  3.4263,  2.4617, 13.5397,
         2.1494,  6.5618,  3.5401,  6.4135,  6.5853, 24.3652, 18.5077, 16.2271,
        23.5134,  8.7337,  1.7692,  3.9813,  0.9224,  0.2685,  5.4472,  1.2669,
        23.2655, 17.9029, 22.3051,  9.9682,  7.0890,  4.8446, 11.5175, 11.3324,
        10.7866,  6.9360,  1.1258,  1.6490, 11.7548,  6.1933,  7.1452, 21.3354,
        15.4273, 15.6173,  8.3866, 14.9201, 11.5642, 11.4827,  7.0760,  8.0285,
         7.4921,  1.4906,  7.6354,  1.8331,  2.6206,  7.8257,  6.2411,  7.5213,
        27.0417,  9.7059, 20.9157,  8.4238, 15.0399,  2.7325, 14.8230, 11.5025,
         2.6803,  7.2031,  9.0513,  8.4817,  3.2141, 11.6947,  4.3495,  2.9475,
         1.4809, 15.6912, 16.0781, 12.6906,  1.3592,  2.9800,  0.1169,  2.5404],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [16/80], Step [200/642], LR 1.0e-04, Loss: 745.7
BCE Train Loss:  tensor([37.9017, 12.0905, 15.3928,  8.7781,  4.9376,  8.7770,  7.1372, 20.0812,
         5.2774, 11.9440,  5.4042,  8.3536,  4.4795, 21.7569,  2.6994, 12.8178,
         7.0226,  6.7288, 12.5487,  2.0580,  5.0190,  1.2296,  0.5206,  5.3569,
        20.7952,  8.6363, 18.0575,  8.4921,  7.9953,  8.3703,  2.7347,  3.1301,
        15.9629,  2.5313,  1.9371,  1.5256,  5.3910, 12.4127,  1.6393, 20.3623,
         8.7376, 22.6179,  8.7342, 14.1962,  8.0384, 19.5266, 11.1864, 15.4381,
         6.6494,  2.4310,  1.2628,  3.4047,  9.4769,  1.1276,  8.5053,  9.1655,
        34.2155, 15.4264,  8.5488,  7.4526, 20.5838,  3.3897,  4.4670,  8.3066,
        12.1245,  7.3883,  5.3207, 22.9747, 13.6103, 13.1922,  0.1862,  7.1856,
        16.3267, 17.5584, 11.2384, 13.5041,  1.0148,  7.9931,  0.1490,  3.7576],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [16/80], Step [300/642], LR 1.0e-04, Loss: 774.7
BCE Train Loss:  tensor([34.4398,  5.9381, 23.6509,  8.9414,  1.6601, 24.4190,  5.5965, 18.5545,
         2.0497, 17.7328, 13.5715,  1.7673,  4.7776, 20.7561,  9.1670, 18.2771,
         8.8476,  8.2254,  3.8539,  5.7757,  3.0604,  4.0489,  0.5200,  3.2670,
        18.5066, 10.5376, 20.6371, 17.5605, 12.0222,  2.2107,  3.8615,  2.6053,
         8.5518,  7.4063,  4.2582,  2.6161,  6.0849,  5.4944,  9.8353, 16.5037,
         7.3035, 28.0655,  9.2225,  8.7908, 11.4905, 18.2566,  2.6230,  4.3705,
         9.0472,  0.9131,  2.9705,  6.8100,  7.4373,  3.0489,  6.3344,  1.7181,
        42.6275,  9.8640, 18.7155,  8.4269, 26.1976, 11.2718, 12.1468, 15.7847,
         3.4997,  5.7240,  1.6769, 21.5033,  1.7408,  6.2610,  0.2568, 21.6717,
         5.1574, 15.5801, 13.5780, 17.5913,  6.2118, 13.0798,  0.3441,  5.0998],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [16/80], Step [400/642], LR 1.0e-04, Loss: 810.0
BCE Train Loss:  tensor([37.3216, 10.0000, 17.3574,  1.5443,  2.9690,  9.4805,  2.8228,  9.5221,
        12.7843,  9.0129,  4.3255,  0.9878,  7.0985, 26.1057, 13.9996,  4.9482,
         7.8056, 12.3858, 15.9596,  5.6829,  1.0450,  0.5419,  2.2037,  3.5829,
        12.7927, 10.2848, 12.1466,  6.1284,  1.9979,  2.2659,  6.6118,  8.1591,
         4.1018,  8.8747,  1.1062,  2.1250,  4.3644,  7.4837,  0.5762, 14.8699,
        12.8054, 13.6384, 14.5734, 16.9712, 20.6871, 25.6457,  4.5649,  1.4541,
         7.6538,  5.1576,  3.0016,  5.7550,  3.6804,  5.2704,  8.5354, 11.7718,
        39.0999, 12.2816, 18.5737, 11.3526, 21.6547,  2.6711, 17.4386,  6.1827,
         3.8943, 17.7110,  7.6012, 25.3693,  2.3863,  3.6448,  0.0696,  5.0861,
         5.9607, 23.1126, 11.8956, 13.5469,  5.6760, 14.0818,  0.1954,  1.0560],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [16/80], Step [500/642], LR 1.0e-04, Loss: 755.1
BCE Train Loss:  tensor([39.5862,  7.9230, 24.9805,  4.2971,  2.2472, 17.9922,  8.5586, 16.1274,
        13.6926, 13.3767,  7.4766,  2.8902,  0.2995, 15.5529,  9.8956,  2.0808,
         6.1319, 16.5216,  5.2012,  1.4432,  2.3596,  6.3343,  0.1191,  2.4517,
        27.4683,  9.4914, 27.9083,  7.6135,  9.0029,  1.9491,  6.5358,  0.9127,
         6.8556,  1.5419,  1.3490,  1.6246,  7.9921,  6.4452,  1.2667, 17.3084,
        10.4664, 14.2822,  5.4856,  9.7539,  5.0965, 15.5524, 12.4113,  1.3997,
         5.3366,  1.1098,  3.7402,  9.5480,  5.6155,  6.3470,  0.9629,  7.2059,
        32.1215, 13.0332,  6.1600,  5.3203, 20.5827,  4.3239,  4.0828,  9.7957,
         5.6419,  7.2843, 10.3441, 22.7730,  1.5389,  2.6558,  5.0927,  2.7580,
         3.8402, 15.9803, 18.1035, 10.2137,  1.0891,  8.7970,  0.3730,  1.5249],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [16/80], Step [600/642], LR 1.0e-04, Loss: 690.5
BCE Val Loss:  tensor([5.2953e+01, 3.3039e+01, 5.5601e+01, 1.9962e+01, 2.3155e-01, 1.0646e+01,
        6.9764e+00, 1.7537e+01, 5.8738e+00, 9.4157e+00, 7.8468e+00, 1.1078e+01,
        7.1750e+00, 1.8829e+01, 8.5009e+00, 2.2678e+01, 3.1314e+02, 1.9296e+00,
        1.3419e+00, 2.0056e+00, 7.1796e-01, 4.1954e-01, 1.6117e-01, 5.7182e-01,
        2.3626e+01, 1.4196e+01, 2.9715e+01, 4.4343e+00, 1.4687e+01, 9.2852e+00,
        1.6705e+00, 7.6776e-01, 7.9326e+00, 1.4897e+00, 1.2987e+00, 1.2181e+00,
        8.3444e+00, 4.1347e+00, 1.4160e+00, 4.5101e+01, 1.1586e+01, 2.4399e+01,
        8.7930e+00, 1.3000e+01, 1.5770e+01, 1.6343e+01, 4.9010e-01, 4.9466e+00,
        3.3653e-01, 3.7697e+00, 9.5133e-02, 2.6672e-01, 6.2741e+00, 6.6448e-01,
        4.5406e-01, 5.8746e-01, 2.3870e+01, 6.3625e+00, 1.3467e+01, 2.3931e+00,
        1.2129e+01, 5.6701e+00, 4.1991e+00, 5.3699e+00, 3.7682e-01, 1.1949e+00,
        4.6884e-01, 1.4569e+01, 8.3741e+00, 1.1469e+01, 1.9127e+00, 1.8866e+01,
        1.1709e+01, 1.0548e+01, 1.5433e+01, 5.0867e+00, 9.0210e-01, 6.6193e+00,
        2.9092e-01, 1.3968e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [16/80], Step [000/314], LR 1.0e-04, Loss: 1068.4
BCE Val Loss:  tensor([5.8551e+01, 1.9615e+01, 4.6640e+01, 1.0750e+01, 2.1679e+00, 3.1715e+01,
        4.3887e+01, 3.7175e+01, 2.3807e+01, 2.9260e+01, 1.2981e+01, 4.2857e+01,
        7.9420e+00, 1.0922e+01, 1.6753e+01, 3.4877e+00, 8.6366e+00, 1.7670e+01,
        4.0416e+00, 1.5584e+01, 2.0163e-01, 9.6562e-02, 1.2030e-01, 2.6638e+00,
        2.5456e+01, 1.9700e+01, 3.0066e+01, 1.2970e+01, 1.4028e+01, 7.6267e-01,
        7.9524e-01, 2.9181e-01, 5.4667e-01, 3.4807e+00, 3.6715e-01, 2.0513e-01,
        2.1495e+00, 1.2777e+00, 4.6353e-01, 2.6197e+00, 4.2649e-01, 3.2795e+00,
        3.7716e-01, 1.2547e+00, 1.1054e+00, 2.1806e+00, 1.4946e-01, 1.7191e-01,
        1.6369e-01, 4.8439e+00, 4.7323e-02, 1.1879e-01, 2.3228e-01, 9.9171e-01,
        2.0092e-01, 1.0364e+00, 1.0265e+01, 5.4649e+00, 6.1914e+00, 3.3461e-01,
        4.3332e+00, 2.1508e+00, 4.9373e-01, 3.8495e-01, 8.3773e-02, 1.1433e-01,
        8.9087e-02, 1.8820e+01, 1.8186e-01, 1.7721e+00, 6.7938e-02, 1.9455e+00,
        5.4566e+00, 3.8737e+00, 6.3426e+00, 8.0594e-01, 4.4870e-01, 3.6172e-01,
        3.0102e-02, 3.6382e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [16/80], Step [100/314], LR 1.0e-04, Loss: 649.7
BCE Val Loss:  tensor([2.1831e+01, 7.0843e-01, 3.4220e+00, 3.1942e-01, 3.1592e-02, 8.1972e-02,
        1.1654e-01, 1.6700e+01, 3.8550e-01, 1.2396e-01, 9.9442e-02, 6.5700e-02,
        6.5103e-02, 1.3416e+01, 3.2902e-01, 1.3034e+00, 1.2001e+00, 1.1549e-01,
        4.4432e-01, 9.3162e-02, 6.0818e-02, 3.5330e-02, 1.8295e-02, 3.0710e-02,
        3.7458e+00, 1.5421e+00, 2.5314e+01, 6.2994e+00, 5.3441e-01, 5.0703e-01,
        2.1607e-01, 7.2577e+00, 8.4573e+00, 1.1482e-01, 4.4322e-01, 5.5624e-01,
        9.8427e+00, 9.8367e+00, 3.1903e-01, 4.2764e+01, 2.4619e+01, 5.8029e+01,
        6.6335e+01, 6.3665e+01, 4.7096e+01, 6.4220e+01, 8.9977e+00, 8.5373e+00,
        3.8546e+01, 9.9770e+00, 2.2315e+01, 4.2166e+01, 6.1597e+01, 2.9755e+01,
        4.8775e+01, 7.9721e+01, 9.4821e+01, 1.3758e+01, 1.0194e+01, 1.0066e+00,
        8.2346e+01, 3.7294e+00, 1.2725e+01, 1.3364e+01, 1.2523e+01, 2.7295e+00,
        1.1896e+01, 1.5821e+01, 6.3929e+00, 8.4245e+00, 8.3589e-01, 1.5116e+01,
        7.1639e+00, 4.1920e+01, 3.9107e+00, 1.5854e+01, 1.0043e+01, 8.4997e-01,
        2.8989e-01, 1.6554e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [16/80], Step [200/314], LR 1.0e-04, Loss: 1240.5
BCE Val Loss:  tensor([3.3530e+01, 4.3789e+00, 1.9333e+01, 2.3773e+00, 7.4522e-01, 9.1753e+00,
        7.5758e+00, 1.4969e+01, 1.3527e+00, 2.2339e+01, 3.2340e+00, 8.9716e+00,
        1.1813e+00, 1.4523e+01, 1.5861e+01, 1.0095e+00, 8.0484e-01, 3.2198e-01,
        1.9008e-01, 7.0830e-02, 2.1978e-01, 2.7692e-02, 4.9093e-02, 4.1551e-01,
        2.2774e+01, 5.5202e+00, 2.0931e+01, 1.0180e+00, 1.3443e+01, 2.0047e-01,
        3.5969e-01, 1.8920e-01, 2.0554e-01, 3.5521e-01, 1.9269e-01, 1.3875e-01,
        7.5830e-01, 2.7545e-01, 2.3179e-01, 3.4274e+00, 4.0595e-01, 2.1709e+00,
        2.5335e-01, 1.0574e+00, 9.5788e-01, 1.8034e+00, 1.0406e-01, 8.3893e-02,
        7.1828e-02, 1.0824e-01, 2.9034e-02, 4.1223e-02, 6.7800e-02, 2.7243e-01,
        1.6005e-01, 7.6819e-01, 6.4897e+00, 7.3652e-01, 1.2850e+01, 5.3761e-01,
        7.7619e+00, 3.5997e+00, 8.9898e-01, 5.3705e-01, 2.4562e-01, 8.9433e-01,
        3.4881e-01, 6.3522e+00, 4.1326e-01, 1.3056e+00, 1.3435e-01, 4.0925e+00,
        3.9115e-01, 6.1884e+00, 8.7406e+01, 3.9468e+00, 3.4506e-01, 5.7506e+00,
        8.0771e-02, 1.9580e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [16/80], Step [300/314], LR 1.0e-04, Loss: 392.5
starting validation
Accuracy th:0.5 is [87.67802537 97.58043883 92.95573884 98.30533254 98.96687419 97.8545583
 98.76707155 95.65063778 98.22248754 97.35139679 98.82676868 99.13378248
 99.4566343  95.60312374 97.59749516 97.65353736 96.48396097 98.06410741
 99.00829668 98.55995906 99.16667682 99.40546533 99.7076059  99.48587371
 95.28392685 97.21007298 94.36897699 97.35017848 98.13964255 98.40645216
 98.69640964 98.73295891 97.07605901 98.95956433 98.90474044 99.05337411
 98.32360717 98.66960685 99.17520498 93.31757654 97.92156528 93.493013
 97.22834761 96.53634824 97.04438299 94.90503283 98.38817753 98.75123354
 98.27000158 98.86209963 99.02047977 98.75488846 99.05581072 98.65133222
 98.79874758 97.83384705 91.41214166 97.07118578 96.53756655 97.86430477
 93.31026669 98.01781167 97.11138997 97.4646995  98.84991655 97.73638235
 98.65498715 96.06729938 98.81945883 98.36259305 99.78801428 96.57167919
 98.38574091 95.82729255 97.27586165 97.58531207 99.19713454 98.48929716
 99.84405648 99.15693035]
Accuracy th:0.7 is [86.40489273 97.48419244 92.419683   98.216396   98.82555037 97.58165714
 98.60747311 95.30707472 98.08238204 97.30997429 98.79143773 99.10210646
 99.44079629 95.45449008 97.48175583 97.54267126 96.34263715 97.90207234
 99.03022624 98.4539662  99.14109234 99.33845835 99.69176789 99.45419768
 95.25712406 97.08702379 94.49202617 97.27464334 98.07994542 98.27731144
 98.59163509 98.6208745  96.72153117 98.86575456 98.69884626 98.92667
 98.20055799 98.60138156 99.18495145 93.13848515 97.88988926 93.06295001
 97.00052387 96.37553149 97.05291115 94.55781484 98.27487482 98.66107869
 98.17010027 98.75488846 98.94738125 98.76219832 99.02900793 98.75610677
 98.75488846 97.66572045 90.80786053 96.68254529 96.54609471 97.71567111
 92.93259098 98.58067031 96.87381976 97.52926987 98.88768412 97.57678391
 98.62818435 95.99298254 98.74026876 98.25294526 99.81481707 97.36357988
 98.27000158 95.54464492 97.16499555 97.51221355 99.18495145 98.38452261
 99.84405648 99.1642402 ]
Avg Prec: is [96.43237023 42.23953048 69.94771389 72.25878026 87.34777555 72.35923934
 84.19545516 55.52489615 65.3746758  62.53721877 49.60432273 64.92692996
 30.718006   35.92729885 39.85388843 64.43155101 36.79396504 59.96058535
 60.99708071 49.51279091 80.2217872  63.23479599 94.06469047 92.57915996
 30.03135348 46.27956667 40.14694848 50.95389056 31.06235848 50.18198606
 81.48975298 51.90903644 59.4504368  77.45363701 81.22343873 84.99492275
 75.80936225 81.22073218 91.20148099 45.74208341 32.84591288 56.90731807
 52.68873355 47.29134104 41.32962736 55.42684706 53.27829379 43.20161094
 50.48270009 51.89365358 72.59940128 49.06502483 31.14833456 80.39285601
 38.1934747  51.52607526 59.44875654 63.8843259  40.4357636  65.36629243
 71.83149951 85.00003595 63.61054915 54.67486721 64.69888019 50.37470942
 60.22676937 29.51179656 45.76170412 67.15339701 10.09731914 75.47503384
 56.4173359  44.69008566 56.5237837  54.87349682 18.39959472 47.42064306
  7.63610736 24.07033391]
Accuracy th:0.5 is [81.78993921 97.24540393 91.42554306 97.8265372  98.49173378 97.47444597
 98.29924099 95.18158892 97.72419927 96.795848   98.54777598 98.87306441
 99.41399349 95.33875075 97.38429113 96.84823528 96.31339774 97.59871347
 98.7743814  98.36746628 98.72930398 99.19104299 99.55897223 99.01316992
 95.22910296 96.70934808 94.21059685 96.97493939 98.01415675 98.26391004
 98.30898746 98.52706473 96.77148183 98.58432524 98.56726892 98.74514199
 97.60724163 98.18471997 98.75001523 92.98985149 97.83506536 92.782739
 97.06996747 96.34751039 96.99808726 94.18013913 98.13720593 98.66595193
 98.05557924 98.67935332 98.7463603  98.60747311 99.00342345 97.99100888
 98.70981104 97.53779803 90.73110708 96.62284816 96.35116531 97.37088973
 92.31125352 98.22126923 96.69107345 97.20641805 98.5928534  97.42815024
 98.34431842 95.95277835 98.76341663 98.05436094 99.81603538 97.15403077
 98.15548056 95.61896176 96.6277214  97.10286181 99.18007822 98.19568475
 99.84405648 99.14718388]
Accuracy th:0.7 is [74.82121319 97.21494621 90.50450165 97.64622751 98.45640282 97.18083357
 98.15304394 94.88188497 97.81800904 96.59482706 98.53193796 98.80971236
 99.41399349 95.3180395  97.32824892 96.62893971 96.29512311 97.51343185
 98.70615611 98.31507901 98.56848723 99.24952181 99.53338775 98.93032492
 95.21935649 96.65696081 94.09363921 96.87503807 98.01293844 98.18106505
 98.04095954 98.57457877 96.59604537 98.37843106 98.61234634 98.73783214
 97.33068554 98.22492416 98.45762113 92.7961404  97.85090338 92.28688734
 96.94204505 96.26222877 96.96397461 93.94256893 98.08116373 98.60381818
 98.05801586 98.60259987 98.54533936 98.56239568 99.00098683 98.3138607
 98.70615611 97.47200936 89.95869933 96.51563699 96.28659495 97.14062938
 91.33173329 97.98369903 96.41086244 97.09433365 98.49904363 97.36845311
 98.27000158 95.95277835 98.69153641 97.92522021 99.81603538 96.86041837
 98.0628891  95.46545486 96.45228494 97.03950975 99.18007822 98.16279041
 99.84405648 99.14718388]
Avg Prec: is [93.04800426 25.33014086 58.58161127 57.36354024 74.83814895 61.40516442
 71.91477646 44.05585722 47.20814619 45.25811737 24.85707752 53.32811972
 15.44619481 22.79861874 25.85460914 42.61083901 21.64928394 35.10350551
 41.00984419 32.05422681 61.82943982 40.36866795 89.13957839 80.90575576
 23.22028796 23.57843282 31.03989364 34.25882482 17.32389658 36.2550886
 70.79921974 33.26219012 50.50891311 62.5750308  68.87841945 75.64450863
 55.0986472  70.50132597 83.72177616 38.16021507 22.58321562 47.93099247
 41.68335748 37.04101405 32.61844284 43.64229483 32.66228608 29.36236644
 36.13723227 37.82160766 59.25672966 33.19444004 15.45596923 68.5141442
 21.86587475 31.44153264 51.80956282 48.90068299 27.60550078 48.00294069
 62.86972897 70.25501937 51.06276938 40.95867144 49.08493354 34.0291527
 45.66783275 18.0081828  36.10582294 52.89727013  6.96297474 64.85342605
 43.26610134 36.2175854  41.15431109 35.67527471  9.61310341 24.49634821
  4.69609728 15.28059317]
mAP score regular 56.70, mAP score EMA 43.14
starting validation
Accuracy th:0.5 is [88.67379226 97.53344794 93.0662481  98.4652565  99.15539278 97.91962528
 98.85392531 95.71467723 98.36808929 97.23198047 98.87385704 99.20273065
 99.40952239 95.44061589 97.63559808 97.70286768 96.46710018 98.19119516
 99.12798665 98.58733837 99.35471012 99.48177492 99.71846426 99.67361786
 95.32102549 97.08249246 94.16000199 97.54590527 97.99436929 98.35314049
 98.85890824 98.76921544 97.10491566 99.09310611 98.99344744 99.28494905
 98.4652565  98.5848469  99.19027331 93.32536064 97.92211675 93.56952438
 97.27931833 96.57921618 96.80095672 94.78785161 98.58982983 98.90624611
 98.21860129 98.87385704 99.05822558 98.68699704 98.92617784 98.66457383
 98.84395944 97.88474475 90.94850138 97.2743354  96.36744151 97.81498368
 93.08368837 98.04918155 97.1696938  97.47614421 98.81157037 97.70785061
 98.61225303 95.86167377 98.75426664 98.20614396 99.73590453 96.40232205
 98.4129357  95.79689563 97.27931833 97.62563221 99.26003438 98.57238957
 99.82559733 99.09808905]
Accuracy th:0.7 is [88.23529412 97.49607594 93.01891023 98.38054663 99.05075118 97.64307248
 98.7119117  95.44061589 98.23355009 97.3266562  98.86389117 99.19774771
 99.40453945 95.31105962 97.50604181 97.58576874 96.33006951 98.00433515
 99.14293545 98.51259436 99.31733812 99.39706505 99.73341306 99.65119466
 95.49293669 97.05508633 94.58853427 97.50105887 97.90965942 98.26843063
 98.75924957 98.73184344 96.70877245 99.04576824 98.81904477 99.16535865
 98.4278845  98.46276503 99.16785011 93.23566784 97.85733862 93.27303984
 97.1472706  96.53935272 97.06006926 94.66078681 98.4727309  98.84894237
 98.12890849 98.83897651 98.98846451 98.71689464 98.92119491 98.73184344
 98.7866557  97.75767995 90.71928644 96.99030819 96.50945512 97.75020555
 93.0587737  98.60976157 96.91307273 97.58078581 98.82901064 97.67047861
 98.6371677  95.87911403 98.78416424 98.20116102 99.8056656  97.29177567
 98.32324289 95.52283429 97.1248474  97.60071754 99.25006852 98.4876797
 99.82559733 99.14542691]
Avg Prec: is [96.84709194 39.87372178 71.21587978 77.17823993 84.83447376 71.470773
 86.5742075  53.48344453 68.67581317 63.28091955 54.00050693 65.67022038
 28.54755548 36.71337585 40.84947425 69.91197153 39.05996983 63.29296044
 64.56305166 49.79537901 84.93257734 71.21182194 94.77485889 95.77360642
 27.17446009 46.73301242 35.79149778 54.8863138  32.16656887 46.84006037
 81.94496881 49.23015765 57.01782096 79.24562016 79.35064724 85.63414174
 74.94977862 81.87907645 91.31752679 44.99530157 33.45874769 53.72785524
 45.62732817 40.66771042 34.67467522 52.85925477 53.95173409 38.92500115
 48.67603643 50.32445233 77.86532404 45.34644585 33.18910194 82.1714612
 39.92052134 47.33804594 56.31909395 60.76518914 39.10731957 66.33144653
 68.52033058 87.84357659 64.30472479 55.3095777  64.95156405 43.48849643
 63.38677685 29.42908211 39.56495451 64.8075261   8.85267502 76.10364438
 52.52063024 41.24875411 62.51232923 53.94269893 14.36598115 49.55763165
  2.26180141 21.61296439]
Accuracy th:0.5 is [84.05461295 97.25689513 92.16433715 98.07160475 98.89129731 97.63061514
 98.4652565  95.29361935 97.67546154 96.75112739 98.57986397 99.01587064
 99.35221865 95.04198121 97.37399407 96.80095672 96.25532551 97.68542741
 98.89129731 98.35314049 98.92866931 98.90624611 99.64870319 99.29740638
 95.45307322 96.62157112 94.48389267 97.1397962  97.81996661 98.20365249
 98.63467623 98.60228717 96.82337992 98.79911304 98.7492837  98.98597304
 97.97194608 98.08406209 98.90375464 93.04631637 97.87727035 93.1484665
 97.13481326 96.50945512 97.03764606 94.346862   98.27341356 98.8165533
 97.96198022 98.75177517 98.85143384 98.61723597 98.88631437 97.94703142
 98.71689464 97.66051274 90.56481551 96.83583726 96.20300471 97.36153674
 92.55300595 98.45529063 96.76358472 97.2892842  98.53003463 97.53843087
 98.35563196 95.7694895  98.7567581  98.03672422 99.81563146 97.19709993
 98.22856716 95.62000149 96.63153699 97.21204873 99.24757705 98.26095622
 99.82559733 99.15290131]
Accuracy th:0.7 is [79.2136931  97.2369634  91.10546379 97.97443755 98.91621197 97.38395994
 98.39549543 95.11174228 97.96945462 96.63651992 98.53003463 98.96105838
 99.35221865 95.10925082 97.29426714 96.44467698 96.21297058 97.53843087
 98.87883997 98.34068316 98.8165533  99.27747465 99.65617759 99.31235518
 95.43563296 96.54433565 94.3917084  97.04512046 97.81747515 98.18870369
 98.41791863 98.66457383 96.80593966 98.5923213  98.86638264 99.07566584
 97.75020555 98.17873782 98.6670653  92.8868625  97.83989835 92.71495129
 97.1248474  96.50945512 97.04013753 94.15501906 98.23355009 98.79163864
 98.02426689 98.7268605  98.64713357 98.57488103 98.87385704 98.37805516
 98.6969629  97.60320901 90.14375763 96.87819219 96.21047911 97.15723647
 91.94757954 98.30081969 96.57423325 97.11239006 98.40795276 97.46119541
 98.25099036 95.7769639  98.74679224 98.02426689 99.81563146 97.19709993
 98.13389142 95.46553056 96.34501831 97.17467673 99.24757705 98.20863542
 99.82559733 99.15040985]
Avg Prec: is [94.20167646 23.48469554 62.21585472 66.53676245 76.00389201 63.51154751
 79.15218182 44.26064877 53.79763872 46.67614169 31.94730288 56.63079938
 13.87763902 24.16408532 28.62219814 51.01743335 25.27219489 40.61016147
 43.81282327 32.56839841 70.70774601 50.69065638 92.73198891 88.09610758
 22.8629524  27.17544439 29.80061493 41.35813644 21.02996605 36.14232789
 76.94349175 33.66172709 52.52852377 65.57980909 72.52644217 81.03996597
 58.47748282 74.15969559 88.30029361 40.37233964 27.446771   48.95697844
 40.20149486 35.59129286 29.76298989 43.11186098 32.27067603 24.10401313
 37.11893463 39.19881029 67.35809509 31.69860766 21.41591737 73.78468134
 26.26542056 32.89086733 51.5156871  49.59669926 26.88137184 52.01160284
 63.4643994  78.91601542 55.18665428 47.04305234 53.88857911 32.90739323
 51.27597259 20.09394411 35.23633558 56.68078974  8.94096769 67.73098016
 43.81244142 36.57081349 50.94494186 38.89482748 10.00295918 28.38301839
  1.71542345 15.33757318]
mAP score regular 56.34, mAP score EMA 45.88
Train_data_mAP: current_mAP = 56.70, highest_mAP = 56.70
Val_data_mAP: current_mAP = 56.34, highest_mAP = 56.34
lr:  [9.993958531997271e-05, 9.993958531997271e-05]
BCE Train Loss:  tensor([42.1940, 11.2528, 20.7448,  7.1577,  3.8184,  5.5635,  1.8715, 12.3140,
         5.6065,  8.4013,  0.8624,  7.1059,  0.3505, 12.9748, 15.1883,  8.0170,
        11.8092,  5.7610,  6.7539,  2.7203,  7.6450,  0.8174,  2.2404,  0.4767,
        18.7907,  9.3420, 24.0197, 18.6986,  1.5434,  5.7950,  8.6324,  4.9085,
        19.7863,  1.5512,  5.3721,  7.4806,  3.9772,  1.8436,  0.9050, 17.2711,
         2.7629, 12.4393,  5.4026,  8.8237,  8.8168, 12.8735, 20.0480,  3.9870,
         2.3629,  1.3793,  1.0725,  1.8287,  3.3108,  4.7402,  5.9481,  6.0717,
        23.8116,  7.0494, 14.4533,  5.9619, 15.1793,  8.2198,  4.2430,  8.5352,
         5.4674,  7.9574,  7.6049, 12.2716,  1.1251, 16.6624,  3.4954, 18.7982,
         2.2993, 15.2714,  7.4101,  9.2969,  1.2419,  4.7871,  2.2934,  7.7025],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [17/80], Step [000/642], LR 1.0e-04, Loss: 664.6
BCE Train Loss:  tensor([35.5679, 11.4595, 20.0944, 15.2145,  4.3227,  8.3860,  1.2086, 21.2316,
        10.7694, 12.3357,  5.4432,  0.7274,  2.1309, 11.9812, 13.1122,  4.9808,
        14.1491,  7.8356,  3.6924,  1.6605,  2.6401,  2.2224,  0.3418,  5.8967,
        13.3512,  8.8378, 20.8244,  9.1800,  7.8754,  5.2296,  1.3248,  1.4853,
        11.5270,  1.7092,  3.5551,  6.0361,  1.3090,  3.5783,  4.6506, 21.2963,
        13.0847, 16.9850,  6.0718,  9.0430,  5.0709, 13.9171,  1.1645,  2.4711,
         4.0165,  1.7628,  0.3674,  3.5477,  1.8024,  1.1934,  6.0546,  3.8972,
        31.1883,  8.4077, 12.8031,  6.4404, 16.2078,  1.5852, 10.4011,  4.2496,
         3.0678,  3.0700,  5.3687, 14.7376,  1.8525,  4.4998,  0.2159,  6.9023,
         2.1015, 20.4696, 17.2661, 13.8899,  0.7052,  7.6303,  0.2944,  3.4538],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [17/80], Step [100/642], LR 1.0e-04, Loss: 626.4
BCE Train Loss:  tensor([33.0307, 10.9597, 24.1242,  6.2119,  4.3223,  6.2201,  6.7106, 13.7420,
         7.3957, 10.7002,  3.9429,  1.1048,  2.5930, 11.5353, 12.6880, 11.0407,
        11.4783, 13.0343,  7.4004, 16.3295,  8.7112,  4.0708,  7.3729,  0.3292,
        22.1714,  8.7641, 32.0622, 11.2076, 10.4138,  4.0224,  3.4585, 13.7215,
         9.4181,  1.6760, 15.6461,  9.8628,  2.6480,  4.3356,  2.6762, 24.1041,
         5.4330, 19.7651,  5.3328, 10.1037,  9.6062, 27.3089,  1.5571,  8.7412,
         4.2802,  6.7595,  0.6188,  4.3148,  3.5282,  1.1185,  3.0619,  8.3537,
        27.7476,  5.8358, 11.9350,  2.9601, 24.4303,  8.1814,  7.4706,  6.7441,
         1.2298, 11.3648,  1.0733, 15.2657,  2.2627,  9.3114,  0.2569,  6.9045,
         2.5753, 11.6507,  7.0258, 11.7128,  0.8243,  6.7850,  0.1025,  4.5919],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [17/80], Step [200/642], LR 1.0e-04, Loss: 719.4
BCE Train Loss:  tensor([30.3267, 12.9495, 30.9374,  8.9506,  3.1899,  6.5851,  6.5861, 25.7926,
         7.2799, 17.9233, 10.1943, 22.9440,  5.7307, 16.6269, 10.1106,  7.0587,
        16.0564,  7.1538,  4.7152,  6.9233,  1.3095,  2.8314,  0.4979,  0.5229,
        20.2387, 16.5818, 21.1673, 17.5952, 12.1189,  4.6517, 10.3192,  5.5071,
         5.0491,  0.7796,  2.1489,  0.5633,  7.2830,  3.6263,  0.6941, 18.4847,
        12.0587, 27.9325,  8.1500, 15.3138, 12.4355, 18.6211,  4.7021,  2.3499,
        10.6743,  1.2387, 15.5465,  7.8854,  1.9326,  6.9814,  2.8993,  8.9540,
        19.2244,  9.1601, 10.0525,  8.5039, 21.6061,  8.7160,  4.8676,  4.8900,
         4.6663,  4.0605,  0.5641, 25.0526,  2.6845,  3.4270,  0.1018,  4.4702,
         2.3401, 11.2079,  7.1557,  3.1021,  7.9105,  2.2278,  0.0930,  1.3007],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [17/80], Step [300/642], LR 1.0e-04, Loss: 735.1
BCE Train Loss:  tensor([43.3627, 11.1006, 32.4201,  4.4467,  4.7746,  7.9194,  9.4408, 20.8069,
         8.0627,  8.7625,  8.4796,  4.0122,  0.8808, 14.0462, 20.6305,  5.1307,
        20.9770,  5.3830,  5.8106,  9.2333,  3.7764,  0.7042,  0.1483,  0.3333,
        17.8048, 10.7571, 20.8788, 19.4180,  9.2836, 10.7048,  4.0445,  2.7924,
         8.0919,  3.3303,  2.3537, 11.2274,  5.5307,  5.6620,  0.7526, 33.4590,
        10.3757, 23.6755,  2.5535, 10.5452, 10.1099, 13.8963,  7.0676,  1.7130,
         4.7381,  4.4701,  0.4346,  2.6716,  1.3806,  0.5100, 17.2708,  6.3284,
        23.0926,  7.5282,  8.0952,  5.1788, 13.2870,  3.6552, 11.4594,  6.3155,
         2.2056,  4.6148,  2.9350, 23.8831,  7.1175,  4.4237,  0.2074, 12.8815,
         3.7433, 17.3837, 14.0322,  9.5919,  1.4208,  3.1612,  0.1584,  0.6114],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [17/80], Step [400/642], LR 1.0e-04, Loss: 721.5
BCE Train Loss:  tensor([37.0927,  6.4702, 20.5949,  6.9573,  0.6672,  5.0137,  7.9178, 12.0205,
         6.5108,  3.9100, 16.1198,  0.6525,  0.6244, 10.8511, 11.4552,  4.6713,
        13.9739,  5.7776,  7.2129,  5.0548,  3.6435,  1.8962,  0.1137,  0.2434,
        10.7871, 18.9224, 24.7100, 11.4332, 17.0076,  5.0954,  4.0237,  8.3412,
         5.2794,  6.8517,  2.9879,  1.4296,  8.3151,  1.5193,  0.5499, 21.5921,
         9.1441, 16.3113,  4.9712,  7.8346,  6.9221, 16.0765,  7.7275,  3.4659,
         6.7070,  9.4167, 10.0669,  1.6339,  1.3031,  2.2082,  9.2523,  6.0402,
        32.5078,  9.5782, 12.6852,  9.9808, 20.7652,  0.6383, 14.3168, 15.2171,
        12.0663,  8.2293, 11.4346, 15.0520,  4.6868,  7.4274,  2.9702, 12.0226,
         8.0705, 13.8884,  5.5960, 11.5781,  8.7202,  8.6001,  4.1361,  3.9594],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [17/80], Step [500/642], LR 1.0e-04, Loss: 711.5
BCE Train Loss:  tensor([30.2780,  3.2012, 17.2981,  2.0304,  3.3473, 11.9588,  2.1265,  8.2843,
        14.9114,  6.1016, 10.1870,  1.5605,  0.5879, 13.3699,  8.7184,  5.0606,
        12.9174,  2.1012,  0.8943,  3.6265,  6.1894,  0.9015,  0.2140,  3.1380,
        11.4396, 15.7629, 21.1073,  5.1322,  5.8841,  2.1685,  3.5157,  4.3520,
        11.8940,  6.9625,  1.2753,  1.5615,  2.4230,  3.2813,  3.0580, 21.9134,
         4.6128, 16.8324,  6.3224,  7.2158,  9.8002, 27.5939, 16.2749,  4.8775,
         3.5940,  4.1042,  0.7303,  9.2472,  1.9680,  3.4867,  3.9120,  5.9102,
        26.0709,  9.8839, 14.3797,  3.7763, 23.1516,  1.5857, 10.0691, 12.2957,
         6.1085,  5.8337, 11.4217,  5.4917,  3.3123, 12.9991,  0.2351, 11.8075,
         8.4925, 15.3817, 12.1355,  9.1041, 12.8717, 10.4340,  0.1988,  3.3116],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [17/80], Step [600/642], LR 1.0e-04, Loss: 647.6
BCE Val Loss:  tensor([4.4866e+01, 4.1686e+01, 4.8582e+01, 2.0923e+01, 4.1440e-01, 1.0395e+01,
        6.1572e+00, 1.9550e+01, 5.7867e+00, 8.4940e+00, 7.5516e+00, 1.1735e+01,
        6.7920e+00, 1.7131e+01, 8.7272e+00, 1.4393e+01, 2.9918e+02, 1.1289e+01,
        1.6906e+00, 4.8337e+00, 7.2814e-01, 6.7312e-01, 5.7566e-02, 5.8836e-02,
        2.7039e+01, 1.3271e+01, 2.8011e+01, 3.6203e+00, 1.8214e+01, 9.1620e+00,
        1.3231e+00, 9.4396e-01, 7.4461e+00, 1.0039e+00, 2.6473e+00, 1.3056e+00,
        2.3028e+01, 3.8708e+00, 9.1091e-01, 4.5464e+01, 1.0689e+01, 2.2930e+01,
        7.5816e+00, 1.3929e+01, 1.6377e+01, 1.5842e+01, 6.9343e-01, 5.1052e+00,
        3.1785e-01, 3.8493e+00, 1.2634e-01, 4.6161e-01, 5.8939e+00, 1.4542e+00,
        9.6105e-01, 3.9674e-01, 2.3742e+01, 7.0473e+00, 1.1559e+01, 7.5364e+00,
        1.2574e+01, 8.8472e+00, 4.3183e+00, 5.1610e+00, 3.3421e-01, 1.0923e+00,
        3.8425e-01, 9.6488e+00, 8.3907e+00, 1.2480e+01, 1.0777e+00, 1.6373e+01,
        1.1897e+01, 1.2641e+01, 1.5437e+01, 6.1394e+00, 5.1835e-01, 8.0289e+00,
        3.7567e-01, 5.0089e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [17/80], Step [000/314], LR 1.0e-04, Loss: 1071.7
BCE Val Loss:  tensor([5.9821e+01, 1.8645e+01, 4.9795e+01, 9.8921e+00, 3.1957e+00, 2.8330e+01,
        3.5076e+01, 3.6872e+01, 1.6109e+01, 3.2050e+01, 1.5165e+01, 4.8842e+01,
        8.9342e+00, 8.8135e+00, 1.6761e+01, 2.3890e+00, 9.1727e+00, 1.7561e+01,
        4.5799e+00, 1.3915e+01, 3.0099e-01, 1.8429e-01, 6.0726e-02, 3.1443e+00,
        2.6087e+01, 1.9471e+01, 3.2137e+01, 1.3627e+01, 1.3288e+01, 5.7647e-01,
        2.6375e-01, 2.1667e-01, 4.2593e-01, 8.8733e-01, 9.2252e-01, 1.7981e-01,
        6.5303e+00, 1.7732e+00, 1.6070e-01, 2.0488e+00, 5.8727e-01, 3.5462e+00,
        6.9913e-01, 8.4126e-01, 7.3991e-01, 1.9160e+00, 2.2900e-01, 3.0384e-01,
        2.2230e-01, 4.5868e+00, 7.4621e-02, 2.4137e-01, 2.1532e-01, 1.3789e+00,
        3.4985e-01, 1.0270e+00, 8.7941e+00, 4.7792e+00, 6.7918e+00, 9.8173e-01,
        4.1497e+00, 2.5337e-01, 3.3628e-01, 5.2826e-01, 6.8718e-02, 1.3263e-01,
        8.9291e-02, 1.9267e+01, 1.3209e-01, 2.4865e+00, 3.9227e-02, 2.3479e-01,
        4.2970e+00, 3.4783e+00, 6.1274e+00, 4.4641e-01, 2.9843e-01, 9.4347e-01,
        3.7898e-02, 1.2888e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [17/80], Step [100/314], LR 1.0e-04, Loss: 640.0
BCE Val Loss:  tensor([2.3080e+01, 3.7650e-01, 4.7867e+00, 3.7756e-01, 7.8175e-02, 1.2117e-01,
        1.0637e-01, 1.4516e+01, 6.6794e-01, 7.2039e-02, 9.0245e-02, 4.5654e-02,
        6.1087e-02, 1.3953e+01, 5.6911e-01, 5.3795e-01, 1.0422e+00, 4.2901e-01,
        3.1492e-01, 1.5252e-01, 1.1365e-01, 5.0905e-02, 1.1627e-02, 1.1849e-02,
        4.2020e+00, 1.1695e+00, 2.6617e+01, 5.8230e+00, 8.1803e-01, 4.3100e-01,
        1.9810e-01, 7.0696e+00, 8.1652e+00, 1.3553e-01, 6.2127e-01, 4.0306e-01,
        1.0468e+01, 9.4401e+00, 1.1937e-01, 3.9276e+01, 2.2765e+01, 5.9053e+01,
        6.2572e+01, 6.4107e+01, 4.9201e+01, 6.4715e+01, 9.1253e+00, 9.5630e+00,
        3.5873e+01, 8.7977e+00, 2.7444e+01, 3.5973e+01, 6.4165e+01, 4.9022e+01,
        4.1929e+01, 1.0007e+02, 1.0388e+02, 1.3980e+01, 6.7607e+00, 1.8164e+00,
        8.9293e+01, 4.3326e-01, 1.2173e+01, 1.3417e+01, 1.4088e+01, 3.0472e+00,
        1.0385e+01, 1.2724e+01, 6.7497e+00, 5.6735e+00, 4.5453e-01, 9.3455e+00,
        7.3424e+00, 4.4697e+01, 2.5055e+00, 1.4537e+01, 1.0700e+01, 2.2451e+00,
        3.5393e-01, 5.6493e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [17/80], Step [200/314], LR 1.0e-04, Loss: 1268.1
BCE Val Loss:  tensor([3.7258e+01, 2.1975e+00, 1.9808e+01, 2.7150e+00, 1.5498e+00, 1.0087e+01,
        8.8304e+00, 1.6957e+01, 7.1537e+00, 1.6312e+01, 3.0401e+00, 6.3641e+00,
        1.1591e+00, 1.5247e+01, 1.7185e+01, 5.2004e-01, 1.1151e+00, 1.7886e+00,
        2.9054e-01, 1.8542e-01, 4.0445e-01, 7.6673e-02, 3.2749e-02, 8.5307e-02,
        2.3611e+01, 5.3563e+00, 2.4604e+01, 8.7842e-01, 1.4924e+01, 1.9412e-01,
        3.9434e-01, 3.3272e-01, 4.1202e-01, 3.1413e-01, 8.8098e-01, 6.3631e-01,
        2.6235e+00, 3.7853e-01, 2.3412e-01, 2.5334e+00, 8.0272e-01, 1.7070e+00,
        2.3914e-01, 3.5530e-01, 3.8926e-01, 1.3792e+00, 1.8455e-01, 1.4892e-01,
        6.1901e-02, 9.6398e-02, 3.1547e-02, 7.7367e-02, 4.8061e-02, 3.4906e-01,
        2.2852e-01, 2.6525e-01, 6.2608e+00, 1.7149e+00, 1.1069e+01, 1.1073e+00,
        5.7387e+00, 3.3193e-01, 8.3409e-01, 7.2153e-01, 1.4397e-01, 2.0180e+00,
        2.2210e-01, 5.7925e+00, 3.2965e-01, 8.6968e-01, 7.0698e-02, 3.4356e-01,
        3.6041e-01, 6.3755e+00, 9.9130e+01, 2.7266e+00, 1.7449e-01, 5.9279e+00,
        7.3329e-02, 3.4833e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [17/80], Step [300/314], LR 1.0e-04, Loss: 407.4
starting validation
Accuracy th:0.5 is [87.21872297 97.54510788 93.05442185 98.37964937 99.08261352 97.93496668
 98.84260669 95.73348278 98.14817071 97.2965729  98.88037426 99.12647263
 99.47369062 95.67987719 97.65597398 97.62307964 96.59848199 98.11771299
 99.01682484 98.69275472 99.26048659 99.47612724 99.70395098 99.39571886
 95.31072965 97.26611518 94.54075852 97.4366784  98.20421291 98.49904363
 98.72686736 98.82798699 97.13697445 99.00829668 98.87550103 99.14718388
 97.88501602 98.73783214 99.24221196 93.46011866 97.99831873 93.58925939
 97.29779121 96.52660177 97.08336887 94.89041313 98.49295208 98.80483912
 98.32482548 98.85357147 98.91570522 98.80362081 99.07164874 98.06776233
 98.84747993 97.75953022 91.64240202 97.26367856 96.56436934 97.94349484
 93.60022417 98.79996589 97.08458718 97.52805156 98.92301507 97.7985161
 98.72199413 96.07826415 98.83773346 98.44178312 99.81603538 97.66572045
 98.45883944 95.86262351 97.2831715  97.57800222 99.19469792 98.56848723
 99.84405648 99.17398667]
Accuracy th:0.7 is [87.57446912 97.39038267 92.71695033 98.36746628 99.02900793 97.62917118
 98.87671934 95.58850404 98.32360717 97.04803791 98.85600809 99.08870506
 99.44566952 95.54220831 97.58653038 97.31728415 96.46203141 98.24807203
 99.02657131 98.60747311 99.21540917 99.46759908 99.66862002 99.33967666
 95.25590575 97.15159416 94.26907567 97.26246025 98.16522703 98.37477614
 98.5928534  98.6756984  96.62041154 98.90108551 99.05093749 99.08261352
 98.26634666 98.7037195  99.1215994  93.09584435 97.94593146 93.12995699
 97.05412946 96.29268649 96.97372108 94.37019529 98.42716341 98.73295891
 98.23710725 98.82189544 98.77559971 98.75123354 99.04728256 98.48198731
 98.84138838 97.64013596 90.93700125 97.10408012 96.43035538 97.98491734
 92.71695033 98.66107869 96.7532072  97.63526273 98.78900111 97.73760066
 98.54655767 95.99785578 98.75488846 98.3552832  99.81481707 97.18936173
 98.32604379 95.73470109 97.10773504 97.45738965 99.18616976 98.5928534
 99.84405648 99.15693035]
Avg Prec: is [96.52173348 44.78640483 71.14838672 75.34328863 88.03925411 73.8801239
 85.92958759 57.38011862 66.89236013 62.94605216 51.5581064  64.30414536
 36.89370757 37.58122563 40.4289675  68.21066257 38.70296151 62.93811247
 62.87044407 55.27157084 84.16322374 66.03053736 94.77219696 93.07868918
 30.27641642 48.26088677 40.71468774 55.14948159 35.36132166 54.60095785
 82.99787528 57.05741608 61.68390022 79.44612029 83.2420317  86.85600606
 76.17107659 82.5849235  92.0202771  47.58877513 36.1893366  57.68332399
 53.40967867 48.07382708 41.71124929 56.14713138 54.58838264 45.45217774
 52.83835286 52.43865551 73.19486514 51.79264268 34.45470954 80.6940946
 41.85610464 53.17040237 61.13886646 65.4513487  41.42703733 69.03051727
 73.59259026 85.85738726 65.4856221  57.37014202 65.67160088 52.06269245
 62.97301825 32.02658089 46.85519404 69.08494679 13.1585273  77.66244733
 60.04054649 45.49291877 58.77945103 55.70548791 21.18686703 50.64760411
  5.90659307 28.13350958]
Accuracy th:0.5 is [83.46998696 97.29291797 91.87388068 97.91912867 98.55874076 97.58774869
 98.42960003 95.28880009 97.84237521 96.91889719 98.56117737 98.92788831
 99.41399349 95.33022259 97.43180517 96.95910138 96.35238362 97.70226971
 98.84626162 98.41741694 98.80605743 99.19347961 99.59430319 99.08870506
 95.23153958 96.77635506 94.26054751 97.06996747 98.02999476 98.30411423
 98.40767047 98.61356465 96.82752403 98.68788148 98.65376884 98.83773346
 97.73272743 98.3418818  98.83895177 93.11899222 97.8825794  93.03249229
 97.0882421  96.34629208 97.01392527 94.3153714  98.20177629 98.68057163
 98.1055299  98.70859273 98.8024025  98.61234634 99.00586007 98.15060733
 98.72321244 97.55972759 90.79567744 96.77026352 96.37187656 97.48053752
 92.57440821 98.31507901 96.81290433 97.26733349 98.65376884 97.5341431
 98.41619863 95.9588699  98.76585324 98.13111439 99.81603538 97.28804474
 98.24319879 95.66525749 96.78000999 97.21494621 99.18129652 98.21395938
 99.84405648 99.14840219]
Accuracy th:0.7 is [77.70982322 97.22956592 90.88583229 97.7985161  98.61965619 97.36236157
 98.36015643 94.98544121 97.92765683 96.68863683 98.53071965 98.85235316
 99.41399349 95.3180395  97.35870664 96.70934808 96.29512311 97.56094589
 98.76219832 98.32604379 98.70493781 99.30190909 99.58090179 99.03022624
 95.22179311 96.67401713 94.09607583 96.94569998 98.01293844 98.2029946
 98.16400872 98.60381818 96.6703622  98.50269855 98.70981104 98.84138838
 97.49881215 98.37112121 98.58676186 92.84852767 97.86186815 92.41602807
 96.98103093 96.28415833 96.97006615 94.01323083 98.11405806 98.62452943
 98.11283976 98.65255053 98.662297   98.57457877 99.00098683 98.39670569
 98.70737442 97.49028399 90.13291748 96.60335522 96.29268649 97.24296731
 91.60707106 98.18106505 96.54609471 97.13210122 98.52219149 97.40256576
 98.31142408 95.95277835 98.70737442 98.03243138 99.81603538 97.03707314
 98.13598762 95.47641963 96.61675662 97.12600967 99.18007822 98.1749735
 99.84405648 99.14718388]
Avg Prec: is [94.0945931  29.34950721 61.46255876 61.29824908 78.37946476 63.89372046
 76.12913336 47.08471186 51.96182106 48.58748356 28.25009534 53.23340366
 19.50068673 24.47177241 29.29500811 48.71471626 23.57167361 41.13280158
 46.06070832 37.78371448 66.00062265 44.84314943 90.85052569 83.22041164
 24.59786363 27.96687936 33.47935192 38.88336635 20.91229036 39.46743604
 74.03673863 40.67495451 53.39946384 67.85143543 72.52057128 78.88106668
 58.92032614 73.69539652 85.31806852 39.85002103 25.74125109 50.53327153
 44.03878656 38.66448745 33.72814028 45.91562409 36.49101768 31.82115285
 40.33244937 39.94111472 63.7312492  36.34370576 17.94830391 71.49937853
 25.24599799 35.36765462 53.30417341 51.711442   29.76383931 52.49669024
 65.59859246 73.98087337 54.97119046 44.2990754  53.14318229 39.00705876
 49.66584404 20.38149183 38.14551048 56.3663678   9.51849539 67.72198282
 47.592611   38.1223472  46.28413559 41.09854039 11.36425315 28.6166265
  2.72268436 18.06653338]
mAP score regular 58.65, mAP score EMA 46.39
starting validation
Accuracy th:0.5 is [88.22781972 97.52846501 93.19580437 98.53501756 99.23262825 97.99436929
 98.90873757 95.70471136 98.07658769 97.304233   98.90624611 99.22266238
 99.42197972 95.57515509 97.54839674 97.51102474 96.59665645 98.22358422
 99.14044398 98.6072701  99.40453945 99.51665546 99.73341306 99.64621172
 95.47300496 97.22699753 94.55365374 97.59573461 98.01430102 98.35314049
 98.89877171 98.82651917 97.05508633 99.11552931 98.88382291 99.28245758
 98.16628049 98.65460797 99.22515385 93.48730598 97.93706555 93.50972918
 97.27682687 96.63153699 97.080001   94.93235668 98.64215063 98.94860104
 98.21610982 98.87634851 98.89378877 98.76672397 98.96853278 98.23105862
 98.79163864 97.86730448 91.27239206 97.36901114 96.47955752 97.86730448
 93.2605825  98.89129731 97.1472706  97.55337967 98.82651917 97.66549568
 98.69945437 95.9488751  98.7941301  98.36808929 99.80068266 97.72030795
 98.44532476 95.72713456 97.28430127 97.56334554 99.25255998 98.54996637
 99.82559733 99.18778185]
Accuracy th:0.7 is [88.65136906 97.43628074 93.0737225  98.52256023 99.16535865 97.71283355
 98.87136557 95.67481376 98.34068316 97.042629   98.91870344 99.21269651
 99.40204799 95.41819269 97.66549568 97.22450607 96.46959165 98.39798689
 99.16785011 98.57986397 99.36467598 99.50668959 99.71098986 99.61880559
 95.46802202 97.1323218  94.4664524  97.45122954 97.99935222 98.4129357
 98.80658744 98.78416424 96.70378952 99.06569998 99.09808905 99.27498318
 98.44532476 98.59481277 99.15788425 93.11607743 97.88474475 93.27303984
 97.18962553 96.51942098 97.0351546  94.51379027 98.6147445  98.89628024
 98.17624636 98.88382291 98.7941301  98.7343349  98.93614371 98.61972743
 98.86887411 97.74522261 90.84136831 97.30174154 96.34750978 97.92460822
 92.96658943 98.8165533  96.77105912 97.68293594 98.7193861  97.71532501
 98.53003463 95.8591823  98.76921544 98.30081969 99.81563146 97.4238234
 98.34068316 95.75204923 97.07003513 97.53095647 99.24757705 98.66955677
 99.82559733 99.17034158]
Avg Prec: is [96.79595793 43.31406245 71.34478584 78.65157098 85.54935618 73.02393656
 87.45890574 55.23332627 69.29972569 62.92624647 55.47070821 66.26844535
 32.00809762 39.09932085 41.02008838 70.56337962 41.67655136 66.87976705
 66.07544615 52.11820047 86.21586361 73.05223717 95.45141738 96.13350941
 28.06940816 50.19440068 34.48934472 56.53260573 34.2999769  50.94504039
 83.49206467 52.13775026 57.43641798 80.13991233 80.86278506 87.12182039
 75.98715167 83.4121716  92.24760258 45.82266104 34.07268837 53.48989779
 47.41378428 42.1835923  35.89911252 53.15408109 53.65787591 40.65778094
 49.88837    51.77773635 76.0595489  46.20970842 35.17777899 82.62699233
 41.98001085 48.58874671 58.4333542  62.29626756 39.17376331 68.7264457
 69.28187758 88.32287215 66.82965661 58.16221732 65.56675523 43.4566414
 64.61008774 31.29905265 42.42569941 68.66224764  8.42848427 77.08981146
 54.04727747 42.78561476 64.18999227 53.43544805 13.75119329 52.47677101
  2.58131077 23.98787923]
Accuracy th:0.5 is [85.27543165 97.28679273 92.43839849 98.16877196 98.97849864 97.76266288
 98.5624237  95.38082069 97.84238981 96.84829459 98.63965917 99.06071704
 99.35471012 95.08433615 97.39890874 96.96290206 96.30266338 97.82494955
 98.95856691 98.40047836 99.02583651 99.05324264 99.67860079 99.41450532
 95.47051349 96.72372125 94.50880733 97.23945487 97.83740688 98.23105862
 98.73682637 98.60228717 96.89064953 98.83897651 98.82153624 99.04825971
 98.09651942 98.18621222 99.01587064 93.13600917 97.89720208 93.2531081
 97.1696938  96.46211725 97.03764606 94.4814012  98.35064903 98.85890824
 97.97692902 98.77668984 98.91372051 98.62720183 98.89877171 98.11894262
 98.74430077 97.69041034 90.70433764 96.97535939 96.26279991 97.45372101
 92.75730623 98.5549493  96.85078606 97.37648554 98.5923213  97.58576874
 98.39798689 95.77447243 98.7567581  98.02177542 99.81563146 97.3864514
 98.26095622 95.64491616 96.81092259 97.29177567 99.25006852 98.29085383
 99.82559733 99.15788425]
Accuracy th:0.7 is [81.52826569 97.24194633 91.52153873 98.12392555 98.98348158 97.55836261
 98.54996637 95.23133269 98.05665595 96.76358472 98.55245783 99.03331091
 99.35221865 95.11672522 97.31669034 96.56426738 96.22293644 97.61068341
 98.91870344 98.35563196 98.96354984 99.31982958 99.67361786 99.40952239
 95.43563296 96.56177592 94.4365548  97.16720233 97.81747515 98.20614396
 98.52754316 98.67703117 96.82088846 98.7119117  98.91870344 99.14293545
 97.91464235 98.25099036 98.8165533  92.93669183 97.85235568 92.82457583
 97.11986446 96.51942098 97.042629   94.23474599 98.27839649 98.8016045
 98.08157062 98.73931784 98.72187757 98.5848469  98.87385704 98.48269676
 98.70194584 97.62812368 90.26334803 96.96788499 96.22791938 97.32416474
 92.15187981 98.4428333  96.67140045 97.17965967 98.4503077  97.49607594
 98.30580263 95.77447243 98.75426664 98.10150235 99.81563146 97.34409647
 98.23105862 95.48297082 96.55679298 97.2818098  99.24757705 98.23853302
 99.82559733 99.15040985]
Avg Prec: is [94.94218576 26.8752683  64.575041   69.56304899 78.55213501 65.76918221
 81.49254906 46.93376693 57.95158904 50.52459189 36.2655893  59.11836801
 17.03500293 26.22067143 31.2134393  55.68571411 28.11155094 46.38761337
 49.10624967 36.27353907 74.67739535 55.1906883  93.38703715 90.41269811
 24.06761961 31.15002618 31.31479524 44.90773339 23.88626934 38.23757675
 78.35128611 37.28605317 53.90706456 68.81844922 74.83567143 82.73208599
 63.35514888 76.18774702 89.63740145 41.67739868 29.30116309 50.2982577
 41.6766041  36.75854936 30.85314891 45.31181067 36.45166103 27.50492469
 39.6987626  41.91140336 70.11364466 34.81781264 23.91170032 76.23117934
 30.06109286 36.14111423 53.01365767 52.22366722 29.13767502 56.10875395
 65.02872276 81.82795319 57.50562529 49.17718364 56.33335408 35.17016662
 53.63102824 21.5153035  36.7877625  59.52365099  9.33258408 70.23721661
 46.48542813 37.54049571 54.11927076 42.90402146 11.4910914  32.54520925
  1.92403068 17.80530126]
mAP score regular 57.65, mAP score EMA 48.49
Train_data_mAP: current_mAP = 58.65, highest_mAP = 58.65
Val_data_mAP: current_mAP = 57.65, highest_mAP = 57.65
lr:  [9.975886243268914e-05, 9.975886243268914e-05]
BCE Train Loss:  tensor([30.2252,  9.2489, 18.4051,  5.9823,  1.2934,  2.8291,  3.5024, 11.1536,
         7.9754,  8.6908,  1.1174,  2.3309,  3.9015, 27.4690, 13.9850, 19.6539,
        23.9076,  3.3874,  3.4385,  1.5073,  4.7282,  1.3675,  0.1460,  6.5422,
        20.4874,  7.0683, 15.6717, 13.1169, 11.5105,  5.3604,  3.2255,  2.6514,
         5.6283,  3.3397,  3.3350,  2.2165,  6.2561,  3.3803,  6.0345, 17.3790,
         4.9742, 17.5922,  4.6148,  6.9484,  7.8828, 13.4117,  9.0166,  4.2601,
         2.5215,  4.7889,  4.6939,  2.3183,  0.7352,  2.1789,  3.3600,  5.1607,
        13.1082,  9.5915,  9.5935, 11.6788, 20.7597,  0.6287,  7.4065,  6.5874,
         7.5184,  7.1794,  7.9067, 12.8333,  4.6350,  4.3714,  0.5070,  8.0027,
         7.4317, 15.3732, 11.4395,  6.6185,  0.6751,  8.1621,  3.6781, 10.4638],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [18/80], Step [000/642], LR 1.0e-04, Loss: 630.1
BCE Train Loss:  tensor([31.8466,  3.1700, 29.2134,  4.9137,  0.9152,  4.2468,  3.1829, 29.1479,
         3.9985,  8.6992,  4.2234,  1.6927,  2.9079, 26.8621, 16.1074, 22.1016,
         8.4270,  4.3064,  1.1514,  3.0963,  7.4733,  0.4473,  5.1278,  0.6574,
        14.0002, 18.4259, 16.4076,  8.0865,  7.5580, 19.7059,  0.9786,  1.3348,
         7.9024,  1.1966,  3.4753,  0.9599,  8.6973,  7.2263,  1.1169, 18.6284,
        18.9562, 30.6284,  7.2791,  8.7366,  5.9239, 19.3830,  1.6844,  7.5308,
         8.0415,  4.6501,  0.5586,  1.8023,  6.1716,  1.9218,  8.1355,  5.5083,
        30.9468,  7.9084, 24.2422,  9.0976, 13.7683,  5.8916, 11.8101,  9.1217,
         8.5176,  4.1878,  6.7489, 11.4893,  2.9219,  2.4592,  0.4501,  7.0409,
         6.7266, 11.4430, 17.4562,  7.1740,  4.4532,  3.9698,  0.1927,  1.4592],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [18/80], Step [100/642], LR 1.0e-04, Loss: 706.0
BCE Train Loss:  tensor([41.6113, 13.0285, 14.0063,  4.7019,  3.2858,  2.1050,  3.0783,  9.4082,
         8.5262,  4.1958,  5.2936,  3.8590,  1.0030, 23.4704, 12.1971,  8.8852,
        11.7229,  1.2673,  7.5869, 10.6767,  0.9724,  2.7728,  0.1548,  0.4789,
        19.8854,  8.2954, 15.5728,  6.8999,  2.0484,  4.5707,  2.0776,  2.0136,
         7.5456,  2.9074,  3.5157,  6.2838,  4.4743,  3.7438,  3.0924, 28.1777,
        10.9066, 17.3207,  7.2043, 13.2413,  5.8085, 16.5938,  5.9020,  3.7174,
         9.6562, 11.5168,  2.8457,  8.8084,  5.6191,  2.4537,  6.0285,  5.6899,
        28.4460,  5.6423, 13.0527,  4.4303, 19.5656,  6.1459, 11.8678,  4.7980,
         4.3810,  3.9511,  8.3084, 16.1586,  3.1313,  2.8413,  0.4896, 11.2217,
         2.9213, 13.1945, 10.3353,  5.3469,  0.8537, 15.3549,  0.1422,  1.8714],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [18/80], Step [200/642], LR 1.0e-04, Loss: 643.2
BCE Train Loss:  tensor([27.9804, 11.2400, 31.2048,  8.5767,  1.6478,  3.5547,  1.0673,  7.9032,
         4.5708,  3.8813,  1.7718,  0.6845,  0.1894, 31.0847, 22.6833,  6.6675,
        11.4518,  3.7337,  4.3218,  3.3788,  1.4281,  0.4473,  3.8658,  0.2868,
        14.8889,  9.0045, 27.4760, 16.4787,  2.9672, 11.5059,  3.4274,  2.3840,
        19.0921,  1.8718, 10.2890,  6.1237,  4.2158,  8.3237,  9.0339, 18.7178,
        11.9827, 22.6306, 11.4646,  9.8444, 13.4706, 26.7588, 12.7334,  1.4386,
         1.6102,  0.5883,  7.6321,  6.9613,  4.5119,  6.9020,  5.8927, 11.2083,
        42.5166, 10.6369, 23.9773, 11.2009, 31.2646,  7.1068,  9.9145, 11.0238,
         8.2133,  6.4362, 10.5090, 14.5228,  1.9178,  7.0197,  2.8925,  6.4913,
         3.3962, 11.7319,  7.2294,  6.1841,  4.2837, 10.1400,  0.4674,  1.0011],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [18/80], Step [300/642], LR 1.0e-04, Loss: 765.1
BCE Train Loss:  tensor([31.6779,  7.0384, 26.7733,  8.2068,  8.8708,  4.0993,  1.0127, 13.5945,
         3.6788,  8.6245, 11.6186,  5.1082,  4.7307, 18.3125, 15.0994,  3.0069,
        14.8398,  6.8236,  3.2498,  8.9123,  3.3509,  2.8004,  0.1764,  0.3630,
        22.1158,  7.4326, 31.9653, 22.0760,  7.8276,  3.4300,  2.8461,  5.3441,
         9.7353,  5.4755,  3.5616,  2.4855,  8.5262,  4.1711,  3.4587, 22.6320,
        15.8889, 28.8549,  7.2633,  6.7511,  7.1826, 16.7357,  7.3710, 14.4128,
         9.9119,  8.2686,  2.3162,  2.1120,  6.3319,  3.1839,  1.8208,  7.8103,
        23.0030, 12.6388, 17.4981,  8.8706, 17.9354,  9.7277,  5.4931,  3.0310,
         1.0838,  4.5921,  1.9200, 12.9154,  2.0440,  3.0023,  2.6478,  7.5025,
         5.1653, 11.7370,  7.6152, 10.4094,  2.1850,  4.3607,  0.2262,  5.2439],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [18/80], Step [400/642], LR 1.0e-04, Loss: 702.1
BCE Train Loss:  tensor([34.2962, 13.3520, 21.3417, 15.6665,  5.2234,  5.7109,  0.9365,  9.3025,
        18.4048,  5.6084,  2.5789,  5.2886,  0.6602, 15.2382, 12.8556,  5.3989,
        17.0042,  5.3861, 10.0809,  4.8041,  1.2686,  6.2374,  0.1994,  0.6081,
        12.5216,  8.1888, 14.4569, 14.2122, 10.1819,  9.1515, 10.6359,  0.9138,
        10.2406,  7.3412,  1.6907,  3.0953, 11.8636,  7.3373,  0.2315, 20.1854,
         4.4505, 12.5993,  6.6021,  8.7561,  6.1663, 10.8601, 11.0325,  9.1309,
         3.0835,  2.3627,  1.0415,  1.6855,  4.7836,  7.0501,  8.5802,  6.2125,
        25.6437, 11.3040,  7.1703,  3.2050, 14.8561,  1.1543,  9.3718,  2.8746,
        10.4984,  8.0057,  7.2480,  6.1820,  3.0112,  7.0597,  1.1530,  7.0418,
         3.2729, 14.5021,  3.4927,  9.6130,  2.4927, 10.8920,  0.0737,  0.8815],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [18/80], Step [500/642], LR 1.0e-04, Loss: 635.1
BCE Train Loss:  tensor([45.3244,  6.3964, 29.6734, 11.3529,  7.0699, 12.6460,  6.4417, 17.1958,
         3.8909, 11.2856,  2.4145,  7.0529,  1.4803, 20.6137,  6.2582,  5.1261,
         6.8787, 11.3693,  6.6942,  4.4913,  0.8519,  6.8540,  0.7685,  3.5528,
        23.2876, 12.8546, 20.3830,  3.1161, 10.9994,  0.8269,  5.8833,  2.2674,
         3.3255,  2.5656,  4.5880,  3.7234,  7.9880,  5.3327,  1.7731, 23.7230,
         2.4121, 20.4358, 17.1009, 20.2985,  5.8171, 21.7994,  3.8195, 11.7951,
         9.1061, 11.6881,  3.0779,  8.4108,  4.2856,  5.1301,  2.5419, 10.1220,
        37.6338, 11.2240, 13.0731,  5.3603, 27.7014,  5.6881, 13.3026, 10.7557,
         4.2195,  4.9092,  4.0528, 17.3804,  7.0943, 12.2878,  0.2187,  3.5537,
        11.8856, 15.2942, 22.7869,  9.1792,  4.2148,  7.4642,  0.1444,  0.8556],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [18/80], Step [600/642], LR 9.9e-05, Loss: 776.4
BCE Val Loss:  tensor([4.7318e+01, 2.7808e+01, 4.5776e+01, 1.9829e+01, 3.4176e-01, 1.1278e+01,
        6.4985e+00, 2.1148e+01, 5.5912e+00, 7.9726e+00, 7.3071e+00, 1.1700e+01,
        6.6948e+00, 1.5425e+01, 8.5709e+00, 2.1661e+01, 2.7217e+02, 3.4657e+00,
        1.1197e+00, 3.2605e+00, 3.5890e-01, 1.9375e-01, 7.8352e-02, 5.0448e-01,
        2.8367e+01, 1.3861e+01, 2.9911e+01, 4.2623e+00, 1.7894e+01, 1.2737e+01,
        1.6329e+00, 1.2715e+00, 8.6803e+00, 4.9926e-01, 1.4683e+00, 9.8011e-01,
        1.2271e+01, 4.2655e+00, 1.5796e+00, 4.4868e+01, 1.2226e+01, 2.5143e+01,
        8.1894e+00, 1.3501e+01, 1.5258e+01, 1.4714e+01, 1.5333e+00, 4.5767e+00,
        3.2312e-01, 3.7856e+00, 1.8159e-01, 3.2990e-01, 6.8583e+00, 2.2125e-01,
        4.1610e-01, 5.3662e-01, 2.4563e+01, 7.0980e+00, 1.1036e+01, 2.2364e+00,
        1.1731e+01, 7.5973e+00, 4.5168e+00, 7.1515e+00, 4.5582e-01, 1.2858e+00,
        6.7828e-01, 9.4425e+00, 8.0004e+00, 9.9886e+00, 6.5637e-01, 1.6214e+01,
        1.0667e+01, 1.0639e+01, 1.5102e+01, 6.5410e+00, 5.5141e-01, 6.2952e+00,
        2.9946e-01, 9.2714e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [18/80], Step [000/314], LR 9.9e-05, Loss: 1012.1
BCE Val Loss:  tensor([5.7096e+01, 1.9509e+01, 4.5880e+01, 1.0348e+01, 5.9985e+00, 3.3580e+01,
        3.8375e+01, 3.2921e+01, 2.1936e+01, 2.5941e+01, 1.1929e+01, 4.1862e+01,
        8.6429e+00, 8.3928e+00, 1.7610e+01, 2.3250e+00, 8.9395e+00, 1.6593e+01,
        2.9935e+00, 1.4274e+01, 2.0856e-01, 7.6280e-02, 6.2066e-02, 3.2797e+00,
        2.7575e+01, 2.1390e+01, 3.2109e+01, 1.2778e+01, 1.5066e+01, 7.9320e-01,
        2.3822e-01, 1.7329e-01, 8.1443e-01, 9.2521e-01, 8.0994e-01, 3.9440e-01,
        1.9524e+00, 1.9456e+00, 1.4420e-01, 1.6790e+00, 3.8197e-01, 3.1076e+00,
        5.4719e-01, 1.5161e+00, 1.4511e+00, 2.9244e+00, 3.3424e-01, 4.3069e-01,
        2.1009e-01, 6.1290e+00, 9.6773e-02, 1.7849e-01, 2.1874e-01, 1.6163e-01,
        2.3997e-01, 9.9500e-01, 8.6002e+00, 4.9192e+00, 5.2581e+00, 2.7044e-01,
        4.0245e+00, 2.5210e-01, 9.7613e-01, 4.9624e-01, 1.1468e-01, 1.4368e-01,
        1.3072e-01, 2.0949e+01, 2.0166e-01, 2.0991e+00, 3.5322e-02, 2.2937e-01,
        4.6924e+00, 3.4642e+00, 5.8097e+00, 4.0312e-01, 4.0976e-01, 2.7917e-01,
        2.5859e-02, 2.0598e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [18/80], Step [100/314], LR 9.9e-05, Loss: 630.5
BCE Val Loss:  tensor([1.9310e+01, 8.8290e-01, 3.9885e+00, 1.3728e+00, 1.2282e-01, 2.3025e-01,
        1.2598e-01, 1.3236e+01, 4.4626e-01, 8.0284e-02, 6.7069e-02, 9.4398e-02,
        3.9829e-02, 1.3437e+01, 3.8464e-01, 1.2228e+00, 1.1683e+00, 2.4372e-01,
        1.9360e-01, 1.1609e-01, 7.3127e-02, 1.9624e-02, 1.2304e-02, 2.9160e-02,
        4.1150e+00, 7.6357e-01, 2.6209e+01, 5.1806e+00, 7.9971e-01, 6.3148e-01,
        2.9212e-01, 6.7278e+00, 7.8995e+00, 6.2907e-02, 3.9315e-01, 4.2873e-01,
        1.0088e+01, 8.3375e+00, 1.8059e-01, 3.7692e+01, 2.3158e+01, 5.5888e+01,
        6.5482e+01, 6.0114e+01, 4.4385e+01, 6.1700e+01, 9.8837e+00, 1.1367e+01,
        3.5608e+01, 1.2322e+01, 2.2603e+01, 3.4363e+01, 5.6571e+01, 1.2190e+01,
        4.3538e+01, 7.1927e+01, 1.1420e+02, 1.3811e+01, 6.9866e+00, 6.1629e-01,
        1.0040e+02, 8.7078e-01, 1.3293e+01, 1.2826e+01, 1.2466e+01, 3.1029e+00,
        9.4690e+00, 1.3195e+01, 8.6195e+00, 1.1154e+01, 6.6691e-01, 9.9448e+00,
        9.5492e+00, 4.1778e+01, 3.4968e+00, 1.4894e+01, 1.0333e+01, 6.8189e-01,
        3.1049e-01, 9.4560e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [18/80], Step [200/314], LR 9.9e-05, Loss: 1201.4
BCE Val Loss:  tensor([3.2178e+01, 4.0722e+00, 1.6124e+01, 1.4789e+00, 9.5932e-01, 9.7418e+00,
        7.6185e+00, 1.4920e+01, 3.7260e+00, 1.6564e+01, 2.8659e+00, 7.2825e+00,
        6.0733e-01, 1.3205e+01, 1.5092e+01, 8.3128e-01, 7.7967e-01, 4.8787e-01,
        1.2326e-01, 9.7800e-02, 1.5428e-01, 2.2481e-02, 3.0543e-02, 1.3487e-01,
        2.1080e+01, 3.4467e+00, 2.2079e+01, 1.2024e+00, 1.6512e+01, 1.4994e-01,
        2.1247e-01, 1.1987e-01, 2.6661e-01, 1.4901e-01, 1.9132e-01, 2.3359e-01,
        9.4621e-01, 2.4400e-01, 7.1165e-02, 2.7493e+00, 4.8477e-01, 1.0526e+00,
        2.2286e-01, 5.3866e-01, 4.7569e-01, 1.2089e+00, 2.7145e-01, 1.8783e-01,
        4.6960e-02, 1.7631e-01, 2.9456e-02, 3.5829e-02, 5.3866e-02, 4.5236e-02,
        8.4437e-02, 5.5903e-01, 6.9438e+00, 1.2803e+00, 1.2800e+01, 4.6326e-01,
        7.2853e+00, 5.1657e-01, 1.9227e+00, 3.7500e-01, 1.1597e-01, 7.3832e-01,
        2.3058e-01, 6.2985e+00, 3.4174e-01, 6.6999e-01, 4.3285e-02, 5.0163e-01,
        5.1074e-01, 6.6952e+00, 6.1266e+01, 2.8474e+00, 1.0907e-01, 5.5682e+00,
        5.2904e-02, 6.0238e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [18/80], Step [300/314], LR 9.9e-05, Loss: 341.9
starting validation
Accuracy th:0.5 is [88.66729207 97.69130493 93.24325971 98.47711407 99.14109234 98.05192432
 98.91570522 95.75419403 98.41498032 97.53048818 98.94859955 99.17033175
 99.48221878 95.74566587 97.74612882 97.83750198 96.7117847  98.33944518
 99.12038109 98.67448009 99.26901475 99.43104982 99.72344392 99.51633143
 95.38991971 97.34043201 94.59801903 97.60115008 98.23710725 98.56361399
 98.81702221 98.84017008 97.36845311 98.97418404 99.05337411 99.1228177
 98.48442392 98.73783214 99.29947247 93.52590734 97.92643852 93.48813976
 97.24784055 96.61919324 97.19179835 95.13041995 98.59529002 98.83895177
 98.39914231 98.91448691 99.10576138 98.87062779 99.07895859 98.41010709
 98.87062779 97.96664271 91.73864841 97.23565746 96.69229176 97.99953704
 93.49788623 98.95225448 97.29779121 97.71567111 98.9546911  97.88136109
 98.7183392  96.08313739 98.85478978 98.40645216 99.80994384 97.7290725
 98.40767047 95.85044042 97.3940376  97.60236839 99.2190641  98.61112803
 99.84405648 99.18007822]
Accuracy th:0.7 is [86.3598153  97.63526273 93.0751331  98.38939584 99.05093749 98.07385388
 98.81945883 95.73470109 98.27121989 97.42327701 98.88159257 99.1496205
 99.46516246 95.57266603 97.62795288 97.50977693 96.56071442 98.20908615
 99.03753609 98.55264921 99.22881057 99.36891607 99.71735237 99.4980568
 95.29854656 97.1710871  94.33730096 97.54876281 98.17253688 98.39548738
 98.62209281 98.70250119 97.00296049 98.85478978 98.92423338 99.10332476
 98.50148025 98.76463493 99.17155005 93.22985831 97.86917801 92.79248547
 97.01027034 96.36943994 97.05656607 94.66868094 98.58798017 98.82798699
 98.27609313 98.84991655 99.03388117 98.75245185 99.10210646 98.12502284
 98.80483912 97.77171331 90.66775502 97.21860114 96.57533412 97.68399508
 92.25399301 98.87550103 97.30753768 97.61089655 98.89255735 97.69617817
 98.67813501 96.02100364 98.83529684 98.34919165 99.81725369 97.33068554
 98.49660701 95.8346024  97.37088973 97.45129811 99.19835285 98.49173378
 99.84405648 99.16789513]
Avg Prec: is [97.01752931 47.96249664 72.74892069 75.67255241 89.3558311  75.1110907
 86.8400646  58.6559222  69.57034109 66.40611065 56.24046823 66.37919678
 37.80395308 39.97517373 45.69878091 70.08061371 41.37637354 66.72801357
 68.10386827 57.79859477 83.77625258 70.47924349 95.31559412 93.78449868
 33.00173049 53.31846057 42.10064923 57.85262885 38.45238399 57.68534508
 84.8893852  59.39297094 64.28625139 80.85003666 83.79033936 86.81483821
 79.82295412 83.72055635 92.859525   48.97217458 37.39080808 58.22602536
 55.93074686 49.6635747  44.49461159 58.63170742 58.40920142 47.91528764
 53.5399366  56.39603419 76.39089195 55.91892275 37.68793125 82.21322523
 45.13344992 55.91148075 63.25286788 65.50690457 44.60753614 72.95155769
 74.72443108 88.36640452 67.94377015 60.57068482 67.37506783 54.37831765
 64.00373907 33.13972838 50.87435658 69.58361513 12.42321583 79.00962864
 61.36771837 47.35355835 60.27004222 59.03359278 24.2223099  54.57133604
  7.39999558 27.95637147]
Accuracy th:0.5 is [84.62250704 97.31484753 92.17845786 98.02755814 98.73052229 97.67424861
 98.52219149 95.46058162 97.98979057 97.05656607 98.6062548  98.98514882
 99.42130335 95.3740817  97.49028399 97.11748151 96.37187656 97.8399386
 98.86209963 98.4393465  98.85357147 99.23490211 99.6381623  99.22759226
 95.26687053 96.8372705  94.33608265 97.17352371 98.04583277 98.34553673
 98.49417039 98.66595193 97.01148865 98.76707155 98.75001523 98.91448691
 97.91181881 98.41741694 99.02657131 93.16285133 97.8959808  93.05685847
 97.16134063 96.41451737 97.07605901 94.5237022  98.2578185  98.70981104
 98.14817071 98.76585324 98.85357147 98.64524068 99.02657131 98.29436776
 98.73661383 97.60480501 91.02959272 96.87138315 96.40842582 97.64257258
 92.86436569 98.53315627 96.91036903 97.32581231 98.70250119 97.55363604
 98.46493098 95.96130651 98.80483912 98.10187498 99.81603538 97.35992495
 98.27487482 95.74688418 96.88722116 97.29779121 99.18129652 98.2444171
 99.84405648 99.15083881]
Accuracy th:0.7 is [80.09405344 97.25636871 91.19771933 97.91303712 98.72077582 97.506122
 98.49904363 95.11336363 98.03243138 96.79828462 98.5514309  98.94494463
 99.41399349 95.32534935 97.39038267 96.81655925 96.31461605 97.67668523
 98.77681802 98.34553673 98.82798699 99.32383865 99.62232429 99.19713454
 95.22301142 96.70691147 94.12531524 97.03950975 98.01781167 98.22005093
 98.33335364 98.62574774 96.73005933 98.60503649 98.79387434 98.93763478
 97.69495986 98.46858591 98.80362081 92.91066142 97.87648786 92.49156321
 96.99565064 96.33289068 96.97737601 94.09607583 98.18471997 98.65620546
 98.19081152 98.6903181  98.72321244 98.59772664 99.00342345 98.51488164
 98.71468428 97.51586847 90.38510739 96.68863683 96.34507377 97.37088973
 91.92992288 98.33335364 96.64965095 97.16986879 98.57336046 97.42449532
 98.3284804  95.95277835 98.74026876 98.10431159 99.81603538 97.17596033
 98.21761431 95.49103934 96.71056639 97.20032651 99.18007822 98.18350166
 99.84405648 99.14718388]
Avg Prec: is [94.84113936 33.12953125 63.94738075 64.11925851 81.53228696 65.94819905
 78.73047857 50.58022987 56.75212108 52.84026411 34.43999009 57.50866069
 21.24237003 26.77531941 31.97300359 52.62543578 26.65951106 47.97029664
 49.70412994 40.57649653 69.63751862 49.21566848 91.82440852 86.2132093
 26.73190252 32.46256553 34.98890373 42.405308   24.83697303 42.36010282
 76.37013373 44.25182192 56.73038897 70.2169289  75.32982864 81.15780898
 65.0400843  75.76536953 88.02830413 42.054071   28.90646147 51.70561625
 46.46429197 41.48126671 37.7838245  49.2658834  40.63328067 34.7779005
 42.86081532 45.60249093 66.78629791 39.1822643  21.98347454 74.25429736
 29.08509443 40.57313121 55.53616994 54.70892096 32.66547789 57.79004908
 67.79240274 78.56406216 57.40392239 47.00636269 56.6041011  40.87440715
 51.91115929 22.10957168 42.432305   58.78703177  8.41417991 70.04000987
 49.48100285 40.1967211  48.47197914 44.83695514 13.39383422 32.1995032
  4.19118137 19.12497523]
mAP score regular 60.82, mAP score EMA 49.42
starting validation
Accuracy th:0.5 is [89.37140294 97.61566634 93.30293744 98.5175773  99.24508558 98.02426689
 98.93365224 95.65986496 98.4727309  97.40638314 98.94860104 99.25006852
 99.45187732 95.6349503  97.72279941 97.75269701 96.66392605 98.40296983
 99.25006852 98.64962503 99.39955652 99.49423225 99.74836186 99.68358373
 95.43314149 97.2593866  94.52873907 97.70286768 98.06413035 98.43785036
 98.93116077 98.83897651 97.19460847 99.13296958 99.07566584 99.28744052
 98.6072701  98.63965917 99.23761118 93.50723771 97.90965942 93.58696465
 97.27184393 96.66392605 96.92303859 94.90744201 98.64713357 98.85143384
 98.24600742 98.87136557 99.10805491 98.83399357 98.91372051 98.36310636
 98.87136557 97.91215088 91.25993472 97.33662207 96.52938685 97.88474475
 93.28798864 98.95358397 97.29177567 97.69788474 98.90873757 97.68542741
 98.74679224 95.96631537 98.7044373  98.29334529 99.79320826 97.85235568
 98.23604156 95.6573735  97.3939258  97.63061514 99.26252585 98.66955677
 99.82559733 99.15040985]
Accuracy th:0.7 is [88.19792212 97.66051274 93.33532651 98.5624237  99.19774771 98.15133169
 98.86139971 95.8068615  98.42290156 97.44126367 98.93614371 99.23511971
 99.42696265 95.47798789 97.66051274 97.50105887 96.59167352 98.31576849
 99.21020505 98.5997957  99.31484665 99.41948825 99.76081919 99.66365199
 95.48546229 97.09245833 94.5785684  97.71283355 98.04918155 98.4054613
 98.8016045  98.75177517 97.0650522  99.03580238 98.99344744 99.29740638
 98.6446421  98.64215063 99.15788425 93.34030944 97.85484715 93.0214017
 97.13481326 96.54433565 97.06256073 94.76542841 98.7044373  98.95607544
 98.21860129 98.91372051 99.06320851 98.7567581  98.97351571 98.12641702
 98.84894237 97.85983008 90.51747764 97.34658794 96.49948925 97.69539328
 92.50317662 98.92866931 97.35406234 97.58078581 98.82901064 97.73027381
 98.66457383 95.90652017 98.79163864 98.33570023 99.81563146 97.53843087
 98.4353589  95.79689563 97.3640282  97.52846501 99.26252585 98.59481277
 99.82559733 99.16037571]
Avg Prec: is [97.08916042 44.17457792 72.67014475 79.34612146 86.03167726 74.72647975
 87.91784225 56.10678589 71.19611095 66.31226145 58.92027095 66.796336
 34.92783304 40.97099636 44.83568071 72.81399211 44.03955412 68.81493306
 71.6013115  54.85415664 87.11095478 75.57071331 95.65512377 95.82654958
 28.9119478  52.48870921 36.9600139  59.87359745 37.01370908 53.37445928
 84.32289979 54.12284681 58.96903446 81.59554937 80.24591101 86.93206711
 79.09092383 83.66319802 92.56030431 46.62014243 34.98474548 54.05404319
 47.6703597  42.45880622 35.49061446 54.21941793 56.78109175 41.74654136
 49.49392633 52.32809855 79.42907466 52.34208334 38.63520182 81.61483468
 42.33015559 49.99480172 58.99203216 62.83987798 41.82046802 71.28784465
 69.12499724 89.65556818 68.28047562 59.12066329 66.66698496 45.02679967
 65.85366441 32.80856389 41.33125673 67.31875645  7.50725557 77.89948505
 53.45190651 43.85469064 64.98867119 55.61809467 16.08022848 54.88475904
  3.07194509 23.44288176]
Accuracy th:0.5 is [86.19727434 97.33662207 92.65266462 98.26843063 99.00839624 97.83740688
 98.64962503 95.50041109 97.97942048 96.94047886 98.6745397  99.11802078
 99.36467598 95.13416548 97.45372101 97.12983033 96.35249271 97.94453995
 99.00839624 98.4577821  99.12798665 99.19774771 99.70849839 99.47679199
 95.48047936 96.81092259 94.55365374 97.3341306  97.87477888 98.25846476
 98.78416424 98.6745397  96.93051299 98.91870344 98.89378877 99.13795251
 98.23604156 98.29334529 99.09061464 93.2306849  97.91713382 93.37518997
 97.18713407 96.44716845 97.01771433 94.59102574 98.41791863 98.87634851
 98.01430102 98.81157037 98.98597304 98.64713357 98.91372051 98.24849889
 98.77419837 97.73774821 90.79403045 97.01023993 96.30515484 97.55836261
 92.90679423 98.68450557 96.96290206 97.43877221 98.65709943 97.63310661
 98.4278845  95.77945537 98.74679224 98.10897675 99.81563146 97.46119541
 98.27839649 95.65986496 96.94297033 97.35406234 99.25505145 98.34566609
 99.82559733 99.16286718]
Accuracy th:0.7 is [83.34454493 97.26187807 91.88030994 98.20863542 99.07068291 97.71532501
 98.6521165  95.34594015 98.14136582 96.88815806 98.58733837 99.09061464
 99.35471012 95.12170815 97.36651967 96.74365299 96.25283404 97.74023968
 98.95109251 98.38054663 99.08812318 99.35720158 99.70102399 99.50170665
 95.43563296 96.60413085 94.44901213 97.24942073 97.82245808 98.22607569
 98.6296933  98.69945437 96.83085432 98.78914717 98.99344744 99.20273065
 98.09153649 98.29085383 98.96105838 93.0064529  97.86232155 92.9242345
 97.14477913 96.53935272 97.04013753 94.32942173 98.33071729 98.83648504
 98.10150235 98.77668984 98.79911304 98.6147445  98.89129731 98.57238957
 98.70942024 97.65802128 90.39788724 97.0725266  96.25532551 97.43628074
 92.42594115 98.57986397 96.73368712 97.2444378  98.49764556 97.52348207
 98.35064903 95.77447243 98.7492837  98.15880609 99.81563146 97.44624661
 98.30580263 95.49791963 96.72621272 97.36153674 99.24757705 98.25846476
 99.82559733 99.15290131]
Avg Prec: is [95.50676504 30.4946685  66.54342232 72.06150672 80.57132877 67.72431298
 83.2651967  49.26886465 61.35906564 53.85075982 40.44418007 61.18990068
 20.43699609 28.50901875 33.69387132 60.03603118 30.60982095 51.55953729
 53.61177367 39.78804639 77.97437901 59.55111324 93.97605413 92.2453908
 25.17594142 35.26083109 32.739301   47.98536571 26.58786116 40.76866385
 79.44439154 41.00986862 55.04127819 71.62754528 76.86439603 84.14992325
 67.35560022 77.86921598 90.66696542 42.85211298 30.61480447 51.40194183
 42.9333718  37.81585988 31.81377948 47.35355461 40.78977141 30.6742268
 42.14312218 44.43781951 72.41569792 37.50848465 26.39699165 78.09722286
 33.07816009 38.99324907 54.31693553 54.72270246 31.23201714 59.53537414
 66.32030498 84.15036279 59.85025532 51.21750436 58.55971193 37.36393964
 56.03391618 23.05359892 38.2433282  62.10427008  9.60549437 72.40409318
 48.91068564 38.46439436 56.75681362 46.12723343 12.62923777 36.96350392
  2.1300655  19.88846185]
mAP score regular 58.99, mAP score EMA 50.83
Train_data_mAP: current_mAP = 60.82, highest_mAP = 60.82
Val_data_mAP: current_mAP = 58.99, highest_mAP = 58.99
lr:  [9.945826656926115e-05, 9.945826656926115e-05]
BCE Train Loss:  tensor([35.9231,  8.7989, 20.3842,  7.9619,  1.9003,  2.8027,  7.1088, 14.1261,
         2.6612, 21.8414, 11.7836,  2.0731, 15.7709, 18.9754, 11.8489, 10.2099,
        22.5041,  5.3490,  3.6519,  2.7392,  0.6427,  4.2225,  1.2285,  0.4740,
        16.8684, 15.1490, 17.6241,  9.7150,  4.6406,  7.4899,  1.3935,  1.6074,
         2.7547,  8.0002,  0.6573,  0.4351,  7.1742,  6.6896,  0.9942, 13.7041,
         9.9702, 18.8720,  4.2225, 10.5223,  8.6568, 20.8166,  1.5117,  4.6538,
         1.6265,  1.5731,  2.7831,  2.4867,  2.6653,  3.3009,  0.8532,  1.7087,
        15.6593,  5.3359, 10.3449,  3.2117, 19.1241,  0.5685,  9.8101,  5.1000,
         6.0516,  8.0803,  7.4632, 18.0125,  2.4633,  3.0448,  0.7571,  8.5972,
         6.7479,  9.2569, 12.2645,  5.2046,  0.9977,  5.6980,  0.1826,  0.7060],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [19/80], Step [000/642], LR 9.9e-05, Loss: 610.8
BCE Train Loss:  tensor([34.6434, 23.4056, 27.3199, 12.6747,  1.8232, 13.7389,  8.9044,  8.8593,
        16.5758,  5.0813,  0.5794,  0.7103,  3.5193, 18.5592,  5.5665,  5.5420,
        12.7161,  9.8746,  6.8271,  1.2824,  0.7008,  0.2004,  0.2203,  0.5297,
        17.4820,  9.3555, 11.9591,  6.6950,  1.8271, 12.0791,  8.8530,  3.7120,
         6.2855,  7.6322,  9.6450,  4.6998,  6.0657,  3.3050,  6.9907, 13.0096,
         7.9384, 15.9512,  9.8654, 13.8649, 13.1737, 19.0104,  7.7397,  2.5250,
         9.2397,  5.1996,  1.5326,  1.0754,  0.8477,  1.0170,  7.6874,  3.4372,
        22.4640,  6.3048, 12.8824,  2.1768, 16.2605,  1.6799, 15.6420,  9.0505,
         1.9355, 11.8614,  5.1367, 14.1749, 10.7145,  5.4638,  4.9553, 16.6989,
         9.2708, 12.2824,  8.2367, 10.5532,  9.9818, 10.6922,  0.0920,  1.0375],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [19/80], Step [100/642], LR 9.9e-05, Loss: 689.1
BCE Train Loss:  tensor([28.5446,  4.3565, 15.8633,  2.0322,  5.7116,  4.0861,  1.5122, 17.8453,
        11.3268,  6.6256,  0.8188,  6.1597,  0.5053, 18.5854,  8.1264,  5.5971,
        23.6644,  5.6977,  4.4533,  5.5686,  1.9891,  0.2175,  2.8725,  3.0787,
        18.2049, 12.8220, 16.4387, 20.4023,  7.4179, 16.6457,  3.4432,  4.4747,
         5.3936, 14.1951,  0.7960,  0.6130,  8.0547,  7.8913, 11.0731, 29.4577,
         6.4071, 28.0434,  9.6792,  7.8404, 13.3114, 19.4749,  2.9938,  3.3458,
         7.1336,  8.8278,  4.1230,  7.5752, 10.7611,  3.2322,  6.0714, 13.6778,
        18.5156, 11.0282, 17.0784,  3.7655, 17.2589,  4.7660, 13.8524,  9.4585,
         4.2047,  9.7050,  3.6996, 13.8394,  8.5582,  5.5617,  0.1134, 10.9817,
         5.3792, 12.7110,  9.9868,  3.2416,  0.7968,  4.6455,  0.4287,  1.8999],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [19/80], Step [200/642], LR 9.9e-05, Loss: 706.5
BCE Train Loss:  tensor([34.8988,  7.6160, 30.2830,  5.2820,  4.1623,  4.1927,  0.9148, 16.6316,
         4.1482, 18.9313,  3.0225,  2.5856,  0.6306, 11.1114,  5.8153,  8.1673,
        29.5863,  3.0177,  3.0154,  5.7451,  6.3049,  0.5322,  0.0533,  0.5275,
        12.4317, 10.8370, 20.6661, 11.1427,  5.8932,  7.3762,  4.0001,  2.7841,
         9.2053,  4.5060,  5.5536,  4.5105,  7.3025,  6.6077,  0.7129, 21.4965,
         3.9950, 22.9758,  8.0729,  6.3788, 11.0271, 10.1064,  0.9066,  7.6187,
         3.7892,  5.9211,  3.7762,  3.5162,  8.3798,  8.3856,  6.9356,  4.5155,
        20.5258,  6.1514, 18.8218, 16.8310, 15.3028,  2.6704,  4.7197,  7.1989,
         4.7097,  2.9581,  4.8391, 10.5915,  5.9774,  2.3133,  0.1159,  5.9091,
         4.0828, 10.9051, 15.2415,  8.7580,  0.6545, 10.0549,  0.1853,  0.7393],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [19/80], Step [300/642], LR 9.9e-05, Loss: 638.8
BCE Train Loss:  tensor([34.8957, 13.3290, 22.8875, 13.2925,  2.4417,  7.9447,  1.7400, 10.5798,
         5.1577,  8.8399,  2.6146,  2.7666,  2.3080, 17.1120, 15.5494, 14.5210,
        11.8886,  5.8051,  2.1239,  1.3091,  0.5315,  7.1408,  0.5306,  4.1734,
        15.1094, 10.6447, 15.9476,  9.9528,  2.3878,  2.5719,  2.3745,  2.0993,
         2.5167,  5.0545,  0.8862,  1.1450,  8.1911,  1.4542,  1.0887, 28.1133,
         7.4894, 27.3877,  7.3152,  8.2563, 11.9269, 13.1013,  7.7102,  5.8109,
        11.8505,  8.5369,  0.8401,  1.0084,  1.7468,  4.2289, 20.4863,  3.4549,
        21.8638,  8.7158,  7.9737,  8.0968, 21.9814, 10.1807, 14.3222,  3.7317,
         7.2281,  2.7171, 14.5898, 15.6701,  3.9679, 11.7656,  0.3714,  8.7152,
         8.4183, 19.0783, 15.7641,  7.8955,  5.9875,  5.3405,  7.1997,  2.8687],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [19/80], Step [400/642], LR 9.9e-05, Loss: 694.6
BCE Train Loss:  tensor([30.1161,  7.7784, 15.7723,  4.2731,  2.3914, 10.0321,  6.7860, 12.4922,
         3.5073,  5.5604,  1.3121,  1.1092,  1.5145, 13.9120,  6.7717,  2.9008,
         2.6316, 10.5737,  0.8332,  3.7834,  3.8212,  1.6940,  0.4742,  4.3999,
        24.1026,  7.5774, 17.5226, 12.5749,  3.8800,  1.6803,  5.8428,  2.5466,
        14.6781,  7.4548,  5.0794,  9.4432,  4.5583,  4.9104,  0.6100, 19.9891,
         2.5250, 16.2095,  5.9238,  5.4177, 10.3337, 15.6243,  8.0531,  5.6041,
         3.4429, 11.0654,  4.5365,  5.5961,  1.0224,  3.5017,  4.2745, 11.0947,
        23.6782,  9.1672, 16.7773,  2.7187, 17.6627,  5.7817,  7.8200,  4.2631,
         3.9440,  4.4597,  3.0624, 11.7203, 14.9479,  2.2762,  0.1000, 13.2597,
         7.2053, 12.0313,  9.1875, 13.3812,  1.1404,  5.6837,  6.0036,  4.5197],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [19/80], Step [500/642], LR 9.9e-05, Loss: 611.9
BCE Train Loss:  tensor([35.0263,  4.8179, 21.1194,  7.3426,  4.9892,  8.2167,  7.0534, 14.3498,
         2.9086,  4.2008,  1.3480,  4.8031,  0.2968, 33.0105,  6.8610,  7.1564,
        15.8630,  6.2430,  2.7579,  4.7654,  1.0772,  0.5497,  0.4960,  2.8021,
        14.2372, 12.2988, 18.3758, 21.2725, 11.0107,  4.2734,  0.7432,  1.2729,
         9.1688,  0.9580,  0.7814,  1.0886,  4.0894,  1.9825,  4.9524, 21.0377,
         9.4599, 13.5898, 16.8536, 19.5894,  9.1729, 26.2055,  3.0666,  1.5926,
        14.3081,  3.2359,  1.4204,  4.1317,  9.9141,  1.3057,  1.7865,  6.1813,
        24.7822, 16.2474,  5.9025, 14.9741, 34.4882,  4.8876,  9.5159,  6.1029,
         0.8637, 19.0136,  5.1027, 22.1315,  1.6520,  1.2192,  0.1716,  8.3544,
         3.9741, 23.8354,  5.4771,  2.9735,  4.0260,  8.2254,  0.1495,  5.3862],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [19/80], Step [600/642], LR 9.9e-05, Loss: 696.9
BCE Val Loss:  tensor([4.6553e+01, 3.0932e+01, 4.9067e+01, 1.8734e+01, 1.6421e-01, 9.6089e+00,
        5.9705e+00, 1.7588e+01, 5.4740e+00, 8.5001e+00, 7.9061e+00, 1.5145e+01,
        6.8949e+00, 1.7003e+01, 8.4440e+00, 3.2335e+01, 2.4811e+02, 3.2810e+00,
        1.0837e+00, 3.1673e+00, 6.1793e-01, 4.0041e-01, 6.7161e-02, 2.1873e-01,
        2.5078e+01, 1.3491e+01, 3.0009e+01, 8.0611e+00, 1.6637e+01, 1.1060e+01,
        9.4884e-01, 1.2611e+00, 7.9260e+00, 1.4204e+00, 4.1011e-01, 4.6373e-01,
        1.1933e+01, 5.3120e+00, 1.6778e+00, 4.1154e+01, 1.1559e+01, 2.4817e+01,
        7.3363e+00, 1.7025e+01, 1.5868e+01, 1.4469e+01, 9.6732e-01, 5.6183e+00,
        2.8136e-01, 3.7292e+00, 1.0016e-01, 2.9724e-01, 6.7025e+00, 3.2155e-01,
        7.5864e-01, 4.3588e-01, 2.6402e+01, 6.0654e+00, 1.2814e+01, 3.2454e+00,
        1.1732e+01, 6.5015e+00, 5.0452e+00, 8.2512e+00, 2.8834e-01, 2.2564e+00,
        3.4489e-01, 9.1954e+00, 7.3539e+00, 1.7121e+01, 4.6885e-01, 1.5101e+01,
        1.0480e+01, 8.7738e+00, 1.6178e+01, 5.4440e+00, 8.5861e-01, 6.6228e+00,
        1.2929e-01, 1.0563e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [19/80], Step [000/314], LR 9.9e-05, Loss: 1006.1
BCE Val Loss:  tensor([5.8473e+01, 1.5781e+01, 4.6954e+01, 9.3406e+00, 3.9919e+00, 3.4909e+01,
        3.0974e+01, 3.5098e+01, 2.3392e+01, 2.6930e+01, 1.3044e+01, 4.2117e+01,
        8.1910e+00, 9.3321e+00, 1.6938e+01, 2.0774e+00, 7.6233e+00, 1.7158e+01,
        1.9389e+00, 1.4763e+01, 4.2690e-01, 1.4788e-01, 1.0800e-01, 5.2393e-01,
        2.5442e+01, 1.9724e+01, 2.8370e+01, 1.4492e+01, 1.3375e+01, 4.5929e-01,
        1.2317e-01, 1.5015e-01, 4.2903e-01, 2.1647e+00, 2.9700e-01, 1.0228e-01,
        3.4984e+00, 1.3357e+00, 9.6790e-02, 2.5516e+00, 5.1473e-01, 3.1628e+00,
        7.4108e-01, 8.8624e-01, 5.5420e-01, 2.0036e+00, 2.2866e-01, 1.1705e-01,
        1.4139e-01, 5.0594e+00, 3.9388e-02, 1.1662e-01, 1.2410e-01, 1.3695e+00,
        3.5369e-01, 9.4365e-01, 1.0791e+01, 5.5064e+00, 4.8345e+00, 4.5960e-01,
        4.3226e+00, 3.7511e-01, 5.7015e-01, 2.6908e-01, 6.2741e-02, 3.8288e-01,
        5.6352e-02, 1.9716e+01, 1.0806e-01, 3.3498e+00, 4.4493e-02, 6.0517e-01,
        5.1317e+00, 4.3401e+00, 6.0563e+00, 1.5654e+00, 8.1458e-01, 5.9837e-01,
        1.5759e-02, 2.9881e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [19/80], Step [100/314], LR 9.9e-05, Loss: 619.5
BCE Val Loss:  tensor([1.7127e+01, 5.2481e-01, 3.3835e+00, 2.1960e-01, 3.3778e-02, 1.1770e-01,
        1.3604e-01, 1.6517e+01, 1.7252e-01, 6.9322e-02, 4.4566e-02, 5.3761e-02,
        3.1483e-02, 1.2707e+01, 4.2311e-01, 1.6834e+00, 1.5352e+00, 1.3187e-01,
        1.3688e-01, 6.2874e-02, 7.0038e-02, 3.3353e-02, 1.1459e-02, 1.7973e-02,
        4.2334e+00, 1.0200e+00, 2.5396e+01, 7.9656e+00, 5.2892e-01, 2.9326e-01,
        6.2446e-01, 7.0201e+00, 7.9323e+00, 1.2039e-01, 1.4269e-01, 1.6737e-01,
        9.9312e+00, 7.7163e+00, 1.4323e-01, 3.9766e+01, 2.0509e+01, 5.5994e+01,
        6.2670e+01, 6.3682e+01, 4.7350e+01, 6.1383e+01, 8.7313e+00, 7.8761e+00,
        3.1858e+01, 1.0137e+01, 2.3132e+01, 3.7819e+01, 6.7128e+01, 2.5562e+01,
        4.6142e+01, 7.6023e+01, 9.5579e+01, 1.2996e+01, 9.5129e+00, 1.0785e+00,
        1.0142e+02, 5.8642e-01, 1.1448e+01, 1.2780e+01, 1.4818e+01, 4.1192e+00,
        1.0572e+01, 1.3812e+01, 7.5683e+00, 4.6075e+00, 3.7744e-01, 1.1218e+01,
        5.9770e+00, 4.5883e+01, 3.0711e+00, 1.7449e+01, 1.0338e+01, 1.3643e+00,
        1.2289e-01, 1.0370e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [19/80], Step [200/314], LR 9.9e-05, Loss: 1212.0
BCE Val Loss:  tensor([3.2541e+01, 2.4655e+00, 1.7099e+01, 2.5444e+00, 6.8492e-01, 9.4269e+00,
        6.9634e+00, 1.5080e+01, 2.9729e+00, 1.5382e+01, 3.3918e+00, 8.3451e+00,
        5.8176e-01, 1.4178e+01, 1.5919e+01, 1.2540e+00, 1.5255e+00, 5.7845e-01,
        1.4668e-01, 1.1506e-01, 7.8148e-01, 4.2117e-02, 4.2290e-02, 2.3190e-01,
        2.1753e+01, 6.1159e+00, 1.9746e+01, 2.3469e+00, 1.5709e+01, 1.3862e-01,
        1.6842e-01, 1.3427e-01, 3.4917e-01, 5.3335e-01, 3.3705e-01, 3.7586e-01,
        9.6710e-01, 3.6592e-01, 1.3297e-01, 2.9979e+00, 3.9549e-01, 9.8010e-01,
        1.8730e-01, 2.6883e-01, 1.8405e-01, 1.2885e+00, 1.8817e-01, 6.3597e-02,
        3.6496e-02, 1.1440e-01, 2.1123e-02, 3.8763e-02, 3.1073e-02, 1.9263e-01,
        1.1704e-01, 2.2909e-01, 7.8196e+00, 7.9088e-01, 1.7911e+01, 1.0206e+00,
        6.6420e+00, 1.0308e+00, 7.3832e-01, 1.8320e-01, 8.2759e-02, 1.0655e+00,
        1.7151e-01, 5.5020e+00, 2.3290e-01, 5.4513e-01, 6.7050e-02, 8.3998e-01,
        2.5080e-01, 5.8550e+00, 6.0440e+01, 6.4837e+00, 3.7921e-01, 6.3810e+00,
        2.2689e-02, 7.2391e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [19/80], Step [300/314], LR 9.9e-05, Loss: 353.3
starting validation
Accuracy th:0.5 is [89.23624225 97.7851147  93.2420414  98.50148025 99.17155005 98.12380453
 98.99124036 95.90160939 98.40523385 97.51708678 98.8998672  99.17033175
 99.48831033 95.8480038  97.77414993 97.92522021 96.83239727 98.42838172
 99.12403601 98.75367016 99.36769776 99.51145819 99.75146502 99.56628209
 95.33753244 97.53657972 94.64675138 97.61576979 98.25538188 98.51000841
 98.72930398 98.86088132 97.37698127 99.06190227 98.99855021 99.06433888
 98.56970553 98.80362081 99.37013438 93.72327335 98.08725527 93.65139314
 97.39525591 96.52782008 97.11138997 95.31072965 98.62331112 98.87062779
 98.37843106 98.93885308 99.10454307 98.87915596 99.11916278 98.81458559
 98.91814184 98.01050182 92.08708471 97.41353054 96.73858749 98.1883749
 93.59291432 98.94250801 97.31728415 97.7290725  98.97296573 97.86917801
 98.77681802 96.16232746 98.85478978 98.53437458 99.81481707 97.87526955
 98.52950135 95.85287704 97.50734031 97.54632619 99.23490211 98.68909979
 99.84405648 99.19713454]
Accuracy th:0.7 is [88.9365383  97.67424861 92.28566903 98.33822687 99.10210646 97.95080469
 98.96321926 95.59094066 98.25660019 97.26733349 98.83529684 99.15693035
 99.46638077 95.68718705 97.62673457 97.87526955 96.62893971 98.28827621
 99.01560654 98.65498715 99.36282453 99.47978217 99.75877487 99.54313422
 95.28514516 97.4634812  94.58949087 97.69983309 98.18959321 98.30167761
 98.37599444 98.73295891 96.84823528 99.0801769  98.78047295 98.88159257
 98.51609995 98.84504331 99.35429637 93.32488639 98.01537506 93.03980215
 97.13088291 96.2792851  96.99199571 94.81365968 98.55874076 98.7743814
 98.22492416 98.93885308 99.02169808 98.80483912 99.07164874 98.843825
 98.84869824 97.85212168 91.29396572 97.28438981 96.76295367 97.98735396
 92.54638711 98.84504331 96.97250277 97.6035867  98.87062779 97.92278359
 98.62452943 96.07217261 98.76950817 98.34066349 99.81603538 97.71810772
 98.31995224 95.57388433 97.40987561 97.69374155 99.22393733 98.61600127
 99.84405648 99.16789513]
Avg Prec: is [97.28278235 49.06225155 74.19130685 77.90124879 90.17196963 77.13345807
 87.91814121 60.56309668 70.26478966 67.77916319 58.69575444 67.12230761
 39.32636774 43.06782389 46.66040984 71.46532466 46.25426334 70.27231804
 68.95589692 60.04413348 86.44594598 70.77186105 95.44960358 94.92565695
 33.12960045 57.27745375 44.61267442 61.42844106 41.31918013 61.42930588
 85.86577889 60.64580176 65.69297702 82.10886148 85.71923219 87.18418301
 81.72287162 85.3088503  93.84017768 50.83689338 41.53084331 59.99170226
 57.45673573 51.81085699 44.42871069 60.66464349 60.20167546 49.39972693
 58.36686259 58.60554457 77.50764173 58.17634644 46.40863011 84.22296634
 47.86022427 60.55499776 64.6778052  69.19114793 48.04955441 74.32465165
 75.60530329 88.21077032 70.39543047 62.10775234 69.83210839 57.63796376
 66.92527238 36.17389807 50.8971596  73.18858737 17.82562954 79.89573833
 64.66117963 48.65287133 62.39791918 60.66888921 25.44554931 56.14458562
  8.28834815 31.5875658 ]
Accuracy th:0.5 is [85.86518195 97.37332635 92.45623226 98.16157211 98.79509265 97.80948088
 98.62452943 95.55439139 98.04217785 97.1296646  98.65376884 99.0387544
 99.42373996 95.43134221 97.50734031 97.28438981 96.4474117  97.96786102
 98.90230382 98.48686054 99.00220514 99.31043725 99.66740171 99.35551467
 95.25346913 96.91158733 94.38359669 97.25758702 98.07385388 98.40888878
 98.65011391 98.70493781 97.03829144 98.84991655 98.79752927 98.95834602
 98.07629049 98.44909297 99.06433888 93.2566611  97.92887514 93.26640757
 97.2685518  96.45106663 97.07849563 94.59923734 98.30533254 98.73295891
 98.20664953 98.78900111 98.94616294 98.68178994 99.04606425 98.35040996
 98.75610677 97.69617817 91.13071235 97.02854497 96.48274266 97.74856544
 93.01543597 98.62331112 97.00783373 97.40134745 98.78412787 97.62795288
 98.55630414 95.98323607 98.80849405 98.24198048 99.81603538 97.50490369
 98.3004593  95.74079263 97.0175802  97.3806362  99.18373314 98.30289592
 99.84405648 99.15693035]
Accuracy th:0.7 is [81.85329126 97.28195319 91.56930349 98.0628891  98.85844471 97.69008662
 98.61600127 95.22544803 98.08969189 96.94082674 98.57457877 99.01195161
 99.41643011 95.32656766 97.41718546 96.95910138 96.34020053 97.79973441
 98.83529684 98.37112121 98.97052911 99.34333159 99.64912708 99.29338093
 95.21691987 96.75442551 94.19110391 97.12113644 98.02512153 98.26391004
 98.49782532 98.63549421 96.82143249 98.70128288 98.86697287 98.99124036
 97.8679597  98.50269855 98.90352213 92.97401347 97.89719911 92.65603489
 97.060221   96.349947   96.98955909 94.20694192 98.23345232 98.67448009
 98.23710725 98.71468428 98.79752927 98.61478296 99.01926146 98.60747311
 98.72077582 97.54388957 90.47282562 96.82508741 96.39380612 97.56581913
 92.14434522 98.48564223 96.7398058  97.26611518 98.65011391 97.48297414
 98.43569157 95.95399666 98.7463603  98.22248754 99.81603538 97.37698127
 98.2724382  95.53246184 96.8238691  97.27098841 99.18007822 98.21517769
 99.84405648 99.14718388]
Avg Prec: is [95.51039257 36.12483502 66.27030068 68.39010808 84.04970138 68.91412599
 81.22652871 52.74064147 58.78522884 55.86576449 39.09493102 59.79681689
 24.73841171 30.35013136 34.03801877 57.29675165 30.06097721 53.0967226
 53.35557472 43.86296536 74.2170634  53.54534414 92.99238868 89.57473327
 27.43210186 36.90254712 37.46306492 46.23973968 26.49960948 46.51527184
 79.02880053 46.73819776 57.99165951 73.29517997 77.3507376  82.60452343
 70.18758393 77.91308528 89.36399477 43.5226163  31.34130029 54.25460966
 49.86105554 42.98687501 38.18931177 51.30862731 44.19289795 37.93433027
 46.71647544 47.50915492 69.11571917 43.23492512 26.76779319 76.76239387
 33.85281996 44.01266537 57.17175184 58.75192765 36.3878544  61.90316824
 69.23280879 80.76690579 60.22689002 49.6445425  59.84860733 44.80555423
 56.04052259 24.53749662 42.372621   62.94363769 12.60507983 72.95515471
 53.20048858 41.54196713 51.95576824 48.73753511 15.80568834 37.6392624
  4.39449469 22.34973044]
mAP score regular 62.87, mAP score EMA 52.34
starting validation
Accuracy th:0.5 is [89.55078855 97.73525675 93.38515584 98.64713357 99.24010265 98.10150235
 98.92368637 95.75703216 98.52006876 97.54341381 99.00341331 99.25255998
 99.44938585 95.69225403 97.77761168 97.86730448 96.84331166 98.4428333
 99.26003438 98.7193861  99.45436879 99.55402746 99.75832773 99.69105813
 95.39078656 97.416349   94.16996786 97.51849914 98.10150235 98.47023943
 98.83897651 98.85143384 97.1397962  99.12798665 99.06071704 99.27000025
 98.58982983 98.7268605  99.27996612 93.46737424 97.98191195 93.51720358
 97.28430127 96.59914792 97.0725266  94.89498468 98.76174104 98.95358397
 98.25099036 98.83399357 99.12300371 98.83648504 98.98597304 98.82402771
 98.87634851 98.02177542 91.36955926 97.47365274 96.30266338 98.01430102
 93.2082617  98.95358397 97.1995914  97.78508608 98.90126317 97.57081994
 98.71440317 96.02860204 98.8090789  98.26344769 99.81314    97.88474475
 98.48269676 95.75703216 97.37648554 97.32416474 99.23013678 98.71440317
 99.82559733 99.14542691]
Accuracy th:0.7 is [89.73515709 97.67297008 92.57542916 98.58235543 99.22017091 98.01928395
 98.97102424 95.74208336 98.36310636 97.39641727 98.93365224 99.24757705
 99.43941999 95.60505269 97.68293594 97.91464235 96.64648579 98.35563196
 99.18030745 98.64713357 99.45436879 99.53160426 99.77825946 99.68607519
 95.52034283 97.3939258  94.64334654 97.64805541 98.07409622 98.31078556
 98.6296933  98.79163864 96.84580312 99.19276478 98.87136557 99.08563171
 98.65709943 98.71689464 99.27747465 93.34030944 97.93208262 93.1185689
 97.2145402  96.50696365 97.042629   94.78037721 98.71689464 98.92866931
 98.17375489 98.92119491 99.02583651 98.7642325  98.96105838 98.83399357
 98.83648504 97.97194608 90.83638538 97.378977   96.54184418 97.86232155
 92.41846675 98.92866931 96.88815806 97.60071754 98.77668984 97.78508608
 98.55744077 95.98375564 98.7866557  98.16628049 99.81563146 97.75269701
 98.33819169 95.56518923 97.40638314 97.61815781 99.25505145 98.6894885
 99.82559733 99.17034158]
Avg Prec: is [97.32482408 46.72377456 72.30440972 79.80994622 86.99469601 74.32257629
 88.49438584 56.85264266 72.21199438 67.64390453 61.17327148 66.98176318
 36.29084926 43.18236642 45.77694824 75.04758184 48.03803821 70.85362719
 72.50223433 58.10820866 88.40735924 76.35247151 96.15849427 96.57063316
 29.48154218 55.71486589 37.14683004 60.28586791 39.3992477  55.40233784
 84.94530229 55.14120517 59.41174888 81.95776921 81.66333385 86.75466123
 79.49951432 84.11440069 93.39224834 47.32185529 36.93418267 54.4298967
 47.11411859 43.41049105 36.02840089 53.97187567 59.08169463 42.59895515
 51.87844209 53.08252296 79.77642659 51.24768288 40.53353299 84.14590102
 43.64991144 53.47753587 59.20804389 64.78703983 42.9166832  70.91851504
 69.25080074 89.64234422 68.67641607 61.40592947 66.66381386 47.09633517
 66.49083271 33.64940765 42.98450367 67.41241393  7.87210423 78.83111282
 55.84236011 44.4222457  65.9535115  56.39476852 16.81135525 55.53262822
  2.98422298 25.85478672]
Accuracy th:0.5 is [86.97461195 97.39143434 92.84201609 98.32075143 99.07815731 97.89720208
 98.7119117  95.59010389 98.11146822 97.0650522  98.7343349  99.15788425
 99.37464185 95.19396068 97.52348207 97.3191818  96.38737325 98.06413035
 99.06071704 98.48518823 99.18030745 99.26501732 99.72593866 99.53907866
 95.47549642 96.89812393 94.56611107 97.46119541 97.92460822 98.29832823
 98.82402771 98.6969629  96.99279966 98.97849864 98.95607544 99.17781598
 98.33320876 98.38303809 99.16037571 93.29297157 97.92211675 93.46737424
 97.1696938  96.47955752 97.04512046 94.65580387 98.4652565  98.87136557
 98.04669009 98.8165533  99.03081944 98.6820141  98.90873757 98.39051249
 98.80658744 97.78259461 90.92607818 97.1323218  96.34252685 97.68044448
 93.04631637 98.76672397 97.0650522  97.51351621 98.72436904 97.63559808
 98.49764556 95.78692977 98.7717069  98.14136582 99.81563146 97.50853327
 98.29583676 95.70720283 97.03266313 97.41884047 99.26003438 98.40296983
 99.82559733 99.16535865]
Accuracy th:0.7 is [84.64010763 97.28430127 92.17181155 98.32075143 99.11303785 97.83989835
 98.7567581  95.40822682 98.20614396 97.01273139 98.65460797 99.12051225
 99.35969305 95.13914842 97.416349   96.94795326 96.31512071 97.87976182
 99.01088771 98.40795276 99.21020505 99.40703092 99.71348133 99.54406159
 95.44809029 96.70129805 94.47641827 97.3490794  97.83740688 98.25348182
 98.72935197 98.72436904 96.87320926 98.86887411 99.03081944 99.25255998
 98.23604156 98.37307223 99.04327678 93.06126517 97.87228742 93.00146997
 97.17965967 96.56675885 97.042629   94.40167427 98.40047836 98.84894237
 98.13887436 98.79911304 98.85890824 98.61972743 98.90624611 98.6446421
 98.73184344 97.71532501 90.48010564 97.1397962  96.29768044 97.57331141
 92.61030969 98.68450557 96.81839699 97.3341306  98.57238957 97.56334554
 98.38802103 95.77945537 98.76174104 98.24351596 99.81563146 97.55088821
 98.34815756 95.50539403 96.84331166 97.41385754 99.25255998 98.29334529
 99.82559733 99.15539278]
Avg Prec: is [95.95952096 33.81218125 68.21240282 74.17683287 82.15308741 69.43813272
 84.66135688 51.24760788 64.20665003 57.02330291 44.5342242  63.00185037
 23.82709207 31.0114081  36.05740334 63.91766712 33.07138416 56.11900655
 57.85172867 43.32694033 80.77356898 63.37255652 94.43366949 93.70746429
 26.26516348 39.16664429 33.99889722 50.90310332 29.20965077 43.33521395
 80.50858146 44.65634904 56.13888855 74.05159097 78.32993108 85.1233766
 70.76707374 79.49014916 91.42814945 43.94330317 31.89395124 52.39614173
 44.08818188 38.98061743 32.75960165 49.32708098 44.5598912  33.25251697
 44.54327729 46.59519305 74.29580723 40.2257848  28.9376471  79.64346975
 35.98435204 41.90473943 55.52169654 57.05220019 33.30175827 62.45451241
 67.33445942 85.98189438 62.02158071 53.11979859 60.81996477 39.44304394
 58.45782904 24.79635839 39.49176779 64.38794745  9.49294192 74.45165667
 50.95991874 39.34995389 59.12698788 49.05578955 13.88814311 41.14695913
  2.33916014 21.83480026]
mAP score regular 60.03, mAP score EMA 52.98
Train_data_mAP: current_mAP = 62.87, highest_mAP = 62.87
Val_data_mAP: current_mAP = 60.03, highest_mAP = 60.03
lr:  [9.903852189145279e-05, 9.903852189145279e-05]
BCE Train Loss:  tensor([23.1353, 12.7528, 18.6721,  6.8751,  1.6089, 11.0480,  8.7282, 16.6286,
         5.2877,  5.9299,  5.8778,  3.6929,  1.4772, 16.5871,  6.9362,  1.8892,
        17.2980,  8.9984,  4.9830,  3.8028,  8.8940,  4.1307,  1.4598,  0.4537,
        29.3356,  8.3589, 27.2893,  6.6798, 10.0444,  1.0472,  1.4034,  8.7295,
        10.0098,  2.1137,  4.4445, 12.6129,  9.6625,  1.4435,  6.9411, 16.9475,
         9.9460, 16.6374,  6.5162,  8.3971,  1.9891, 15.1992,  2.2889,  4.2502,
         2.7514,  1.0378,  5.1336,  2.3019,  0.3778,  0.2909,  5.5980,  1.8694,
        22.2768,  8.2084,  7.4376,  2.8789, 15.0884,  1.4264,  9.8221,  7.5056,
         6.4392,  7.0901,  5.7046, 10.4002,  0.6805,  0.9892,  0.2235,  1.7804,
         0.9052, 12.5210,  8.2341,  5.7507,  2.6397,  2.9217,  0.0983,  0.7755],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [20/80], Step [000/642], LR 9.9e-05, Loss: 580.6
BCE Train Loss:  tensor([29.8330,  9.7138, 17.9787,  4.1258,  1.4926,  2.6001,  2.4621, 11.1792,
         7.1082,  5.5702,  1.3259,  8.8494,  0.6245,  5.4071, 11.7922, 24.2925,
         6.4446,  8.7544,  1.8452,  5.1055,  7.7110,  4.7273,  0.3384,  0.8096,
         9.8330,  7.3400, 12.5741,  8.9533,  1.8540,  6.1568,  2.7112,  6.5817,
         5.4854,  4.3804,  9.1043,  6.8640,  3.8940,  1.7912,  2.2777, 26.7658,
        15.6476, 18.4918, 13.5343, 12.8332, 12.3417, 24.5026, 10.1493,  5.5055,
        14.0642,  8.8741,  7.9466,  4.3308,  1.1003,  6.8085, 11.9813,  9.4840,
        23.0785,  5.8837,  7.0046, 10.3040, 14.0998, 11.7731,  9.9039,  3.5401,
         2.7840,  4.8144,  3.0038,  9.7287,  5.7385,  9.7878,  2.7031, 11.3328,
         8.1519,  7.7040,  9.4119, 13.1830,  1.2245,  9.8982,  0.3385,  9.7579],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [20/80], Step [100/642], LR 9.9e-05, Loss: 669.4
BCE Train Loss:  tensor([36.3140,  6.9989, 20.9444,  7.3246,  2.6669,  5.5464,  6.7720, 10.3637,
         8.1854, 10.2174,  4.1185,  3.3171,  2.8151, 16.2078,  8.9525, 12.6235,
         8.1592,  2.1442,  0.9905,  5.3260,  2.2267,  2.2752,  0.4562,  1.6302,
        19.4290,  9.8061, 31.5448,  6.1399, 13.5017,  1.2166,  0.9048,  9.9017,
         4.9330,  2.2754,  3.4492,  5.1204,  1.6563,  0.9008,  2.8008, 27.4110,
        17.3908, 12.8435,  8.8074, 12.2626,  6.7435, 16.2410,  2.0292,  0.9654,
        12.2410,  1.1852,  4.0309,  4.3507,  7.5221,  1.0482,  5.3093,  4.6121,
        24.7163,  6.7136, 13.7035, 10.1534, 14.4942, 10.3094,  6.5317,  7.3642,
         4.6305,  4.0555,  1.6108, 11.4426,  1.1924,  4.0420,  0.1401,  6.8989,
         9.3994, 22.9449, 15.5404,  8.7413,  6.6805,  6.8777,  0.1669,  1.4922],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [20/80], Step [200/642], LR 9.9e-05, Loss: 645.0
BCE Train Loss:  tensor([26.6616,  3.2553, 14.6207,  3.4241,  5.4776, 13.9092,  1.8886, 11.2547,
         2.9389,  9.2611,  4.8509,  2.8853,  0.6884, 11.2527, 10.9960,  1.7525,
        13.1622,  3.6216,  9.4986, 10.1397,  4.0129,  3.0866,  0.4824,  3.0836,
        13.5675, 17.7961, 35.7294, 10.8203, 15.8064,  4.8026,  2.0045,  5.9501,
         8.0445,  6.6258,  6.8250,  8.8500,  4.3621,  0.8873,  1.5177, 20.0735,
         2.6850, 15.9887,  7.2146,  6.1803,  7.1916, 15.4540,  8.3586,  0.5387,
         6.8668,  3.7202,  0.7375,  8.1403,  5.4485, 15.3237,  0.8283,  5.0601,
        29.4178, 12.8187, 13.3427,  4.2268, 28.3712, 10.4042,  3.5771,  8.1088,
         1.6138, 13.8430,  2.5460, 14.2590, 13.0482,  8.1518,  0.2706,  5.5238,
         1.3545, 11.5532,  5.6756,  6.1556,  6.1867, 15.6925,  0.1526, 11.3503],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [20/80], Step [300/642], LR 9.9e-05, Loss: 673.2
BCE Train Loss:  tensor([46.6670,  3.3248, 22.2096,  6.1915,  0.8801,  1.6017,  1.0093, 21.1070,
         2.9797,  4.7023,  2.6076,  2.7566,  0.5811, 17.0300, 13.0896, 11.2120,
         4.3928, 10.2110,  1.4608,  3.7076,  1.2927,  0.5903,  2.3098,  0.5606,
        19.9282,  2.9021, 15.1432,  4.2078,  6.0717,  4.4752,  2.3103,  6.2713,
         4.6912,  3.3570,  5.3364,  2.0582,  3.6149,  8.6385,  0.6591, 23.3492,
         7.9784, 26.2040,  5.1901, 16.2146, 11.5187, 15.6489,  3.4690,  2.5409,
         6.4090,  2.7349,  4.7329, 12.7926,  9.2189,  1.8699,  4.5863, 14.8162,
        20.6520, 14.7384, 19.6478,  9.2598, 19.1951,  5.3366, 11.4333,  9.5290,
         4.0570, 12.5954,  9.2486, 11.9787,  4.9180,  5.9661,  0.2330,  5.2961,
         4.2979, 18.6195, 13.9694,  4.4222,  1.0959,  1.9684,  0.3332,  4.9235],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [20/80], Step [400/642], LR 9.9e-05, Loss: 655.1
BCE Train Loss:  tensor([26.6882,  7.7732, 16.2077, 11.1535,  0.6698,  8.0368,  6.9590, 14.7344,
         2.5751,  6.0811, 12.3666,  4.2316,  4.9218,  9.9760,  2.0834, 10.5228,
        14.5185,  5.4251,  3.9376,  1.7797,  0.9279,  0.1811,  0.9510,  0.1564,
        25.1267,  6.0101, 27.5114, 11.1660, 13.7879, 11.7042,  8.3856,  3.4999,
         5.7894,  7.1113,  2.4791,  4.6769, 10.7363, 10.2638,  0.3611, 21.3109,
         7.6051, 17.7778,  8.1039, 13.1064,  9.8615,  8.0038,  3.5779, 12.0833,
         5.5468,  3.5855,  0.6152,  5.7982,  4.5544, 10.6754,  1.8659, 13.3319,
        25.7176,  7.5915,  9.9740, 12.1703, 20.6661,  1.6727,  9.8301, 15.8250,
         9.6876,  8.4785, 10.4989, 21.3929,  0.9045,  2.5417,  0.0992,  4.1573,
         4.3276, 21.0119, 11.9576,  1.8822,  1.9658, 12.2307,  0.1542,  1.2341],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [20/80], Step [500/642], LR 9.9e-05, Loss: 684.8
BCE Train Loss:  tensor([42.2642,  4.7394, 18.0945,  1.8198,  0.5806,  5.6750,  1.9328, 11.5363,
         6.6897,  3.8891,  1.6832,  1.0130,  0.9028, 19.1879,  9.4755,  8.5259,
        11.1264,  7.6848,  1.7795,  6.3243,  2.2721,  0.4831,  1.2364,  0.3539,
        12.2994, 11.8127, 25.3289, 12.5154, 17.0252,  1.0904,  3.6860,  2.2037,
         6.8926,  1.6360,  1.5292,  9.9441,  1.4344,  1.9780,  4.5649, 21.6207,
         7.9526, 14.4978,  7.4694,  8.4088, 10.9733, 30.2353,  9.2288, 10.9476,
         7.7202,  3.9632,  0.9718,  3.8089,  1.5468,  3.6270,  3.8868,  1.9862,
        31.2748,  9.9423, 17.7966,  7.4357, 17.4082,  1.2798,  7.5467,  4.9486,
         2.2889, 10.3577,  4.3255,  7.8822,  4.5057,  4.8363,  0.1999,  5.5272,
         9.3304, 26.0162, 17.2201, 10.9989,  1.8241, 15.9295,  0.1716,  2.8430],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [20/80], Step [600/642], LR 9.9e-05, Loss: 653.9
BCE Val Loss:  tensor([4.2577e+01, 2.7355e+01, 4.4000e+01, 1.8173e+01, 2.2428e-01, 1.0001e+01,
        4.8048e+00, 1.7703e+01, 5.1144e+00, 8.4033e+00, 6.7169e+00, 1.1754e+01,
        7.7171e+00, 1.5720e+01, 9.2717e+00, 3.1060e+01, 2.2553e+02, 3.3964e+00,
        1.1707e+00, 3.4285e+00, 6.7229e-01, 4.1978e-01, 6.5183e-02, 4.4685e-01,
        2.4550e+01, 1.2726e+01, 2.6631e+01, 2.2775e+00, 1.5877e+01, 1.1662e+01,
        2.0640e+00, 1.8920e+00, 7.9889e+00, 6.0851e-01, 1.1419e+00, 4.7468e-01,
        1.1587e+01, 4.7951e+00, 1.1397e+00, 4.1287e+01, 1.1315e+01, 2.2843e+01,
        7.5994e+00, 1.2946e+01, 1.4904e+01, 1.4761e+01, 1.1790e+00, 4.7962e+00,
        2.4012e-01, 3.7644e+00, 1.0474e-01, 3.2449e-01, 6.7515e+00, 2.5553e-01,
        2.3455e-01, 4.3459e-01, 2.6748e+01, 8.1637e+00, 1.1406e+01, 7.6624e+00,
        1.2037e+01, 8.2717e+00, 6.4230e+00, 6.0222e+00, 9.7327e-01, 3.3700e+00,
        9.6944e-01, 9.2681e+00, 8.9355e+00, 1.3722e+01, 5.0145e-01, 1.3709e+01,
        9.9721e+00, 1.2803e+01, 1.4987e+01, 6.5289e+00, 5.0059e-01, 6.5577e+00,
        9.6588e-02, 6.1588e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [20/80], Step [000/314], LR 9.9e-05, Loss: 955.1
BCE Val Loss:  tensor([6.0271e+01, 1.9207e+01, 5.3803e+01, 1.0308e+01, 5.9905e+00, 3.4654e+01,
        3.5795e+01, 3.6007e+01, 1.9221e+01, 2.7864e+01, 1.4095e+01, 5.3905e+01,
        9.3975e+00, 9.0457e+00, 1.9335e+01, 3.2576e+00, 8.7714e+00, 1.3865e+01,
        3.6028e+00, 1.4675e+01, 2.6322e-01, 1.0064e-01, 1.1445e-01, 3.8623e-01,
        2.6609e+01, 2.1503e+01, 2.9844e+01, 1.2347e+01, 1.4502e+01, 7.3685e-01,
        4.3469e-01, 7.4015e-01, 6.6039e-01, 1.3898e+00, 5.9425e-01, 9.3319e-02,
        3.4112e+00, 7.6324e-01, 1.1200e-01, 1.8859e+00, 2.5819e-01, 2.9403e+00,
        4.1034e-01, 9.2505e-01, 6.6110e-01, 2.4736e+00, 4.0952e-01, 3.2161e-01,
        1.5365e-01, 5.2244e+00, 6.2151e-02, 1.6708e-01, 1.8771e-01, 2.4482e-01,
        2.0422e-01, 3.9062e-01, 1.0074e+01, 4.9056e+00, 4.5854e+00, 7.4940e-01,
        3.0704e+00, 1.8738e-01, 2.6790e+00, 8.1298e-01, 2.1511e-01, 5.6100e-01,
        1.9458e-01, 2.0809e+01, 2.7377e-01, 2.8879e+00, 3.3737e-02, 3.1680e-01,
        3.6271e+00, 3.1187e+00, 5.0731e+00, 4.3022e-01, 4.8845e-01, 2.7840e-01,
        1.2699e-02, 1.8001e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [20/80], Step [100/314], LR 9.9e-05, Loss: 650.2
BCE Val Loss:  tensor([1.6140e+01, 9.0070e-01, 3.7662e+00, 2.4437e-01, 1.2421e-01, 1.0686e-01,
        1.3794e-01, 1.5406e+01, 3.5703e-01, 6.3018e-02, 2.4831e-02, 4.9813e-02,
        5.6060e-02, 1.2786e+01, 6.2483e-01, 1.7897e+00, 2.0696e+00, 2.0259e-01,
        1.8230e-01, 7.5846e-02, 1.1697e-01, 2.4645e-02, 1.5865e-02, 5.1084e-02,
        4.4600e+00, 2.3315e+00, 2.6345e+01, 4.4522e+00, 6.0144e-01, 6.5468e-01,
        3.3834e-01, 5.2089e+00, 7.0451e+00, 9.1552e-02, 6.7374e-01, 3.6064e-01,
        1.2622e+01, 9.8588e+00, 9.9420e-02, 3.8921e+01, 2.0999e+01, 5.7693e+01,
        5.6870e+01, 6.2134e+01, 4.4203e+01, 5.9480e+01, 8.3713e+00, 9.4492e+00,
        3.2770e+01, 9.1425e+00, 2.3471e+01, 3.6361e+01, 6.0831e+01, 1.3476e+01,
        4.8401e+01, 7.7053e+01, 9.4294e+01, 1.4032e+01, 8.8493e+00, 2.7778e+00,
        9.8228e+01, 2.0289e-01, 1.5481e+01, 1.2584e+01, 1.0495e+01, 8.4557e+00,
        8.9462e+00, 1.4935e+01, 7.1163e+00, 6.1682e+00, 2.4478e-01, 1.1750e+01,
        5.6902e+00, 4.0456e+01, 2.9767e+00, 1.4348e+01, 9.5165e+00, 8.8698e-01,
        1.4509e-01, 9.3197e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [20/80], Step [200/314], LR 9.9e-05, Loss: 1179.6
BCE Val Loss:  tensor([3.1638e+01, 4.0671e+00, 1.6377e+01, 2.8237e+00, 9.8126e-01, 9.0978e+00,
        7.3113e+00, 1.4881e+01, 4.7863e+00, 1.3904e+01, 4.4527e+00, 6.9676e+00,
        7.1410e-01, 1.3469e+01, 1.4967e+01, 1.0306e+00, 1.7379e+00, 1.2465e+00,
        8.6472e-02, 7.8485e-02, 1.7223e-01, 2.8067e-02, 3.5342e-02, 2.5702e-01,
        1.8994e+01, 7.4854e+00, 2.1404e+01, 9.3143e-01, 1.4787e+01, 1.9778e-01,
        4.1964e-01, 5.3232e-01, 3.8991e-01, 2.3165e-01, 5.5728e-01, 2.4317e-01,
        9.0072e-01, 2.3213e-01, 4.9751e-02, 3.4905e+00, 5.7571e-01, 1.4071e+00,
        2.7606e-01, 4.4235e-01, 3.4100e-01, 1.1827e+00, 2.3353e-01, 1.7010e-01,
        5.0646e-02, 7.6428e-02, 2.7655e-02, 4.8809e-02, 4.9839e-02, 9.2130e-02,
        6.2589e-02, 2.4937e-01, 7.7904e+00, 2.1575e+00, 1.4246e+01, 1.5057e+00,
        7.1223e+00, 4.0054e-01, 4.3554e+00, 6.0845e-01, 2.3683e-01, 2.8399e+00,
        6.1959e-01, 5.3215e+00, 2.1253e-01, 5.0441e-01, 2.6849e-02, 3.9184e-01,
        3.0908e-01, 6.7707e+00, 7.2649e+01, 3.0685e+00, 1.1748e-01, 6.1667e+00,
        2.0759e-02, 4.0246e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [20/80], Step [300/314], LR 9.9e-05, Loss: 364.7
starting validation
Accuracy th:0.5 is [89.67848832 97.73029081 93.67819593 98.60016325 99.23490211 98.23223401
 99.03997271 95.96739806 98.52584642 97.61820641 98.94372632 99.16911344
 99.51023988 95.90770093 97.81557242 98.08603696 97.00174218 98.47224084
 99.17033175 98.8011842  99.28728938 99.54678915 99.76730303 99.60526797
 95.42646898 97.61211486 94.76370902 97.81557242 98.33579026 98.69275472
 98.91448691 98.85600809 97.45495303 99.10941631 99.18495145 99.10941631
 98.65864207 98.87793765 99.41643011 93.75251276 98.04095954 93.74520291
 97.54510788 96.69351007 97.19423496 95.26565222 98.68788148 98.83773346
 98.35771981 98.86697287 99.13987403 98.96809249 99.14474726 98.86209963
 98.91570522 98.06045248 92.14434522 97.48906568 96.81290433 98.22736078
 93.81099158 98.91205029 96.55340456 97.82531889 98.8718461  97.74734713
 98.78900111 96.22080628 98.85357147 98.47589576 99.81603538 97.56825575
 98.60503649 95.80779961 97.43546009 97.73638235 99.2202824  98.65255053
 99.84405648 99.20444439]
Accuracy th:0.7 is [89.06080579 97.76805838 93.311485   98.51244502 99.1362191  98.04095954
 99.04484594 95.5129689  98.42716341 97.38672774 98.85966302 99.108198
 99.51023988 95.71764477 97.82044566 98.01050182 96.81534094 98.36746628
 99.10210646 98.70006457 99.34211328 99.50171172 99.75390163 99.62476091
 95.33875075 97.66572045 94.50908249 97.67546692 98.23467063 98.52584642
 98.8011842  98.88768412 97.35017848 99.00464176 99.04728256 98.89012073
 98.65742376 98.70981104 99.33480343 93.24325971 97.93131175 93.01665428
 97.30753768 96.46812295 97.02245343 94.75639917 98.60381818 98.75123354
 98.24319879 98.75123354 99.04484594 98.89133904 99.1215994  98.68422656
 98.83286022 97.88379771 91.63509217 97.54145296 96.70325654 98.25416357
 92.78761224 98.71468428 97.44886149 97.87039632 99.02657131 98.03730461
 98.81945883 96.0843557  98.76098001 98.33091702 99.81603538 97.06143931
 98.41010709 95.97105298 97.29413628 97.51586847 99.19957116 98.53193796
 99.84405648 99.1642402 ]
Avg Prec: is [97.41651378 51.88252877 75.19420976 78.3895226  91.21693409 77.75631392
 88.92273727 62.52900505 72.10052131 69.23666252 61.16540077 68.62066066
 40.60734678 45.40086856 48.39537735 74.75884034 49.11421104 71.28702168
 71.23808833 62.66288069 85.6768381  73.23893384 95.85840185 95.77418818
 35.3285356  60.52486732 46.75565899 63.30765228 46.40023331 65.73126379
 86.78855485 63.00611571 68.67463876 82.7636801  87.16423694 89.21949291
 83.47040801 86.77640791 94.4028762  52.21568741 42.6946209  60.93458399
 59.13201386 52.64913982 46.25665228 61.72408135 63.77249848 52.69147164
 56.94952958 60.07985968 78.48660695 61.1112675  44.56132833 84.83630766
 51.9926605  60.67861727 65.94368383 71.46133874 48.8305592  76.50679219
 76.62170157 89.37971424 71.96954701 66.31364778 70.85950246 59.93373321
 69.21393313 38.06337529 51.519551   72.594175   16.40271008 81.49581598
 67.42996888 49.30434473 63.07159377 62.35056934 27.71700923 58.88016021
 10.02524038 34.65938779]
Accuracy th:0.5 is [86.61566014 97.45738965 92.75349959 98.21761431 98.8986489  97.90329065
 98.76950817 95.67865889 98.12867777 97.21494621 98.7037195  99.10088815
 99.44810614 95.4861661  97.58409376 97.47566428 96.49858067 98.0775088
 98.97296573 98.52584642 99.01316992 99.34820482 99.66131017 99.42252166
 95.29123671 97.00539711 94.46522338 97.3526151  98.12380453 98.4259451
 98.66107869 98.72808567 97.22469268 98.8998672  98.87915596 99.05946565
 98.19812137 98.5782337  99.19591623 93.37483705 97.94471315 93.37483705
 97.27586165 96.46446803 97.12357306 94.84655401 98.36746628 98.74757861
 98.2310157  98.80727574 98.96443757 98.75367016 99.05702903 98.47224084
 98.79387434 97.76684007 91.4170149  97.13453783 96.48396097 97.87161462
 93.26640757 98.67813501 97.09067872 97.51221355 98.8011842  97.69008662
 98.55874076 96.00638394 98.84991655 98.23710725 99.81603538 97.54388957
 98.39670569 95.86506012 97.10895335 97.46226289 99.19591623 98.35162827
 99.84405648 99.16180358]
Accuracy th:0.7 is [83.40419829 97.33677709 91.95794398 98.17741012 98.93032492 97.8131358
 98.7743814  95.33875075 98.17375519 97.03463652 98.61356465 99.05946565
 99.42739489 95.36189861 97.47200936 97.14915754 96.36213009 97.87405124
 98.88159257 98.40645216 99.05824734 99.39571886 99.67836649 99.36526114
 95.24006774 96.83848881 94.23618133 97.20885467 98.05070601 98.3138607
 98.55874076 98.65133222 96.89574932 98.78534618 98.96078264 99.04240933
 98.02877645 98.62818435 99.0387544  93.03980215 97.88867095 92.81197841
 97.09433365 96.39015119 97.01270696 94.33486434 98.28340298 98.72199413
 98.23954387 98.73905045 98.84260669 98.6342759  99.02778962 98.67448009
 98.73905045 97.60236839 90.70430428 96.98955909 96.3913695  97.70957956
 92.44283086 98.60138156 96.84336204 97.31241091 98.6756984  97.53292479
 98.45152959 95.95399666 98.77072648 98.27852975 99.81603538 97.53657972
 98.39914231 95.56048294 96.94204505 97.31606584 99.18495145 98.24929034
 99.84405648 99.14596557]
Avg Prec: is [95.98485788 39.6448886  68.33634542 70.20613205 85.65303901 70.99563755
 83.68601253 55.35558701 61.97669532 58.58807788 44.38403486 62.91511936
 29.15323072 32.46955533 37.47963844 61.84488246 33.299886   56.88230412
 57.44645683 47.55643594 76.34471127 58.07352128 93.87013566 91.4732474
 30.00747231 41.70263127 39.49953059 48.80864191 31.49492351 48.9853666
 80.65839098 51.35781445 61.18779908 75.33769982 80.44815506 84.47727386
 73.44650848 80.12067854 90.89574669 45.13627299 32.65795322 55.69044831
 50.98742915 45.3216264  40.31667293 53.97924779 48.70078662 40.93111562
 47.16885895 50.1312859  70.94141844 48.04040872 28.79063132 78.45839798
 36.2137248  48.37818623 59.30665749 61.71180404 37.215198   65.08288998
 71.1319117  83.31307236 62.29746149 53.54258966 61.72581588 47.44449247
 57.89260436 27.08905114 45.76239356 64.18452958 12.33448325 75.13690819
 58.26463859 43.60299283 53.77840404 52.12143601 18.35202286 42.43345629
  6.59377263 23.17374022]
mAP score regular 64.50, mAP score EMA 54.97
starting validation
Accuracy th:0.5 is [89.73266562 97.63310661 93.41007051 98.6446421  99.30986372 98.16129756
 98.97849864 95.7769639  98.5026285  97.51102474 98.96853278 99.23761118
 99.44440292 95.7171687  97.72778235 98.04669009 96.82836286 98.5175773
 99.26252585 98.7268605  99.39955652 99.58392506 99.77327653 99.69604106
 95.36836336 97.416349   94.571094   97.78757755 98.14634876 98.5250517
 98.94112664 98.76174104 97.1771682  99.18279891 99.10307198 99.26252585
 98.66457383 98.64713357 99.32481252 93.58696465 97.96696315 93.57450731
 97.33911354 96.67140045 97.04512046 95.01955801 98.80658744 98.95856691
 98.30081969 98.89628024 99.13546105 98.84395944 98.98846451 98.70194584
 98.89378877 98.00931809 91.21508832 97.43378927 96.60413085 98.02924982
 93.36273264 98.91870344 96.52191245 97.72778235 98.81157037 97.25440367
 98.6521165  95.96133244 98.80658744 98.35812343 99.81064853 97.62563221
 98.45279916 95.42566709 97.43129781 97.69290181 99.26252585 98.69447144
 99.82559733 99.18778185]
Accuracy th:0.7 is [89.62304108 97.79505195 93.42003638 98.60976157 99.27498318 98.07907915
 98.98099011 95.69225403 98.47771383 97.4238234  98.89628024 99.18279891
 99.46184319 95.6498991  97.81249221 97.98440342 96.80593966 98.42539303
 99.26003438 98.66457383 99.46184319 99.55402746 99.76580213 99.73590453
 95.51535989 97.52846501 94.59600867 97.71034208 98.10897675 98.44034183
 98.84894237 98.86638264 97.2070658  99.14791838 99.07068291 99.11303785
 98.69197997 98.46276503 99.29242345 93.30293744 97.91464235 93.13850064
 97.30174154 96.63153699 97.06006926 94.74798814 98.75924957 98.92617784
 98.21860129 98.81157037 99.05822558 98.84645091 99.00092184 98.57238957
 98.83399357 97.90716795 91.24996886 97.58327728 96.59914792 98.08157062
 92.72990009 98.7642325  97.3565538  97.80501781 98.94361811 97.74771408
 98.81904477 95.9712983  98.77419837 98.22109276 99.81563146 97.18215113
 98.36310636 95.96880684 97.29177567 97.58826021 99.26252585 98.63218477
 99.82559733 99.18778185]
Avg Prec: is [97.33865427 48.50984257 72.99732319 80.71545531 87.55174432 74.95736645
 88.90021402 56.39700149 72.82474688 68.12882902 60.5233997  67.54789384
 37.79110034 43.98579567 46.49281319 76.11481015 49.59804149 71.37743042
 73.49729807 59.7424811  88.96917783 79.19320123 96.02207195 96.80343823
 29.76141525 58.81680123 37.59856595 62.17128558 41.2479587  57.79518106
 84.34040063 56.34948469 61.20763641 82.7834861  82.29991417 88.21142343
 80.65543369 85.16293346 93.76313232 48.63983836 37.88464858 54.06928646
 49.16894282 42.78583987 36.25975469 55.24525221 60.15848123 44.16285538
 51.78392537 54.56434532 80.5407564  54.74217911 40.53476184 84.07813918
 45.3778299  53.06770162 60.24669437 67.49894204 44.08174202 72.43883993
 69.92377781 89.86642621 70.5520906  63.26509645 69.22437945 48.89838769
 69.18510042 34.07869504 43.99275817 68.71852281  8.63317706 78.75190547
 56.52229905 45.911311   66.42060963 57.3675547  18.87250121 57.48145125
  3.0713876  27.61644149]
Accuracy th:0.5 is [87.77188131 97.45621247 93.06873957 98.35064903 99.12051225 97.98440342
 98.7642325  95.62000149 98.19368662 97.15723647 98.79662157 99.17034158
 99.39955652 95.27867055 97.60071754 97.46617834 96.40979645 98.16628049
 99.12798665 98.55744077 99.22266238 99.34225278 99.74337893 99.59638239
 95.45805616 96.99529113 94.5860428  97.50105887 97.99187782 98.32324289
 98.86139971 98.73682637 97.0276802  99.03331091 98.99095598 99.24010265
 98.44034183 98.44532476 99.21020505 93.37518997 97.92959115 93.56703291
 97.2145402  96.47706605 97.05508633 94.70563321 98.52006876 98.87883997
 98.11395969 98.85143384 99.05075118 98.6894885  98.93614371 98.4951541
 98.82901064 97.83989835 91.01577098 97.21204873 96.34750978 97.78508608
 93.0961457  98.83897651 97.20457433 97.57081994 98.7567581  97.68044448
 98.5325261  95.80437003 98.7492837  98.17873782 99.81563146 97.62064928
 98.30580263 95.75952363 97.13481326 97.47863567 99.26003438 98.44781623
 99.82559733 99.17283305]
Accuracy th:0.7 is [85.64666019 97.3266562  92.44088995 98.40296983 99.15290131 97.90965942
 98.83399357 95.52283429 98.26344769 97.09744126 98.71689464 99.16785011
 99.36467598 95.16904602 97.46617834 97.13481326 96.36744151 98.02177542
 99.05075118 98.46027356 99.27249172 99.46184319 99.72843013 99.58641652
 95.44559882 96.79099086 94.5262476  97.4088746  97.87228742 98.33320876
 98.79163864 98.75426664 96.91556419 98.91621197 99.07566584 99.25505145
 98.37307223 98.4278845  99.09559758 93.10611157 97.88225328 93.09116277
 97.20457433 96.57423325 97.042629   94.5561452  98.4577821  98.88880584
 98.17873782 98.81406184 98.90126317 98.6222189  98.91870344 98.7119117
 98.75426664 97.74023968 90.58723871 97.1995914  96.33006951 97.69041034
 92.83454169 98.78416424 96.91805566 97.38146847 98.64215063 97.61068341
 98.46027356 95.7919127  98.7717069  98.30829409 99.81563146 97.65054688
 98.4054613  95.56020629 96.96539353 97.45621247 99.25255998 98.35064903
 99.82559733 99.16535865]
Avg Prec: is [96.33493487 36.88556658 69.64772461 76.02835832 83.49490895 71.01889411
 85.82568712 52.96370399 66.59086297 59.9451664  48.36161181 64.38484434
 26.57818262 33.70323936 38.32073852 67.03645672 35.67165266 60.14973701
 61.60222239 46.67912354 83.02480963 67.04481634 94.79073817 94.72131158
 27.28202734 42.75730655 35.08275778 53.39715141 31.81784314 45.75752154
 81.57220249 47.68402728 57.26943649 76.149636   79.5860491  85.98644496
 73.64619447 80.80509976 91.96495154 44.91745492 33.10959713 53.19907978
 45.3370339  40.18908116 33.81908046 50.97566305 47.90152869 35.91800787
 46.79845005 48.49449485 75.84110747 42.83848967 31.53338596 80.9671446
 38.90639441 44.80917897 56.64942467 59.28375267 35.37952284 65.06790775
 68.21341477 87.39108517 64.05686337 54.8689816  63.03282961 41.49590292
 60.86321863 26.74687671 40.53670094 66.38581913  9.10208878 76.11678483
 52.67058523 40.3675432  60.98260342 51.33328482 14.9183826  45.09005946
  2.43510916 23.42745088]
mAP score regular 61.05, mAP score EMA 54.92
Train_data_mAP: current_mAP = 64.50, highest_mAP = 64.50
Val_data_mAP: current_mAP = 61.05, highest_mAP = 61.05
lr:  [9.850063960095822e-05, 9.850063960095822e-05]
BCE Train Loss:  tensor([23.1592,  6.3750, 18.7487, 15.1285,  3.5960,  7.2955,  3.7589, 12.9984,
         7.4849, 14.5995,  0.7540,  6.2850,  0.8238, 26.2359, 24.6000,  8.0875,
         8.7809,  8.6700,  3.8294,  7.3151,  0.8493,  1.7819,  2.9731,  0.4996,
        17.2670,  5.0209, 20.3823, 18.0102, 11.6818,  2.4396,  3.7058,  3.8203,
         6.8512,  2.1513,  2.6253,  2.4605,  0.9461,  7.4184,  0.5768, 21.9692,
         5.3119, 29.9459,  4.1310,  7.0212,  4.0097, 12.1280,  6.6037,  3.6919,
         2.4224, 13.9688,  6.8958,  2.4194,  1.4200,  8.9072,  0.4957, 11.2018,
        27.4371,  7.0238, 16.4925,  5.9064, 15.9037,  4.4952,  9.1719,  5.6600,
         6.7983, 10.1516,  4.8143, 14.3075,  2.5820,  3.1960,  2.9480,  7.6159,
         1.7933,  9.9490,  8.2207,  8.2273,  0.6626,  2.6797,  0.0846,  0.7605],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [21/80], Step [000/642], LR 9.8e-05, Loss: 639.4
BCE Train Loss:  tensor([31.2000,  9.6416, 29.0277,  8.2252,  5.5400,  6.4550,  3.8139, 28.2993,
         4.7508,  6.3153,  9.5411,  1.4713,  0.5688, 27.6988, 10.1193,  4.4027,
        12.8261,  3.7042,  6.4851,  1.6335, 12.0632,  0.8527,  0.1852,  0.2271,
        18.5077, 13.4859, 13.2501,  5.8760,  8.8580,  4.2593,  1.9294,  2.0877,
         5.0929,  2.3979,  3.1374,  3.4433,  6.1268,  4.1894,  2.2300, 16.8876,
         3.4703, 15.9832,  3.7507, 11.5382,  8.5816, 11.6722, 11.6232,  2.5694,
         3.7213, 10.5614,  1.0757,  3.6417,  1.7934,  1.8448,  9.7758,  5.2300,
        31.2640,  6.2671,  8.8017,  7.4786, 14.7490,  4.7678,  5.1933,  4.3460,
         2.0072,  5.3391,  3.3033, 13.0193,  1.1250,  7.0001,  0.1880, 11.9502,
         3.4855, 13.8682, 10.9891, 24.5213, 13.6248, 20.3253,  2.8326, 11.6465],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [21/80], Step [100/642], LR 9.8e-05, Loss: 671.7
BCE Train Loss:  tensor([31.0013, 13.1750, 20.0323,  6.0093,  1.0107,  2.0277,  7.1222, 14.4347,
         6.1766, 10.0315,  0.9988,  3.1826,  4.9619, 20.6800, 11.0192,  1.8413,
         4.3373,  5.6311,  1.2190,  9.0431,  2.2736,  7.3918,  2.4353,  2.5075,
        24.4575, 14.7244, 14.3803,  6.6951,  2.8480,  5.1607,  1.2118,  1.0591,
         2.6561,  9.1515,  2.3860,  9.7945,  7.4802,  3.1525,  0.8210, 16.2214,
         5.9586, 21.9445, 11.2164, 12.7923, 17.5400, 21.1836,  3.4341,  1.3285,
         5.9298,  0.6119,  5.8470,  3.8665,  2.9489,  2.8709,  2.2216,  6.6170,
        39.9918,  9.6617, 20.5514,  2.9383, 28.6850, 12.2478,  7.8561, 13.2900,
         2.2490, 10.8683,  3.5174, 17.0813, 13.3654,  1.5071,  0.0856,  6.7902,
         6.0000, 13.9415, 17.4095,  9.3931,  8.1738,  5.1338,  0.3079,  4.5716],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [21/80], Step [200/642], LR 9.8e-05, Loss: 692.7
BCE Train Loss:  tensor([29.5799, 11.7140, 16.8980,  5.1184,  0.7890,  4.0037,  7.1780,  8.5960,
         4.7209,  4.6353,  1.2038,  3.8718,  4.5206, 21.5071,  7.7137, 11.9291,
        12.5770,  4.7813,  8.8838, 11.0935,  3.3825,  1.8281,  3.6904,  3.4824,
         8.7818, 16.4794, 12.2654, 10.8131,  3.5404,  2.6622,  6.7092,  1.1252,
         5.3131,  1.5697,  1.8726,  1.6587,  3.4307, 18.8433,  0.8478, 10.0223,
         8.1019, 15.3784,  6.2338, 14.5447,  3.6441,  6.4546,  6.6906,  4.7618,
         2.0950,  1.9840,  5.4374,  4.5772,  3.2452,  1.2055,  0.8165,  4.4551,
        20.5790, 10.2108,  9.7235,  2.4913, 17.7676,  0.7387,  6.9915,  6.1348,
         3.4968,  4.5049,  2.9582, 12.2023,  1.4326,  2.4773,  0.4586,  7.2384,
         2.6229, 10.0450,  5.0450,  5.8193, 15.4394,  2.6296,  0.1433,  5.9708],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [21/80], Step [300/642], LR 9.8e-05, Loss: 546.4
BCE Train Loss:  tensor([36.5717,  3.1321, 14.6107,  9.9993,  2.2684,  5.6200,  3.3225, 10.6690,
        12.6512, 15.2972,  4.7488,  3.0962,  0.5615, 20.0112, 14.7060,  9.2656,
        11.2378,  2.5432, 11.2374,  5.6982,  0.4739,  0.2515,  0.3496,  0.6547,
        37.3035,  8.2441, 15.8339,  8.3402, 16.3449,  2.8432,  4.1421,  3.1882,
         7.8118,  7.7366,  1.1900,  2.0562,  5.2090,  2.7282,  0.6583, 28.7285,
        10.5871, 18.2021,  4.9998, 10.4061, 11.0571, 19.0148,  3.8754,  2.6897,
         2.2121,  4.7405,  1.5164,  4.9516,  1.9604,  4.7860,  4.9426, 10.1277,
        37.2490,  9.1234, 15.6452,  6.8161, 18.7758,  3.7245,  7.7081, 10.3479,
         1.2811,  4.0423,  2.8399, 20.7090,  6.4039,  1.7642,  3.7592,  8.1787,
         5.8198, 16.3089, 10.0274, 14.6963, 14.3973, 11.8896,  0.2607,  2.0473],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [21/80], Step [400/642], LR 9.8e-05, Loss: 701.2
BCE Train Loss:  tensor([35.5918,  8.3413, 17.3968, 12.6343,  4.9099,  2.0241,  1.3561, 15.6681,
        10.1152,  9.4441,  3.0429,  4.3888,  0.6593, 19.4192, 21.1273,  4.9098,
        14.2565,  5.3556,  1.9447,  9.6096,  1.8863,  0.3335,  0.4102,  0.8621,
        16.2882,  4.9501, 33.5997,  6.9314, 11.3911,  1.2463,  2.0986,  3.2493,
        13.8479, 10.0012,  4.8219,  4.2241,  1.5301,  3.7841,  0.3819, 17.9084,
         1.9534, 23.8355,  7.7796,  5.9354,  5.2081, 13.1781,  5.4781,  1.9455,
         5.5471,  5.1699,  2.1514,  1.4220,  4.5688,  3.1635,  0.8809,  6.8689,
        19.6402,  8.2026, 12.2363,  9.0644, 10.5385,  4.5182, 19.8284,  7.6969,
         7.6070,  5.6278,  2.2120, 12.0132,  5.5514,  2.9537,  0.1656,  7.9158,
         5.0735, 18.8356,  3.3523, 12.1174,  5.1340,  1.0292,  0.1184,  5.1665],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [21/80], Step [500/642], LR 9.8e-05, Loss: 623.6
BCE Train Loss:  tensor([31.2243,  5.6464, 15.7761,  1.3564,  0.4152,  6.5112,  1.0917, 20.0056,
         6.4343,  4.0143, 14.2489,  0.9395,  1.2641, 20.8238,  8.9449, 10.9076,
        18.7302,  5.9864,  8.6148,  6.4000,  2.5240,  0.3246,  0.1137,  0.5209,
         9.1405,  8.3615, 12.6867, 15.1365, 10.5369,  8.1652,  4.7320,  4.1660,
         5.6823,  4.2936,  6.4185,  5.4138, 12.9485,  3.9626,  1.8934, 25.1702,
         5.0377, 25.4687,  6.6217, 11.8038,  9.6522, 12.0620,  6.9696,  8.5908,
         2.8348,  2.5576,  8.2038,  1.3763,  1.1077,  5.7972,  8.1008,  8.1186,
        20.0046,  2.9514, 10.4721,  4.2030, 21.5243,  2.3194,  8.8723,  8.6975,
         1.0737, 11.3058,  5.2265, 10.4252,  4.0717,  1.6256,  0.2949,  4.8800,
         4.2779, 15.6307,  5.8568,  5.9610,  5.6603,  1.8338,  0.1907,  2.6729],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [21/80], Step [600/642], LR 9.8e-05, Loss: 615.9
BCE Val Loss:  tensor([4.7332e+01, 3.0161e+01, 4.0373e+01, 2.0234e+01, 1.4174e-01, 1.2135e+01,
        5.7642e+00, 2.0213e+01, 5.3044e+00, 8.7820e+00, 8.4941e+00, 1.1166e+01,
        6.8552e+00, 1.7605e+01, 8.4819e+00, 2.5099e+01, 2.4183e+02, 3.2242e+00,
        8.5759e-01, 6.5099e+00, 3.3604e-01, 3.8643e-01, 4.0293e-02, 4.2460e-01,
        2.4380e+01, 1.2769e+01, 2.7218e+01, 1.9957e+00, 1.3075e+01, 1.5939e+01,
        2.1023e+00, 1.8800e+00, 7.5794e+00, 1.1679e+00, 1.0356e+00, 4.8679e-01,
        1.2276e+01, 4.5934e+00, 1.7500e+00, 3.8898e+01, 1.0661e+01, 2.1194e+01,
        6.8344e+00, 1.3735e+01, 1.4429e+01, 1.3678e+01, 5.9361e-01, 5.1073e+00,
        1.0507e+00, 4.2825e+00, 1.6931e-01, 3.9570e-01, 4.8008e+00, 1.0541e+00,
        2.8672e-01, 1.0578e+00, 2.4205e+01, 5.9971e+00, 1.0762e+01, 2.3972e+00,
        1.0869e+01, 6.9120e+00, 3.4124e+00, 6.0383e+00, 3.8072e-01, 9.6239e-01,
        2.8755e-01, 8.0068e+00, 8.0894e+00, 1.4520e+01, 6.2819e-01, 1.8559e+01,
        1.3074e+01, 1.1175e+01, 1.6860e+01, 6.7662e+00, 1.0054e+00, 7.7166e+00,
        1.7500e-01, 3.8053e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [21/80], Step [000/314], LR 9.8e-05, Loss: 967.4
BCE Val Loss:  tensor([5.5351e+01, 1.6843e+01, 5.1315e+01, 9.4051e+00, 2.6915e+00, 3.3779e+01,
        3.7840e+01, 3.2803e+01, 2.1389e+01, 2.8411e+01, 1.3606e+01, 4.3399e+01,
        1.0047e+01, 1.0151e+01, 1.7308e+01, 3.2504e+00, 7.2291e+00, 1.4438e+01,
        3.0154e+00, 1.2170e+01, 2.0720e-01, 8.6239e-02, 9.1004e-02, 6.9196e-01,
        2.8859e+01, 1.9763e+01, 3.2046e+01, 1.3407e+01, 1.5485e+01, 8.2293e-01,
        1.8171e-01, 2.4768e-01, 3.9582e-01, 1.6769e+00, 6.5350e-01, 1.0430e-01,
        3.8606e+00, 1.5027e+00, 1.8134e-01, 2.3174e+00, 4.3411e-01, 3.3736e+00,
        1.4119e+00, 2.2175e+00, 1.5742e+00, 1.6415e+00, 1.2330e-01, 1.4364e-01,
        2.1527e-01, 4.5415e+00, 9.0396e-02, 2.5033e-01, 1.2116e-01, 3.8310e+00,
        1.3754e-01, 7.6482e-01, 1.0307e+01, 4.6551e+00, 4.9760e+00, 1.4686e-01,
        5.8201e+00, 2.1375e-01, 3.3754e-01, 1.2372e-01, 6.2565e-02, 7.5743e-02,
        3.4529e-02, 1.9230e+01, 2.9786e-02, 3.5655e+00, 1.3310e-02, 9.1679e-02,
        5.2862e+00, 3.4133e+00, 5.2606e+00, 3.5794e-01, 5.9435e-01, 4.5850e-01,
        9.5370e-03, 7.9060e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [21/80], Step [100/314], LR 9.8e-05, Loss: 633.0
BCE Val Loss:  tensor([1.5836e+01, 2.4631e-01, 3.5497e+00, 1.4258e-01, 1.3805e-01, 1.4811e-01,
        7.0753e-02, 1.4734e+01, 4.0734e-01, 9.3449e-02, 5.7306e-02, 4.1306e-02,
        2.0235e-02, 1.3298e+01, 2.5397e-01, 5.3802e-01, 9.4474e-01, 2.2201e-01,
        7.7509e-02, 1.4838e-01, 6.9968e-02, 1.3096e-02, 7.3879e-03, 3.5347e-02,
        3.7083e+00, 1.1477e+00, 2.9359e+01, 4.5222e+00, 2.0224e-01, 5.5242e-01,
        2.1864e-01, 6.3658e+00, 9.4077e+00, 1.1130e-01, 1.1214e+00, 3.0634e-01,
        1.1364e+01, 9.3457e+00, 1.4889e-01, 3.8288e+01, 2.0348e+01, 5.9540e+01,
        5.0194e+01, 5.6867e+01, 4.5561e+01, 5.8608e+01, 9.4515e+00, 7.9784e+00,
        3.3384e+01, 1.1922e+01, 2.1918e+01, 3.3248e+01, 6.0844e+01, 4.6876e+01,
        4.7886e+01, 6.0801e+01, 1.0033e+02, 1.3216e+01, 6.4732e+00, 4.4675e-01,
        8.8143e+01, 1.9710e-01, 1.2747e+01, 1.0951e+01, 1.1756e+01, 3.1089e+00,
        7.9795e+00, 1.2364e+01, 6.3571e+00, 4.4884e+00, 1.3805e-01, 1.1482e+01,
        6.0191e+00, 4.1205e+01, 1.2879e+00, 1.4602e+01, 8.6695e+00, 8.2265e-01,
        8.2366e-02, 3.0441e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [21/80], Step [200/314], LR 9.8e-05, Loss: 1155.9
BCE Val Loss:  tensor([2.7612e+01, 1.3501e+00, 1.3884e+01, 1.6778e+00, 5.0765e-01, 9.3182e+00,
        7.1979e+00, 1.4379e+01, 4.5281e+00, 1.4491e+01, 3.7851e+00, 7.0393e+00,
        4.0655e-01, 1.4637e+01, 1.6224e+01, 4.0331e-01, 1.1792e+00, 9.5003e-01,
        5.4535e-02, 1.5068e-01, 1.4435e-01, 2.7368e-02, 2.2159e-02, 2.3743e-01,
        2.2381e+01, 5.7054e+00, 2.1133e+01, 1.1424e+00, 1.5874e+01, 2.0957e-01,
        3.0279e-01, 5.2540e-01, 2.7251e-01, 2.4421e-01, 4.5152e-01, 4.4654e-01,
        5.4789e-01, 2.7244e-01, 6.6366e-02, 3.0451e+00, 4.3022e-01, 1.1660e+00,
        3.5052e-01, 5.6862e-01, 4.2930e-01, 7.2168e-01, 1.0159e-01, 5.5582e-02,
        4.6549e-02, 1.1932e-01, 3.2412e-02, 3.8493e-02, 3.2711e-02, 3.9781e-01,
        3.9992e-02, 5.8700e-01, 6.0257e+00, 1.2807e+00, 1.2229e+01, 3.2443e-01,
        5.6789e+00, 3.8980e-01, 7.9449e-01, 1.4964e-01, 1.0322e-01, 1.1390e+00,
        1.2936e-01, 6.7419e+00, 4.7343e-02, 1.8165e-01, 1.7309e-02, 2.1371e-01,
        1.4856e-01, 6.0853e+00, 6.8968e+01, 3.5193e+00, 2.0822e-01, 5.5648e+00,
        1.6479e-02, 1.6759e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [21/80], Step [300/314], LR 9.8e-05, Loss: 337.9
starting validation
Accuracy th:0.5 is [90.15362873 97.8119175  93.92063937 98.62209281 99.2751063  98.18593828
 99.03753609 96.16476407 98.58554355 97.77171331 99.06190227 99.23855704
 99.53216944 96.04536982 97.88988926 98.14938902 96.99808726 98.63062097
 99.16180358 98.81093067 99.38231747 99.55775393 99.74293686 99.60770458
 95.31316626 97.76927669 94.8441174  97.82288227 98.25660019 98.74392369
 98.95225448 99.0107333  97.26246025 99.16302189 99.23124718 99.19347961
 98.83164191 98.91083198 99.43470474 93.89018165 98.08116373 93.86094224
 97.6730303  96.79706631 97.18448849 95.34849722 98.6903181  98.8572264
 98.40645216 98.98393051 99.13012756 98.99002205 99.16789513 98.42229018
 98.95103617 98.22492416 92.51227446 97.64866412 96.90062256 98.23345232
 94.22156163 99.09357829 97.67668523 97.86186815 99.01316992 98.01293844
 98.87550103 96.26710201 98.88037426 98.61843788 99.81603538 97.95811455
 98.58554355 96.08557401 97.60115008 97.75343868 99.25561336 98.75245185
 99.84405648 99.22393733]
Accuracy th:0.7 is [89.30324923 97.67790353 93.69037902 98.53193796 99.16302189 98.30289592
 98.85357147 95.74079263 98.55264921 97.69739647 99.02169808 99.22150071
 99.49074695 95.87480659 97.75343868 98.05557924 96.795848   98.51609995
 99.03266286 98.79387434 99.30069078 99.49440187 99.72953546 99.58333841
 95.24737759 97.67546692 94.44573044 97.71567111 98.15669887 98.61478296
 98.85600809 98.82067714 96.73371426 99.13500079 99.16545851 99.04240933
 98.75367016 98.91692353 99.36404284 93.42844264 97.96298778 93.48692146
 97.51586847 96.66548897 97.18448849 94.80025828 98.56726892 98.76463493
 98.26147342 98.9546911  99.15449373 98.93154323 99.11550785 98.79021942
 98.88402919 98.10796652 91.62412739 97.49272061 96.77148183 97.97395256
 93.41747786 98.97783896 97.41596715 97.68277677 99.03997271 97.94958638
 98.84017008 96.10628525 98.76098001 98.46493098 99.81603538 97.66450214
 98.41010709 95.98567269 97.46835443 97.72785419 99.24343027 98.76341663
 99.84405648 99.18129652]
Avg Prec: is [97.61203288 55.44558833 77.06741811 79.92450949 92.57016962 78.80801442
 90.29779408 64.65331072 74.65842691 72.52751337 64.3351826  71.08488973
 46.61090084 47.86285355 51.22472693 76.85295346 51.9150355  74.60672386
 73.85021123 65.0073343  88.5715025  75.0080236  96.07608098 95.55197925
 37.22253144 63.67980719 47.97886845 63.98261836 48.65661028 66.36282056
 87.60995786 66.89729277 69.67416704 84.45123552 88.85148529 89.0341752
 85.91468078 87.24433374 94.91234075 53.71816041 45.57509715 61.84918924
 64.31180147 55.59151718 47.65865706 63.56135529 65.30494318 53.5882476
 59.13155602 62.00319187 79.31520892 62.24482317 48.83840454 85.77531509
 55.67961305 65.26206665 67.94338246 72.70443912 51.31465886 78.0078179
 78.51377143 90.35173575 73.19377138 66.27847443 72.99169697 60.76198825
 71.29811769 40.7946987  54.48961036 76.45533984 16.21653461 82.85373139
 67.48452507 52.33604935 65.58661539 63.90959157 29.88605938 61.76649789
 10.1867844  39.94320686]
Accuracy th:0.5 is [87.36370171 97.50734031 93.03614722 98.31142408 98.97905727 97.96420609
 98.83895177 95.76028557 98.26025511 97.33434047 98.79509265 99.11916278
 99.45297937 95.60799698 97.62795288 97.59384023 96.61919324 98.25660019
 99.01438823 98.61234634 99.15571204 99.41033857 99.68323973 99.42008504
 95.32413104 97.14062938 94.5383219  97.42571362 98.17375519 98.47467745
 98.70128288 98.83407853 97.26002364 98.99245867 98.9693108  99.11916278
 98.33091702 98.66107869 99.24830351 93.47352006 97.96907932 93.48326653
 97.42815024 96.43888354 97.16499555 94.95742011 98.44665635 98.78534618
 98.27731144 98.83773346 98.98758543 98.75610677 99.09114168 98.59407171
 98.83164191 97.88623433 91.54981055 97.241749   96.59848199 98.00075535
 93.47473837 98.82798699 97.19788989 97.53901634 98.90961367 97.77536823
 98.65011391 96.04171489 98.86088132 98.34919165 99.81603538 97.68155846
 98.44909297 95.83582071 97.22834761 97.52439663 99.19469792 98.41498032
 99.84405648 99.18007822]
Accuracy th:0.7 is [84.37762698 97.36236157 92.25155639 98.28827621 99.02291639 97.88867095
 98.86575456 95.45083515 98.23954387 97.15037585 98.69275472 99.08505013
 99.43104982 95.39966618 97.55729097 97.30997429 96.43522862 98.02877645
 98.94007139 98.47833238 99.1496205  99.45419768 99.66983833 99.4286132
 95.24494097 96.89453101 94.29100523 97.27829827 98.08603696 98.34553673
 98.69275472 98.67326178 96.94448167 98.86088132 99.03509947 99.09601491
 98.216396   98.69762795 99.12890925 93.15066824 97.91425543 92.93259098
 97.16134063 96.44010185 97.02245343 94.45060367 98.35406489 98.74392369
 98.31507901 98.79143773 98.89377566 98.66107869 99.04484594 98.76219832
 98.75610677 97.69983309 90.82613516 97.09677026 96.44253847 97.83872029
 92.76202775 98.73539552 96.99930556 97.3940376  98.79021942 97.61211486
 98.5234098  95.96617975 98.75732508 98.37721275 99.81603538 97.68034015
 98.44665635 95.60312374 97.07727732 97.39891083 99.18616976 98.31020577
 99.84405648 99.15205711]
Avg Prec: is [96.34125585 43.3077271  70.49424415 72.55388313 88.0720605  72.59175626
 85.39351846 57.01769266 65.45562984 62.16930906 49.27653051 64.74477128
 32.61055872 36.54749415 40.33547319 65.18238004 36.69696864 62.19089363
 60.25389255 51.76525496 80.40924009 63.97506059 94.24004171 92.21199008
 31.72807225 46.59945183 41.11447478 51.99953756 34.88014044 51.62058717
 82.54624893 55.06644967 62.50399419 77.81583387 82.65362564 86.02047167
 76.52462601 81.9168197  91.83498923 47.11175823 35.23070431 56.81393693
 54.7880027  46.61956959 41.85849817 55.98107388 51.02493208 43.57267119
 50.4236551  51.99066244 72.32717766 49.61559183 34.08723649 80.72897578
 40.31026457 53.18902066 61.01278669 64.91501679 40.60613691 68.55437061
 73.02278887 85.50438923 64.51391374 55.34860645 65.7561528  50.63422412
 61.81276253 29.80037011 46.59586114 68.35403151 12.51974978 77.20289029
 59.97299896 44.87885754 57.05567594 54.2512958  21.21936721 46.30611002
  7.06285253 28.44472018]
mAP score regular 66.49, mAP score EMA 57.62
starting validation
Accuracy th:0.5 is [89.85973042 97.81249221 93.49478038 98.65709943 99.32232105 98.06413035
 98.96604131 95.83925057 98.54498343 97.52597354 99.03580238 99.26003438
 99.46433465 95.72713456 97.82494955 98.11395969 96.87570073 98.57986397
 99.21518798 98.6820141  99.48426639 99.58890799 99.76580213 99.75583626
 95.48795376 97.57580288 94.61843187 97.79256048 98.08655355 98.55744077
 99.00092184 98.87883997 97.15723647 99.22515385 99.17532451 99.27000025
 98.77419837 98.7492837  99.30986372 93.64675985 97.99436929 93.55457558
 97.27184393 96.55430152 96.79099086 95.12419962 98.77668984 98.94610957
 98.31327703 98.94112664 99.16286718 98.84146797 99.02085358 98.47023943
 98.92617784 98.04419862 91.5912998  97.49358447 96.63651992 98.03423275
 93.50225478 99.08064878 97.53843087 97.79256048 98.91621197 97.69290181
 98.85143384 96.02112764 98.8165533  98.40795276 99.81064853 97.94453995
 98.50013703 95.69972843 97.53344794 97.56832847 99.21767945 98.76921544
 99.82559733 99.14542691]
Accuracy th:0.7 is [90.0864539  97.70037621 93.66170865 98.6296933  99.26003438 98.21860129
 98.85392531 95.7694895  98.58733837 97.59324314 99.04078531 99.26750878
 99.45686025 95.71966016 97.76017141 98.03174129 96.80344819 98.4577821
 99.18030745 98.7567581  99.42447119 99.52911279 99.76580213 99.73092159
 95.45058176 97.58078581 94.6159404  97.75518848 97.99935222 98.54249197
 98.92866931 98.83150211 96.77105912 99.24259412 99.12300371 99.16037571
 98.7268605  98.71689464 99.28993198 93.46239131 97.92460822 93.58696465
 97.3939258  96.70877245 97.07501806 94.84017241 98.7044373  98.91621197
 98.17624636 98.94112664 99.17532451 98.85890824 98.97849864 98.74679224
 98.89628024 98.07658769 91.30976406 97.55088821 96.63651992 97.81498368
 93.14597504 98.98846451 97.29925007 97.64805541 98.98348158 97.78508608
 98.83399357 96.03358497 98.76921544 98.35812343 99.81563146 97.72529088
 98.38552956 95.95385804 97.44624661 97.67795301 99.25505145 98.75426664
 99.82559733 99.17781598]
Avg Prec: is [97.42360349 49.2594753  74.49851918 81.1201709  88.33674582 76.1604759
 89.47214758 57.97510123 74.04946504 69.22535285 62.57869148 68.72597537
 38.04265005 45.28738136 47.89374293 77.97854326 51.06489809 72.13405742
 73.85298604 60.77118683 89.41982082 80.04591451 96.0288162  96.9910881
 29.22737427 60.40959969 37.84291911 62.39482917 43.61910415 59.5519057
 85.84141104 57.21991282 63.41869046 83.95005099 82.22910339 87.63328088
 81.88932041 85.10242103 93.89279484 48.95373013 38.53789416 55.66810012
 51.18694689 44.92701222 38.67672308 57.22477368 60.55236033 43.37014919
 52.51926161 56.00155011 81.60861913 54.35660672 42.82072712 84.74993417
 48.75706723 54.8080628  61.40359662 67.13872731 45.95579171 73.65981008
 70.86335179 90.96973284 71.24949917 63.55649188 70.87973901 48.09812997
 70.81600427 35.63860602 45.62012835 72.11950621  8.58350192 79.72238432
 56.68872047 46.6770381  67.74010526 58.00581584 18.96719617 58.5433003
  3.14304674 26.28778249]
Accuracy th:0.5 is [88.33744425 97.52846501 93.16839824 98.4353589  99.15040985 98.05914742
 98.82901064 95.74208336 98.28337943 97.28679273 98.84894237 99.19774771
 99.41450532 95.35341456 97.65552981 97.62314074 96.49450632 98.26593916
 99.16286718 98.57986397 99.30986372 99.36965892 99.75583626 99.63873732
 95.45058176 97.05259486 94.5785684  97.58576874 98.03921569 98.36310636
 98.87136557 98.7717069  97.1024242  99.09061464 99.02085358 99.27747465
 98.50013703 98.5175773  99.24757705 93.41256198 97.93457408 93.61686225
 97.24692927 96.46710018 97.02269726 94.81276628 98.58235543 98.89129731
 98.13887436 98.88880584 99.07566584 98.7044373  98.94112664 98.57488103
 98.84894237 97.87727035 91.15529312 97.28679273 96.42723671 97.86730448
 93.22071904 98.85890824 97.26187807 97.64307248 98.80658744 97.68044448
 98.61972743 95.8517079  98.76672397 98.21361836 99.81563146 97.68044448
 98.30081969 95.77198097 97.22699753 97.56832847 99.25754292 98.5026285
 99.82559733 99.16535865]
Accuracy th:0.7 is [86.54607968 97.3939258  92.74235743 98.47522236 99.19027331 97.98938635
 98.86887411 95.61252709 98.33320876 97.24194633 98.78914717 99.19027331
 99.38959065 95.23631562 97.50853327 97.33163914 96.41727085 98.15133169
 99.12051225 98.53501756 99.32232105 99.48924932 99.74337893 99.63126292
 95.45556469 96.87570073 94.53870494 97.51351621 97.91962528 98.36061489
 98.82402771 98.78167277 96.96539353 98.97351571 99.09559758 99.27249172
 98.45279916 98.4876797  99.15788425 93.19829584 97.90218502 93.18832997
 97.24942073 96.59914792 97.04761193 94.6009916  98.52256023 98.91372051
 98.19866956 98.84146797 98.95109251 98.66955677 98.93116077 98.75426664
 98.79662157 97.79754341 90.71679498 97.29177567 96.38488178 97.77262875
 92.91426863 98.84645091 97.02518873 97.45621247 98.6894885  97.64805541
 98.50511996 95.80935297 98.7866557  98.35563196 99.81563146 97.72778235
 98.42539303 95.60505269 97.09245833 97.51600767 99.25505145 98.4054613
 99.82559733 99.17034158]
Avg Prec: is [96.63687265 39.60079052 70.85821578 77.55036045 84.73268357 72.31816149
 86.76007709 54.53825156 68.53941872 62.54745483 51.53769444 65.57088304
 29.01119367 36.32552165 40.36158706 69.58856093 38.43279403 63.43514936
 64.59064485 49.67783012 84.83864625 69.92536391 95.08188186 95.39799754
 28.08158246 46.30656339 36.03957239 55.65590323 34.34660781 48.21410973
 82.46030577 50.18305238 58.35872655 77.99465991 80.48331255 86.63874196
 76.03430603 81.96675047 92.49163908 45.914873   34.21874636 53.95594257
 46.60793657 41.3042221  34.69847496 52.34928809 51.01256778 38.16238116
 48.65730504 50.17412096 77.22995808 45.36534309 34.17019358 82.01063358
 41.36630367 47.38152753 57.68372177 61.37939173 37.38102942 67.28619918
 68.98124092 88.4287268  65.93600634 56.57672334 65.01910386 43.28362958
 63.19528892 28.58479966 41.45478137 68.13868389  8.85410872 77.46692391
 54.03963821 41.53933287 62.46543479 53.25639441 15.85606903 48.53311883
  2.60274953 24.80719835]
mAP score regular 62.00, mAP score EMA 56.63
Train_data_mAP: current_mAP = 66.49, highest_mAP = 66.49
Val_data_mAP: current_mAP = 62.00, highest_mAP = 62.00
lr:  [9.784591550332817e-05, 9.784591550332817e-05]
BCE Train Loss:  tensor([27.1206,  6.7093, 24.4151,  5.8584,  1.9165,  6.0874,  9.7965, 12.8631,
        10.5721,  9.2158,  1.3065,  0.9042,  1.4741, 12.4202,  7.4728, 18.7353,
        18.0816,  2.2041,  3.6476,  9.0547,  2.8613,  2.7690,  0.1469,  0.8360,
        18.5938, 16.6689, 17.2105,  8.6035,  8.0589,  8.1415,  3.3642,  3.4412,
        12.5354,  1.3175,  6.5364,  6.8430,  5.1971,  3.0811,  0.8769, 31.7598,
        11.0991, 28.0422,  9.0750,  6.3579,  8.4431, 16.3108,  4.8448,  3.5442,
        17.6825,  5.2720,  7.1723,  6.6382,  5.4160,  7.4349,  3.1277,  2.6579,
        25.2431,  6.8182, 21.7260, 20.8484, 19.9370,  1.8518, 13.2411,  4.4984,
         0.7082,  6.8295,  3.8241, 12.3328,  3.3134,  5.5197,  0.1511,  2.9563,
         8.5185, 12.7813, 14.9394, 13.1747,  1.3666,  5.0721,  2.2172,  1.3082],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [22/80], Step [000/642], LR 9.8e-05, Loss: 701.0
BCE Train Loss:  tensor([47.5609,  5.6749, 18.0226, 12.1182,  2.9398,  4.2513, 11.3005,  8.8227,
         7.0734,  8.5295,  3.5525, 12.7340,  1.8683, 17.5058, 10.3399,  1.4590,
        14.3183,  2.5007,  4.7955,  1.6302,  1.5658,  0.7031,  0.1706,  0.8001,
        10.0973, 18.3167, 26.7866,  5.1248,  6.2311,  3.6720,  2.4899,  3.2009,
         8.4319,  4.5874,  6.2398,  1.9152,  1.9930, 10.4389,  3.9872, 17.2215,
        12.8399, 26.3041,  8.7194, 13.6260, 14.5816, 14.6843,  6.1107,  9.3421,
         2.8993, 10.0196,  2.3870,  5.1408,  1.5598,  2.5405,  8.4994,  8.1543,
        16.0315,  6.3172, 11.7939,  2.0802, 18.8414,  2.0212,  9.3565, 12.3136,
         3.0684,  3.4762,  7.5679, 15.5966,  5.6599,  3.6471,  0.7229,  9.4814,
         8.6154,  6.5788, 22.0176,  5.8752,  3.0135,  1.0196,  0.1106,  2.3065],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [22/80], Step [100/642], LR 9.8e-05, Loss: 655.9
BCE Train Loss:  tensor([41.9732,  7.6910, 15.2968,  7.7640,  4.8554,  1.8700,  3.5745,  7.1670,
         9.7342,  5.0944, 18.4954,  8.8980,  2.7643, 14.0963, 16.5549,  7.6621,
         4.4521, 10.0784,  2.0736,  8.6131,  5.5255,  0.1737,  0.8469,  0.4172,
        24.0858,  6.1981, 23.1619, 11.6598, 17.8275,  1.8239,  7.2848,  4.1433,
         6.2943,  0.5197,  3.8790,  4.2959,  4.9354,  1.8326,  1.2007, 24.3991,
         7.9976, 13.4273,  6.5193, 11.0603,  3.5031,  9.2033,  1.3173,  5.5123,
        13.1823,  1.7462,  1.9863,  4.6233,  8.7032,  6.8254,  5.4156,  2.9787,
        20.0243,  5.5786,  4.0637,  3.8897, 12.3577,  0.4780, 13.5516, 12.2753,
         8.2834,  6.7008,  9.2751, 17.2006,  2.7039,  2.0129,  0.3042,  3.5657,
         2.4623, 16.0141, 16.8039,  4.9130, 12.3812,  3.4621,  0.0798,  3.5839],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [22/80], Step [200/642], LR 9.8e-05, Loss: 635.2
BCE Train Loss:  tensor([26.2594, 10.2220, 15.0768,  8.3664,  1.3577,  3.3539,  2.7810, 16.9118,
         8.5525,  9.5311,  0.7907,  4.7243,  1.5402, 20.1815,  5.9801,  6.1741,
        13.2984,  2.4884,  0.9449,  1.3355,  1.3416,  0.1631,  0.5469,  0.6296,
        16.9419,  8.2051, 12.5384,  4.9327,  2.1630,  2.8857,  8.0015, 10.5868,
         9.2693,  3.1237,  1.3215,  3.6113,  3.1280,  6.3098,  1.6074, 21.9380,
        10.6296, 21.1127, 10.2623, 14.2789, 15.4492, 16.1488,  7.6617,  3.0893,
         3.9420,  5.0823,  1.0024,  6.0208,  3.3351, 12.4565,  7.5219,  5.1684,
        20.1475,  6.0573, 14.7499,  6.2008, 17.9802,  3.4196,  3.8551,  1.9512,
         5.4285,  9.3766,  4.0115, 11.8434,  0.8158,  2.2621,  0.0545,  3.6842,
        11.2785, 20.4835, 16.0127,  8.7305,  6.3059,  1.3343,  0.2701,  4.8890],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [22/80], Step [300/642], LR 9.7e-05, Loss: 603.4
BCE Train Loss:  tensor([40.1198,  8.6828, 17.7496,  7.5160,  0.4328,  5.1604,  3.6083, 11.0078,
         6.1217, 11.8586,  6.7552,  9.4154,  0.5993, 14.9328, 14.4990, 12.2447,
        10.5640, 13.3188,  0.9579,  2.8445,  1.2577,  0.4057,  0.5835,  4.2884,
         9.3827, 11.0230, 17.9417,  7.3919,  6.6346,  0.6820,  1.7914,  8.5309,
         7.4624,  0.9673,  0.7403,  1.2219,  2.9229,  2.7568,  2.3033, 21.6967,
         6.6225, 13.7648, 10.7881,  8.4933,  3.5453, 13.8024,  6.1840,  8.0116,
         3.1689,  4.4116, 11.3085,  2.2746,  1.1037,  7.9498,  1.7769,  1.9200,
        30.7477,  3.1533, 21.6197,  7.1347, 11.2402,  2.6125, 10.4435,  8.8381,
         4.1716,  3.7527,  4.4050, 12.8429,  0.6599,  1.3477,  3.5878,  5.8005,
         3.9693, 12.2444, 17.7735,  5.9594,  1.2108,  6.8648,  1.3895,  4.2675],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [22/80], Step [400/642], LR 9.7e-05, Loss: 599.5
BCE Train Loss:  tensor([30.4125,  8.4510, 24.2017,  4.1482,  2.2496, 12.4086,  4.9380, 17.4517,
         7.0373, 12.0142, 11.7684,  0.7908,  3.6503, 12.0455,  8.6964, 11.3415,
        20.9915,  7.6347,  0.6273,  1.2488,  0.7783,  1.5243,  2.4674,  0.9690,
        16.1951, 12.7825, 17.4290,  5.9186,  8.2000,  4.1373,  3.0934,  4.3638,
         9.6678,  1.2417,  1.1045,  2.1651, 13.0240,  1.4403,  8.3039, 30.0872,
         9.3390, 15.6783, 11.3823,  4.9813,  8.8370, 15.9735,  7.4241,  5.6984,
         5.8656,  2.0809,  1.3331,  7.8880,  3.0881,  1.7068,  0.7107,  1.9448,
        28.5386, 10.0864, 14.3156,  5.7576, 25.0115,  2.4696, 14.9828, 10.4756,
         6.1027, 20.4146,  1.8252, 11.1501,  5.6820, 10.6997,  0.3646,  8.6443,
         2.8542, 19.8546,  8.9556,  6.7082,  2.1756,  8.9247,  0.1114,  0.5900],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [22/80], Step [500/642], LR 9.7e-05, Loss: 677.6
BCE Train Loss:  tensor([32.7718,  8.4814, 25.6006, 17.4999,  2.2042,  7.8176,  1.6928, 14.2580,
         2.0359, 10.0785,  5.4233,  5.7342,  9.4732,  9.8053,  6.8157,  4.5698,
        19.2582,  3.7163,  1.2350,  1.0622,  2.8224,  4.1704,  4.0864,  0.4011,
        19.9058, 12.6042, 27.7203,  3.5908, 10.2521,  1.0948,  1.4844,  2.2581,
         5.7817,  0.9573,  1.9151,  2.3182, 10.2692,  3.5373,  1.4605, 26.2568,
         9.8754, 17.4303,  4.5927, 13.9620,  7.5862, 22.1693,  6.0490,  3.2107,
         6.3299,  2.0117,  2.4219,  2.7589,  1.1127,  8.6759,  3.2767,  6.8204,
        29.6778,  6.1422, 22.8032,  8.9458, 21.6250,  4.7210,  2.8308,  5.5279,
         3.3821,  2.6858,  4.2085, 14.2422,  5.9284,  4.1390,  0.2680,  2.4545,
         2.6526, 14.8340, 14.0083,  5.5993,  4.7355,  8.4096,  0.2866,  0.9410],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [22/80], Step [600/642], LR 9.7e-05, Loss: 641.8
BCE Val Loss:  tensor([4.5310e+01, 3.1653e+01, 4.3715e+01, 1.9659e+01, 7.2150e-02, 8.4769e+00,
        6.5825e+00, 2.5680e+01, 5.5643e+00, 7.4898e+00, 8.9412e+00, 1.1348e+01,
        7.5249e+00, 1.6228e+01, 8.7311e+00, 1.8024e+01, 2.3541e+02, 2.2122e+00,
        2.1720e+00, 2.2794e+00, 7.6186e-01, 1.0151e+00, 4.0757e-02, 1.1627e-01,
        2.5433e+01, 1.2528e+01, 2.9694e+01, 3.2772e+00, 1.5082e+01, 1.1819e+01,
        2.4969e+00, 1.1709e+00, 8.4535e+00, 7.2745e-01, 1.0537e+00, 5.8334e-01,
        1.5006e+01, 4.9276e+00, 2.6193e+00, 4.1018e+01, 1.1585e+01, 2.1284e+01,
        6.9490e+00, 1.4446e+01, 1.2707e+01, 1.2566e+01, 7.6396e-01, 4.5999e+00,
        4.2069e-01, 4.4184e+00, 9.3648e-02, 1.7014e-01, 5.2544e+00, 4.8849e-01,
        4.2557e-01, 6.8642e-01, 2.2877e+01, 7.3242e+00, 1.1695e+01, 5.2657e+00,
        9.6964e+00, 6.0475e+00, 4.1077e+00, 5.2634e+00, 1.9117e-01, 1.2906e+00,
        1.8130e-01, 1.0240e+01, 7.7055e+00, 1.4447e+01, 2.9588e-01, 1.5775e+01,
        1.0783e+01, 9.6730e+00, 1.5456e+01, 6.7465e+00, 1.0149e+00, 6.6832e+00,
        3.5120e-01, 8.6391e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [22/80], Step [000/314], LR 9.7e-05, Loss: 955.7
BCE Val Loss:  tensor([5.4553e+01, 1.8317e+01, 4.3591e+01, 1.0897e+01, 5.3657e+00, 4.0395e+01,
        4.0634e+01, 3.2855e+01, 2.7549e+01, 2.8007e+01, 1.4671e+01, 3.3027e+01,
        9.4190e+00, 7.8971e+00, 1.6088e+01, 4.4371e+00, 6.8795e+00, 1.4475e+01,
        4.8967e+00, 1.4374e+01, 5.9841e-01, 2.2040e-01, 8.8259e-02, 2.6496e-01,
        2.9049e+01, 1.7847e+01, 3.1482e+01, 1.4286e+01, 1.5580e+01, 3.3226e-01,
        4.1825e-01, 2.5955e-01, 5.3737e-01, 1.6167e+00, 1.9692e+00, 2.7270e-01,
        4.2282e+00, 1.3852e+00, 2.7872e-01, 1.9103e+00, 3.7651e-01, 3.3564e+00,
        8.9918e-01, 1.8078e+00, 1.1504e+00, 1.7900e+00, 1.3629e-01, 1.4749e-01,
        1.3954e-01, 5.7025e+00, 4.1731e-02, 5.4782e-02, 1.3209e-01, 1.6433e+00,
        2.2339e-01, 3.7081e-01, 8.0950e+00, 4.7779e+00, 5.1121e+00, 4.3363e-01,
        5.8442e+00, 1.3685e-01, 4.9191e-01, 1.9129e-01, 2.7203e-02, 1.0572e-01,
        2.3969e-02, 1.9367e+01, 7.6055e-02, 4.2720e+00, 1.1517e-02, 1.8145e-01,
        2.8517e+00, 3.1611e+00, 4.2843e+00, 6.5424e-01, 5.1831e-01, 2.6742e-01,
        1.9843e-02, 1.3005e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [22/80], Step [100/314], LR 9.7e-05, Loss: 630.0
BCE Val Loss:  tensor([1.6776e+01, 2.5059e-01, 3.7187e+00, 3.5171e-01, 3.5084e-02, 7.5242e-02,
        6.1068e-02, 1.3542e+01, 2.3377e-01, 8.5159e-02, 6.0318e-02, 1.0615e-01,
        5.3068e-02, 1.4000e+01, 3.9332e-01, 4.9253e-01, 1.1911e+00, 1.2497e-01,
        2.3081e-01, 4.3175e-02, 1.3424e-01, 4.3181e-02, 9.0905e-03, 2.3863e-02,
        4.1410e+00, 1.0655e+00, 2.6232e+01, 3.8477e+00, 4.3121e-01, 3.4675e-01,
        2.2192e-01, 4.9837e+00, 7.7412e+00, 1.1795e-01, 2.8646e-01, 1.6024e-01,
        1.0008e+01, 8.5098e+00, 1.4812e-01, 3.8364e+01, 2.1528e+01, 6.2220e+01,
        5.3439e+01, 5.9692e+01, 4.1630e+01, 5.4171e+01, 9.1726e+00, 7.5509e+00,
        3.1951e+01, 9.8149e+00, 2.5080e+01, 4.3747e+01, 5.5376e+01, 2.5859e+01,
        4.0539e+01, 6.5524e+01, 9.8223e+01, 1.1657e+01, 6.7636e+00, 1.3037e+00,
        7.7417e+01, 1.3760e-01, 9.3781e+00, 1.1283e+01, 1.3038e+01, 4.1613e+00,
        8.2958e+00, 1.7831e+01, 6.3069e+00, 2.8297e+00, 8.0430e-02, 1.0250e+01,
        4.6544e+00, 4.3559e+01, 2.5349e+00, 1.4793e+01, 1.0884e+01, 7.5096e-01,
        1.4469e-01, 6.5613e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [22/80], Step [200/314], LR 9.7e-05, Loss: 1122.9
BCE Val Loss:  tensor([2.5786e+01, 8.5883e-01, 1.7194e+01, 2.0117e+00, 3.5819e-01, 7.5177e+00,
        6.2746e+00, 1.4410e+01, 2.7834e+00, 1.6113e+01, 4.2827e+00, 1.0022e+01,
        1.0561e+00, 1.3179e+01, 1.5276e+01, 3.4670e-01, 1.0388e+00, 5.3726e-01,
        1.3220e-01, 4.0894e-02, 2.4132e-01, 8.6683e-02, 2.1736e-02, 1.4829e-01,
        2.3287e+01, 6.7690e+00, 2.4623e+01, 7.8152e-01, 1.3844e+01, 1.4193e-01,
        1.0027e+00, 2.1004e-01, 2.1897e-01, 3.2503e-01, 3.2789e-01, 3.2041e-01,
        5.0610e-01, 1.7036e-01, 9.2762e-02, 2.7467e+00, 7.9875e-01, 1.5792e+00,
        2.4469e-01, 4.6786e-01, 5.1514e-01, 1.6802e+00, 1.1765e-01, 8.7687e-02,
        5.9987e-02, 1.0428e-01, 2.6220e-02, 2.2298e-02, 3.8417e-02, 5.8762e-01,
        7.0536e-02, 3.0952e-01, 4.2071e+00, 1.7823e+00, 1.3082e+01, 8.1203e-01,
        6.2713e+00, 2.1652e-01, 8.8722e-01, 1.7386e-01, 4.8574e-02, 1.5893e+00,
        1.1971e-01, 6.3981e+00, 1.6532e-01, 4.8270e-01, 1.6176e-02, 4.0337e-01,
        2.8291e-01, 6.3230e+00, 6.2573e+01, 5.0625e+00, 1.8726e-01, 5.5930e+00,
        3.7174e-02, 3.3218e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [22/80], Step [300/314], LR 9.7e-05, Loss: 338.5
starting validation
Accuracy th:0.5 is [90.47891717 97.81557242 93.99982944 98.69640964 99.28728938 98.28705791
 99.15693035 95.94303188 98.53437458 97.79120625 99.07774028 99.21175424
 99.52242297 96.01856703 97.95933285 98.08481865 97.12844629 98.58310693
 99.27997953 98.88159257 99.43470474 99.5675004  99.7490284  99.64912708
 95.38626479 97.81069919 94.8026949  97.92887514 98.37477614 98.78290956
 99.02900793 99.01682484 97.59749516 99.16911344 99.22881057 99.24586689
 98.78656449 98.91570522 99.47247231 93.94135062 98.14573409 93.9523154
 97.62917118 96.82996065 97.2965729  95.55804632 98.66717023 98.93885308
 98.49295208 99.025353   99.15571204 98.82433206 99.21419086 98.94859955
 99.03753609 98.28096636 92.48059843 97.73394574 96.8933127  98.40279724
 94.36288544 98.93397985 97.588967   97.99831873 99.0521558  98.09822005
 98.84869824 96.28172171 98.93276154 98.64645899 99.81603538 98.13842424
 98.65620546 96.20740488 97.64988243 97.85699492 99.26292321 98.77681802
 99.84405648 99.24830351]
Accuracy th:0.7 is [89.28375629 97.69739647 93.6599213  98.65742376 99.15571204 98.04095954
 99.05702903 96.21105981 98.397924   97.69983309 99.04971918 99.22271902
 99.54557084 95.77003204 97.80948088 97.80460764 96.93717182 98.41619863
 99.1776416  98.75488846 99.47125401 99.59064826 99.72953546 99.61623275
 95.276617   97.68034015 94.41039948 97.85090338 98.2578185  98.65011391
 98.96687419 98.85966302 97.23809408 99.11550785 99.17398667 99.14718388
 98.72077582 98.71224766 99.49562018 93.48204822 98.10796652 93.52468903
 97.48053752 96.64355941 97.19423496 95.25346913 98.54899429 98.843825
 98.35284658 98.94859955 99.05581072 98.70859273 99.14840219 98.99367698
 98.94859955 98.21030446 91.41457828 97.5755656  96.72396779 98.40767047
 93.78297048 98.6769167  97.1857068  97.82531889 98.91692353 98.0775088
 98.70128288 96.19278518 98.8292053  98.57214215 99.81603538 97.98126241
 98.46614929 95.82972917 97.54145296 97.78145978 99.22759226 98.66473362
 99.84405648 99.20931763]
Avg Prec: is [97.73372866 55.85036784 77.49100199 81.51393899 93.03540259 80.18278309
 90.4774233  65.95395037 76.03058635 73.07511541 66.04583908 71.88149052
 47.7131002  49.43511164 52.91735995 78.55011894 53.58062208 76.32194006
 76.36762875 68.17815007 89.51336314 77.16806684 96.22939052 96.10224073
 37.08742034 65.66066493 48.26112576 66.8672259  50.76670968 69.53041073
 88.97713985 69.28853042 71.82727601 84.79544627 88.81528177 90.15519579
 86.19133464 88.24687329 95.41657007 54.81030206 46.83039363 62.65354502
 63.59053239 56.50643945 49.80297013 65.02871589 67.95766331 55.55945819
 62.43323025 63.87866515 79.74673367 64.90288134 54.36071365 86.43802885
 57.69418567 67.75070236 69.17876125 75.12656618 51.46917125 79.88018437
 79.13249858 90.94679634 75.37501494 69.14476849 75.34527526 63.53287715
 73.28021846 40.36895108 54.95101003 76.46024016 18.99957633 84.39998924
 69.36522754 54.7513306  66.46741455 65.22966876 32.91340164 64.79141583
 11.66506326 41.13332242]
Accuracy th:0.5 is [88.03864475 97.57191067 93.23473155 98.37964937 99.05702903 98.06532571
 98.89499397 95.85165873 98.30776915 97.42815024 98.83895177 99.12769094
 99.47612724 95.64454624 97.71688941 97.78267809 96.69229176 98.29924099
 99.06921212 98.69397303 99.18860638 99.43957798 99.70516928 99.49562018
 95.36799016 97.26124194 94.67355417 97.55850928 98.21030446 98.54777598
 98.77681802 98.88281088 97.36845311 98.99976852 99.00586007 99.11063462
 98.43812819 98.72199413 99.30556402 93.48935807 98.01659337 93.55271013
 97.45738965 96.54974964 97.17352371 95.10483547 98.47955069 98.8158039
 98.32238886 98.88646581 99.06433888 98.79996589 99.09966984 98.65255053
 98.87915596 97.98491734 91.82514833 97.36479819 96.63746787 98.034868
 93.73545644 98.8158039  97.36357988 97.60967824 98.93154323 97.85821323
 98.70493781 96.05511629 98.86697287 98.42107187 99.81603538 97.83141044
 98.45640282 95.98445438 97.30388275 97.61942471 99.20322608 98.47589576
 99.84405648 99.18616976]
Accuracy th:0.7 is [85.51796396 97.41962208 92.55491527 98.34797334 99.1215994  97.95567793
 98.92910661 95.54951816 98.3004593  97.27951658 98.75245185 99.10576138
 99.44932445 95.44474361 97.57434729 97.48906568 96.51929192 98.14573409
 98.98393051 98.52706473 99.22150071 99.49318356 99.70516928 99.46150754
 95.26443391 97.01514358 94.38846993 97.41840377 98.09943836 98.40645216
 98.73052229 98.73661383 97.0041788  98.91814184 99.04119102 99.13500079
 98.31873393 98.72564905 99.20200777 93.23594985 97.93862161 93.0617317
 97.28560812 96.51441868 97.02610836 94.64553307 98.39061415 98.76341663
 98.32117055 98.80727574 98.96078264 98.69640964 99.05946565 98.79265603
 98.79143773 97.7838964  90.9857336  97.23200253 96.52294685 97.93009344
 92.9496473  98.78656449 97.13331953 97.49515722 98.81458559 97.70957956
 98.58676186 95.98445438 98.8158039  98.45883944 99.81603538 97.82166397
 98.46005775 95.66891242 97.17839695 97.49759384 99.19347961 98.36746628
 99.84405648 99.16180358]
Avg Prec: is [96.7512182  45.10965371 72.10119391 74.81732538 89.17744284 74.38100191
 86.45729072 59.39891566 67.98146716 64.68894741 53.3639887  66.16344692
 36.2094734  38.6392366  43.22622571 68.68686215 40.06975459 64.75087911
 64.43323242 55.99734239 82.42190211 66.55517508 94.30651404 93.23008911
 32.12457991 50.72016679 43.31570134 56.02571689 37.25761024 56.03996235
 84.34989697 60.05421813 64.86821057 78.84525303 83.43251544 86.75186677
 79.13091314 82.74567717 92.78109252 48.25927486 37.99586237 58.05763802
 57.49663613 49.46112084 44.11462779 58.34205161 55.50994686 45.98133657
 52.66468808 55.2192107  74.68542216 53.96159322 37.74937701 81.31228474
 45.16995977 56.94540507 62.73495979 66.90854096 42.56419975 71.03386172
 74.62070173 86.3821475  67.78074209 58.51554156 67.57319115 54.4567363
 64.33847677 31.41262034 49.41770822 70.14093505 16.24716978 79.57266891
 61.31230858 47.50685071 58.70966638 57.25195297 23.51096945 51.3067195
  8.32377708 30.30257635]
mAP score regular 67.96, mAP score EMA 60.03
starting validation
Accuracy th:0.5 is [90.35054937 97.80252635 93.59693051 98.66208237 99.29491492 98.21860129
 98.98348158 95.19645215 98.53501756 97.56832847 99.03580238 99.21020505
 99.38460772 95.78194683 97.87727035 97.98191195 96.90559833 98.56491517
 99.27747465 98.8090789  99.48924932 99.58641652 99.79071679 99.75583626
 95.53030869 97.63061514 94.58853427 97.87228742 98.21610982 98.6222189
 99.02583651 98.88880584 97.34658794 99.24010265 99.10556345 99.28993198
 98.7418093  98.7791813  99.33976132 93.64177691 97.98689489 93.63181105
 97.39143434 96.67140045 96.88317513 95.06191295 98.7791813  98.95856691
 98.36061489 98.95358397 99.11303785 98.7567581  99.03331091 98.85143384
 98.96853278 98.01679249 91.53399606 97.61317488 96.56426738 98.12143409
 93.63679398 98.91870344 97.49109301 97.86730448 98.95109251 97.66051274
 98.85143384 95.81931883 98.82402771 98.42290156 99.81563146 98.03921569
 98.51259436 95.98126417 97.55587114 97.60071754 99.23511971 98.76672397
 99.8206144  99.18279891]
Accuracy th:0.7 is [90.1686723  97.74273115 93.74143558 98.7193861  99.25006852 98.07160475
 98.91122904 95.74457483 98.4353589  97.60819194 99.06569998 99.27747465
 99.45187732 95.6573735  97.85983008 97.81249221 96.86822632 98.43037596
 99.27249172 98.72935197 99.52163839 99.63624586 99.78324239 99.75085333
 95.45307322 97.60071754 94.51628174 97.85733862 98.12641702 98.57238957
 98.97351571 98.84395944 97.18962553 99.26003438 99.10556345 99.25006852
 98.7791813  98.59730423 99.35969305 93.44993398 98.02426689 93.68662332
 97.3864514  96.69880659 97.07501806 95.12419962 98.67952263 98.95109251
 98.25846476 98.93614371 99.00839624 98.68699704 99.01088771 98.86389117
 98.94610957 98.10897675 91.07307472 97.58327728 96.53686125 98.14884022
 93.40259611 98.76921544 97.1771682  97.77013728 98.81904477 97.83491541
 98.70194584 96.02860204 98.82651917 98.41791863 99.81563146 97.89471062
 98.44034183 95.84672497 97.47116127 97.65054688 99.26750878 98.70692877
 99.82559733 99.19027331]
Avg Prec: is [97.52092421 50.38672757 74.69012898 82.15078294 88.72849413 75.69303816
 89.31259961 57.77295337 74.08209106 69.12574006 63.15609846 69.2715201
 40.4687055  45.86619183 49.29922074 77.82585838 52.17371641 74.1305733
 74.77035977 63.80722607 90.25217772 81.81099716 96.41100072 97.05324225
 29.85119141 61.022595   37.18537475 64.34668801 45.15599867 61.17090466
 85.97654093 59.69994491 64.81709679 84.44188245 82.41145608 87.83936347
 82.02370966 86.07157589 93.85152093 49.733369   41.65175466 56.93332218
 51.7112919  45.30815435 37.22232663 57.40400922 60.69430778 44.08013946
 54.05506789 56.48299835 80.24841714 53.71814521 45.592786   84.87312093
 51.68036022 56.57417704 61.61135352 68.61855748 44.51719455 74.8385651
 71.45306788 90.84407949 72.43416891 64.83670403 69.50208774 49.82937574
 70.74037261 36.16676993 47.24189301 72.59934603  8.60382023 80.67230013
 58.90873804 46.88160489 68.08752894 56.92657949 17.63502352 60.21736337
  3.5648979  29.43339731]
Accuracy th:0.5 is [88.917956   97.59075168 93.35027531 98.47771383 99.17532451 98.08904502
 98.89129731 95.77198097 98.33570023 97.36651967 98.90624611 99.21518798
 99.42945412 95.48795376 97.68044448 97.78010315 96.55928445 98.35064903
 99.18279891 98.61723597 99.35720158 99.42696265 99.76580213 99.67361786
 95.43812442 97.12733886 94.59600867 97.63310661 98.09153649 98.38802103
 98.92119491 98.78167277 97.13730473 99.14293545 99.05573411 99.30238932
 98.5698981  98.58733837 99.26750878 93.44993398 97.95948875 93.64675985
 97.25689513 96.50945512 97.01023993 94.86508708 98.63218477 98.89877171
 98.16628049 98.90126317 99.10556345 98.74430077 98.95607544 98.64962503
 98.89129731 97.95699728 91.30727259 97.36901114 96.48703192 97.93706555
 93.33532651 98.89628024 97.35904527 97.68542741 98.85392531 97.68542741
 98.68699704 95.8816055  98.7492837  98.27092209 99.81563146 97.71532501
 98.32075143 95.82430177 97.31669034 97.62812368 99.25505145 98.5773725
 99.82559733 99.18279891]
Accuracy th:0.7 is [87.3533149  97.45870394 92.92672596 98.5549493  99.22515385 98.06911329
 98.89378877 95.66235643 98.40795276 97.3191818  98.84395944 99.22017091
 99.39955652 95.29860229 97.58826021 97.53843087 96.47457458 98.23355009
 99.15290131 98.58235543 99.38959065 99.50668959 99.75334479 99.67112639
 95.46553056 97.00027406 94.55863667 97.58327728 97.96447168 98.40047836
 98.85890824 98.79662157 97.03266313 99.04576824 99.11054638 99.29989785
 98.51259436 98.51508583 99.20273065 93.31539477 97.90965942 93.2381593
 97.27931833 96.63901139 97.04512046 94.69068441 98.58733837 98.94112664
 98.23604156 98.85641677 99.00839624 98.6820141  98.94610957 98.8016045
 98.82153624 97.85484715 90.82143658 97.39143434 96.42225378 97.87727035
 93.0886713  98.86389117 97.14976206 97.53843087 98.7492837  97.70037621
 98.55744077 95.8442335  98.78167277 98.40795276 99.81563146 97.81996661
 98.44781623 95.6498991  97.192117   97.59075168 99.26501732 98.49017116
 99.82559733 99.17283305]
Avg Prec: is [96.88743443 42.02317247 71.89417377 78.80777098 85.72963581 73.41795614
 87.50821083 55.80797647 70.1474312  64.51761075 54.39143783 66.4899558
 31.25515316 38.80903572 42.24224553 71.74059762 41.33580632 66.1832544
 67.19782366 52.48469587 86.58430271 72.84271807 95.32447299 95.90716814
 28.78819855 49.56235    36.76630864 57.75637864 36.75117453 50.51150795
 83.31079776 52.43242185 59.56642971 79.56952419 81.18003316 87.20444305
 77.92763959 82.95252232 92.94989019 46.81071161 35.51490469 54.65429772
 47.76597496 42.44370178 35.52973811 53.56982811 53.72844494 40.12468797
 50.01747392 51.64277473 78.43468305 47.80381267 36.76278842 82.91285717
 43.73319156 49.92311312 58.70556515 63.29085854 39.28972504 69.17711213
 69.64880293 89.29363636 67.57683779 58.14990982 66.6743803  44.94565802
 65.09327705 30.36533676 42.29752232 69.56872136  8.84037005 78.5178018
 55.18612768 42.61998676 63.87088761 54.63511155 16.61443334 51.50369468
  2.71159827 25.86237791]
mAP score regular 62.70, mAP score EMA 58.16
Train_data_mAP: current_mAP = 67.96, highest_mAP = 67.96
Val_data_mAP: current_mAP = 62.70, highest_mAP = 62.70
lr:  [9.707592688626087e-05, 9.707592688626087e-05]
BCE Train Loss:  tensor([27.3261, 10.1442, 18.3410,  5.2641,  1.1781,  1.6458,  0.8992,  9.1539,
         9.3397,  8.3465,  1.8593,  8.7655,  8.5714, 19.7871,  3.5293,  7.5456,
        20.5013,  4.0735,  1.0154,  0.6196,  0.8644,  2.6853,  0.2986,  0.4252,
        15.8206,  8.0418, 16.9928, 14.2931,  1.4154,  2.3032,  2.7203,  2.0805,
        12.1275,  3.3033,  2.8027,  0.6408, 10.4893,  1.9130,  2.0222, 14.6723,
         8.4922, 20.9753,  6.8614,  6.4521,  9.5020, 13.6109,  6.0100,  1.1826,
         6.9061,  1.1747,  1.9278,  1.2776,  4.8602,  4.3293,  2.4417, 11.8512,
        24.0794,  6.7918,  8.9903,  6.2918,  8.3675,  4.6219,  8.0265,  1.4797,
         1.4715,  3.3201,  3.5476, 13.8036,  1.2472,  5.1559,  0.1560,  5.9382,
         0.9088, 11.0719,  3.4044,  2.3646,  1.0148,  5.6231,  0.2133,  1.3961],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [23/80], Step [000/642], LR 9.7e-05, Loss: 521.0
BCE Train Loss:  tensor([19.2918, 19.8816, 20.9390,  6.7578,  3.0843,  5.1591,  4.6763, 11.5677,
         5.9603,  3.6585,  0.6871,  3.8092,  0.1903, 12.4850,  6.3647, 14.5158,
        18.6982,  7.2631,  1.9171,  1.6866,  0.3303,  0.4066,  0.3919,  3.7687,
        17.0413, 10.1672, 22.9760,  1.9021,  5.4630,  4.0009,  2.1705,  3.3582,
         6.2091,  4.2815,  0.8714,  2.8416,  9.5174,  1.7954,  7.7919, 20.9589,
        14.0502, 14.6163,  6.7662,  6.6897,  7.2705, 19.2751,  7.5076,  4.2475,
         8.2916,  3.1776,  1.6535,  0.9385,  1.4900,  1.3202,  6.0145,  3.2679,
        34.7325, 10.6410, 22.4530, 12.7627, 16.1203,  0.7431,  5.4811, 10.8520,
         1.5341, 14.0366,  1.8670, 14.5157,  3.0629,  1.9800,  0.1930,  5.1619,
         7.2998, 14.6321, 20.3835,  8.2079,  0.8860,  5.2491,  0.2610,  5.0933],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [23/80], Step [100/642], LR 9.7e-05, Loss: 619.6
BCE Train Loss:  tensor([26.1417, 14.2898, 28.0038, 12.3532,  3.3333,  6.1822,  8.5055, 11.5862,
         5.2926,  5.0526,  4.8889,  6.9084,  7.1601,  9.0823,  6.2249,  2.5124,
        10.0992,  8.0803,  0.5134,  3.2271,  0.8171,  0.5152,  0.8731,  0.5242,
        25.8138,  9.0774, 17.4095, 12.4819,  7.9376,  5.0110,  3.2119,  1.9168,
        12.5369,  2.5173,  0.6830,  0.4804,  5.2734,  4.9378,  1.2135, 22.4675,
        15.2952, 23.3311,  6.8293,  8.8746,  9.2642, 15.0689,  2.7526,  7.2280,
         7.5700,  8.3656,  1.7792,  2.2787,  6.9978,  4.2350, 11.7105,  3.3065,
        36.2106,  9.9033, 11.6969,  4.9205, 20.1708,  4.5314,  5.3295,  6.4619,
         4.4043,  3.1838,  3.7830, 25.7539,  3.0011,  8.6761,  0.1858,  3.9074,
         3.1738,  8.4019, 17.6444, 10.0197,  3.7924, 10.1918,  0.3021,  4.5800],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [23/80], Step [200/642], LR 9.7e-05, Loss: 660.3
BCE Train Loss:  tensor([22.2126, 14.2340, 20.5325, 10.5848,  0.5786,  9.7579,  0.7526, 22.1402,
         6.0165, 13.5983,  8.7582,  2.0939,  4.0355, 21.0894,  6.9767,  8.0167,
         8.7384,  7.1611,  4.5112,  0.9443,  1.3091,  0.2452,  4.4930,  4.8415,
        17.5880,  9.1461, 17.6864, 12.7992,  1.6456,  7.2214, 10.7652,  4.4275,
        10.0249,  6.1424,  3.0951,  5.5247,  1.2452,  0.5563,  0.8802, 17.2313,
         4.2896, 19.8064,  8.6185,  9.5083,  7.3180, 12.3568,  7.8836,  2.6872,
         2.2222,  1.0129,  7.7516,  4.8761,  0.7000,  4.8713,  0.3116,  8.6592,
        25.5685, 13.1827, 15.7691,  4.2755, 20.2275,  0.5597, 15.4902, 10.9536,
         1.7280,  9.6328, 11.0500, 10.8667,  5.8531,  9.5080,  0.1129,  3.5542,
         3.9348, 10.6638, 13.5811,  7.9877,  4.7862,  3.4194,  0.1626,  1.0214],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [23/80], Step [300/642], LR 9.7e-05, Loss: 636.4
BCE Train Loss:  tensor([24.2712,  6.0147, 12.1929,  5.2159,  2.8936,  7.1056,  6.1308,  9.5822,
         2.5950,  7.4879,  3.6993,  0.8857,  4.7385, 20.4684,  6.8484,  6.9790,
         3.4263,  2.5776,  9.2476,  3.4077,  1.2817,  3.6873,  0.1182,  2.0546,
         7.9145,  5.2398, 12.8166, 14.1951,  3.0983,  1.8183,  1.4870,  7.6133,
         8.8886,  2.7779, 15.4374,  1.3229, 10.6090,  2.0631,  7.9468, 20.7259,
        15.9610, 15.7129, 12.4310, 13.4713,  9.6212, 12.6553,  3.0256,  1.6826,
         1.3959,  3.6669,  7.9167,  2.0352,  3.7628,  3.7900,  0.7724, 16.4523,
        31.1570, 11.8172,  9.4905,  5.5965, 19.7124,  1.6531, 14.6849,  3.9375,
         1.5944,  6.8228,  1.3368, 20.3793,  3.9583,  7.1422,  0.3205,  2.2833,
         9.7906, 23.8247,  5.4884, 16.2881,  0.5832,  3.2423,  0.3251,  1.2737],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [23/80], Step [400/642], LR 9.7e-05, Loss: 603.9
BCE Train Loss:  tensor([44.5361,  8.0804, 26.4987,  4.3363,  3.0829,  8.9703,  2.7719, 10.1349,
         2.7024,  8.5227,  4.3237, 10.6182,  0.4712, 15.5389,  9.6903,  3.2486,
        10.9862,  4.5065,  6.4267,  6.1169,  2.0558,  0.4318,  0.3217,  0.3101,
        10.6952,  5.1434, 10.6611,  5.2845,  2.4016,  3.6618,  4.2691,  1.8969,
         9.3536,  0.9864,  6.7207,  4.0136,  4.4091,  3.8311,  5.0078, 25.4318,
         3.1478, 20.4327,  4.7536, 13.2773,  7.2017, 17.0157, 17.0911,  5.9393,
         4.1610,  5.0183,  1.4110,  8.6305,  2.8074,  0.8321,  3.3984, 13.6034,
        18.5098,  6.3371,  5.9842, 10.0724, 16.9580,  0.7777,  1.6142,  7.8546,
         4.1218,  2.5261,  4.4686, 12.8991,  2.8734,  4.3410,  0.2365,  4.5274,
         5.3294,  9.4755, 14.8581,  2.8821, 12.7925,  6.7470,  0.2095,  1.5047],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [23/80], Step [500/642], LR 9.6e-05, Loss: 585.1
BCE Train Loss:  tensor([18.7236,  2.4785, 13.2532,  2.0232,  6.2053,  3.0067,  1.6880, 11.2222,
         7.9972,  6.6086,  3.4334,  1.4634,  1.3012,  9.4958, 14.6578,  6.4082,
        11.0108,  1.4529,  0.3413,  4.3330,  0.7549,  0.3776,  2.7406,  6.7630,
        17.0948,  7.4730, 18.4391, 10.7695,  7.3857,  3.0716,  2.2012,  3.9143,
         8.6684,  3.2675, 10.8162,  2.2014,  5.9048,  3.8811, 12.0233, 21.1796,
         5.5566, 26.9584,  7.7181,  4.6429,  8.7239, 11.5903,  5.9013,  2.4212,
         6.4741,  6.1503,  0.7335,  3.3291,  0.8337,  4.3986, 13.5649,  7.9182,
        16.1460,  5.3639,  9.0086,  2.5625, 15.8018,  2.8968,  7.7153,  6.7767,
         2.5907,  5.0469,  2.5605, 13.8637,  2.5461,  8.8251,  0.2464,  3.3524,
         3.9952, 10.7072,  8.8141,  7.9269,  1.7975,  1.7832,  0.0871,  1.4011],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [23/80], Step [600/642], LR 9.6e-05, Loss: 534.8
BCE Val Loss:  tensor([4.7306e+01, 2.2175e+01, 4.9760e+01, 2.1403e+01, 1.4862e-01, 1.0391e+01,
        4.2007e+00, 1.9646e+01, 4.4479e+00, 8.3434e+00, 6.8066e+00, 1.1844e+01,
        7.8135e+00, 1.4822e+01, 8.5871e+00, 4.1950e+01, 2.1386e+02, 2.0798e+00,
        6.7039e-01, 2.0876e+00, 4.2617e-01, 7.4709e-01, 1.8296e-02, 1.1379e-01,
        2.4356e+01, 1.3664e+01, 2.9552e+01, 2.3364e+00, 1.5765e+01, 1.5982e+01,
        1.1516e+00, 2.1166e+00, 8.8166e+00, 7.7421e-01, 3.8544e-01, 2.0701e-01,
        8.7729e+00, 4.0654e+00, 1.7697e+00, 3.5721e+01, 1.0615e+01, 2.2975e+01,
        6.8531e+00, 1.4944e+01, 1.5004e+01, 1.4050e+01, 1.0040e+00, 4.7969e+00,
        2.4256e-01, 3.7773e+00, 6.4268e-02, 2.3796e-01, 6.0829e+00, 3.4130e-01,
        3.0110e-01, 3.7890e-01, 2.8267e+01, 9.2573e+00, 1.0543e+01, 3.3432e+00,
        1.2301e+01, 1.0015e+01, 3.9105e+00, 7.1842e+00, 2.3990e-01, 1.8106e+00,
        4.7457e-01, 8.6153e+00, 7.4664e+00, 1.4232e+01, 7.0550e-01, 1.6148e+01,
        1.0887e+01, 1.0702e+01, 1.7121e+01, 6.6855e+00, 4.0911e-01, 8.1698e+00,
        1.0642e-01, 7.1152e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [23/80], Step [000/314], LR 9.6e-05, Loss: 956.1
BCE Val Loss:  tensor([5.3556e+01, 1.7382e+01, 4.4033e+01, 1.0589e+01, 3.8098e+00, 3.8458e+01,
        2.6202e+01, 3.3637e+01, 2.3250e+01, 2.5006e+01, 1.2143e+01, 3.7310e+01,
        8.8680e+00, 7.2380e+00, 1.7042e+01, 3.9069e+00, 7.5364e+00, 1.5100e+01,
        4.3105e+00, 1.6968e+01, 1.8455e-01, 1.4859e-01, 3.4264e-02, 1.5141e-01,
        2.8123e+01, 1.9271e+01, 2.9584e+01, 1.3033e+01, 1.4193e+01, 5.7354e-01,
        1.6564e-01, 2.2947e-01, 4.4196e-01, 1.3394e+00, 3.7295e-01, 6.1061e-02,
        2.6367e+00, 5.1863e-01, 9.7685e-02, 2.9845e+00, 4.1858e-01, 2.8396e+00,
        6.1447e-01, 1.2992e+00, 7.8197e-01, 1.7983e+00, 1.5323e-01, 1.2955e-01,
        1.3817e-01, 5.8591e+00, 3.4814e-02, 1.3243e-01, 1.4109e-01, 6.5464e-01,
        1.6613e-01, 3.4887e-01, 8.8784e+00, 5.2185e+00, 5.6954e+00, 1.0365e-01,
        7.3258e+00, 1.9263e-01, 5.4616e-01, 2.5111e-01, 4.4954e-02, 2.5001e-01,
        5.1442e-02, 1.9955e+01, 1.3012e-01, 3.6209e+00, 4.3046e-02, 1.1433e-01,
        2.6128e+00, 2.9536e+00, 5.1517e+00, 3.5689e-01, 6.9664e-01, 3.7177e-01,
        7.5362e-03, 1.3449e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [23/80], Step [100/314], LR 9.6e-05, Loss: 600.7
BCE Val Loss:  tensor([1.6349e+01, 7.2392e-01, 4.5116e+00, 4.4677e-01, 8.6763e-02, 9.0977e-02,
        1.2932e-01, 1.7023e+01, 2.3525e-01, 5.2185e-02, 2.9093e-02, 6.2923e-02,
        2.9793e-02, 1.1847e+01, 5.9044e-01, 2.2654e+00, 1.4478e+00, 1.1214e-01,
        3.9295e-02, 3.7897e-02, 6.3710e-02, 3.1733e-02, 3.2728e-03, 1.0109e-02,
        3.9898e+00, 2.0038e+00, 2.7841e+01, 3.3843e+00, 8.9878e-01, 3.8139e-01,
        3.5038e-01, 6.4930e+00, 7.7200e+00, 7.1446e-02, 2.5313e+00, 7.6987e-01,
        1.2337e+01, 9.4343e+00, 6.9152e-02, 4.2397e+01, 2.0681e+01, 5.9391e+01,
        5.2193e+01, 5.6229e+01, 4.3403e+01, 6.1981e+01, 9.5305e+00, 9.2200e+00,
        3.6593e+01, 9.0943e+00, 2.3343e+01, 3.7673e+01, 5.4979e+01, 1.9767e+01,
        4.3130e+01, 7.1729e+01, 8.3402e+01, 1.1486e+01, 5.9602e+00, 5.8894e-01,
        7.8949e+01, 1.2948e-01, 1.2510e+01, 1.1454e+01, 1.2945e+01, 3.4932e+00,
        1.0659e+01, 1.3032e+01, 7.2042e+00, 4.0746e+00, 4.8058e-01, 1.1733e+01,
        6.1598e+00, 3.8721e+01, 4.7937e+00, 1.4972e+01, 9.6459e+00, 1.5867e+00,
        4.9961e-02, 4.4925e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [23/80], Step [200/314], LR 9.6e-05, Loss: 1130.3
BCE Val Loss:  tensor([2.5159e+01, 2.0835e+00, 1.6955e+01, 1.6736e+00, 3.1545e-01, 8.8437e+00,
        8.3205e+00, 1.5546e+01, 2.0909e+00, 1.4622e+01, 3.5103e+00, 8.4681e+00,
        6.1590e-01, 1.2111e+01, 1.3604e+01, 5.6473e-01, 1.4347e+00, 4.1854e-01,
        3.9959e-02, 4.1827e-02, 1.5676e-01, 4.8132e-02, 8.3648e-03, 1.0552e-01,
        2.1841e+01, 6.1053e+00, 2.1903e+01, 1.0538e+00, 1.2990e+01, 2.0124e-01,
        2.6183e-01, 1.0008e-01, 1.5745e-01, 1.7622e-01, 9.7575e-02, 6.3496e-02,
        1.0146e-01, 7.7133e-02, 2.7134e-02, 2.4351e+00, 7.7413e-01, 9.9219e-01,
        1.3037e-01, 3.2388e-01, 2.1196e-01, 1.0629e+00, 1.4826e-01, 8.2373e-02,
        3.1608e-02, 8.2451e-02, 1.1740e-02, 6.8347e-02, 4.2776e-02, 8.1557e-02,
        5.2572e-02, 2.5081e-01, 6.2702e+00, 2.0307e+00, 1.2203e+01, 1.0746e-01,
        6.7891e+00, 1.3994e-01, 9.4757e-01, 1.3476e-01, 3.4405e-02, 7.0783e-01,
        1.6304e-01, 6.0898e+00, 1.8840e-01, 1.8591e-01, 5.0723e-02, 1.4034e-01,
        3.9171e-01, 6.2080e+00, 4.0172e+01, 2.1946e+00, 6.2044e-02, 5.3234e+00,
        1.1292e-02, 2.4357e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [23/80], Step [300/314], LR 9.6e-05, Loss: 299.2
starting validation
Accuracy th:0.5 is [91.00157162 97.952023   94.13506171 98.70250119 99.34942313 98.40279724
 99.18616976 96.34872869 98.62331112 97.93618499 99.11794447 99.2336838
 99.56140885 96.11115849 97.96420609 98.24076217 97.20154482 98.68909979
 99.24343027 98.89012073 99.46028923 99.54800746 99.75390163 99.65643693
 95.48860272 97.87526955 94.97082151 98.01050182 98.48564223 98.84017008
 99.01682484 99.01560654 97.71810772 99.21419086 99.21175424 99.27266968
 98.88646581 98.87428272 99.56262716 94.04003363 98.20177629 94.07292796
 97.80460764 96.99321402 97.33068554 95.65063778 98.7743814  98.95225448
 98.5368112  99.03997271 99.26048659 99.05702903 99.27023306 99.07530366
 99.06312058 98.30411423 92.76690099 97.66937537 96.96153799 98.34066349
 94.55050499 99.06190227 97.75953022 98.07141726 99.0947966  98.2029946
 98.95956433 96.38527796 98.84869824 98.6756984  99.81603538 97.8959808
 98.55264921 95.89917277 97.54145296 97.9093822  99.26657814 98.90717706
 99.84405648 99.26414152]
Accuracy th:0.7 is [89.58102362 97.87039632 93.71230857 98.57579708 99.24343027 98.36137474
 99.11916278 96.09775709 98.47467745 97.69008662 99.05702903 99.2336838
 99.54678915 95.91866571 97.90816389 98.26147342 97.02854497 98.48929716
 99.14840219 98.76463493 99.4420146  99.60161304 99.74293686 99.67349326
 95.33996905 97.85212168 94.63213167 97.89110756 98.44178312 98.8158039
 98.93032492 98.90474044 97.50855862 99.13256417 99.14474726 99.13500079
 98.75610677 98.73052229 99.47247231 93.71352688 98.1055299  93.31270331
 97.60724163 96.76660859 97.15281247 95.35824369 98.74026876 98.86819118
 98.58188862 98.96809249 99.16180358 99.00464176 99.22150071 98.99367698
 98.9693108  98.10796652 92.25886624 97.7570936  96.86407329 98.13598762
 94.1338434  98.92179676 97.38672774 97.8265372  98.96321926 98.08238204
 98.88037426 96.24273583 98.93032492 98.58067031 99.81603538 97.38307282
 98.7037195  96.25370061 97.6316078  97.79486117 99.24952181 98.88281088
 99.84405648 99.22393733]
Avg Prec: is [97.92187482 58.54468755 78.51773371 83.5955482  93.47326058 81.9319155
 91.48711254 67.51355148 76.97320003 74.99273533 68.46670652 72.233874
 51.22110571 52.15716556 54.52279646 78.86999735 56.69153367 79.16632752
 76.90793696 69.76919401 90.13077379 78.21013963 96.14406883 96.30742057
 39.57093744 67.12355332 50.49624613 69.46013132 54.18397813 71.48021827
 89.18191695 69.03523746 73.45262907 86.57692386 89.23268629 91.33260832
 87.66425122 87.74217151 96.3390765  56.39959292 49.61351537 64.51415503
 65.93906649 60.17923638 51.87095927 67.01651308 67.80878465 56.50706623
 64.52328099 64.77014614 82.35742364 66.39799514 57.61746233 88.06411544
 62.30056152 71.18065765 70.30383703 76.08098472 53.70742351 79.81829677
 80.07203121 91.84790224 76.5352938  71.09133268 76.19431323 66.1683866
 75.02807032 44.14922897 57.05693569 78.16297932 19.71589894 85.19172837
 70.22541216 55.03420531 67.16894861 66.99369451 33.09922986 67.24941103
  9.26757737 44.28982813]
Accuracy th:0.5 is [88.77693985 97.62551626 93.49423131 98.48929716 99.1228177  98.11771299
 98.91692353 95.91257416 98.42229018 97.50246708 98.94738125 99.17642329
 99.48343709 95.73835601 97.73150912 97.80095272 96.75686212 98.46127606
 99.16545851 98.73052229 99.25926828 99.46759908 99.73075377 99.55288069
 95.41184927 97.37941789 94.73446961 97.64866412 98.27731144 98.58919847
 98.85113485 98.90230382 97.45860796 99.08992337 99.0521558  99.19957116
 98.59894494 98.75367016 99.37744423 93.65382975 98.06410741 93.757386
 97.49637553 96.63137632 97.18327018 95.2071734  98.55630414 98.84991655
 98.39061415 98.91205029 99.11185293 98.88646581 99.11672616 98.79387434
 98.9132686  98.06776233 92.04931714 97.42936855 96.67523544 98.16279041
 93.87678025 98.90717706 97.42693193 97.74734713 98.98880374 97.88136109
 98.77681802 96.13065143 98.8292053  98.46371267 99.81725369 97.91547374
 98.49782532 95.98567269 97.40622068 97.6596289  99.2202824  98.55630414
 99.84405648 99.20078946]
Accuracy th:0.7 is [86.41342089 97.46591781 92.84730937 98.4539662  99.17033175 98.10674821
 98.92910661 95.62018007 98.38452261 97.35992495 98.843825   99.13987403
 99.46759908 95.52880691 97.62551626 97.59505854 96.60579184 98.25660019
 99.06312058 98.6062548  99.29459924 99.50414834 99.73928193 99.52729621
 95.276617   97.13088291 94.4542586  97.53536141 98.16400872 98.4527479
 98.85113485 98.75610677 97.08580548 98.97296573 99.11794447 99.18007822
 98.49904363 98.7463603  99.28607108 93.31635823 97.96786102 93.22864
 97.30388275 96.5582778  97.07484071 94.76492733 98.47345914 98.79143773
 98.41010709 98.84504331 99.0241347  98.74757861 99.08139521 98.8998672
 98.82189544 97.85943154 91.26228969 97.30753768 96.56315103 98.0494877
 93.1859992  98.92667    97.21616452 97.56703744 98.86331794 97.73516405
 98.64645899 96.00760225 98.83042361 98.47833238 99.81603538 97.94958638
 98.48564223 95.73835601 97.27951658 97.54388957 99.19957116 98.40888878
 99.84405648 99.16302189]
Avg Prec: is [97.05812471 48.18671014 73.79069716 77.78068827 90.50260223 76.45575795
 87.29732531 60.83810814 69.71797578 66.28770917 58.58631332 68.13760818
 39.2979018  41.6208804  45.48627678 70.38300473 42.92940075 69.29693358
 68.86384018 59.91939366 84.96850545 69.19287073 94.95855284 94.40030207
 34.76274669 54.91012513 45.05765601 59.38055889 42.28041978 59.13272909
 86.28767875 61.53803257 66.7226476  81.3181803  85.32608464 88.30851974
 82.36286748 83.76725852 94.11954982 50.13645794 40.72270347 60.04724547
 58.17881674 52.08957249 45.42511055 60.26881659 56.92748807 47.78349709
 56.30343124 56.5421236  76.60522216 57.48861013 41.79544652 83.99989164
 49.48031481 60.74654396 64.61196938 69.57794409 44.71470149 73.27112492
 75.78327126 88.38422763 69.18130593 61.60030858 69.16838353 56.35250014
 65.60556785 34.66134454 49.96425378 71.93278219 15.5145621  80.99463357
 63.36116765 48.454257   61.09843797 59.58527444 26.24915074 55.96333168
  7.43132442 34.41086831]
mAP score regular 69.50, mAP score EMA 62.30
starting validation
Accuracy th:0.5 is [90.50751177 97.87228742 93.69908065 98.68450557 99.28993198 98.17873782
 99.05573411 95.90901164 98.55744077 97.54092234 99.06569998 99.27498318
 99.45187732 95.87911403 97.90467648 98.07409622 97.080001   98.55744077
 99.26501732 98.82402771 99.46931759 99.52163839 99.76580213 99.74088746
 95.50539403 97.57331141 94.533722   97.94952288 98.17375489 98.61972743
 99.02832798 98.92119491 97.39641727 99.27747465 99.12300371 99.32481252
 98.82402771 98.7418093  99.39208212 93.63430251 98.03174129 93.68662332
 97.37648554 96.69382365 96.96041059 95.11921668 98.78416424 98.94860104
 98.23105862 98.94112664 99.19774771 98.83648504 99.04825971 98.87634851
 98.93863517 98.16877196 91.31972993 97.53843087 96.75361886 98.05167302
 93.56204998 99.00839624 97.50604181 97.87228742 98.93116077 97.68791888
 98.79911304 95.95884097 98.75924957 98.4802053  99.79569973 97.78757755
 98.23853302 95.24877295 97.26935247 97.70535914 99.24757705 98.83897651
 99.82559733 99.13795251]
Accuracy th:0.7 is [90.0864539  97.85235568 93.57699878 98.64962503 99.25255998 98.20365249
 99.02085358 95.90652017 98.50013703 97.51600767 99.02334504 99.27000025
 99.46931759 95.7919127  97.86232155 98.12641702 96.98034233 98.46276503
 99.21518798 98.7642325  99.45436879 99.59638239 99.73839599 99.76580213
 95.48546229 97.67546154 94.62839774 97.86232155 98.21860129 98.68699704
 98.92368637 98.93116077 97.22450607 99.25006852 99.09061464 99.21767945
 98.75426664 98.54996637 99.29989785 93.59693051 97.99935222 93.36273264
 97.46866981 96.76109326 97.1024242  95.13914842 98.81904477 98.95358397
 98.36061489 98.95109251 99.10556345 98.89877171 99.03081944 98.7941301
 98.93116077 98.09651942 91.538979   97.61317488 96.61409672 97.87727035
 93.51222064 98.92866931 97.32914767 97.76266288 98.82901064 97.80750928
 98.7717069  96.05600817 98.83897651 98.39798689 99.81563146 97.39890874
 98.43785036 95.9264519  97.51351621 97.67297008 99.26501732 98.83150211
 99.82559733 99.17034158]
Avg Prec: is [97.58754247 51.89079074 74.60827396 81.57669752 88.18963949 76.25565274
 90.09054598 59.62684915 74.39958909 69.77287679 63.84277083 68.64738831
 41.22784194 47.00757827 49.77960198 79.16538377 54.32940455 74.771307
 73.44366145 64.32158232 89.69660455 80.30265246 96.2251458  97.00501398
 29.83074771 62.00679624 38.43205861 64.55921338 46.0268114  64.5500805
 86.24615215 59.67977352 65.60010138 85.27895276 81.80946432 88.58804136
 81.98483381 86.31719215 94.9838147  50.15573705 40.69579043 55.97708163
 52.89549003 46.22164281 37.75989431 57.57001476 61.63966792 43.93768191
 54.42414396 56.5995485  82.14998806 54.96151465 46.46281553 84.60994346
 51.19562198 57.81792944 61.80489642 68.3272581  46.91825595 73.65827985
 71.29309878 91.40167156 72.10314443 65.88624614 69.16875262 49.23714027
 70.36529886 36.39622499 46.5526861  72.64312922  9.83167568 80.07677545
 58.4251495  46.80779928 68.56653937 58.71572906 20.29991154 62.11535985
  3.50142087 28.55550931]
Accuracy th:0.5 is [89.39382615 97.65802128 93.44993398 98.50511996 99.22017091 98.09901089
 98.93614371 95.77447243 98.38054663 97.44624661 98.93365224 99.22266238
 99.43194559 95.57266363 97.72778235 97.87477888 96.68136632 98.41542716
 99.18778185 98.64962503 99.37713332 99.47679199 99.77078506 99.70351546
 95.45556469 97.23945487 94.58355134 97.72778235 98.10897675 98.41542716
 98.91372051 98.81406184 97.18215113 99.15290131 99.06569998 99.31982958
 98.62720183 98.6595909  99.30238932 93.50225478 97.99686075 93.62433665
 97.30672447 96.53686125 96.99030819 94.88751028 98.69197997 98.90126317
 98.16378902 98.92119491 99.13546105 98.7791813  98.96604131 98.71689464
 98.88880584 97.99436929 91.43682886 97.416349   96.50447218 97.97692902
 93.42751078 98.95358397 97.4238234  97.73276528 98.90375464 97.69290181
 98.75426664 95.90153723 98.77668984 98.31078556 99.81563146 97.78757755
 98.33570023 95.86416523 97.36901114 97.63808954 99.25754292 98.63965917
 99.82559733 99.18778185]
Accuracy th:0.7 is [88.04594265 97.51351621 93.13102624 98.59481277 99.24010265 98.13887436
 98.94112664 95.7470663  98.4652565  97.42631487 98.88631437 99.24508558
 99.42696265 95.38580362 97.64307248 97.67795301 96.55928445 98.34317463
 99.20273065 98.63965917 99.44191145 99.54406159 99.76580213 99.69354959
 95.46553056 97.10491566 94.571094   97.64556394 98.03672422 98.4278845
 98.88382291 98.82153624 97.08249246 99.09310611 99.13047811 99.31982958
 98.6147445  98.57986397 99.25255998 93.40757904 97.92211675 93.32785211
 97.2743354  96.66890899 97.042629   94.82522361 98.61723597 98.94860104
 98.26095622 98.87883997 99.05324264 98.70942024 98.96604131 98.81904477
 98.85641677 97.91713382 90.94351845 97.45372101 96.45962578 97.96198022
 93.22570197 98.93116077 97.2444378  97.62812368 98.80409597 97.73525675
 98.6222189  95.8816055  98.79911304 98.40296983 99.81563146 97.86481302
 98.46276503 95.71467723 97.28679273 97.62314074 99.26750878 98.55245783
 99.82559733 99.17283305]
Avg Prec: is [97.08792995 44.3046746  72.80270515 79.89595551 86.65366029 74.36595786
 88.13297277 56.9139283  71.49716174 66.12703079 57.08780572 67.21722681
 33.34220323 40.93204232 43.92933211 73.49154244 44.26935001 68.72911538
 69.54684835 55.19584054 87.52344398 75.16507155 95.54996699 96.29160777
 29.40285477 52.47515492 37.40294589 59.7142153  38.91978687 52.99913599
 84.16068448 54.16963245 60.73912377 80.89362491 81.87759135 87.7204688
 79.51503863 83.8202011  93.35912725 47.65845992 36.80427753 55.29363183
 48.9044541  43.50880675 36.15828938 54.70951044 56.10849822 41.82365735
 51.37287692 52.97397066 79.31854903 49.84236705 39.07526937 83.64668092
 45.72719557 52.00478201 59.58844777 64.8900755  40.95472052 70.76771867
 70.19383542 89.9348965  68.95735404 59.675628   68.01259468 46.45200786
 66.84406873 31.93728037 43.41927772 70.71953402  8.82636409 79.34695939
 56.33178471 43.65822594 65.03354095 55.83810815 17.40312286 54.10648759
  2.8274215  27.04044611]
mAP score regular 63.09, mAP score EMA 59.51
Train_data_mAP: current_mAP = 69.50, highest_mAP = 69.50
Val_data_mAP: current_mAP = 63.09, highest_mAP = 63.09
lr:  [9.619252871977788e-05, 9.619252871977788e-05]
BCE Train Loss:  tensor([25.6000, 10.4991, 24.1734,  8.1006,  4.2839,  7.2172,  4.9338, 10.8765,
         1.9488,  2.2195,  1.7316,  0.8552,  0.6145, 16.0636,  7.8792,  4.3265,
        12.1579,  1.4289,  0.4271,  0.6324,  7.6843,  1.0463,  0.1100,  0.3315,
        15.4444, 10.2011, 12.0830,  5.2004,  6.0141,  7.2965,  1.3851,  0.7324,
         3.8561,  1.3246,  4.4867,  0.3967,  7.1591,  5.3283,  4.9255, 23.0543,
         6.8674, 21.5374, 11.0744,  5.2344, 16.1648, 13.8386,  4.6579,  4.2056,
         4.6785,  3.7294,  4.9652, 10.6941,  1.2493,  3.1641,  2.2431,  3.5456,
        28.9856,  9.2991, 17.3424,  4.9173, 12.7004,  2.7091, 13.3549,  5.6002,
         1.9346,  4.7629,  1.1417, 11.8429,  4.7763,  3.4946,  0.5578, 10.7611,
         3.2793,  8.5386,  7.3271, 14.1047,  0.9687,  1.5935,  0.2847,  3.7631],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [24/80], Step [000/642], LR 9.6e-05, Loss: 555.9
BCE Train Loss:  tensor([22.2237,  5.9515, 22.5335,  1.6135,  3.6225,  3.8777,  0.6064, 12.1506,
         3.9256, 11.2696, 13.0880,  3.9015,  1.2720,  7.5315,  3.1163,  9.2195,
        12.0174,  5.4455,  0.4457,  3.0434,  4.1329,  1.5077,  1.7030,  0.9794,
        25.8247, 11.8351, 14.7731,  5.7441,  4.6880,  2.0184,  5.5440,  3.4856,
         9.9978,  0.6508,  0.3312,  4.2422,  8.7032,  3.4953,  0.4479, 19.9542,
         3.5590, 19.8695,  8.7435,  9.8298,  7.6753,  4.7588,  2.2740,  1.6452,
         3.5688,  4.1035,  1.3520,  5.2314,  2.7453,  4.7017,  8.1945, 21.3261,
        19.7840,  6.2269, 14.8859,  7.4706, 12.0718,  4.0720,  5.3857,  9.0036,
         3.3334,  6.2510,  7.3871, 13.4923,  4.8341, 13.6810,  0.1234,  4.0690,
         4.4579, 18.1898, 10.0960,  4.2038,  0.6138,  2.4147,  0.1741,  0.7441],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [24/80], Step [100/642], LR 9.6e-05, Loss: 559.5
BCE Train Loss:  tensor([28.7292,  6.9852, 17.3658,  2.7859,  1.6062,  7.7897,  3.7037, 18.0714,
         7.0516,  3.0823,  1.1066,  4.9538,  3.9382, 21.0953,  7.9116,  7.0242,
        11.7933,  5.0856,  0.9914,  6.4399,  1.2639,  2.1220,  0.1340,  1.6947,
        11.3788, 11.3577, 12.0812, 10.6914,  3.8416,  2.8776,  2.0919,  6.9351,
        11.2506,  4.0576,  0.5285,  4.7483,  1.8886,  2.3512,  0.3039, 20.3241,
         8.3183, 18.5037,  6.6933,  8.3863,  5.1637,  9.5706,  3.2679,  2.9203,
         4.7037,  5.3125,  2.1674,  0.9237,  1.6015,  8.8496,  2.4868,  4.1334,
        19.3642,  5.0006, 17.3932,  1.4358, 20.0173,  1.9708,  9.9423,  5.9081,
         0.8518,  5.9210,  1.2476,  7.9286,  2.3809,  2.5786,  3.4516,  6.4852,
         2.8219, 12.9936,  9.8518,  4.0961,  9.0815,  3.6942,  0.2168,  0.7921],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [24/80], Step [200/642], LR 9.6e-05, Loss: 527.9
BCE Train Loss:  tensor([20.8833,  8.7511, 18.0154,  6.7383,  0.9322, 12.0545,  4.0291,  8.8810,
         6.9318,  8.3862,  3.8625,  9.5860,  0.4415,  4.1213,  4.4981,  8.0801,
        10.9851,  1.4585,  5.1040,  4.1384,  3.5136,  2.6211,  0.2322,  1.0571,
        14.8455, 12.1086, 20.5947,  9.2538,  9.1861,  5.0043,  1.4297,  4.4988,
        12.1250,  0.6111,  3.6985,  2.8742,  7.5698,  2.0438,  1.9907, 23.3078,
         5.5957, 19.4538,  5.6487,  9.5559, 14.4713, 11.2621,  8.2332,  8.3807,
         7.4238, 10.4372,  3.8354,  4.0626,  0.5416,  6.4698,  1.0368,  5.3909,
        27.0299,  6.7220,  9.3566,  5.0432, 23.2868,  0.8324, 11.2601, 11.7729,
         3.5795,  3.3356,  6.6144, 14.7516, 17.4930,  2.6111,  0.8898, 10.1076,
         5.3325, 21.7249,  4.1466,  2.5830,  1.1196,  3.8804,  0.1517,  8.4872],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [24/80], Step [300/642], LR 9.6e-05, Loss: 610.4
BCE Train Loss:  tensor([17.8931,  5.7214, 16.7185,  1.5849,  2.0453, 17.9075,  0.9965, 39.7203,
         1.7467,  9.5175,  3.9215,  8.2918,  1.6842, 19.4984,  4.5534,  9.4630,
        31.5962,  6.4710,  0.2401,  4.4511,  0.3860,  0.1723,  0.0731,  0.1674,
        15.6671,  6.6885, 14.5139,  4.9562,  8.4179,  6.7773,  3.5250,  8.1469,
        10.7471,  2.7174,  2.2439,  3.2382,  3.1099,  8.4214,  1.8748,  9.0237,
         1.4740, 13.8630,  6.4277,  8.5735, 14.3137, 16.9160,  9.2232,  6.5174,
         4.2121,  6.9418,  2.2415,  9.6710,  1.5746,  0.7489,  1.7221,  3.4406,
        28.5220,  2.5764,  9.5762,  2.9476, 27.2240,  4.2787,  3.2034,  5.4840,
         2.0975,  2.7662,  3.3012, 10.6924,  2.3433,  2.2493,  0.0757, 11.1112,
         4.1555, 17.9745, 10.9247,  9.3947,  0.6957,  6.9289,  0.3704,  2.6305],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [24/80], Step [400/642], LR 9.6e-05, Loss: 594.3
BCE Train Loss:  tensor([26.3676,  2.5144, 11.0993,  4.5657,  0.8621,  2.7880,  0.8846, 11.1701,
         1.9228,  7.9221,  0.8174,  2.8306,  1.7410,  9.0276,  8.6477,  6.6369,
        17.2122,  2.8979,  2.4720,  9.4819,  2.3845,  6.7729,  0.3269,  2.4723,
         9.7435, 11.7561, 19.7925,  5.2357,  7.2773,  2.3296,  7.4738,  3.4601,
         5.4397,  1.8005,  3.1000,  3.4867,  1.2203,  1.2932,  1.2229, 16.9683,
         6.4746, 13.6257,  2.9057,  5.8449,  8.2225,  9.1280, 12.6813,  4.5821,
         1.0057,  0.3490,  0.2617,  1.3055,  1.4761,  2.8584,  2.6911,  5.4535,
        24.9881,  6.8578,  8.8452,  4.8400, 23.2986,  6.0726,  8.6373,  4.2500,
         0.6257, 14.8724,  0.6936, 10.3921,  7.7234,  5.0905,  9.9578,  7.5501,
         2.9493,  9.5582,  8.4323, 11.3530,  1.4058,  5.6908,  0.2020,  5.8555],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [24/80], Step [500/642], LR 9.5e-05, Loss: 514.4
BCE Train Loss:  tensor([29.8924,  7.6200, 14.3098,  8.0887,  2.9054, 11.8270,  0.8910, 16.1751,
         2.9319,  6.0348,  7.2002,  1.4898,  0.3538, 18.5214, 13.6249,  8.3183,
        13.3658,  7.2246,  1.8321,  2.5204,  9.3101, 12.3663,  2.9749,  2.1639,
        10.9376,  4.6270, 19.7389,  4.1921, 17.4797,  5.2110,  2.4996,  2.8801,
         5.4256,  0.6390,  2.7312,  8.1306,  1.3682,  3.6990,  0.5876, 16.7856,
         5.5403, 20.3895,  6.5677, 11.0207,  7.5140, 13.6201,  5.8219,  9.3937,
         4.0344,  6.6047,  3.9532,  1.1065,  4.3872, 12.4544,  1.5144,  8.0563,
        22.7051,  6.6876, 10.2844, 12.6511, 22.7292,  1.4877, 10.6483,  4.4554,
         4.8921,  3.8323,  8.2295, 22.3511,  8.8028,  2.6461,  0.3189,  6.7602,
         4.0447, 20.8061, 11.7699,  8.9071,  0.9286,  5.3294,  0.1574,  1.2831],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [24/80], Step [600/642], LR 9.5e-05, Loss: 633.6
BCE Val Loss:  tensor([4.9078e+01, 2.2328e+01, 4.7717e+01, 2.1632e+01, 2.5254e-01, 8.9389e+00,
        6.2217e+00, 1.8973e+01, 4.9419e+00, 8.2939e+00, 8.4905e+00, 1.1788e+01,
        7.7389e+00, 1.6738e+01, 8.5483e+00, 2.9450e+01, 2.4862e+02, 1.5087e+00,
        1.1833e+00, 6.1841e+00, 4.6896e-01, 2.9540e-01, 2.0683e-02, 1.7502e-01,
        2.4484e+01, 1.3860e+01, 2.9039e+01, 1.0437e+01, 1.3277e+01, 1.4979e+01,
        2.3545e+00, 1.6483e+00, 9.0179e+00, 6.2152e-01, 9.0945e-01, 4.8862e-01,
        1.0545e+01, 4.4902e+00, 2.0641e+00, 3.9027e+01, 1.0603e+01, 2.1177e+01,
        6.9050e+00, 1.4550e+01, 1.4946e+01, 1.3564e+01, 1.6633e+00, 4.4852e+00,
        4.4407e-01, 4.1330e+00, 6.5735e-02, 2.7331e-01, 5.9764e+00, 3.1937e-01,
        4.0745e-01, 1.3432e+00, 2.7201e+01, 6.3499e+00, 9.5325e+00, 3.7523e+00,
        8.9528e+00, 7.7324e+00, 3.2774e+00, 7.3926e+00, 2.7021e-01, 1.5703e+00,
        3.7972e-01, 1.0773e+01, 7.9027e+00, 1.2391e+01, 3.6608e-01, 1.6005e+01,
        1.2136e+01, 1.0269e+01, 1.6168e+01, 5.0717e+00, 6.3094e-01, 7.4846e+00,
        9.7597e-02, 5.8192e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [24/80], Step [000/314], LR 9.5e-05, Loss: 984.0
BCE Val Loss:  tensor([5.7893e+01, 1.9170e+01, 3.9749e+01, 1.0359e+01, 1.4420e+00, 3.4211e+01,
        4.8785e+01, 3.3908e+01, 2.1735e+01, 2.7368e+01, 1.5006e+01, 4.2585e+01,
        1.0698e+01, 8.6437e+00, 1.7063e+01, 4.6800e+00, 8.9455e+00, 1.5953e+01,
        3.1378e+00, 1.2473e+01, 3.0656e-01, 9.6441e-02, 5.0439e-02, 1.1729e-01,
        3.0632e+01, 2.0026e+01, 3.3774e+01, 1.5344e+01, 1.7548e+01, 7.4501e-01,
        8.8668e-01, 5.0157e-01, 6.9832e-01, 1.8516e+00, 1.2067e+00, 2.1980e-01,
        3.8956e+00, 6.0370e-01, 5.8364e-01, 2.1172e+00, 3.4908e-01, 3.7696e+00,
        1.0475e+00, 2.5416e+00, 1.2147e+00, 2.4496e+00, 3.1406e-01, 2.2077e-01,
        1.1636e-01, 5.3467e+00, 2.5296e-02, 1.1492e-01, 6.5551e-02, 3.1142e-01,
        2.1995e-01, 9.7050e-01, 1.0451e+01, 6.2832e+00, 4.7611e+00, 2.5455e-01,
        5.6812e+00, 8.0664e-02, 1.0820e+00, 5.6788e-01, 9.6663e-02, 2.2568e-01,
        6.8778e-02, 1.9503e+01, 1.5035e-01, 2.9872e+00, 9.8003e-03, 1.5963e-01,
        3.9359e+00, 3.4068e+00, 4.3079e+00, 7.7481e-01, 3.9831e-01, 5.4721e-01,
        4.7112e-03, 1.0750e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [24/80], Step [100/314], LR 9.5e-05, Loss: 649.9
BCE Val Loss:  tensor([1.3256e+01, 6.2257e-01, 4.0549e+00, 9.2302e-02, 9.9570e-02, 1.1108e-01,
        6.0389e-02, 1.5555e+01, 3.1744e-01, 4.3277e-02, 4.9197e-02, 5.2238e-02,
        1.4380e-02, 1.2227e+01, 4.8744e-01, 1.8773e+00, 9.9154e-01, 9.1734e-02,
        9.3810e-02, 5.5298e-02, 6.8407e-02, 1.9493e-02, 4.3406e-03, 1.9496e-02,
        4.2059e+00, 2.3092e+00, 2.4339e+01, 1.3622e+01, 4.2672e-01, 4.4983e-01,
        1.7705e-01, 4.5784e+00, 8.1330e+00, 1.3435e-01, 3.1682e-01, 9.0923e-02,
        1.2014e+01, 9.2955e+00, 1.2615e-01, 4.2789e+01, 2.2340e+01, 6.2778e+01,
        5.3446e+01, 5.6684e+01, 4.6799e+01, 5.9477e+01, 9.5616e+00, 9.4198e+00,
        3.0286e+01, 1.1508e+01, 2.5900e+01, 3.8263e+01, 6.6222e+01, 1.3133e+01,
        3.7493e+01, 5.7830e+01, 7.9994e+01, 1.0742e+01, 9.4754e+00, 5.6382e-01,
        8.3437e+01, 8.6480e-02, 1.1203e+01, 1.1530e+01, 1.2892e+01, 5.1279e+00,
        9.1612e+00, 1.2582e+01, 7.8657e+00, 6.1229e+00, 1.5353e-01, 1.0469e+01,
        4.8832e+00, 4.0841e+01, 2.4341e+00, 1.5547e+01, 1.0258e+01, 1.2675e+00,
        4.5472e-02, 3.5902e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [24/80], Step [200/314], LR 9.5e-05, Loss: 1121.5
BCE Val Loss:  tensor([2.6427e+01, 1.9128e+00, 1.1786e+01, 1.7239e+00, 9.1639e-01, 1.0647e+01,
        7.3449e+00, 1.5518e+01, 3.4390e+00, 1.6282e+01, 5.6332e+00, 6.4369e+00,
        1.7842e-01, 1.4461e+01, 1.6918e+01, 5.8903e-01, 8.0226e-01, 5.5122e-01,
        1.0694e-01, 1.0021e-01, 3.8768e-01, 3.6925e-02, 1.3924e-02, 3.2896e-01,
        2.3725e+01, 7.8812e+00, 2.3665e+01, 2.8473e+00, 1.5744e+01, 2.5005e-01,
        6.4916e-01, 3.6818e-01, 1.2697e-01, 4.4463e-01, 1.5674e-01, 1.5457e-01,
        8.8986e-01, 1.0882e-01, 3.1477e-02, 2.4257e+00, 1.3408e+00, 1.2440e+00,
        4.0824e-01, 1.2016e+00, 4.1060e-01, 1.4508e+00, 2.4498e-01, 1.2821e-01,
        6.2309e-02, 1.2396e-01, 1.7182e-02, 6.1032e-02, 2.8514e-02, 1.2514e-01,
        7.4455e-02, 6.6020e-01, 7.6544e+00, 1.9337e+00, 1.3430e+01, 6.0327e-01,
        5.8042e+00, 9.0554e-02, 1.8788e+00, 9.0363e-01, 8.6590e-02, 2.1671e+00,
        2.5299e-01, 6.2575e+00, 1.8176e-01, 3.4693e-01, 1.1054e-02, 1.6963e-01,
        1.2603e-01, 7.6554e+00, 6.7688e+01, 4.4426e+00, 1.1611e-01, 5.6826e+00,
        8.7804e-03, 2.6618e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [24/80], Step [300/314], LR 9.5e-05, Loss: 357.1
starting validation
Accuracy th:0.5 is [91.25863476 98.04826939 94.29466015 98.75123354 99.35795129 98.41619863
 99.05702903 96.40964413 98.78656449 97.98126241 99.12038109 99.23490211
 99.54191591 96.22811613 98.07263557 98.36259305 97.2271293  98.72199413
 99.32262034 98.82798699 99.51633143 99.57602856 99.77948612 99.61866936
 95.45083515 97.95811455 95.03782849 96.88600285 98.43081834 98.95956433
 98.97662066 99.02778962 97.77780485 99.26048659 99.24952181 99.30190909
 98.97418404 99.01682484 99.56262716 94.26785736 98.2297974  94.14480818
 97.71810772 96.85920006 97.38185451 95.67987719 98.84017008 99.00220514
 98.55508583 99.03022624 99.14596557 98.97662066 99.15814866 99.01438823
 99.15814866 98.38817753 92.93990083 97.88136109 97.07118578 98.52584642
 94.58949087 99.14352895 97.87892448 98.11040314 99.16302189 98.16400872
 98.94372632 96.43157369 98.93519816 98.68666317 99.81603538 98.2858396
 98.73661383 96.24517245 97.71079787 97.90816389 99.26657814 98.8998672
 99.84405648 99.26292321]
Accuracy th:0.7 is [90.09636822 97.98248072 93.69159732 98.56605061 99.3445499  98.20421291
 98.86453625 96.2098415  98.64036744 97.81557242 99.09845153 99.19835285
 99.51998635 96.02709519 97.95811455 98.20055799 97.04438299 98.56361399
 99.23733873 98.94372632 99.53460606 99.48709202 99.74659178 99.65278201
 95.29367332 97.8679597  94.61385704 97.73272743 98.29436776 98.90352213
 99.00342345 98.84747993 97.53901634 99.13987403 99.26779644 99.18860638
 98.85600809 98.87915596 99.52120466 93.8974915  98.16766365 93.63799174
 97.77171331 97.00174218 97.15646739 95.27783531 98.80605743 98.94007139
 98.37477614 99.0521558  98.9973319  98.86940949 99.108198   98.98393051
 99.04728256 98.39426908 92.54029556 97.76074853 96.99930556 98.30898746
 94.01932238 99.01926146 97.62551626 98.13111439 99.05459241 98.21517769
 98.74148707 96.24639076 98.96687419 98.62331112 99.81603538 98.04705108
 98.55752245 96.17816547 97.52317832 97.88501602 99.2336838  98.85844471
 99.84405648 99.22759226]
Avg Prec: is [98.06114936 60.53388284 79.5093822  83.00427403 93.75264331 82.41046795
 92.39385742 68.62790223 79.39572885 76.11886863 67.65502207 72.39218433
 51.78870476 53.79258224 57.10286851 80.55758819 57.79350536 79.08400549
 78.90830241 71.09182175 91.49987595 80.06797956 96.96623115 96.46010379
 40.28824487 68.47973937 51.40962019 69.52009886 55.73892162 74.96444212
 89.34364097 69.52692883 74.85804966 88.40802584 90.16824801 91.63579235
 89.10526522 89.74221715 96.29042972 59.04766179 51.71876526 65.21262022
 67.09669017 60.71421559 52.62615506 67.73825008 71.20504331 59.88191049
 66.23250721 67.73243472 82.9570148  67.08318577 55.73171196 87.47581144
 65.1233832  72.30967512 71.81596385 78.12889543 56.4333054  82.7904527
 80.9944295  92.66230031 78.04222267 72.88263523 78.23929456 68.43756694
 77.4026482  46.38469273 60.71342527 79.43500013 19.37617829 86.32799496
 73.23812559 56.42739537 69.36518761 68.05464353 34.76078424 67.37562411
 12.17542261 45.22630869]
Accuracy th:0.5 is [89.47259414 97.7290725  93.65382975 98.54655767 99.18129652 98.20664953
 99.00586007 96.11846834 98.51488164 97.6450092  98.95834602 99.17885991
 99.51023988 95.86018689 97.80095272 98.01415675 96.86285498 98.5087901
 99.17276836 98.78656449 99.36769776 99.4980568  99.75268333 99.55166238
 95.49469427 97.51099524 94.79660336 97.72785419 98.31142408 98.66473362
 98.83651515 98.93763478 97.48906568 99.14352895 99.1215994  99.2056627
 98.68422656 98.82676868 99.40302872 93.79271695 98.05314263 93.80977327
 97.52561494 96.65452419 97.26124194 95.26443391 98.61600127 98.89499397
 98.42716341 98.94738125 99.12890925 98.89133904 99.13865572 98.82189544
 98.94616294 98.09334682 92.21257051 97.59262192 96.76904521 98.3138607
 94.07414627 99.00464176 97.54632619 97.83384705 99.03144455 98.00075535
 98.85113485 96.22689782 98.90839537 98.5368112  99.81603538 97.97273425
 98.58798017 96.09410217 97.50003046 97.71810772 99.22393733 98.62696605
 99.84405648 99.21175424]
Accuracy th:0.7 is [87.45507487 97.57069236 93.02883737 98.49417039 99.23977534 98.12867777
 98.98758543 95.80170807 98.47955069 97.52196002 98.87915596 99.15205711
 99.47734555 95.62139837 97.67181199 97.80338933 96.69229176 98.39305077
 99.0947966  98.67082516 99.37500761 99.53338775 99.75024671 99.54313422
 95.30220148 97.26977011 94.46035014 97.6169881  98.20543122 98.52462811
 98.84747993 98.78900111 97.16743217 99.03388117 99.12403601 99.22393733
 98.57701539 98.84626162 99.30921894 93.4649919  97.97273425 93.30904838
 97.38429113 96.6557425  97.07727732 94.90259622 98.52950135 98.82676868
 98.44300143 98.86575456 99.08505013 98.78534618 99.10454307 98.92057845
 98.86940949 97.94714977 91.37315579 97.41109392 96.64599603 98.16888196
 93.35899904 98.97905727 97.4220587  97.68886831 98.95347279 97.84481183
 98.7317406  96.04049658 98.86331794 98.53315627 99.81603538 97.99100888
 98.59041678 95.78587006 97.35870664 97.62186133 99.20078946 98.49173378
 99.84405648 99.18007822]
Avg Prec: is [97.33055593 51.49865877 74.97349792 78.59825615 91.26886055 77.87177447
 89.01661947 62.91580129 72.95062729 69.75261206 58.97442224 68.39812843
 41.89118492 44.75216536 48.25192867 73.79462301 45.63602215 71.41750117
 70.50574034 62.52210796 87.45823177 71.34105553 96.04577725 94.65986451
 36.61866651 58.26873562 46.59904485 61.25131001 43.87384925 62.64322251
 85.97747961 63.81869079 68.68996508 83.07251974 86.83902892 89.22247612
 83.57842114 85.35120963 94.21817518 52.55913195 42.72116977 61.0056676
 59.65180908 53.3081031  47.19135579 62.05776203 61.78754436 51.44470902
 58.10753034 59.99124851 78.7568971  58.3776619  42.74964218 84.80273033
 52.61834139 62.86686184 66.45128464 71.69500713 47.71282077 76.05105836
 77.18817055 89.51106871 72.03919181 64.05794232 72.10608081 59.41877056
 69.81704246 37.5950742  54.62248703 74.81846263 14.76644098 82.4882402
 66.97097117 50.51397409 63.4400952  61.61920141 26.93551721 57.08946493
  8.98806707 35.76183602]
mAP score regular 70.81, mAP score EMA 64.29
starting validation
Accuracy th:0.5 is [90.59222164 97.81498368 93.92580412 98.66457383 99.37215038 98.19119516
 98.95358397 95.71467723 98.5549493  97.56085407 99.01088771 99.26252585
 99.47180905 95.89904577 97.90218502 98.22607569 97.0202058  98.60976157
 99.31484665 98.68699704 99.51665546 99.61880559 99.77825946 99.74337893
 95.50788549 97.67047861 94.5785684  96.64648579 98.20614396 98.57238957
 99.04327678 98.99095598 97.38894287 99.26750878 99.16037571 99.33228692
 98.83150211 98.83150211 99.39706505 93.64675985 98.02426689 93.72648678
 97.20457433 96.28771458 97.01273139 95.30358522 98.7567581  98.95109251
 98.31078556 98.88133144 99.08563171 98.86389117 99.01088771 98.87883997
 98.95607544 97.95699728 91.16027605 97.64058101 96.58669058 98.17624636
 93.58945611 99.05075118 97.52846501 97.76017141 98.97600718 97.44624661
 98.77419837 95.9712983  98.74430077 98.51508583 99.81314    97.96447168
 98.5175773  95.6349503  97.60071754 97.61317488 99.25505145 98.85392531
 99.82559733 99.13296958]
Accuracy th:0.7 is [90.43276777 97.86730448 93.60689638 98.5624237  99.38709919 98.12890849
 98.78416424 95.9189775  98.57488103 97.61068341 99.05075118 99.25255998
 99.45686025 95.81931883 97.89720208 98.16129756 96.97037646 98.49764556
 99.28993198 98.79163864 99.55153599 99.51914692 99.75085333 99.75832773
 95.46054762 97.69041034 94.64085507 97.51849914 98.14884022 98.7193861
 99.03331091 98.90873757 97.31669034 99.22515385 99.16785011 99.24010265
 98.7791813  98.68450557 99.35969305 93.62433665 98.03174129 93.51720358
 97.43129781 96.72870419 97.07003513 95.05443855 98.7866557  98.96604131
 98.29832823 98.99344744 98.95358397 98.78914717 98.96105838 98.83399357
 98.93863517 98.20365249 91.48914966 97.66549568 96.65645165 98.03174129
 93.44495104 98.96853278 97.44624661 97.89471062 98.82901064 97.82494955
 98.63467623 96.03607644 98.83399357 98.48269676 99.81563146 97.81249221
 98.45279916 96.01863617 97.45122954 97.73774821 99.26750878 98.81157037
 99.82559733 99.14791838]
Avg Prec: is [97.64156975 51.74537056 75.40985833 81.43844993 89.70675796 76.46331326
 90.13641176 58.6402924  75.26866088 69.9151374  64.05687876 69.19089442
 43.31383229 47.70577579 50.68210224 79.13875932 54.65882292 74.21392296
 76.42048079 64.16330994 90.84222786 83.90175283 96.12035751 97.50357336
 29.12606726 62.5783289  38.66940574 66.09861421 46.36467892 65.32664226
 86.74100812 61.86683546 66.37216493 85.87512938 83.42953658 88.93024231
 83.80172194 87.01268368 94.41945229 50.48733104 42.85860925 56.50099963
 52.63473418 45.76802001 37.56566353 58.47010289 62.0031295  45.20152967
 54.69623569 58.6603653  81.45701098 53.49515989 46.26691131 85.1183095
 52.1618499  59.08030031 61.45138233 69.21104805 46.00707403 75.25228356
 71.53138667 91.45426098 71.17836454 65.97087859 69.35927218 51.49798736
 70.09144636 35.31253342 47.46989852 73.18432093  8.94726089 79.79073732
 58.86964051 47.25611065 68.40703364 58.34308518 20.45241136 61.56456725
  2.89021607 25.19523817]
Accuracy th:0.5 is [89.76754615 97.70785061 93.57699878 98.55993223 99.26252585 98.11894262
 98.97102424 95.84174203 98.4204101  97.48860154 98.98348158 99.23761118
 99.42945412 95.63245883 97.77013728 97.93706555 96.76607619 98.49764556
 99.22266238 98.6894885  99.41201385 99.51416399 99.76331066 99.72095573
 95.47798789 97.3490794  94.57358547 97.76017141 98.13887436 98.46027356
 98.92617784 98.86389117 97.24692927 99.18778185 99.10307198 99.32730398
 98.66457383 98.69197997 99.32232105 93.50723771 97.99686075 93.72150385
 97.3266562  96.51194658 96.97785086 94.99962628 98.7343349  98.91372051
 98.17624636 98.92119491 99.14293545 98.8016045  98.98099011 98.77419837
 98.91122904 98.01928395 91.4866582  97.49856741 96.54682712 98.03921569
 93.50723771 98.99344744 97.50604181 97.75518848 98.94610957 97.71532501
 98.7866557  95.90901164 98.77668984 98.34068316 99.81563146 97.80252635
 98.36808929 95.8816055  97.45870394 97.65802128 99.25255998 98.67204823
 99.82559733 99.17532451]
Accuracy th:0.7 is [88.63143733 97.56334554 93.31041184 98.62471037 99.27498318 98.15880609
 98.97351571 95.78942123 98.50761143 97.46866981 98.94112664 99.24757705
 99.43941999 95.48297082 97.71532501 97.82993248 96.65894312 98.4054613
 99.22764531 98.67204823 99.44938585 99.57146772 99.77327653 99.72095573
 95.49044523 97.18962553 94.61344894 97.70785061 98.09153649 98.47771383
 98.93614371 98.85890824 97.11239006 99.14542691 99.12798665 99.33976132
 98.6745397  98.6296933  99.29242345 93.47484864 97.92211675 93.42751078
 97.31669034 96.74863592 97.06006926 94.90744201 98.69197997 98.96105838
 98.28337943 98.89378877 99.09061464 98.7343349  98.99095598 98.86139971
 98.87385704 97.98689489 91.08054912 97.50105887 96.48952338 98.02177542
 93.31788624 98.97102424 97.31419887 97.69041034 98.87385704 97.77262875
 98.68699704 95.93890924 98.8165533  98.41542716 99.81563146 97.87976182
 98.48518823 95.7844383  97.35406234 97.63559808 99.26750878 98.60976157
 99.82559733 99.17532451]
Avg Prec: is [97.26365107 46.26916603 73.58207639 80.75539438 87.48381314 75.21196989
 88.7175934  57.87514453 72.55546371 67.5179766  59.65240749 67.80956625
 35.34607696 42.81595279 45.52054929 74.9775242  47.16531806 70.89932214
 71.54749205 57.69774225 88.84192814 77.24331274 95.76673725 96.6140246
 29.89025847 55.04899418 37.93357519 61.36108258 40.83384568 55.46717122
 84.80171065 55.69932672 61.83403161 82.14492092 82.47590575 88.12407657
 80.60621361 84.50489423 93.78124216 48.42932135 38.04100756 55.86598041
 49.83743996 44.39656375 36.77455359 55.74350853 58.11370126 43.10965063
 52.59858691 54.08421007 80.12648435 51.46593694 41.20507377 84.42516185
 47.55983083 53.91649843 60.42593421 66.25283697 42.52913242 72.14601076
 70.68630358 90.50392118 70.15040502 61.20075686 69.18278188 47.87387003
 68.51020726 33.30886758 44.19346136 71.66962263  8.90581966 80.02419659
 57.24947017 44.61951497 65.93720154 56.95306241 18.24929769 56.13307022
  2.93801657 27.72501369]
mAP score regular 63.48, mAP score EMA 60.71
Train_data_mAP: current_mAP = 70.81, highest_mAP = 70.81
Val_data_mAP: current_mAP = 63.48, highest_mAP = 63.48
lr:  [9.519784918743882e-05, 9.519784918743882e-05]
BCE Train Loss:  tensor([23.9121, 10.5218, 20.6481,  8.3959,  4.5702,  2.1043,  1.1552,  9.4899,
         4.1103,  1.7809,  4.6662,  4.5790,  0.2357, 18.2707,  7.4127, 10.0350,
         4.9249,  0.6581,  0.5618,  2.6320,  3.2910,  1.9580,  0.1910,  0.3280,
         6.2208,  6.5310, 10.1741,  6.7671,  6.6925,  6.1419,  2.0225,  1.8484,
         5.0134,  4.0399,  0.7769,  0.3974,  1.1440,  2.7968,  0.6590, 15.2734,
         5.6910, 16.4926, 10.1114,  8.8417,  5.8547, 12.4957,  1.8873,  1.8113,
         3.4084,  4.0173,  5.1985,  2.4134,  0.7002,  1.8205,  3.2886,  6.1873,
        14.5247,  2.7782, 11.6464,  8.6629, 18.8482,  0.4193,  5.2688,  3.2846,
         1.1222,  6.3639,  5.2106, 13.6974,  1.2451,  3.6847,  0.0718,  1.9286,
         1.4710, 11.7478,  5.0889,  8.0699,  5.2323,  1.2323,  0.0885,  3.7708],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [25/80], Step [000/642], LR 9.5e-05, Loss: 448.6
BCE Train Loss:  tensor([15.8861,  4.0139, 17.7463,  7.6350,  0.4407,  4.1322,  0.7746, 13.4899,
         3.0440, 10.7263,  6.2493,  0.8532,  6.5704,  9.0295, 18.4550,  7.4972,
         9.6188,  2.5458,  0.9863,  4.1842,  0.6784,  0.6036,  0.1419,  0.1699,
        24.1583, 13.4077, 16.8580,  7.9821,  2.0910, 10.0141,  3.0477,  2.1447,
        10.0997,  0.8874,  4.0708,  1.7562,  2.9923,  3.1419,  0.3808, 17.2246,
         8.1132, 13.7951, 14.9256, 11.2796, 18.9723, 15.7403,  4.1836,  3.7503,
         0.9719,  0.7571,  3.6924,  0.9332,  2.4325,  4.7197,  2.1938,  4.3038,
        20.7732, 12.8232, 12.5232, 11.4993, 11.0109,  1.1571,  6.3182,  4.1256,
         3.5996,  7.3930,  3.5436,  8.4076,  1.5286,  2.2482,  0.1293,  2.2119,
         5.4139, 10.8055,  5.5306,  4.7793,  0.5364,  6.7910,  0.1325,  0.4847],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [25/80], Step [100/642], LR 9.5e-05, Loss: 520.3
BCE Train Loss:  tensor([39.9413,  5.1988, 21.5531,  1.5433,  7.7039,  8.0947,  0.9795, 12.3213,
         4.1250,  9.5436,  5.7093,  4.0101,  0.4268, 11.1075,  7.7984,  5.4579,
         7.7355,  7.9290,  0.6751,  1.8273,  2.4983,  0.1586,  0.4954,  1.5256,
        25.4124, 15.0922, 16.7090, 20.7691, 15.1331,  2.3002,  3.0144,  7.6411,
         5.6510,  1.3882,  0.2560,  0.1853,  3.0429,  0.7880,  0.1683, 41.3655,
         4.2391, 24.6982,  5.0919, 13.8504,  6.4563,  9.4484,  4.0189,  3.3431,
         7.2061,  3.5588,  0.2938,  2.5801,  2.3146,  1.0181,  3.4306,  4.8667,
        21.8375,  5.8585, 11.7768,  2.4352, 21.6972,  4.6327,  3.4905,  7.1632,
         0.8634,  5.9878,  6.2952, 15.5384,  9.4745,  2.3756,  0.2942,  4.1211,
         5.7481,  7.0954, 14.1786,  3.9726,  3.5725,  6.6080,  0.6386,  2.2359],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [25/80], Step [200/642], LR 9.5e-05, Loss: 591.6
BCE Train Loss:  tensor([24.9323,  5.2059, 16.1621, 10.7676,  0.6902,  7.0561,  0.9201, 11.0185,
         6.6785,  4.3570,  4.3757,  3.4719,  0.7867, 14.4999,  5.4727, 14.6558,
        29.0350,  2.0923,  4.6506,  8.4114,  1.3819,  0.6306,  1.0199,  4.5505,
         9.4069,  9.0099, 24.7296,  5.2593,  2.6030, 11.6874,  2.3236,  0.4961,
        10.6452,  2.5099,  4.1856,  6.1685,  3.3495,  5.6113,  0.4205, 24.6282,
         9.0687, 21.8578,  3.2499,  7.0370,  5.1395, 15.2454,  6.7775,  7.8679,
        11.9463,  4.7666,  0.2424,  3.8303,  6.7580,  3.9999,  1.3020, 13.7553,
        22.5857,  6.3639,  6.2740,  4.2987, 22.6622,  4.6145, 12.0118, 10.8698,
         5.0932,  5.5441,  3.5092, 12.8800,  1.9451,  1.5915,  0.1206,  7.2119,
         2.9287, 20.0300,  2.9425, 12.3297,  6.2406,  2.9498,  0.1723,  7.7146],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [25/80], Step [300/642], LR 9.5e-05, Loss: 611.6
BCE Train Loss:  tensor([25.7665, 12.9503, 17.8883,  7.6670,  1.8123,  7.3282,  2.1433, 10.8481,
         5.2754,  5.7584,  4.4587,  5.1728,  1.9458, 22.3658, 13.2197,  6.4219,
        13.8203,  5.7195,  6.5890,  3.2518,  3.8493,  0.5975,  0.2002,  1.2613,
        16.1809,  8.8206, 20.2881,  9.3736,  7.7008,  2.9651,  6.4124,  3.9574,
         4.8326,  1.4088,  1.9388,  0.9115,  2.4416,  2.9590,  1.8397, 23.9156,
         1.6627, 13.9847,  6.8868, 11.7783,  5.4457,  8.7923,  0.9031,  0.9232,
         2.0514,  2.0062,  4.9778,  1.8478,  0.7206,  4.4951,  6.9825,  4.0452,
        18.2969,  5.0333,  5.8781,  9.8022, 14.6046,  2.0483,  2.8633,  8.1177,
         1.8590,  1.8740,  0.9063, 11.6490,  2.6374,  2.3360,  0.0727,  2.8015,
         6.6596, 12.7209,  5.0460,  5.7716,  3.3760,  1.2314,  0.1621,  0.3951],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [25/80], Step [400/642], LR 9.5e-05, Loss: 505.9
BCE Train Loss:  tensor([45.3445,  7.1228, 16.2535,  3.4216,  6.4055,  7.3945,  1.5522, 15.2877,
         5.0431,  5.1392,  1.4939,  0.8387,  0.7891,  9.6011,  5.6143,  8.2332,
         6.8711, 24.4511,  3.9415, 10.8638,  0.1908,  0.1149,  0.0979,  1.0324,
        25.6306,  5.9369, 10.8181,  5.9277, 13.7072,  2.2460,  4.7721, 11.7118,
         2.8469,  0.4123,  1.4363,  0.6671,  4.6472,  1.7440,  6.0196, 21.2211,
         7.5356, 24.9227, 13.4835, 16.5166,  9.4016, 15.9477,  7.1446,  2.0197,
         8.0551,  1.1326,  4.7350,  2.1815,  5.0361, 12.7456,  0.7644, 17.4844,
        19.9538,  9.5244, 12.6794,  7.0686, 17.6559, 10.7795,  7.7804,  3.0190,
         3.2476,  5.6318,  3.4100,  7.1513,  8.7719,  6.1746,  0.2032,  9.4546,
         6.9582, 36.9246,  3.2210,  3.8818,  7.6762,  2.9651,  0.1063,  4.5767],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [25/80], Step [500/642], LR 9.4e-05, Loss: 654.8
BCE Train Loss:  tensor([30.5398, 13.0534, 35.0858,  3.9577,  1.5335,  7.6654,  1.0566, 17.0098,
         2.2994,  8.0428,  6.2162, 13.3404,  0.9846, 20.8902,  3.1751,  4.8213,
         7.0000,  4.4826,  1.7212,  5.4398,  0.3444,  1.1298,  0.1404,  2.1893,
        18.6730, 10.4401, 18.6646,  8.2362,  2.2855,  3.4956,  5.5235,  7.5094,
         3.4830,  4.6883,  0.5363,  0.4063,  3.5881,  1.1778,  0.3615, 20.9460,
        13.1413, 24.7384,  4.4474,  7.8603, 13.8895, 15.5425,  7.5605,  6.3560,
         9.2752,  1.0557,  1.0450,  1.4685,  0.2641,  5.5850,  0.5845,  1.7468,
        39.5164,  6.4452, 21.1620,  2.0178, 19.7332,  7.1991,  6.9447, 19.5576,
         4.0013,  5.8478,  5.9444, 15.5667,  3.1647,  2.2059,  0.2475, 10.7435,
         1.5466, 19.7108, 10.9420,  7.9230,  4.9466,  1.3878,  0.0508,  6.1219],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [25/80], Step [600/642], LR 9.4e-05, Loss: 639.6
BCE Val Loss:  tensor([4.8724e+01, 1.9791e+01, 4.0453e+01, 1.9778e+01, 7.0024e-02, 1.0862e+01,
        5.2042e+00, 1.9658e+01, 5.3053e+00, 7.7556e+00, 7.0415e+00, 1.0608e+01,
        7.1770e+00, 1.6900e+01, 7.5748e+00, 2.6703e+01, 2.3176e+02, 2.5065e+00,
        1.6369e+00, 2.9290e+00, 2.9124e-01, 5.4172e-01, 2.5883e-02, 9.5401e-02,
        2.5183e+01, 1.3770e+01, 2.7026e+01, 1.8416e+00, 1.3178e+01, 1.2553e+01,
        1.4703e+00, 3.1568e+00, 9.1490e+00, 8.0337e-01, 5.3770e-01, 6.1097e-01,
        1.8191e+01, 5.1186e+00, 3.4086e-01, 3.6434e+01, 1.1288e+01, 1.9072e+01,
        5.9324e+00, 1.6792e+01, 1.5155e+01, 1.3857e+01, 1.0774e+00, 4.7138e+00,
        7.0823e-01, 3.5239e+00, 7.7736e-02, 2.5765e-01, 4.5125e+00, 3.1236e-01,
        3.3242e-01, 2.1238e-01, 2.5209e+01, 6.2142e+00, 1.0343e+01, 2.4235e+00,
        8.9369e+00, 3.4185e+00, 5.2777e+00, 6.0269e+00, 8.1655e-02, 3.1422e-01,
        8.3245e-02, 9.7297e+00, 6.6996e+00, 1.3752e+01, 2.7950e-01, 1.6872e+01,
        1.1184e+01, 9.4613e+00, 1.7325e+01, 4.9817e+00, 4.7209e-01, 7.5822e+00,
        8.5290e-02, 5.9000e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [25/80], Step [000/314], LR 9.4e-05, Loss: 927.9
BCE Val Loss:  tensor([5.7249e+01, 1.7917e+01, 4.1857e+01, 1.0464e+01, 1.2296e+00, 3.5228e+01,
        3.5898e+01, 4.3540e+01, 2.2567e+01, 2.9356e+01, 1.3675e+01, 3.3233e+01,
        1.3126e+01, 9.7091e+00, 1.7828e+01, 2.9155e+00, 6.8420e+00, 1.6497e+01,
        4.2832e+00, 1.3279e+01, 1.6863e-01, 1.3733e-01, 3.5452e-02, 8.8061e-02,
        2.6555e+01, 2.0470e+01, 3.3588e+01, 1.3650e+01, 1.8460e+01, 4.4001e-01,
        1.6660e-01, 1.3991e-01, 1.2447e+00, 1.6658e+00, 9.2644e-01, 5.4377e-01,
        6.3002e+00, 7.3459e-01, 6.2131e-01, 2.7823e+00, 1.0275e-01, 4.1040e+00,
        5.3475e-01, 7.1775e-01, 7.6638e-01, 1.5984e+00, 2.0292e-01, 9.0977e-02,
        2.2445e-01, 4.7481e+00, 2.6479e-02, 7.1581e-02, 9.7461e-02, 4.4057e-01,
        1.6395e-01, 2.4575e-01, 1.0300e+01, 6.1658e+00, 4.7593e+00, 1.1890e-01,
        4.1144e+00, 1.4101e-01, 2.8601e-01, 2.6785e-01, 3.3838e-02, 4.6485e-02,
        1.5832e-02, 2.0300e+01, 1.0088e-01, 3.2652e+00, 1.5301e-02, 1.2461e-01,
        4.5801e+00, 3.9045e+00, 4.8178e+00, 5.5147e-01, 6.5641e-01, 4.0931e-01,
        4.0122e-03, 7.9309e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [25/80], Step [100/314], LR 9.4e-05, Loss: 634.6
BCE Val Loss:  tensor([1.4043e+01, 8.4919e-01, 3.4923e+00, 6.0333e-01, 9.3424e-02, 1.1923e-01,
        5.0550e-02, 1.5899e+01, 1.9435e-01, 4.6672e-02, 3.1458e-02, 9.7602e-02,
        1.3648e-02, 1.1369e+01, 4.5053e-01, 9.8448e-01, 1.0957e+00, 8.5686e-02,
        8.4259e-02, 4.8631e-02, 4.3758e-02, 2.4659e-02, 5.1263e-03, 1.4291e-02,
        3.9681e+00, 1.7546e+00, 2.7477e+01, 4.5282e+00, 1.8839e-01, 1.9590e-01,
        3.9446e-01, 5.8803e+00, 8.5444e+00, 7.0443e-02, 1.8610e+00, 2.8203e+00,
        1.0409e+01, 8.4795e+00, 5.2480e-02, 5.5082e+01, 1.9257e+01, 7.0412e+01,
        5.2978e+01, 5.3390e+01, 4.5665e+01, 5.6694e+01, 7.6526e+00, 7.8606e+00,
        4.1059e+01, 1.1618e+01, 2.3939e+01, 3.4982e+01, 5.6288e+01, 2.2294e+01,
        4.1775e+01, 7.7540e+01, 9.5855e+01, 1.1829e+01, 7.8976e+00, 2.5052e-01,
        8.0570e+01, 1.8806e-01, 1.2272e+01, 1.2137e+01, 1.5832e+01, 1.2570e+00,
        1.2126e+01, 2.0139e+01, 6.7798e+00, 4.5426e+00, 1.3574e-01, 1.1754e+01,
        4.6893e+00, 4.4760e+01, 1.8367e+00, 1.3481e+01, 1.0403e+01, 7.7124e-01,
        2.8265e-02, 3.1896e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [25/80], Step [200/314], LR 9.4e-05, Loss: 1174.7
BCE Val Loss:  tensor([2.4734e+01, 2.5264e+00, 1.2398e+01, 1.0296e+00, 3.5496e-01, 8.2359e+00,
        6.4576e+00, 1.7937e+01, 2.5253e+00, 1.5811e+01, 3.6632e+00, 8.8004e+00,
        3.2121e-01, 1.4380e+01, 1.6117e+01, 5.0825e-01, 8.0325e-01, 5.0724e-01,
        6.5264e-02, 5.2436e-02, 1.7927e-01, 4.0668e-02, 1.3662e-02, 1.1194e-01,
        1.9100e+01, 5.9939e+00, 2.4533e+01, 7.0782e-01, 1.6628e+01, 7.0822e-02,
        3.2206e-01, 9.0784e-02, 1.3548e-01, 3.0994e-01, 2.2275e-01, 5.7736e-01,
        1.8328e+00, 8.7747e-02, 2.9937e-02, 2.7941e+00, 7.4639e-01, 2.0425e+00,
        3.5576e-01, 6.3855e-01, 3.3293e-01, 1.4672e+00, 1.7696e-01, 5.6495e-02,
        8.4610e-02, 1.5037e-01, 1.7244e-02, 3.9781e-02, 3.8166e-02, 8.0522e-02,
        6.5279e-02, 1.2578e-01, 5.2057e+00, 1.9475e+00, 1.5909e+01, 2.2617e-01,
        8.0067e+00, 2.7687e-01, 3.4412e-01, 2.7248e-01, 3.7445e-02, 4.3636e-01,
        8.6773e-02, 6.0456e+00, 1.6238e-01, 5.1882e-01, 2.0199e-02, 3.2781e-01,
        1.1216e-01, 5.3356e+00, 4.8604e+01, 4.1696e+00, 7.5657e-02, 4.2649e+00,
        1.0581e-02, 2.6438e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [25/80], Step [300/314], LR 9.4e-05, Loss: 319.9
starting validation
Accuracy th:0.5 is [91.46818387 98.06532571 94.53101205 98.76585324 99.37013438 98.46858591
 99.16789513 96.11603172 98.75123354 98.05679755 99.17033175 99.26414152
 99.55653562 96.37553149 98.0909102  98.49904363 97.43911502 98.85235316
 99.36038791 99.04119102 99.55166238 99.65278201 99.77217626 99.64790877
 95.62748992 98.0360863  94.93792717 98.11040314 98.41741694 98.97418404
 99.11185293 99.04971918 97.88501602 99.31531049 99.25439505 99.19591623
 98.8998672  99.09601491 99.57481025 94.15577296 98.25416357 94.01201252
 97.82531889 97.11869982 97.38307282 95.84191226 98.93276154 98.99245867
 98.70615611 99.05093749 99.26292321 99.0521558  99.2751063  99.13256417
 99.13378248 98.43203665 93.20305552 97.91669205 97.16621386 98.6208745
 94.64553307 99.22515564 97.80460764 98.27609313 99.18007822 98.22126923
 98.9973319  96.32070759 98.97296573 98.64524068 99.81969031 98.32482548
 98.72808567 96.39867935 97.82166397 97.98248072 99.25195843 98.95225448
 99.84527479 99.26657814]
Accuracy th:0.7 is [90.39485386 98.00928351 93.68672409 98.75001523 99.26779644 98.44543804
 99.0107333  95.65429271 98.59894494 97.72663588 99.11063462 99.27876122
 99.52485959 96.14283452 97.94593146 98.34066349 97.20032651 98.70128288
 99.29703585 98.92545169 99.50902158 99.62841583 99.76486641 99.66252848
 95.50809566 97.92278359 94.54806837 97.94349484 98.29802268 98.87793765
 98.98393051 99.07286705 97.8119175  99.22515564 99.29703585 99.31165556
 98.97905727 98.95103617 99.46759908 94.23008979 98.09822005 94.08267443
 97.82897382 96.83361557 97.18205188 95.61652514 98.80971236 98.94494463
 98.60869141 99.09845153 99.21784579 98.91083198 99.21784579 99.07895859
 99.0241347  98.21274107 92.51471108 97.78755132 97.09798857 98.44178312
 94.10094906 99.1642402  97.41353054 98.20543122 99.12403601 97.99466381
 98.86088132 96.4608131  98.94616294 98.65864207 99.81603538 98.2444171
 98.50269855 96.03805997 97.71688941 97.96420609 99.23612042 98.87550103
 99.84405648 99.22515564]
Avg Prec: is [98.15082462 61.74130374 81.38584504 83.80321737 94.39092925 82.87905917
 92.38395439 70.36566116 79.21697056 78.41641469 69.46469578 74.38795358
 57.44749983 55.79291699 59.57375976 82.31558499 62.08425289 81.56165334
 81.18223235 75.323504   92.22178074 80.91912481 96.59568909 96.4275778
 43.66344399 70.51198176 52.81761039 72.70814818 58.88560392 76.27695494
 91.25337898 72.94518171 77.34157635 89.24247748 90.50772585 91.4245845
 89.08618542 91.11116309 96.90237248 59.44736145 55.25960757 65.63149547
 68.1728243  62.81779028 54.62653366 69.60201012 73.49333322 60.42351252
 69.53153512 68.47332855 82.95669931 69.05863881 60.85034977 88.99507006
 66.30465394 73.23331119 73.30973853 78.9317205  58.88540256 84.30778565
 81.11686689 93.08154364 79.8870879  75.60043743 79.73180512 71.09147482
 78.63056557 47.56557157 61.44034886 79.29675137 23.3405244  86.86014098
 75.0600819  57.84951192 70.37603188 70.317601   35.66492877 69.44368728
 14.95210969 45.17981684]
Accuracy th:0.5 is [89.77960795 97.78024147 93.93160415 98.58310693 99.23490211 98.27609313
 99.05946565 96.17085562 98.54290274 97.72419927 99.00342345 99.22271902
 99.51876805 95.92841218 97.86308646 98.16157211 96.96884785 98.58188862
 99.22759226 98.8572264  99.40912026 99.54191591 99.74293686 99.57359194
 95.54829985 97.62186133 94.86117372 97.8545583  98.35771981 98.74514199
 98.94859955 99.01926146 97.59993177 99.14352895 99.20688101 99.24464858
 98.7597617  98.91936014 99.48587371 93.83535776 98.10187498 93.98764635
 97.60602332 96.82874234 97.32703062 95.46423655 98.66473362 98.90108551
 98.49660701 98.98880374 99.16180358 98.93519816 99.18495145 98.91083198
 98.9827122  98.20664953 92.43795763 97.6316078  96.84092543 98.39548738
 94.24470949 99.05459241 97.6730303  97.9106005  99.10088815 98.07629049
 98.88890243 96.28294002 98.90595875 98.51731826 99.818472   97.99100888
 98.62818435 96.13186974 97.56703744 97.80460764 99.23490211 98.70128288
 99.84405648 99.2202824 ]
Accuracy th:0.7 is [88.01915181 97.62307964 93.31635823 98.55508583 99.23612042 98.20543122
 99.04728256 95.86627843 98.5234098  97.6169881  98.94981786 99.21175424
 99.50414834 95.68231381 97.74856544 97.94593146 96.78975646 98.44909297
 99.13500079 98.72930398 99.39328225 99.54678915 99.74415516 99.57481025
 95.3460606  97.37941789 94.56390639 97.70348802 98.27121989 98.60259987
 98.94372632 98.83651515 97.27707996 99.0667755  99.19835285 99.23002887
 98.68178994 98.8998672  99.42617658 93.54418197 98.0080652  93.44428065
 97.50855862 96.72396779 97.10286181 95.0536665  98.58432524 98.86088132
 98.48686054 98.9132686  99.11794447 98.81945883 99.12525432 99.00707837
 98.88281088 98.02755814 91.52422607 97.50490369 96.70812977 98.28827621
 93.55758336 99.04850087 97.43546009 97.7424739  98.99002205 97.88014279
 98.78290956 96.10872187 98.8852475  98.58188862 99.81603538 98.05923417
 98.61965619 95.8346024  97.42449532 97.68765    99.2056627  98.58919847
 99.84405648 99.18860638]
Avg Prec: is [97.53413763 54.18718327 77.02530643 80.00722748 92.06694341 78.93472555
 89.63304324 64.85279139 73.95312266 71.8459283  61.38066665 70.64188543
 46.54296358 46.87801942 51.02005611 76.53277768 49.8914672  74.03697318
 73.14318234 66.01929629 88.18127208 74.20031535 95.6568439  95.06885799
 38.71040183 61.34671233 47.72731157 64.66600783 46.90795717 65.40890899
 87.90979523 67.57895953 71.05088359 84.60065879 88.34498124 89.7758585
 85.00146531 87.14470216 95.48418898 53.38589656 45.69488736 62.58383123
 62.76876635 56.61632422 49.63668426 64.04126207 64.12292592 52.67290629
 61.06857954 62.27160288 79.06552985 61.31529525 49.30614621 85.5777863
 55.75559511 64.9275678  67.91466653 73.14050003 50.10822602 78.60278722
 78.07855353 90.57737727 73.53360685 66.71801376 73.87159088 62.27102168
 71.78917737 39.63441124 56.65856216 75.02148741 17.05508051 83.35083954
 68.73453458 52.18965147 64.72254911 64.04404568 28.04038619 60.03473628
 13.78630448 36.98674152]
mAP score regular 72.42, mAP score EMA 66.36
starting validation
Accuracy th:0.5 is [90.61962777 97.81996661 93.81368812 98.64962503 99.34225278 98.18122929
 99.04576824 95.8816055  98.57238957 97.67795301 99.09061464 99.15290131
 99.47928345 95.75703216 97.92460822 98.16129756 97.2145402  98.63965917
 99.36218452 98.84894237 99.53409572 99.65866906 99.78573386 99.76081919
 95.35341456 97.75518848 94.68570147 97.92959115 98.17873782 98.74430077
 99.04576824 98.7791813  97.41136607 99.32979545 99.10307198 99.24757705
 98.66208237 98.82153624 99.39457359 93.29795451 98.01928395 93.32037771
 97.29925007 96.74863592 97.01522286 95.01457508 98.7941301  98.96105838
 98.25348182 98.88631437 99.20273065 98.87634851 99.03829384 98.87634851
 99.00839624 98.15133169 91.57884246 97.70037621 96.58918205 98.16378902
 93.47235718 99.06819144 97.48611007 97.84986422 98.97849864 97.86730448
 98.88880584 95.43812442 98.83648504 98.50761143 99.81064853 97.94703142
 98.47771383 96.04355084 97.59324314 97.54839674 99.25754292 98.86139971
 99.82559733 99.10307198]
Accuracy th:0.7 is [90.47263124 97.86481302 93.61437078 98.71440317 99.30488078 98.25846476
 98.92866931 95.65488203 98.5175773  97.60320901 99.09808905 99.25754292
 99.46931759 95.81184443 97.86232155 98.18122929 97.06006926 98.57488103
 99.31982958 98.80658744 99.48675785 99.64870319 99.79071679 99.76081919
 95.53778309 97.73774821 94.5411964  97.88474475 98.11894262 98.71440317
 98.89378877 98.91372051 97.45122954 99.32730398 99.17781598 99.27747465
 98.84645091 98.75426664 99.30488078 93.76385878 97.99935222 93.83112839
 97.44126367 96.77604206 97.08996686 95.19146922 98.84645091 98.96853278
 98.30331116 99.02334504 99.17034158 98.83399357 99.04078531 98.84146797
 98.93614371 98.15133169 91.49911553 97.71781648 96.70628099 98.09651942
 93.41754491 99.01836211 97.1995914  97.95699728 98.91621197 97.77013728
 98.7492837  96.04853377 98.80658744 98.44532476 99.81563146 97.90467648
 98.4204101  95.98873857 97.62314074 97.67795301 99.27996612 98.79911304
 99.82559733 99.15040985]
Avg Prec: is [97.6705242  51.36613382 75.58849459 81.9974702  89.57478454 76.87221135
 90.2161073  59.39860818 75.15266404 70.81644272 65.1584841  69.52714882
 43.78914204 46.84921528 51.02213647 79.92507218 57.09507207 75.95517432
 77.51745863 66.31592251 91.00071362 83.97582966 96.3990509  97.82283942
 30.56963499 63.59848136 38.54321284 65.99133752 47.44174805 67.31700269
 86.26948513 59.09784461 67.2949016  87.15461025 83.67155252 89.0214538
 83.92355242 87.04552986 94.47683158 50.7195066  43.16159672 57.31658931
 53.84976805 46.6613328  37.67480025 58.14252511 62.54145745 44.63785859
 54.27811864 59.3855164  82.15795373 56.04577082 46.20318754 85.7449851
 52.35377732 58.4698191  61.81089623 70.58861069 47.06565404 76.37502363
 70.93203172 91.38603845 72.14384464 66.80412473 70.71401494 52.13653729
 72.66062253 37.41703789 46.50612387 73.32807537  8.23182216 81.09352277
 59.93221079 48.10607384 69.21961275 59.00053816 21.71321886 62.27457419
  2.98874109 27.43011465]
Accuracy th:0.5 is [90.04908189 97.76017141 93.66170865 98.59481277 99.27498318 98.13638289
 99.00590478 95.83925057 98.46276503 97.54092234 99.01337918 99.25255998
 99.43941999 95.75204923 97.80750928 98.02177542 96.86573486 98.5624237
 99.24757705 98.72935197 99.46682612 99.54904452 99.76580213 99.73341306
 95.45556469 97.49856741 94.55116227 97.81000075 98.17375489 98.49017116
 98.97102424 98.85392531 97.2818098  99.22515385 99.13296958 99.32979545
 98.74679224 98.73931784 99.33477838 93.52467798 98.01928395 93.70157212
 97.3490794  96.52191245 96.94795326 95.02952388 98.76672397 98.91621197
 98.20614396 98.94112664 99.15539278 98.82402771 99.00092184 98.81904477
 98.94112664 98.05665595 91.51904726 97.55337967 96.58669058 98.07658769
 93.54460971 99.00590478 97.56832847 97.80501781 98.94610957 97.74771408
 98.83150211 95.8890799  98.78167277 98.40047836 99.81563146 97.87976182
 98.39549543 95.9189775  97.49856741 97.64556394 99.25505145 98.71440317
 99.82559733 99.17781598]
Accuracy th:0.7 is [89.14467947 97.63559808 93.41505344 98.64962503 99.29491492 98.19617809
 99.03331091 95.84921643 98.52754316 97.57081994 98.99843038 99.27249172
 99.44938585 95.58262949 97.74522261 97.92959115 96.72122979 98.47771383
 99.25754292 98.68699704 99.48177492 99.58143359 99.78075093 99.73839599
 95.52034283 97.28679273 94.64085507 97.77761168 98.13139996 98.52256023
 98.94860104 98.87385704 97.17467673 99.18778185 99.15539278 99.34972718
 98.73682637 98.6969629  99.31733812 93.51471211 97.94453995 93.53713531
 97.32416474 96.74116152 97.080001   94.95727135 98.72935197 98.98348158
 98.31576849 98.93116077 99.09808905 98.77419837 98.99843038 98.88382291
 98.89378877 98.05914742 91.17771632 97.54092234 96.53436978 98.07658769
 93.37269851 98.99095598 97.44126367 97.75767995 98.90873757 97.81498368
 98.74430077 95.96133244 98.83150211 98.45279916 99.81563146 97.91713382
 98.5026285  95.8292847  97.4088746  97.66300421 99.27249172 98.6595909
 99.82559733 99.17283305]
Avg Prec: is [97.40104072 47.86607933 74.23978661 81.39414813 88.19796095 75.88466458
 89.20300826 58.65194523 73.47679319 68.68627678 61.62432045 68.356038
 37.21281355 44.42037222 47.00400287 76.29884553 49.6392445  72.62402569
 73.25452494 59.64161451 89.65017949 78.9780745  95.98070361 96.88844558
 30.23857159 57.2147815  38.44803972 62.80039415 42.54052926 57.92902529
 85.37425464 57.10047073 62.96400462 83.24897463 82.96328896 88.50819797
 81.81710985 85.2577676  94.13943191 49.11482292 39.35865581 56.40861237
 50.70023061 45.26169341 37.25686953 56.54269061 59.65501311 44.09365215
 53.68382129 54.963161   80.78147482 52.85758354 43.05671951 85.02523292
 49.25186271 55.57567305 61.13962063 67.39178686 43.82850642 73.31829334
 71.1541677  91.01920681 71.13498945 62.58651224 69.95948035 49.14537273
 69.88342765 34.56408349 45.02602229 72.46176565  8.95379173 80.55746461
 57.95572865 45.482325   66.71619359 57.84974949 19.2523809  57.9979486
  3.03000519 28.46903409]
mAP score regular 64.02, mAP score EMA 61.74
Train_data_mAP: current_mAP = 72.42, highest_mAP = 72.42
Val_data_mAP: current_mAP = 64.02, highest_mAP = 64.02
lr:  [9.409428455936069e-05, 9.409428455936069e-05]
BCE Train Loss:  tensor([21.2266,  4.0796, 12.2510,  6.5402,  1.3963,  7.8535,  3.2760, 10.7370,
         2.1490,  7.9150,  0.9408,  1.1944,  0.2660, 12.8112, 11.4553,  6.9332,
         3.3032,  8.7727,  1.1228,  2.8135,  0.4761,  0.2151,  1.4453,  0.4560,
         6.8159, 13.1417,  6.3571,  4.6922, 20.1375,  7.1544,  0.8778,  1.5687,
        13.5370,  2.6464,  2.2362,  1.9841,  1.0770,  2.9534,  5.9027, 13.5528,
         7.0826, 25.0554,  8.8146,  7.4297,  6.8046, 14.5519,  8.9225, 10.6761,
         5.7962,  8.9840,  5.4811,  1.3772,  1.5086,  0.7006,  1.3350,  9.6634,
        20.4880,  7.0259,  8.0597,  2.8563, 11.5731,  2.5686,  6.2928,  6.9715,
         1.4666,  4.1851,  2.5132, 10.1807,  3.1409,  3.5587,  0.2476,  3.8819,
         1.1246,  9.7739, 11.0890,  5.1075,  2.7164,  3.1252,  0.0916,  2.3885],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [26/80], Step [000/642], LR 9.4e-05, Loss: 488.9
BCE Train Loss:  tensor([20.2159, 18.2732, 15.5275,  1.5599,  0.6856,  7.2914,  1.0408, 13.8620,
         4.7504,  6.3194,  5.0268,  1.1038,  2.6032, 10.8162, 10.3036,  8.5688,
        12.4324,  6.9120,  2.1423,  1.6848,  1.8838,  0.3111,  1.8268,  2.7546,
        12.9574,  6.9137,  9.0662,  4.1074,  6.3267,  2.1391,  6.0863,  4.0284,
         7.7349,  4.9654,  4.1239,  3.9912,  1.7354, 11.4502,  4.3709, 20.6141,
         4.2941, 13.1428,  4.5618,  3.4465,  6.2999,  6.0627, 10.0372,  5.0181,
         2.0687,  1.6135,  3.7793,  3.3238,  0.3679,  0.2641,  2.5903,  4.2260,
        22.0288,  7.3214, 12.0374,  1.5283,  9.6033,  3.0238, 10.1348,  5.2180,
         4.8856,  4.5294,  2.4593,  8.4820,  0.7585,  1.8509,  5.9617,  6.5040,
         1.7422,  8.4643,  3.4160,  1.4006,  1.9208,  4.7518,  0.3791,  0.4510],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [26/80], Step [100/642], LR 9.4e-05, Loss: 468.5
BCE Train Loss:  tensor([38.7015,  4.8225, 22.5453,  3.1479,  3.7844, 12.6562,  1.3901, 11.0798,
         4.7409,  9.1758,  1.0515,  3.8979,  4.4251, 26.2541, 10.3061,  1.8148,
         5.1208,  2.6890,  0.6191,  7.8874,  4.5377,  1.7927,  0.2115,  0.4200,
        18.7223, 15.1279, 16.1438, 11.6625,  1.9173,  4.4075,  2.9641,  2.8224,
         8.2586,  1.6667,  0.5561,  0.7654,  4.6093,  2.4056,  1.1863, 20.6553,
         8.5902, 23.0113,  8.0235, 11.9768,  6.0500, 11.5552,  9.9580,  8.6946,
         7.8070,  1.0634,  2.0511,  3.0016,  3.4754, 11.7875,  3.2970,  4.8291,
        23.7240,  2.5858, 12.8052,  2.6182, 19.3503,  3.1549,  6.1338,  5.9032,
         0.7213,  3.6194,  2.9047,  5.5231,  2.1843,  2.9263,  1.6939,  3.9619,
         8.2758, 11.5404,  7.8936,  5.4605,  2.9212,  4.1074,  0.1438,  5.2107],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [26/80], Step [200/642], LR 9.4e-05, Loss: 567.5
BCE Train Loss:  tensor([37.1702,  7.3810, 22.3492, 10.9268,  2.0887, 10.3937,  2.8210, 13.8144,
         3.9576,  9.4295,  8.9033,  3.9891,  3.7690, 12.0131,  8.4248,  2.6027,
        13.0520, 12.2240,  2.4286,  3.2909,  0.9336,  0.1423,  1.8560,  0.0870,
        10.5792,  4.9665,  9.9164,  3.9784,  5.0746,  3.3788,  0.9045,  1.1728,
         8.9948,  1.6855,  6.4776,  6.7122,  6.9721,  1.7722,  0.3942, 13.9963,
         4.1531, 14.3340,  5.3528,  4.9213,  9.0382, 11.5978,  4.8699,  0.5101,
         2.8480,  0.5139,  2.1369,  3.4619,  4.9346,  0.6341,  2.0249,  8.1460,
        25.6134,  6.6253, 20.5196, 13.3851, 13.3902,  4.9106,  7.5906,  6.1030,
         1.2387,  2.0537,  6.9502, 10.6070,  1.2677,  0.8358,  0.0651,  3.4836,
         1.2016, 10.4292, 13.6373, 13.0846,  2.6227,  3.7670,  0.0955,  5.1709],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [26/80], Step [300/642], LR 9.4e-05, Loss: 535.2
BCE Train Loss:  tensor([27.9146, 11.7549, 27.4047,  7.9013,  0.9880,  3.2404,  5.0661,  9.0570,
         1.4321,  3.5812,  0.7630, 12.4216,  0.3176, 11.4929,  3.2511,  3.2483,
         6.1673, 10.5385,  2.6918,  5.4225,  4.8762,  2.7022,  0.1420,  0.1894,
        11.5561,  5.0287, 19.4245,  6.1528,  2.3977,  0.9340,  3.2223,  2.1615,
         6.8448,  0.6487,  1.2024,  0.6060,  2.0495, 10.0655,  0.2742, 24.1114,
         5.5294, 12.4118,  5.1091,  7.8985, 12.7929, 15.6088,  7.0988,  0.4199,
         0.5281,  4.8287,  2.9030,  5.0647,  0.6043,  4.0847,  0.9416,  4.7709,
        21.0138,  6.5313, 20.5126,  2.2261,  9.6766,  1.0694,  8.4219,  8.8754,
         1.7244, 12.8120,  6.1102, 10.2341,  9.3399, 10.6769,  2.8753,  1.8359,
        11.8524, 11.2477,  9.8060,  8.3350,  1.7481,  6.7736,  5.7127,  1.4348],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [26/80], Step [400/642], LR 9.3e-05, Loss: 540.7
BCE Train Loss:  tensor([27.4187,  4.1573, 14.2554, 10.1348,  1.0309, 10.6236, 11.5957,  9.8497,
         0.9475,  6.3075,  6.4913,  0.5175,  0.2171, 14.9914,  1.9178,  4.5041,
        11.4460,  4.0444,  2.3720,  2.6593,  0.9900,  3.4844,  0.4923,  0.8201,
        26.4236,  4.3323, 20.0303, 12.1546, 11.4759, 11.5990,  4.7167,  0.2765,
         6.1884,  0.4092,  1.0463,  1.0910,  5.7194,  2.3910,  0.6692, 17.7542,
         2.3358, 26.3499,  7.4654, 10.1817, 10.8745, 13.8836,  4.1021,  2.8535,
         5.9916,  3.4326,  2.3755,  2.1334,  3.0359,  5.1827,  2.6482,  7.0679,
        16.5248,  7.4135, 19.3218,  4.0716, 13.2552,  2.7557, 10.3416,  9.7263,
         2.6218, 12.1030,  2.7054, 16.6778,  2.0228,  2.9459,  0.2102,  2.2715,
         5.9226, 11.5146,  5.0726,  3.5780,  3.7798,  3.1987,  0.1433,  4.1463],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [26/80], Step [500/642], LR 9.3e-05, Loss: 549.8
BCE Train Loss:  tensor([23.3290,  5.5446, 17.0879,  3.5923,  0.5026,  6.6849,  0.5430, 17.5263,
         8.8110,  6.8428,  1.9891,  0.6286,  0.3966, 15.8186,  6.7125,  4.5535,
         5.9125,  1.2686,  0.5791,  7.3840,  7.8082,  0.1855,  0.0790,  0.0986,
        19.0884,  1.4634, 12.1474,  7.5035,  5.5856,  2.1988,  8.4719,  2.7934,
        10.5587,  0.3853,  0.9291,  3.3525,  2.1673,  0.4848,  2.2732, 22.2710,
        10.6392, 15.5893,  5.4216, 13.2397,  6.3832, 17.3315,  1.4462,  6.2251,
         3.9356,  4.9044,  2.5629,  4.7524,  1.9770,  6.0406,  4.1972,  7.3681,
        22.2329, 10.7068,  9.9844,  4.9625, 18.3431,  1.1174,  1.3898,  8.2193,
         0.7988,  3.8349,  0.8944, 18.6655,  4.0831,  4.1839,  0.2782,  9.0238,
         2.3648,  8.3228,  9.3291,  3.0890,  7.1371,  1.2543,  0.0423,  0.6762],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [26/80], Step [600/642], LR 9.3e-05, Loss: 508.5
BCE Val Loss:  tensor([5.4911e+01, 2.0419e+01, 4.8487e+01, 2.0537e+01, 7.4682e-02, 9.1445e+00,
        5.6166e+00, 2.2109e+01, 5.7609e+00, 8.8894e+00, 9.6135e+00, 1.2307e+01,
        7.8994e+00, 1.6021e+01, 7.6814e+00, 1.1809e+01, 1.9081e+02, 5.1392e+00,
        1.2202e+00, 2.5077e+00, 5.7926e-01, 1.9399e-01, 4.6410e-02, 2.7820e-02,
        2.8132e+01, 1.2584e+01, 2.8417e+01, 1.7206e+00, 1.5179e+01, 1.1664e+01,
        3.1839e-01, 1.9280e+00, 1.0792e+01, 1.6127e-01, 2.3492e-01, 1.9233e-01,
        1.1100e+01, 5.0553e+00, 1.5352e+00, 4.1509e+01, 1.1703e+01, 2.3564e+01,
        7.2225e+00, 1.7361e+01, 1.6343e+01, 1.4494e+01, 4.9276e-01, 5.3202e+00,
        1.3908e-01, 3.6709e+00, 4.4072e-02, 1.5025e-01, 5.9297e+00, 3.0511e-01,
        3.9907e-01, 4.2717e-01, 2.5759e+01, 7.8500e+00, 8.7915e+00, 5.2789e+00,
        1.0348e+01, 6.6031e+00, 2.6944e+00, 6.7358e+00, 3.4575e-01, 2.3598e+00,
        2.8481e-01, 1.0329e+01, 8.6166e+00, 1.5025e+01, 2.5236e-01, 1.4603e+01,
        9.0400e+00, 9.8230e+00, 1.7581e+01, 6.2829e+00, 7.9128e-01, 7.0211e+00,
        1.8569e-01, 4.9876e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [26/80], Step [000/314], LR 9.3e-05, Loss: 917.0
BCE Val Loss:  tensor([6.0694e+01, 1.9990e+01, 5.5462e+01, 1.3306e+01, 2.3558e+00, 3.9319e+01,
        4.2284e+01, 3.6286e+01, 1.9280e+01, 3.3364e+01, 1.5075e+01, 3.0440e+01,
        9.8510e+00, 7.0603e+00, 1.7944e+01, 2.8998e+00, 7.1890e+00, 1.8787e+01,
        4.8018e+00, 1.9439e+01, 2.6206e-01, 6.7776e-02, 9.8052e-02, 5.9993e-02,
        2.9369e+01, 2.2524e+01, 3.3994e+01, 1.5107e+01, 1.8138e+01, 3.5965e-01,
        4.5643e-02, 9.5427e-02, 6.6177e-01, 4.5134e-01, 6.5642e-01, 1.2245e-01,
        3.1104e+00, 9.6999e-01, 8.6205e-02, 1.4533e+00, 1.7554e-01, 4.3180e+00,
        5.2808e-01, 7.6524e-01, 5.9885e-01, 1.9880e+00, 1.5439e-01, 1.3373e-01,
        5.2700e-02, 4.2964e+00, 2.3180e-02, 9.2634e-02, 7.6767e-02, 2.2041e-01,
        2.3652e-01, 1.6053e+00, 8.6672e+00, 5.9446e+00, 6.2709e+00, 5.1900e-01,
        5.3595e+00, 1.8454e-01, 1.0250e+00, 2.2677e-01, 4.5888e-02, 1.7520e-01,
        3.7303e-02, 1.9053e+01, 1.0642e-01, 3.0014e+00, 7.1518e-03, 9.2419e-02,
        3.3015e+00, 2.9109e+00, 7.5328e+00, 3.1913e-01, 1.3599e+00, 4.4237e-01,
        8.1718e-03, 7.3874e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [26/80], Step [100/314], LR 9.3e-05, Loss: 665.4
BCE Val Loss:  tensor([1.2671e+01, 5.3300e-01, 3.6954e+00, 1.7802e-01, 5.1522e-02, 7.3132e-02,
        1.4545e-01, 1.5047e+01, 1.5049e-01, 5.9225e-02, 3.6912e-02, 4.4372e-02,
        1.8118e-02, 1.3411e+01, 4.1139e-01, 1.0330e+00, 2.5155e+00, 1.8647e-01,
        7.9380e-02, 3.6530e-02, 8.7378e-02, 1.3799e-02, 5.9326e-03, 4.5802e-03,
        5.0374e+00, 1.0011e+00, 2.3302e+01, 4.2042e+00, 9.3640e-01, 2.3462e-01,
        1.4557e+00, 5.6145e+00, 8.5758e+00, 3.2406e-02, 1.3553e-01, 1.7014e-01,
        1.0862e+01, 6.4310e+00, 5.2949e-02, 3.6550e+01, 1.8895e+01, 6.3174e+01,
        5.5321e+01, 6.1067e+01, 4.9740e+01, 6.0038e+01, 6.1065e+00, 9.1637e+00,
        3.8097e+01, 9.3919e+00, 2.4701e+01, 3.3558e+01, 5.6227e+01, 1.9715e+01,
        3.4983e+01, 5.2819e+01, 9.2876e+01, 1.3159e+01, 6.8059e+00, 1.0895e+00,
        8.1673e+01, 6.5704e-02, 1.1752e+01, 1.2626e+01, 1.3056e+01, 6.0396e+00,
        9.3166e+00, 1.4117e+01, 6.7829e+00, 2.5716e+00, 6.4087e-02, 1.1672e+01,
        5.4829e+00, 3.7725e+01, 3.6290e+00, 1.3324e+01, 9.7455e+00, 1.1224e+00,
        5.9227e-02, 3.4342e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [26/80], Step [200/314], LR 9.3e-05, Loss: 1103.2
BCE Val Loss:  tensor([2.9596e+01, 1.4353e+00, 1.3606e+01, 1.5377e+00, 2.0015e-01, 9.4218e+00,
        7.4531e+00, 1.4757e+01, 3.1353e+00, 1.6793e+01, 3.1664e+00, 7.2027e+00,
        3.4730e-01, 1.2704e+01, 1.6426e+01, 1.7447e-01, 8.7152e-01, 7.4511e-01,
        2.8180e-02, 4.0692e-02, 3.0594e-01, 1.6336e-02, 1.6456e-02, 3.8431e-02,
        2.1039e+01, 5.7749e+00, 2.1445e+01, 9.7513e-01, 1.4690e+01, 7.7491e-02,
        5.0889e-02, 6.7326e-02, 9.4817e-02, 2.9923e-02, 2.3668e-02, 4.4690e-02,
        8.8226e-01, 7.9805e-02, 1.4508e-02, 1.5636e+00, 8.3093e-01, 9.6111e-01,
        2.0307e-01, 3.4106e-01, 9.0085e-02, 4.7178e-01, 5.8574e-02, 5.4341e-02,
        2.7622e-02, 7.3525e-02, 1.0127e-02, 4.6767e-02, 3.2481e-02, 1.7218e-01,
        5.0781e-02, 3.0824e-01, 5.7742e+00, 1.8268e+00, 1.0388e+01, 7.3220e-01,
        5.9589e+00, 1.6200e-01, 1.4517e+00, 1.3610e-01, 5.5216e-02, 8.7524e-01,
        1.8517e-01, 6.3188e+00, 1.8068e-01, 1.5502e-01, 6.0882e-03, 1.0061e-01,
        6.0639e-01, 5.0321e+00, 3.2009e+01, 2.2024e+00, 1.4782e-01, 4.4835e+00,
        2.0513e-02, 1.4545e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [26/80], Step [300/314], LR 9.3e-05, Loss: 289.4
starting validation
Accuracy th:0.5 is [90.75547325 98.10918483 94.48715293 98.82555037 99.36647945 98.5648323
 99.1642402  96.58508059 98.76950817 98.10065667 99.18738807 99.29338093
 99.60404966 96.31827098 98.12258623 98.28949452 97.43911502 98.84017008
 99.33236681 99.0241347  99.55166238 99.65521863 99.80263398 99.70029605
 95.61774345 98.09212851 95.11092701 98.15060733 98.59529002 99.01438823
 98.82189544 99.12647263 97.98126241 99.16667682 99.27145137 99.289726
 99.0387544  99.13012756 99.58942995 94.22765317 98.28462129 94.24714611
 97.89719911 97.09798857 97.28195319 95.69937013 98.90108551 99.04119102
 98.62696605 99.11428954 99.26414152 99.10332476 99.29216262 99.1776416
 99.15449373 98.44178312 93.26397096 97.98491734 97.07971394 98.65742376
 94.89894129 99.20809932 97.98248072 98.26269173 99.12769094 98.13598762
 99.00951499 96.60822846 98.99124036 98.74392369 99.818472   98.12380453
 98.88037426 96.36456671 97.72785419 98.02268491 99.29825416 98.94372632
 99.84405648 99.27876122]
Accuracy th:0.7 is [88.31885576 98.09943836 94.56146977 98.79143773 99.26292321 98.44056481
 99.01560654 96.28294002 98.662297   97.98248072 99.17155005 99.27754291
 99.58942995 96.0709543  98.01415675 97.99588212 97.3940376  98.84138838
 99.28363446 98.86575456 99.53582437 99.62476091 99.79410582 99.65643693
 95.4715464  97.92765683 94.6918288  97.96664271 98.52584642 98.8718461
 98.44665635 99.05459241 97.67912184 99.00951499 99.17033175 99.14718388
 98.97174742 99.08870506 99.56628209 93.64164667 98.14329747 93.56976645
 97.73150912 96.79097477 97.05534777 95.03539187 98.82433206 98.95590941
 98.47589576 99.07286705 99.18860638 99.07652197 99.27145137 99.11794447
 99.13865572 98.51000841 92.88142201 97.86186815 96.84579866 98.5928534
 94.18623067 99.03388117 97.95324131 98.1469524  99.20931763 98.30167761
 99.02291639 96.43766523 98.98514882 98.51731826 99.81725369 97.63282611
 98.67448009 96.35238362 97.83872029 97.83750198 99.28119784 98.8986489
 99.84405648 99.21175424]
Avg Prec: is [98.20829534 62.56535865 81.40471894 84.41646238 94.80978663 84.30923207
 92.71799984 71.46041548 80.19354192 79.13622716 71.37454734 74.86529129
 59.97244651 57.30334387 59.22812257 82.68016077 62.48591776 81.38746601
 80.31553975 75.98797226 91.87592203 81.93005081 97.00829157 97.06645594
 42.82031097 72.58930851 54.08749216 73.79106469 59.87906172 77.76692139
 90.8604209  74.29088826 77.35566452 88.47055311 90.57532758 91.93007834
 90.22493868 91.16473985 96.71392376 60.43617293 56.65987806 66.69706127
 69.60046905 63.64312171 55.59823969 70.40175145 74.54955091 63.06431501
 69.12505928 70.47389057 84.32728652 69.87904476 61.12715733 89.83209523
 65.36497732 74.95424588 74.19464132 79.43472021 59.32823853 84.42617618
 82.85141219 93.84965246 80.42953724 75.82284787 80.59851362 70.00782659
 78.93611391 49.27860054 63.19226168 81.12017229 19.16806578 87.32461505
 76.36714287 59.10355272 70.82881151 70.40312099 39.17811013 71.31116612
 17.08425627 51.23087819]
Accuracy th:0.5 is [90.43018482 97.85699492 94.09729414 98.662297   99.289726   98.34797334
 99.12769094 96.2658837  98.58067031 97.87892448 99.05702903 99.22759226
 99.54191591 96.03318673 97.92156528 98.22126923 97.08580548 98.63671252
 99.25683167 98.90352213 99.4005921  99.57237363 99.78314104 99.6381623
 95.49469427 97.74125559 94.92452577 97.90572727 98.39426908 98.79996589
 98.93641647 99.04119102 97.69252324 99.18251483 99.17885991 99.24343027
 98.86697287 98.97783896 99.50780327 93.98399142 98.15548056 94.05465333
 97.7144528  96.84336204 97.31362922 95.61530683 98.76950817 98.92545169
 98.51122672 98.98880374 99.1922613  98.9693108  99.19957116 98.97905727
 99.00829668 98.3552832  92.59755607 97.76562176 96.90793241 98.40767047
 94.41892764 99.13134587 97.71688941 97.98735396 99.1228177  98.12014961
 98.92545169 96.34629208 98.96321926 98.60381818 99.81969031 98.09334682
 98.65986038 96.19278518 97.66328383 97.86917801 99.25561336 98.74270538
 99.84405648 99.23977534]
Accuracy th:0.7 is [88.78546801 97.69008662 93.49666793 98.59894494 99.28485277 98.28096636
 99.09723322 95.98079945 98.54290274 97.73881897 98.99245867 99.21175424
 99.51754974 95.76759542 97.7851147  98.02390322 96.91280564 98.56361399
 99.15449373 98.79752927 99.42373996 99.55775393 99.76242979 99.61135951
 95.35824369 97.51830509 94.66746263 97.77658654 98.32117055 98.63183928
 98.93763478 98.8718461  97.30144613 99.1215994  99.19957116 99.23490211
 98.7743814  98.94007139 99.4432329  93.71352688 98.04705108 93.61606218
 97.54998112 96.79706631 97.1576857  95.15478613 98.64524068 98.88159257
 98.5087901  98.91814184 99.17520498 98.84504331 99.15205711 99.03388117
 98.91570522 98.13964255 91.69113437 97.58287545 96.79219308 98.35406489
 93.85850562 99.10454307 97.55241773 97.86064985 99.04606425 97.97882579
 98.843825   96.15014437 98.89743059 98.60747311 99.81603538 98.08969189
 98.65620546 95.90282769 97.53779803 97.77414993 99.2190641  98.63914913
 99.84405648 99.20931763]
Avg Prec: is [97.76216432 55.66220175 78.03145959 80.85339874 93.12612017 80.66668742
 90.57285327 66.39416922 75.40742127 74.4540417  64.79198083 71.65537034
 50.51771203 49.16883831 52.50585918 77.54350427 52.73390147 75.97915067
 74.47490928 68.5290685  88.91865348 76.06255318 96.31926855 95.98164979
 38.65086504 64.78372934 49.53680577 66.66968284 50.06471817 68.40994803
 88.56557089 69.45988535 72.07020808 84.90142543 88.58402386 90.36426601
 86.95345097 87.96080067 95.7380547  55.33891386 47.28016595 63.59110022
 64.95087973 57.64310098 50.28167443 66.03773469 66.6178501  55.39624581
 62.01503735 63.86300759 80.996329   63.63805141 50.50047936 87.07984695
 56.79256131 69.11825273 69.01622391 75.09255153 52.13510379 79.7110118
 79.70357136 91.79618073 74.89248741 68.35754288 76.83511423 63.58930011
 73.55967819 42.02238715 57.64167299 77.55589343 16.98488169 84.36662532
 70.25235567 53.4487239  66.89328508 65.70919428 32.73800423 62.38638855
 12.16550853 39.85875451]
mAP score regular 73.21, mAP score EMA 67.98
starting validation
Accuracy th:0.5 is [90.22597603 97.70785061 93.36771557 98.6745397  99.34225278 98.27590503
 99.02583651 95.6648479  98.57238957 97.52846501 99.04825971 99.21020505
 99.48924932 95.91399457 97.84238981 98.07160475 97.00276553 98.74430077
 99.31982958 98.88382291 99.56150186 99.64870319 99.79320826 99.74587039
 95.32351695 97.79256048 94.57358547 97.95450582 98.21361836 98.75177517
 98.79662157 98.86887411 97.41884047 99.24010265 99.16785011 99.29491492
 98.90624611 98.85641677 99.40204799 93.75389292 98.05914742 93.66918305
 97.37648554 96.76109326 97.08996686 95.15658868 98.86139971 98.99344744
 98.33819169 98.95607544 99.16535865 98.87385704 99.06071704 98.88880584
 98.93614371 97.94952288 91.18768219 97.54590527 96.69382365 98.16129756
 93.70904652 99.05075118 97.47116127 97.96696315 98.89628024 97.56583701
 98.82402771 95.8367591  98.83399357 98.45279916 99.81314    97.87727035
 98.46774796 95.54027456 97.36651967 97.70286768 99.25505145 98.85392531
 99.82559733 99.15040985]
Accuracy th:0.7 is [89.0151232  97.84737275 94.01549692 98.68450557 99.27000025 98.27839649
 98.87883997 95.9040287  98.5773725  97.57829434 99.10805491 99.29242345
 99.49921519 95.8292847  97.86232155 97.86730448 97.1098986  98.76174104
 99.30986372 98.8016045  99.54904452 99.60634826 99.79320826 99.74587039
 95.51785136 97.72529088 94.5636196  97.92959115 98.22109276 98.70194584
 98.54498343 98.95607544 97.3565538  99.16286718 99.14044398 99.22764531
 98.82651917 98.86887411 99.42945412 93.52467798 97.99187782 93.46737424
 97.41884047 96.66890899 97.06754366 94.80280041 98.83399357 98.97102424
 98.27839649 98.95607544 99.08812318 98.88631437 99.07566584 98.83648504
 98.97849864 98.16628049 91.80307447 97.64058101 96.63153699 98.24849889
 93.51222064 98.95109251 97.63808954 97.94453995 98.98846451 97.87727035
 98.88382291 96.08092284 98.85641677 98.32573436 99.81563146 97.56085407
 98.49764556 95.98126417 97.57331141 97.69539328 99.27498318 98.81904477
 99.82559733 99.16535865]
Avg Prec: is [97.58438562 52.07617164 76.25599131 81.63656809 90.01430496 77.39908554
 89.71307888 58.90911691 75.29120103 69.33256817 65.49925705 69.99396648
 45.04028197 47.74091811 50.87814127 79.00697378 55.82458805 77.69592598
 76.98156396 67.4152585  91.76432061 84.37278873 96.69157978 97.54465173
 29.81271014 64.25290388 38.25773971 65.63643893 47.34197816 67.31597583
 86.40875845 59.70777562 67.09012645 86.89093534 83.66512952 88.39949215
 84.02403131 87.35378803 93.97784891 50.72041953 42.42378139 56.03708757
 52.95050732 46.52442012 38.15741193 57.25555716 63.65058572 46.44145011
 55.08363135 58.11224759 82.62094939 56.58268688 48.28759647 85.34981787
 53.49397065 59.2965347  62.19880706 68.47925404 45.47918094 76.18826954
 71.94361889 91.76463537 73.22288966 67.24953054 70.26908534 53.58102075
 72.61536814 37.54095536 48.82427315 73.07561552  8.78557141 80.93360369
 58.60552113 47.28614776 69.47386844 59.17269813 22.01701475 62.76113974
  2.95777534 28.17652259]
Accuracy th:0.5 is [90.23843337 97.80252635 93.75389292 98.59481277 99.31484665 98.18122929
 99.02334504 95.86167377 98.48518823 97.54839674 99.04078531 99.26501732
 99.44938585 95.77945537 97.84737275 98.08655355 96.93549593 98.60228717
 99.29242345 98.78914717 99.49921519 99.56897626 99.77327653 99.75334479
 95.41320976 97.58327728 94.5262476  97.87976182 98.15880609 98.52754316
 98.98846451 98.86638264 97.31419887 99.23761118 99.15290131 99.33976132
 98.78416424 98.7866557  99.36965892 93.55208411 98.03423275 93.72150385
 97.35406234 96.56177592 96.94546179 95.07187882 98.78914717 98.92617784
 98.25597329 98.95109251 99.16037571 98.84645091 99.02085358 98.84146797
 98.96105838 98.10648529 91.5315046  97.58576874 96.60662232 98.11146822
 93.59942198 99.04576824 97.58327728 97.81249221 98.96354984 97.75767995
 98.86638264 95.94638364 98.8016045  98.4353589  99.81563146 97.94204848
 98.40296983 95.92894337 97.51849914 97.67546154 99.25255998 98.7717069
 99.82559733 99.15040985]
Accuracy th:0.7 is [89.56324588 97.70785061 93.52467798 98.67952263 99.31733812 98.22358422
 99.04576824 95.86914817 98.5549493  97.60320901 99.03331091 99.27498318
 99.45436879 95.63993323 97.78508608 97.99686075 96.82088846 98.55245783
 99.26252585 98.7268605  99.49921519 99.59139946 99.78573386 99.74337893
 95.52283429 97.40389167 94.68071854 97.82744101 98.16628049 98.57238957
 98.97849864 98.88631437 97.229489   99.21518798 99.16286718 99.35471012
 98.80409597 98.73931784 99.31982958 93.55457558 97.95699728 93.60440491
 97.37399407 96.74614446 97.10491566 95.02454095 98.7717069  98.99843038
 98.35064903 98.94361811 99.11552931 98.8016045  99.01836211 98.89877171
 98.91621197 98.10897675 91.26740912 97.56334554 96.58918205 98.12641702
 93.47484864 99.02085358 97.50105887 97.79754341 98.94361811 97.81000075
 98.78914717 95.99870444 98.83399357 98.47023943 99.81563146 97.95699728
 98.5101029  95.86416523 97.48860154 97.68791888 99.26750878 98.6969629
 99.82559733 99.18030745]
Avg Prec: is [97.51399619 49.21240454 74.77887727 81.84357277 88.8072787  76.45434668
 89.64161209 59.29932005 74.25357096 69.61093991 63.03503977 68.86076959
 39.07321768 45.77615332 48.29554752 77.36617293 51.74777407 74.11558468
 74.76170912 61.59748757 90.0846813  80.54090365 96.14436177 97.13105819
 30.50789416 59.19094509 38.9477656  63.97183826 43.9598775  60.2144211
 85.80178132 58.29292729 63.94652229 84.13734359 83.31400403 88.81539264
 82.87389211 85.8357395  94.40333641 49.74692737 40.47897226 56.86095015
 51.54034953 45.97658465 37.75535344 57.26327945 61.00099516 44.99314432
 54.48193565 55.89191512 81.2963784  54.18916192 44.78227079 85.54750128
 50.60402185 56.94202286 61.75280275 68.37042369 45.02509179 74.28583816
 71.52699633 91.42243432 71.94693588 63.8830906  70.52605854 50.20477272
 70.99283309 35.68884624 45.78959633 73.06631084  8.8641982  81.01466355
 58.72478588 46.31513427 67.52099894 58.60613936 20.22545201 59.47918323
  3.12554839 29.07720866]
mAP score regular 64.13, mAP score EMA 62.64
Train_data_mAP: current_mAP = 73.21, highest_mAP = 73.21
Val_data_mAP: current_mAP = 64.13, highest_mAP = 64.13
lr:  [9.288449341939341e-05, 9.288449341939341e-05]
BCE Train Loss:  tensor([29.0382,  3.1481, 21.2364,  2.1445,  2.8647,  1.2204,  3.2489, 13.0554,
         1.2847,  5.1132,  6.9170,  1.8194,  1.9443,  5.0316, 10.1638,  2.6548,
         6.9920,  9.2792,  0.5836,  1.0556,  0.3333,  5.0458,  3.5633,  4.0509,
         8.1952,  4.8469, 12.6832, 15.1480, 10.0004,  4.6984,  7.7984,  1.3373,
         4.4634,  0.7549,  2.5960,  2.2263,  4.3374,  0.6006,  3.4241, 24.1705,
         8.3509, 23.7134, 11.2735,  8.7758, 13.7155,  7.9748,  6.8504,  4.4751,
         7.3124,  3.2816,  9.6037,  7.4873,  0.9096,  3.4466,  5.8305,  4.9492,
        15.5716,  4.8602,  3.9153,  6.6526, 14.3594,  2.7094,  6.0726,  4.0409,
         2.3060,  4.6122,  6.7221, 21.3469,  0.8696,  4.3399,  0.0537,  6.7847,
         2.3775,  8.8474,  4.6811,  8.9578,  1.9608,  5.2192,  0.1589,  1.6820],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [27/80], Step [000/642], LR 9.3e-05, Loss: 516.1
BCE Train Loss:  tensor([29.3193, 12.5431, 15.1001,  8.3108,  0.6617,  5.8674,  1.7943, 11.1208,
         4.0601,  4.3220, 10.9851,  5.1366,  0.1869, 18.5393,  9.8759,  7.8089,
         7.5913, 10.9682,  1.4085,  3.8137,  0.6622,  0.7300,  3.5813, 10.6655,
        17.8685,  2.2839, 19.6707,  5.1882,  7.5583,  0.9197,  2.0423,  1.5022,
         7.7362,  4.7987,  0.9660,  0.3636,  0.9560,  2.2369,  0.2439, 24.8344,
         6.4139, 20.8046,  9.3009,  9.8679,  7.0898, 14.4313,  1.0294,  5.7302,
         3.2765,  1.1188,  0.5231, 15.4644,  0.8339,  3.6261,  7.8021,  5.1372,
        16.5053,  6.4709, 10.9812,  5.0857, 10.7355,  3.7724,  6.7685,  4.3031,
         6.6278,  3.0758,  5.0560, 17.6515,  1.9817,  4.6945,  0.3602,  5.8250,
         6.9615, 12.4673, 12.5534, 22.5980,  1.3878,  4.6419,  0.2124,  8.6937],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [27/80], Step [100/642], LR 9.3e-05, Loss: 576.1
BCE Train Loss:  tensor([24.2203,  5.6493, 18.8859,  1.6826,  0.8206,  4.2428,  8.9457, 13.0012,
         2.9378,  5.0978,  2.8100,  2.0813,  0.2659, 14.1102,  7.7902,  6.4616,
         8.0982,  4.4823,  5.5982,  2.2771,  0.7541,  0.3862,  0.0983,  0.3306,
        23.3329,  9.1046, 18.6073,  2.4284,  3.4822,  3.7937,  4.8935, 10.7014,
         8.3863,  1.0056,  1.1212,  0.6258,  1.7367,  3.9898,  6.4008, 16.6524,
         5.6538, 15.7553, 11.7675, 10.3783,  6.6316,  7.4334,  4.9314, 10.8736,
         6.8840,  3.5588,  3.7149,  4.2206,  2.4217,  1.7078,  8.3618,  4.5445,
        24.2135,  3.2826, 14.2004,  7.7807, 19.6530,  1.2233,  1.6001,  5.5938,
         3.2285,  2.3613,  1.6825, 10.4542,  3.1120,  6.8771,  0.0614,  5.4528,
         8.5589, 14.4348, 15.3665,  2.9879,  8.8707,  7.3147,  0.2377,  0.8025],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [27/80], Step [200/642], LR 9.2e-05, Loss: 535.5
BCE Train Loss:  tensor([23.4122,  5.9112, 20.3507,  1.6968,  0.5849,  7.8650,  0.9679, 10.4124,
         3.4049, 12.0944,  1.6585,  0.9809,  0.2248, 15.4094,  8.5132,  6.9314,
         8.6301,  1.5408,  2.3639,  2.0711,  6.5556,  0.2258,  1.6358,  0.5975,
        13.9577,  3.1792, 12.9385,  6.5000, 10.3660,  0.9177,  1.8964,  2.1846,
         8.3984,  9.4321,  2.0455,  1.9881,  4.7831,  3.3967,  4.1860, 16.5932,
         5.6028, 21.7006, 11.0031, 13.4127, 11.1289, 18.5785,  9.2504,  6.0248,
         6.2724, 10.8230,  4.8682,  2.8286,  4.7175, 10.5970,  6.8237,  2.7925,
        15.9514,  6.6549,  4.9416,  1.7249, 13.8138,  9.1023,  5.0219,  4.3901,
         2.5759,  7.5075,  1.8111, 23.2359,  0.8991,  1.4472,  0.1558, 10.5850,
         0.9998, 13.9153, 19.5638, 16.0325,  7.5058,  6.0981,  0.4064,  1.8546],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [27/80], Step [300/642], LR 9.2e-05, Loss: 569.4
BCE Train Loss:  tensor([18.3018, 10.2576, 10.5662,  5.3995,  1.4663,  4.2370,  2.3456,  7.4496,
         3.0180,  9.9190,  3.1113,  0.6919,  0.3300, 16.7827, 10.4266,  7.2727,
        11.5551,  9.5213,  0.8612,  0.8449,  1.7937,  0.8316,  0.2793,  0.5154,
        16.6170, 10.8070, 22.2224,  3.3249,  2.0886,  1.7645,  6.6666,  3.8250,
         4.0751,  0.4062,  1.2961,  3.2406,  2.6490,  6.6362,  0.3432, 18.5825,
         7.0559, 20.3007,  6.6315, 14.0495,  7.0301, 12.0063,  1.4700,  5.7940,
         3.2497,  9.3997,  3.3279,  1.1337,  0.9126,  1.3674,  4.5491,  3.5661,
        20.6843,  7.7873,  6.5061, 16.7507, 17.0110,  1.0185,  5.3089,  5.7866,
         1.5096,  8.8134,  6.1160, 22.9753,  4.3763,  5.5589,  8.8895,  3.6842,
         1.9488,  6.5631,  8.1271,  3.8731,  1.4314,  5.3273,  0.0934,  4.7810],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [27/80], Step [400/642], LR 9.2e-05, Loss: 519.1
BCE Train Loss:  tensor([26.5678,  4.7403,  9.7047,  1.2563,  1.2418,  9.6200,  0.8007, 14.5806,
         2.7105,  5.5122,  7.0491,  2.8003,  0.9689, 11.1796, 10.5325,  3.8353,
         4.7024,  1.6553,  0.5545,  4.9136,  5.0516,  4.6385,  0.1309,  0.1779,
        13.5923,  3.1877, 16.2630,  3.2342,  5.8312,  1.0408,  2.1404,  8.5631,
         6.7305,  0.5877,  2.3083,  4.2604,  5.5639,  1.7748,  0.2877, 15.3335,
         8.0645, 16.3250,  6.2974, 11.9570,  7.7304, 15.1650,  1.1285,  3.1140,
         4.4544,  2.1931,  3.9408,  2.9184,  1.0864,  1.3119,  0.7855,  2.6781,
        17.9584,  8.2430,  5.0722,  2.5570, 12.8526,  1.1445, 11.5797,  6.3496,
         9.1748,  5.8112,  4.4147, 16.0137,  1.7019,  3.5820,  0.5318,  4.4996,
        11.5388, 10.3634,  9.0271,  9.4009,  1.5555,  6.5827,  0.2534,  4.5744],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [27/80], Step [500/642], LR 9.2e-05, Loss: 479.6
BCE Train Loss:  tensor([33.7117,  5.0370, 19.0960,  1.8369,  1.2382,  3.3701,  4.4765,  6.6361,
         3.8278,  5.3532,  5.5563,  3.3648,  0.5031, 10.8145, 19.6107,  4.8709,
        13.9582,  1.7728,  0.6009,  2.5354,  0.4866,  0.1813,  0.1357,  0.1416,
        14.5795,  5.8178, 14.3064,  7.3129,  1.5798,  7.1498,  1.5062,  2.2774,
         2.5957,  1.1602,  0.7028,  2.2281,  0.5794,  3.7104,  1.9696, 24.4077,
         2.1289, 15.6825,  8.9213,  4.9114, 10.0581, 18.6803,  1.8352,  3.5547,
         7.1034,  1.9855, 11.1707,  1.2588,  8.7052,  2.4150,  0.9383,  3.7310,
        26.6028, 16.4930,  8.2817,  4.5457, 16.2013,  4.1736,  3.2668,  5.2789,
         4.4503,  2.3396,  2.6542,  7.6882,  0.5936,  1.1378,  0.0943,  2.3528,
         5.4363, 13.4104, 13.1187,  6.1956,  6.9670,  3.3141,  4.4049,  8.0691],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [27/80], Step [600/642], LR 9.2e-05, Loss: 511.2
BCE Val Loss:  tensor([4.8378e+01, 2.3587e+01, 4.0655e+01, 2.1436e+01, 4.7014e-02, 1.0401e+01,
        5.3186e+00, 2.0122e+01, 6.3273e+00, 8.3341e+00, 8.7653e+00, 1.2052e+01,
        7.6431e+00, 1.5789e+01, 7.8032e+00, 1.4539e+01, 1.7552e+02, 5.0839e+00,
        7.2524e-01, 1.7078e+00, 1.7786e-01, 6.0233e-01, 1.9007e-02, 2.2910e-02,
        2.2860e+01, 1.2199e+01, 2.9034e+01, 1.7535e+00, 1.4232e+01, 1.6396e+01,
        2.0621e+00, 1.9784e+00, 1.0645e+01, 1.3410e+00, 3.4010e-01, 1.3750e-01,
        1.0078e+01, 4.3328e+00, 2.2357e+00, 3.5956e+01, 1.3320e+01, 1.8938e+01,
        5.2237e+00, 1.4422e+01, 1.2718e+01, 1.6808e+01, 6.9680e-01, 4.5461e+00,
        1.5469e+00, 3.2159e+00, 8.2401e-02, 2.6255e-01, 4.1744e+00, 1.9373e-01,
        2.4874e-01, 2.5018e-01, 2.0453e+01, 7.4818e+00, 1.0028e+01, 1.6032e+00,
        9.8635e+00, 2.8623e+00, 4.3929e+00, 8.9114e+00, 8.5889e-02, 1.4466e-01,
        9.8424e-02, 5.3648e+00, 8.1501e+00, 1.4751e+01, 1.1321e-01, 1.8321e+01,
        1.1203e+01, 8.6678e+00, 1.6012e+01, 5.5042e+00, 7.0851e-01, 8.8127e+00,
        1.0685e-01, 8.1138e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [27/80], Step [000/314], LR 9.2e-05, Loss: 861.7
BCE Val Loss:  tensor([5.9270e+01, 1.7919e+01, 4.6339e+01, 1.0818e+01, 2.0053e+00, 3.6775e+01,
        3.0594e+01, 3.8109e+01, 2.0326e+01, 2.7675e+01, 1.5772e+01, 3.7068e+01,
        1.0090e+01, 8.2196e+00, 1.7112e+01, 4.4809e+00, 5.1373e+00, 2.0742e+01,
        1.9834e+00, 1.6155e+01, 1.5636e-01, 1.1487e-01, 5.1159e-02, 1.9063e-02,
        2.6634e+01, 2.2474e+01, 2.9730e+01, 1.8543e+01, 1.5733e+01, 2.0461e-01,
        2.9234e-01, 2.0071e-01, 8.3368e-01, 2.6656e+00, 9.3864e-01, 1.0338e-01,
        2.1114e+00, 1.1279e+00, 7.7298e-02, 3.0240e+00, 7.2288e-02, 5.5518e+00,
        7.9732e-01, 2.3181e+00, 3.4230e+00, 3.1167e+00, 1.3861e-01, 2.3981e-01,
        2.7653e-01, 5.3082e+00, 3.1456e-02, 1.2221e-01, 6.8081e-02, 8.4298e-01,
        1.0693e-01, 4.3874e-01, 1.0999e+01, 8.4062e+00, 4.6928e+00, 1.3171e-01,
        8.1130e+00, 1.3174e-01, 5.2732e-01, 1.6665e-01, 4.2518e-02, 2.4348e-02,
        3.8484e-02, 2.1654e+01, 8.2744e-02, 3.3110e+00, 1.0568e-02, 1.8157e-01,
        2.7029e+00, 4.3849e+00, 4.6973e+00, 4.2347e-01, 6.8932e-01, 3.5094e-01,
        4.7293e-03, 8.5715e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [27/80], Step [100/314], LR 9.2e-05, Loss: 646.3
BCE Val Loss:  tensor([1.1714e+01, 3.5734e-01, 3.6028e+00, 1.0837e-01, 6.4967e-02, 6.1123e-02,
        8.0974e-02, 1.7058e+01, 1.3539e-01, 3.1154e-02, 4.2967e-02, 3.6967e-02,
        1.5516e-02, 1.3298e+01, 3.9435e-01, 7.1115e-01, 1.7367e+00, 1.2090e-01,
        5.1440e-02, 2.2614e-02, 3.2401e-02, 1.6891e-02, 3.3659e-03, 3.3388e-03,
        3.8839e+00, 1.6630e+00, 2.7076e+01, 5.0579e+00, 3.8658e-01, 2.3287e-01,
        1.2287e-01, 6.9223e+00, 8.3781e+00, 1.3031e-01, 7.2430e-01, 1.9394e-01,
        1.0424e+01, 7.0074e+00, 4.6559e-02, 4.9567e+01, 2.1172e+01, 7.2322e+01,
        5.6688e+01, 5.5945e+01, 5.7862e+01, 7.0864e+01, 7.9839e+00, 7.7762e+00,
        5.1850e+01, 1.0422e+01, 2.4126e+01, 3.3849e+01, 5.7633e+01, 1.0577e+01,
        4.3560e+01, 8.9419e+01, 1.0951e+02, 1.3535e+01, 7.1970e+00, 1.8909e-01,
        7.3660e+01, 5.3764e-01, 1.1951e+01, 1.1186e+01, 1.5598e+01, 5.8114e-01,
        1.1390e+01, 1.2520e+01, 7.4053e+00, 5.7143e+00, 1.1418e-01, 1.2945e+01,
        7.8783e+00, 4.7785e+01, 2.4835e+00, 1.4477e+01, 1.0849e+01, 1.2241e+00,
        4.7873e-02, 5.6560e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [27/80], Step [200/314], LR 9.2e-05, Loss: 1222.9
BCE Val Loss:  tensor([2.6032e+01, 2.0064e+00, 1.2452e+01, 1.2097e+00, 6.4427e-01, 9.0168e+00,
        7.2733e+00, 1.6116e+01, 2.5928e+00, 1.8158e+01, 4.4300e+00, 7.8044e+00,
        4.3502e-01, 1.3450e+01, 1.6134e+01, 2.0123e-01, 1.0715e+00, 6.5011e-01,
        3.6419e-02, 4.7630e-02, 8.3301e-02, 4.7226e-02, 1.3889e-02, 4.5669e-02,
        1.9645e+01, 1.0424e+01, 2.1257e+01, 8.8406e-01, 1.3565e+01, 8.6633e-02,
        4.4625e-01, 1.4784e-01, 2.5452e-01, 1.3801e-01, 1.2204e-01, 7.6525e-02,
        1.8797e-01, 1.4904e-01, 1.8988e-02, 3.7390e+00, 4.4088e-01, 2.6863e+00,
        7.0229e-01, 1.3375e+00, 2.1263e+00, 4.8184e+00, 8.7910e-02, 1.5301e-01,
        1.5626e-01, 8.5023e-02, 2.2652e-02, 8.3700e-02, 3.8518e-02, 9.2300e-02,
        5.5836e-02, 1.3911e-01, 4.9177e+00, 4.9815e-01, 1.2481e+01, 2.0874e-01,
        6.7206e+00, 2.4730e-01, 6.5005e-01, 3.9071e-01, 4.5283e-02, 1.6728e-01,
        2.0257e-01, 6.1930e+00, 7.7593e-02, 2.0773e-01, 1.0469e-02, 1.7572e-01,
        4.6789e-01, 6.3094e+00, 6.4798e+01, 3.5558e+00, 1.4495e-01, 4.6920e+00,
        1.4661e-02, 4.8020e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [27/80], Step [300/314], LR 9.2e-05, Loss: 337.3
starting validation
Accuracy th:0.5 is [91.97256369 98.19812137 94.74177946 98.83895177 99.45907092 98.54533936
 99.30190909 96.53147501 98.83895177 98.17131858 99.22881057 99.30800063
 99.59795811 96.46446803 98.15669887 98.47589576 97.55241773 98.90595875
 99.41033857 99.08505013 99.57602856 99.66252848 99.78801428 99.69664112
 95.73835601 98.08116373 95.11945517 98.23345232 98.60990972 99.03997271
 99.05824734 99.14840219 97.91303712 99.30800063 99.33358512 99.31652879
 99.06555719 99.16058528 99.63694399 94.06074487 98.1469524  94.27882214
 97.8545583  97.26489687 96.98224924 95.42281405 98.96565588 99.05702903
 98.43081834 99.12403601 99.32018372 99.07164874 99.29459924 99.12038109
 99.20444439 98.50757179 93.36265396 97.54998112 97.28438981 98.65133222
 94.84289909 99.30921894 97.96420609 98.31020577 99.20688101 98.1323327
 99.06921212 96.45837648 99.0107333  98.82311375 99.81603538 98.40279724
 98.82676868 96.39867935 97.85821323 98.0214666  99.31409218 98.98758543
 99.84771141 99.29703585]
Accuracy th:0.7 is [90.76521972 98.06410741 94.04490686 98.64158575 99.37378931 98.47955069
 99.21662748 96.09166555 98.69762795 97.94105822 99.22271902 99.28850769
 99.59795811 96.23908091 98.04826939 98.22126923 97.52074171 98.78169126
 99.32871188 98.97418404 99.5260779  99.66740171 99.76121149 99.62719752
 95.53733507 98.18959321 95.07072282 98.15060733 98.52828304 98.92179676
 99.01804315 99.01682484 97.84359352 99.27876122 99.16058528 99.11794447
 98.91205029 99.07652197 99.55531731 94.32024464 98.03121307 94.28613199
 97.9800441  97.06143931 97.50734031 95.95765159 98.8572264  99.03388117
 98.70859273 99.10088815 99.19835285 99.11672616 99.21784579 98.94981786
 99.11063462 98.32360717 92.53420402 97.1442843  97.08580548 98.38574091
 94.8441174  99.29703585 97.58653038 98.33213533 99.16545851 97.93374837
 98.95225448 96.30243296 98.83895177 98.70250119 99.81603538 98.29802268
 98.84747993 96.02100364 97.71201618 98.0214666  99.28485277 98.96809249
 99.84527479 99.31652879]
Avg Prec: is [98.32396141 66.03707504 82.07527356 85.57923178 95.15478941 84.56844375
 93.86986857 71.96300222 81.13583571 80.30305736 74.56014235 76.63280235
 59.74709202 58.61160638 60.6494475  83.98882873 65.65859849 83.41258735
 82.61899885 76.77338899 92.68322023 83.98928037 96.96340098 96.74067586
 45.28470166 74.26886158 54.73317128 74.88651564 60.44886158 79.04539744
 90.55477865 76.41395515 78.12732228 89.5253029  91.91206552 92.80496437
 91.81626572 91.89841145 97.27723246 60.59401039 57.9032707  67.62182607
 71.74412288 65.87116778 56.68584964 70.62620852 75.6150893  63.46159983
 70.24502003 71.42647351 85.8426951  70.80255763 65.76179517 90.57778817
 70.27181437 77.59735183 75.42202245 79.51067521 62.27779267 85.70023782
 83.31578964 94.49674807 81.49774642 77.26225033 80.83937203 72.09529742
 79.3275386  51.93285275 64.31393696 82.63332545 20.20246523 87.54853732
 76.81627017 61.20595815 72.65124118 71.18840692 42.4176375  72.84696713
 15.27302878 52.43417979]
Accuracy th:0.5 is [90.91263508 97.91912867 94.27029398 98.70981104 99.37500761 98.43203665
 99.19347961 96.32679914 98.67813501 97.91912867 99.0947966  99.26779644
 99.56140885 96.08191908 97.95933285 98.30776915 97.2551504  98.73905045
 99.31409218 98.98027558 99.49927511 99.58942995 99.76121149 99.64059892
 95.55926463 97.80582595 95.01711724 97.99953704 98.4539662  98.81458559
 98.94616294 99.07164874 97.71201618 99.24464858 99.27023306 99.28119784
 98.94738125 98.98393051 99.554099   94.03394208 98.20055799 94.07901951
 97.76196684 96.94935491 97.38307282 95.62992654 98.78656449 98.96565588
 98.55995906 99.03631778 99.25804998 98.9973319  99.24464858 99.0241347
 99.08505013 98.42107187 92.91066142 97.770495   96.98468586 98.52584642
 94.61751197 99.17885991 97.80948088 98.04583277 99.1362191  98.1749735
 98.95225448 96.42182722 98.95347279 98.66595193 99.81969031 98.17619181
 98.75123354 96.24517245 97.71079787 97.90450896 99.27754291 98.84869824
 99.84527479 99.25683167]
Accuracy th:0.7 is [89.28862952 97.76440346 93.65139314 98.67813501 99.36647945 98.3565015
 99.16058528 96.06973599 98.61721958 97.80948088 99.04484594 99.23612042
 99.53704268 95.85775027 97.84237521 98.15304394 97.04438299 98.66107869
 99.22271902 98.85844471 99.49927511 99.58942995 99.75511994 99.63085245
 95.38626479 97.63769935 94.67842741 97.88745264 98.36502967 98.6769167
 98.96687419 98.91205029 97.3672348  99.15083881 99.24099365 99.27876122
 98.87550103 98.96200095 99.50049342 93.76225923 98.08481865 93.68672409
 97.64988243 96.878693   97.18083357 95.29732825 98.68788148 98.92057845
 98.57092384 98.98149389 99.23124718 98.91570522 99.19347961 99.07895859
 98.99245867 98.22857909 91.97256369 97.66572045 96.87381976 98.45883944
 94.02541392 99.17276836 97.66693876 97.95689624 99.06555719 98.05923417
 98.87062779 96.19156687 98.92423338 98.64645899 99.81603538 98.17984674
 98.73417722 95.97470791 97.57312898 97.83141044 99.23733873 98.72808567
 99.84405648 99.20809932]
Avg Prec: is [97.93303299 59.2730692  79.08096249 82.04625408 93.86143515 81.88245898
 91.8476887  67.65027608 77.45620664 75.39835971 67.83033504 73.62092549
 52.77956255 50.97640172 54.6170978  79.69620046 56.4736951  78.30366106
 77.22624398 70.80633979 90.54895376 79.22657904 96.23709366 95.94135585
 40.76957427 66.45263157 50.51711827 69.04632176 51.67290685 70.28017146
 89.03025778 71.61866048 73.09289239 86.50308223 90.03717013 91.03884671
 88.77833609 88.66714241 96.23465681 56.15080106 49.87305037 64.36045721
 66.31153127 59.99767285 52.22409639 66.84478198 68.65263772 56.23625972
 64.90016188 65.28760558 82.8052639  65.14359709 55.76463368 88.05797667
 62.61583298 71.84966005 71.08424233 76.07717224 54.72020773 81.61856157
 80.95823709 92.7407088  77.1564525  71.15356123 77.00150394 66.72053818
 74.45448473 44.75300527 58.25555997 78.86846649 17.82391439 85.23373863
 72.75714364 55.31189151 68.11286882 67.50506467 34.74772442 66.05819409
 11.13921559 42.79059443]
mAP score regular 74.46, mAP score EMA 69.73
starting validation
Accuracy th:0.5 is [90.68938884 97.88225328 93.86850039 98.69447144 99.38211625 98.23105862
 99.13047811 95.93890924 98.57488103 97.68044448 99.04327678 99.28744052
 99.47928345 95.8591823  97.92211675 98.17624636 97.1098986  98.74430077
 99.36467598 98.87634851 99.54406159 99.63624586 99.80068266 99.76081919
 95.30856815 97.50853327 94.30450706 97.96696315 98.26593916 98.76672397
 99.08064878 98.89129731 97.43628074 99.30488078 99.14542691 99.28744052
 98.87634851 98.87136557 99.41201385 92.77225503 98.05167302 93.2306849
 97.14228766 96.58170765 95.95385804 94.08525799 98.83150211 98.90126317
 97.90467648 98.97600718 99.17532451 98.79911304 99.08064878 98.82153624
 98.99843038 98.18372076 91.45426913 97.42133194 96.64399432 98.14634876
 93.06873957 99.10805491 97.55337967 97.92211675 98.95856691 97.77013728
 98.91870344 96.10583751 98.84395944 98.47522236 99.81563146 98.00931809
 98.24849889 96.06597404 97.60819194 97.54839674 99.25505145 98.87883997
 99.82559733 99.05822558]
Accuracy th:0.7 is [90.18611256 97.88474475 93.77631612 98.64713357 99.33976132 98.25348182
 99.06320851 95.82430177 98.57238957 97.62064928 99.08563171 99.30737225
 99.49672372 95.88658843 97.94204848 98.00682662 97.1846426  98.6745397
 99.33228692 98.82153624 99.51416399 99.66116053 99.79320826 99.73839599
 95.53529163 97.75020555 94.62590627 97.95450582 98.22856716 98.7492837
 99.01587064 98.92368637 97.416349   99.34474425 99.07815731 99.16785011
 98.8165533  98.83150211 99.38709919 93.55955851 97.97942048 93.80372225
 97.50105887 96.80593966 96.83085432 95.00959215 98.83648504 98.96853278
 98.24351596 99.00341331 99.09808905 98.90375464 99.03081944 98.7044373
 98.97351571 98.11645115 91.30228966 97.13730473 96.70129805 98.05914742
 93.58198171 99.07317438 97.2892842  97.99187782 98.92866931 97.68044448
 98.81904477 96.08092284 98.76672397 98.38802103 99.81563146 97.91962528
 98.42539303 95.89157137 97.52597354 97.66300421 99.26003438 98.88382291
 99.82559733 99.14293545]
Avg Prec: is [97.63228658 52.8048232  75.71777877 82.23722246 90.37976344 77.03040433
 90.69051193 59.094006   75.33748007 70.76475018 66.33951895 69.98940314
 44.62473941 48.08924084 52.49788286 80.04508929 58.03080738 77.59169507
 78.44355416 68.04592324 91.06456218 84.9064925  96.44067156 97.55263479
 30.96313236 64.83400106 39.31691229 66.44861834 47.91420043 68.52065917
 87.59778684 60.32386012 67.41511937 87.07459907 83.19951298 89.37718479
 84.46663956 87.73813758 95.03979786 49.63545226 44.81810089 57.29020548
 53.17145191 46.76279965 37.87403584 57.69510312 63.57890667 44.812821
 55.79557896 59.27225898 81.21044319 57.16972762 48.80857653 85.63113376
 53.40024802 58.27817476 60.78763428 68.69369892 46.58328151 75.39612276
 70.2953348  91.42819928 72.57991579 67.43349719 69.51215458 48.91582513
 72.14683528 37.72568223 46.27912642 72.38436391  8.03457176 80.5900405
 57.04603821 48.18549391 69.1206166  58.53991934 20.83282323 62.98259064
  2.91158077 31.24948691]
Accuracy th:0.5 is [90.4377507  97.84737275 93.83112839 98.61225303 99.33228692 98.20614396
 99.05324264 95.84672497 98.52256023 97.59324314 99.06071704 99.26501732
 99.46433465 95.8143359  97.86730448 98.13139996 96.98532526 98.62720183
 99.31484665 98.8016045  99.52412986 99.59139946 99.77576799 99.75334479
 95.39327802 97.66051274 94.50631587 97.90965942 98.17873782 98.6072701
 99.02334504 98.88880584 97.3490794  99.24508558 99.15788425 99.34972718
 98.83897651 98.8165533  99.38709919 93.64426838 98.03423275 93.68413185
 97.3490794  96.59167352 96.94795326 95.11423375 98.82153624 98.94860104
 98.26593916 98.96354984 99.16037571 98.86139971 99.03580238 98.86887411
 98.97849864 98.12392555 91.56638513 97.62812368 96.62655405 98.10150235
 93.64177691 99.05573411 97.59573461 97.82494955 98.98846451 97.76764581
 98.88133144 95.9488751  98.80658744 98.47522236 99.81563146 97.95699728
 98.4353589  95.9115031  97.55088821 97.66798714 99.25006852 98.79911304
 99.82559733 99.14542691]
Accuracy th:0.7 is [89.86471336 97.76266288 93.62184518 98.68699704 99.34972718 98.24102449
 99.07566584 95.9414007  98.5848469  97.65802128 99.05573411 99.28245758
 99.46433465 95.7022199  97.81000075 98.05416449 96.87819219 98.64215063
 99.30737225 98.75177517 99.53160426 99.61631412 99.78573386 99.75085333
 95.52034283 97.50853327 94.67075267 97.83989835 98.20614396 98.6147445
 99.01337918 98.91372051 97.24194633 99.24259412 99.17034158 99.34474425
 98.84645091 98.77668984 99.33726985 93.59942198 98.00682662 93.65921718
 97.43628074 96.77853352 97.0949498  95.10177642 98.8016045  98.99843038
 98.34815756 98.95358397 99.14542691 98.83150211 99.03580238 98.90375464
 98.94610957 98.14385729 91.36706779 97.60071754 96.63153699 98.15631462
 93.54211825 99.04825971 97.56832847 97.83989835 98.97351571 97.82494955
 98.83648504 96.03607644 98.84645091 98.46774796 99.81563146 97.97692902
 98.50761143 95.92146897 97.53344794 97.71532501 99.26750878 98.7418093
 99.82559733 99.18279891]
Avg Prec: is [97.60128561 50.29037679 75.24223748 82.24841663 89.28729071 76.93276951
 90.04443301 59.74206115 74.8990546  70.31996089 64.14890061 69.23077483
 40.60218903 46.85138987 49.38191335 78.32103631 53.49947294 75.37329385
 75.98015969 63.32036314 90.61188772 81.91898607 96.27565377 97.28151295
 30.74466856 60.80534765 39.27961758 64.88962942 45.17104925 62.32261128
 86.2259301  59.33582012 64.79730525 84.88330562 83.62981149 89.09259461
 83.48030545 86.44524392 94.53236648 50.34255205 41.59072697 57.21261496
 52.28592371 46.65014611 38.3001016  57.82311612 62.16204945 45.73352865
 55.34681932 56.6730713  81.80200706 55.30928532 46.16305735 85.96512563
 51.86565803 58.00961723 62.25705266 69.21876168 45.90690626 75.15129992
 71.87483637 91.77326275 72.6247836  65.02928066 71.0388135  51.17209166
 71.88966143 36.6610038  46.70711118 73.5348889   8.90032301 81.3587926
 59.33538476 47.05971751 68.16299614 59.2065482  21.03085115 60.62782661
  3.20244774 29.55121442]
mAP score regular 64.26, mAP score EMA 63.39
Train_data_mAP: current_mAP = 74.46, highest_mAP = 74.46
Val_data_mAP: current_mAP = 64.26, highest_mAP = 64.26
lr:  [9.157139026035833e-05, 9.157139026035833e-05]
BCE Train Loss:  tensor([23.1015,  9.8441, 17.3154,  2.4475,  2.8065,  1.5383,  1.0055,  4.8833,
         0.6218,  3.8394,  0.7108,  0.8668,  0.5578, 16.4773,  3.6186,  8.5919,
         4.5937,  5.1580,  2.2627,  2.7127,  2.6546,  0.3686,  4.3101,  0.1940,
        24.7993,  5.9136, 17.0654,  4.5984,  2.9876,  3.1853,  4.3898,  2.1008,
         7.0133,  2.4713,  5.6026,  8.9512,  9.3116,  0.8279,  0.3262, 23.9588,
         7.1564, 24.0585, 11.6926, 13.1294, 11.2724, 14.6248, 13.0541,  9.2255,
         2.7358,  6.5168,  1.6195,  2.1962,  1.2606,  1.8285,  0.5249, 12.2703,
        32.0051,  5.1434, 12.1954,  4.5148, 18.0877,  1.5168,  4.3997,  7.2837,
         1.0356,  7.1131,  1.3564,  6.3612,  4.2931,  2.4803,  0.3246,  4.4439,
         6.7547, 10.9744,  8.2574, 17.7358,  5.6689,  0.5845,  0.3029,  2.5516],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [28/80], Step [000/642], LR 9.2e-05, Loss: 542.5
BCE Train Loss:  tensor([18.7962,  7.7003, 13.2509,  5.3018,  1.2702,  4.6071,  0.8633,  8.3007,
         2.8890,  9.4918,  4.2591,  3.0000,  0.2377, 11.7372,  3.5397,  5.8211,
         9.0122,  3.3209,  1.4110,  2.2991,  5.2276,  0.0872,  4.2866,  0.0994,
        14.1596,  5.6496, 14.1604,  8.8348,  5.3704,  1.1800,  2.3918,  2.6283,
         8.7911,  1.5879,  1.8238,  1.9398,  5.0066,  3.9798,  1.5302, 18.5833,
         6.2203,  8.0629,  5.1892,  8.7991, 13.9435, 18.2927,  2.0550,  1.5871,
         2.5556,  1.2538,  1.6036,  1.3136,  6.1992,  0.8779,  2.6671,  2.8730,
        21.8131,  8.8452,  8.5314,  1.8500,  9.1092,  1.6771,  2.6187,  7.6243,
         3.6326,  2.5490,  3.8381, 15.0984,  4.5670,  2.1454,  0.0841,  4.2683,
         4.5664, 16.3746,  9.8035,  1.3427,  0.9190,  2.3272,  0.0688,  3.4360],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [28/80], Step [100/642], LR 9.1e-05, Loss: 445.0
BCE Train Loss:  tensor([1.9061e+01, 5.3052e+00, 1.6322e+01, 1.8328e+00, 3.7694e+00, 4.5406e+00,
        9.4104e+00, 6.8256e+00, 4.6031e+00, 4.4577e+00, 3.7095e+00, 5.2889e+00,
        5.8983e-01, 1.5376e+01, 9.3940e+00, 2.4216e+00, 7.7927e+00, 7.6310e+00,
        2.3699e+00, 3.8503e+00, 1.2680e+01, 2.0417e+00, 9.8607e-02, 3.8923e-02,
        1.3999e+01, 8.4944e+00, 8.1546e+00, 6.7237e+00, 1.9629e+00, 3.4047e+00,
        1.8561e+00, 7.7706e+00, 1.2646e+01, 2.1267e+00, 8.8879e+00, 9.1204e-01,
        1.6759e+00, 1.4554e+00, 1.9678e+00, 1.3807e+01, 9.2093e+00, 1.3941e+01,
        3.9318e+00, 1.0525e+01, 1.1070e+01, 9.7909e+00, 6.4457e+00, 1.3536e+00,
        2.8331e+00, 4.1963e+00, 8.2744e-01, 1.5869e+00, 9.7128e-01, 1.7425e+00,
        1.4025e+00, 3.9289e+00, 4.2243e+01, 9.6569e+00, 7.4656e+00, 4.4294e+00,
        1.2343e+01, 1.5315e+00, 8.2657e+00, 3.4117e+00, 9.8655e+00, 7.0964e+00,
        6.2318e+00, 1.6037e+01, 4.1715e+00, 4.3856e+00, 2.2949e+00, 1.7229e+01,
        6.9036e+00, 1.6981e+01, 1.2572e+01, 4.4637e+00, 7.5038e+00, 7.4534e-01,
        9.5169e-02, 1.4530e+00], device='cuda:0', grad_fn=<NegBackward0>)
Epoch [28/80], Step [200/642], LR 9.1e-05, Loss: 536.4
BCE Train Loss:  tensor([31.5499,  5.3079, 16.3710,  2.4473,  0.6148,  8.1854,  1.9185, 15.3239,
         3.7531, 11.4191,  5.5501,  5.7505,  0.4400, 11.1761, 14.7385,  7.8245,
        11.8583,  4.8150,  2.7859,  2.4451,  0.7636,  0.9520,  0.7024,  1.0890,
        12.8769, 14.2540, 18.8659,  5.6665,  8.8770,  4.3667,  2.9083,  3.0730,
         7.8570,  3.3279,  5.7077,  1.9611,  3.6624,  6.1541,  4.3535, 20.0966,
         7.9820, 19.2879,  8.1624,  7.2869, 10.4897, 17.9868,  3.6345, 16.0989,
         8.8069,  7.3436,  0.1767,  2.9914,  0.9943,  7.1024,  4.0453, 15.8954,
        21.3063,  6.1302,  7.6798,  6.8950, 18.7476,  0.7071,  6.4416,  6.2981,
         1.7925,  3.3681,  2.1888, 12.3597,  1.6988,  4.1675,  1.7995,  6.6433,
         6.3049, 13.0737, 14.9863,  3.4833,  5.5156,  4.3735,  0.1320,  0.6926],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [28/80], Step [300/642], LR 9.1e-05, Loss: 586.9
BCE Train Loss:  tensor([25.3766, 11.3694, 19.1016,  2.1051,  3.3621,  4.7729,  0.8370, 18.0225,
         5.6246, 12.0698,  5.2022,  0.7213,  0.4333, 13.1132, 11.5488,  1.7464,
         3.8359, 12.7801,  0.6583,  3.0126,  4.0735,  0.1275,  0.4366,  0.2297,
        20.1005,  3.0423, 19.4233,  4.5690,  8.3244,  2.1978, 12.4904,  1.0860,
         6.9968,  0.9457,  0.6686,  3.7333,  1.1666,  1.6168,  0.5017, 10.0252,
         6.9179, 19.2138, 10.2435,  5.4787, 13.9311, 11.7552,  1.8859,  2.9886,
         3.1002,  7.4253,  1.0674,  1.0770,  0.5419,  0.4945,  0.9318,  6.5839,
        15.1675,  3.0960, 12.6705,  5.1294,  9.5773,  4.2254, 10.5076,  1.7066,
         0.9473,  5.1441,  1.2687, 11.3255,  2.8576,  8.8851,  0.3642,  1.7587,
         1.2856,  5.6038,  3.0624,  6.9749,  9.6263,  6.0247,  0.1205,  0.6678],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [28/80], Step [400/642], LR 9.1e-05, Loss: 479.1
BCE Train Loss:  tensor([24.9592, 14.3892, 20.6094, 11.3733,  0.4415,  1.4558,  0.4962,  5.6702,
         2.1636,  3.4380,  0.6116,  0.7303,  0.3996, 11.7822, 16.3117,  3.4826,
         5.4827,  8.3403,  1.3531,  4.0469,  0.1703,  4.7626,  0.1774,  4.3313,
        20.3694, 15.1464, 24.6149,  8.8360,  4.5383,  2.4267,  0.7253,  0.6837,
         8.7072,  6.0799,  4.3653,  1.5112,  1.2788,  0.4804,  0.1618, 22.6567,
         6.2585, 19.9648,  6.8566, 17.8538, 15.0726, 10.2693,  8.5276,  1.7805,
        11.4751,  6.5798,  1.1770,  0.7151,  2.0384,  3.1381,  3.8488,  2.3394,
        21.2936,  8.3594, 16.6261,  3.5127, 15.8513,  1.3408, 10.1014,  5.3484,
         1.0523,  6.1821,  1.7043, 17.3797,  2.7025,  3.0801,  0.1664,  3.4746,
         1.7717, 10.3539, 16.4402,  5.0394,  0.5846,  7.0220,  4.4089,  1.3358],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [28/80], Step [500/642], LR 9.0e-05, Loss: 552.6
BCE Train Loss:  tensor([21.2416, 12.1082, 17.3906,  3.2583,  0.8374,  1.6975,  2.7242, 11.3189,
         4.5947,  6.7655,  4.0363,  0.7562,  0.2110, 18.7213,  8.7666,  3.4687,
         6.1717,  3.5161,  3.0224,  5.1895,  3.8025,  0.3804,  0.2450,  0.1468,
        12.8774,  7.3030, 11.4325,  5.9169,  3.0302,  5.1054,  0.3440,  0.4018,
         6.6569,  4.1839,  3.0865,  0.9899,  0.6003,  2.3957,  1.7872, 14.9667,
         8.2048, 11.1926,  3.9080,  6.7273,  6.1946, 14.3465,  2.3036,  1.3776,
         8.3229,  2.1624,  0.4859,  0.7380,  2.5542,  8.3439,  4.4137,  4.9760,
        16.6534,  5.7628,  7.3883,  5.7172, 13.1644,  1.0776,  7.9932,  3.9186,
         0.9992,  2.6613,  0.6322, 13.9246,  1.9166,  3.9158,  0.3249,  7.0141,
         4.5660, 13.3697,  4.6350,  4.9981,  4.6023,  7.9987,  0.1438,  0.8243],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [28/80], Step [600/642], LR 9.0e-05, Loss: 441.9
BCE Val Loss:  tensor([4.6135e+01, 1.9813e+01, 4.7013e+01, 2.2540e+01, 1.4749e-01, 9.5128e+00,
        8.0379e+00, 2.3573e+01, 6.3854e+00, 7.8661e+00, 8.5724e+00, 1.1694e+01,
        7.0852e+00, 1.4173e+01, 7.8671e+00, 2.1236e+01, 1.7682e+02, 4.4126e+00,
        1.3238e+00, 2.9834e+00, 3.7327e-01, 1.5331e-01, 2.7351e-02, 6.0929e-02,
        2.5034e+01, 1.3643e+01, 2.9351e+01, 1.7131e+00, 1.7432e+01, 1.8229e+01,
        8.3071e-01, 9.6511e-01, 9.6795e+00, 2.5784e-01, 2.7951e-01, 2.2087e-01,
        1.0795e+01, 4.5971e+00, 2.1461e+00, 4.1445e+01, 1.1015e+01, 2.1721e+01,
        7.2856e+00, 1.3440e+01, 1.4546e+01, 1.4918e+01, 7.7042e-01, 4.6032e+00,
        1.1125e+00, 3.5621e+00, 1.5803e-01, 2.2216e-01, 2.4517e+00, 4.1912e-01,
        1.8038e-01, 1.8656e-01, 2.4072e+01, 7.8324e+00, 1.0127e+01, 2.0522e+00,
        8.3294e+00, 5.6086e+00, 3.6266e+00, 7.1619e+00, 1.4639e-01, 6.4968e-01,
        1.8760e-01, 7.4478e+00, 7.2985e+00, 1.3924e+01, 1.4267e-01, 1.8079e+01,
        1.0355e+01, 8.2485e+00, 1.6338e+01, 7.6506e+00, 4.1347e-01, 7.2539e+00,
        1.4984e-01, 8.4647e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [28/80], Step [000/314], LR 9.0e-05, Loss: 889.0
BCE Val Loss:  tensor([5.7304e+01, 1.7190e+01, 5.0819e+01, 1.1767e+01, 2.1253e+00, 3.5392e+01,
        3.4195e+01, 3.3994e+01, 2.0287e+01, 2.8920e+01, 1.6342e+01, 4.3508e+01,
        1.1191e+01, 6.4267e+00, 2.0503e+01, 3.9132e+00, 9.9051e+00, 1.8778e+01,
        3.9751e+00, 1.2422e+01, 1.6749e-01, 5.3019e-02, 4.7867e-02, 4.0166e-02,
        2.7389e+01, 2.4190e+01, 3.0565e+01, 1.5550e+01, 1.8538e+01, 8.4230e-01,
        1.7806e-01, 7.8437e-02, 9.0329e-01, 7.5705e-01, 1.1708e+00, 1.7558e-01,
        3.3202e+00, 3.2984e+00, 2.2393e-01, 1.1067e+00, 1.2831e-01, 3.6768e+00,
        5.1995e-01, 3.1520e+00, 1.2291e+00, 1.1530e+00, 2.7710e-01, 2.6934e-01,
        1.2971e-01, 6.6692e+00, 1.1846e-01, 1.6603e-01, 1.2955e-01, 4.9496e-01,
        8.8980e-02, 3.2475e-01, 8.2271e+00, 6.4180e+00, 4.7588e+00, 9.8842e-02,
        3.3539e+00, 3.3432e-01, 7.4178e-01, 1.0721e-01, 1.4820e-02, 4.8432e-02,
        1.6090e-02, 2.0620e+01, 9.0402e-02, 4.8595e+00, 8.7044e-03, 2.7527e-01,
        3.2732e+00, 3.1837e+00, 3.7536e+00, 1.0954e-01, 1.4415e+00, 3.0031e-01,
        6.1729e-03, 9.6257e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [28/80], Step [100/314], LR 9.0e-05, Loss: 648.2
BCE Val Loss:  tensor([1.2173e+01, 5.4610e-01, 3.4234e+00, 4.8212e-01, 4.5515e-02, 4.2714e-02,
        4.1742e-02, 1.6660e+01, 2.1253e-01, 3.3411e-02, 2.4031e-02, 2.1516e-02,
        1.3536e-02, 1.2606e+01, 2.3939e-01, 1.1173e+00, 2.1111e+00, 1.1696e-01,
        1.0088e-01, 4.3649e-02, 5.6918e-02, 9.9212e-03, 5.7943e-03, 1.3009e-02,
        4.6086e+00, 3.5161e-01, 2.7134e+01, 3.6482e+00, 8.6719e-01, 4.8206e-01,
        3.1633e-01, 7.1114e+00, 8.3291e+00, 8.0368e-02, 4.6701e-01, 6.3604e-01,
        1.1704e+01, 4.8573e+00, 4.0062e-02, 3.6368e+01, 1.7887e+01, 6.2682e+01,
        5.9175e+01, 6.1501e+01, 4.6215e+01, 5.7335e+01, 1.2416e+01, 1.0113e+01,
        3.8618e+01, 1.1683e+01, 2.6607e+01, 3.2694e+01, 4.6209e+01, 1.7074e+01,
        4.5628e+01, 7.2130e+01, 1.0356e+02, 1.1901e+01, 6.2416e+00, 2.5556e-01,
        9.7640e+01, 9.4630e-02, 1.2370e+01, 9.7502e+00, 1.3676e+01, 2.5234e+00,
        8.9395e+00, 1.4093e+01, 7.0464e+00, 3.4483e+00, 1.2817e-01, 1.2786e+01,
        4.9138e+00, 4.5316e+01, 1.6683e+00, 1.4967e+01, 1.0294e+01, 1.0856e+00,
        5.7829e-02, 4.8212e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [28/80], Step [200/314], LR 9.0e-05, Loss: 1158.3
BCE Val Loss:  tensor([2.8679e+01, 1.6819e+00, 1.5969e+01, 1.7794e+00, 3.0692e-01, 1.1091e+01,
        7.8391e+00, 1.4968e+01, 1.2023e+00, 2.1362e+01, 3.5563e+00, 7.6371e+00,
        1.2131e+00, 1.4624e+01, 1.7507e+01, 3.5063e-01, 3.8695e+00, 5.5295e-01,
        6.6581e-02, 1.1661e-01, 1.4837e-01, 2.5611e-02, 2.8601e-02, 9.8886e-02,
        1.8580e+01, 3.6327e+00, 2.1416e+01, 1.0037e+00, 1.4821e+01, 2.6346e-01,
        4.1397e-01, 5.2399e-02, 1.1247e-01, 9.7185e-02, 3.7972e-02, 3.8903e-02,
        3.2681e-01, 4.1181e-01, 1.8432e-02, 2.1884e+00, 6.7454e-01, 1.0176e+00,
        1.2647e-01, 5.4814e-01, 1.9714e-01, 7.0131e-01, 2.3377e-01, 1.5460e-01,
        4.8314e-02, 6.7629e-02, 6.2090e-02, 8.5755e-02, 6.4784e-02, 2.3834e-01,
        2.8419e-02, 8.9769e-02, 4.2533e+00, 1.2738e+00, 1.2608e+01, 3.7991e-01,
        5.4079e+00, 1.6002e-01, 1.1563e+00, 3.5504e-01, 3.6562e-02, 5.2514e-01,
        1.1791e-01, 6.0585e+00, 7.6565e-02, 7.5360e-02, 7.4861e-03, 4.8422e-01,
        2.5764e-01, 8.4027e+00, 5.3155e+01, 1.9800e+00, 6.4137e-02, 4.3538e+00,
        3.1988e-02, 3.6082e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [28/80], Step [300/314], LR 9.0e-05, Loss: 323.7
starting validation
Accuracy th:0.5 is [92.24546485 98.20421291 94.93061732 98.9132686  99.41764842 98.55630414
 99.35064144 96.70447485 98.84869824 98.19933968 99.22881057 99.30556402
 99.62841583 96.51076376 98.04826939 98.61965619 97.55363604 98.96078264
 99.41277519 99.15693035 99.57602856 99.6795848  99.81603538 99.75877487
 95.77734189 98.06898064 95.24494097 98.27852975 98.61843788 99.09114168
 99.19591623 99.09235999 98.0628891  99.32993019 99.43957798 99.40912026
 99.12769094 98.99245867 99.62841583 94.42745581 98.34919165 94.58218102
 98.02390322 97.10042519 97.49393891 95.99420085 98.98758543 99.03631778
 98.8024025  99.0947966  99.19591623 99.14109234 99.35551467 99.2336838
 99.20322608 98.57214215 93.57463969 98.15182564 97.19301665 98.72321244
 94.97813136 99.30434571 98.14573409 98.41741694 99.2190641  98.42107187
 99.13378248 96.75808043 99.03997271 98.83286022 99.818472   98.44178312
 98.90717706 96.62893971 97.90207234 97.9654244  99.29703585 99.05337411
 99.84527479 99.34089497]
Accuracy th:0.7 is [90.57881848 98.0775088  94.57852609 98.90839537 99.32627526 98.35406489
 99.2751063  96.54000317 98.7183392  98.12136792 99.18860638 99.27388799
 99.61623275 96.28903157 97.89354418 98.47589576 97.51465016 98.85844471
 99.35307806 99.05946565 99.5821201  99.63085245 99.7916692  99.73684531
 95.64454624 97.86430477 95.0536665  98.26391004 98.61600127 99.0801769
 99.09114168 98.86453625 97.80582595 99.20444439 99.40302872 99.32993019
 99.02047977 99.15571204 99.58333841 93.96084356 98.19690306 93.8280479
 97.76196684 97.21494621 97.44520656 95.64454624 98.96200095 99.0521558
 98.70615611 98.9827122  99.31531049 99.08505013 99.36526114 99.10697969
 99.10332476 98.36746628 92.85583753 98.01902998 96.9627563  98.47224084
 93.83779437 99.15449373 98.10187498 98.24076217 99.14231064 98.3004593
 98.99489529 96.59482706 99.03266286 98.69640964 99.81603538 98.49417039
 98.88281088 96.29146818 97.79242456 97.74369221 99.26414152 98.95590941
 99.84527479 99.35185975]
Avg Prec: is [98.47105193 66.36311553 83.00466619 86.66295794 95.06174439 85.34800243
 94.27101054 73.42044143 82.1348433  80.57084108 73.68063745 76.93382732
 64.81354019 60.49120709 61.54064919 85.08151303 65.58242272 83.91173514
 83.5616054  79.21271761 92.8064847  85.12208279 97.67192679 97.90034114
 47.03774969 75.92347975 56.31230431 76.19459763 62.56921581 81.98261738
 92.16678794 78.47174062 79.98660703 90.70028295 93.25004425 93.66312712
 91.60666328 91.89790849 97.30100903 61.71218306 60.30364342 69.99648441
 73.32907807 66.15548838 57.80188628 72.7293759  76.2443414  66.14947064
 72.78111959 71.26770696 85.93898668 72.30663986 68.94667177 91.18684935
 73.95248722 78.23182464 76.71829603 82.03989854 61.93067563 86.96951505
 84.66140364 94.14562364 82.34220909 79.2959793  82.49721145 73.70736767
 82.35534188 54.31087445 66.08562162 83.89108979 25.50514254 88.76522893
 78.39489215 62.88152377 72.92941376 72.34030389 42.04310318 76.35655649
 15.29588566 55.92112564]
Accuracy th:0.5 is [91.34878961 97.97638918 94.44451213 98.78290956 99.40181041 98.44056481
 99.26657814 96.43522862 98.72930398 97.94714977 99.11428954 99.25074012
 99.56019054 96.2098415  97.99100888 98.397924   97.26124194 98.78047295
 99.30434571 99.01316992 99.51998635 99.63450738 99.8050706  99.69664112
 95.60556036 97.93009344 95.06950451 98.09943836 98.4953887  98.89255735
 99.04362764 99.09357829 97.88379771 99.26657814 99.32505696 99.32871188
 98.9693108  99.06068396 99.56506378 94.15333634 98.26147342 94.36044882
 97.83750198 96.99930556 97.43424179 95.77734189 98.86088132 98.98514882
 98.62209281 99.06799381 99.25317674 99.04606425 99.26414152 99.03997271
 99.15327542 98.47955069 93.0605134  97.95811455 97.05412946 98.60503649
 94.86970188 99.15693035 97.92156528 98.12989608 99.17520498 98.24319879
 98.99855021 96.45959479 98.97296573 98.71102935 99.81603538 98.26634666
 98.78656449 96.37553149 97.75465699 97.95689624 99.2617049  98.89743059
 99.84527479 99.29459924]
Accuracy th:0.7 is [89.96966411 97.81922735 93.85972393 98.75610677 99.38231747 98.3833043
 99.22271902 96.17816547 98.68178994 97.79729779 99.05337411 99.23977534
 99.54435253 95.93937696 97.85943154 98.22126923 97.11748151 98.7183392
 99.23490211 98.90108551 99.52485959 99.63450738 99.79654244 99.68202142
 95.42403236 97.73516405 94.7612724  97.94593146 98.41619863 98.75610677
 99.04971918 98.97296573 97.56338251 99.20931763 99.31165556 99.31896541
 98.94859955 99.01682484 99.52485959 93.87678025 98.11040314 93.87434364
 97.70836125 96.93108027 97.22469268 95.3606803  98.77072648 98.94494463
 98.56239568 98.99976852 99.23977534 98.93276154 99.2202824  99.12647263
 99.06068396 98.29193114 92.19185926 97.8119175  96.92620704 98.51000841
 94.32389956 99.17033175 97.76440346 98.03974123 99.0947966  98.11649468
 98.92788831 96.2524823  98.93885308 98.71712089 99.81603538 98.25660019
 98.72686736 96.06486276 97.64257258 97.84968507 99.23855704 98.8011842
 99.84405648 99.24586689]
Avg Prec: is [98.10970959 60.28219726 80.24718689 83.95005435 94.16691007 82.40116109
 92.57396928 69.11926724 78.41907229 76.21434045 67.92881949 73.40427173
 54.99717183 53.97480111 56.50545349 80.93303066 58.13116207 79.06801972
 79.00849551 73.74094678 90.9653194  80.60353706 97.151671   97.16945244
 42.15843709 69.24228165 52.12122539 70.88530922 54.64556786 73.17905738
 90.16069575 73.12442725 75.8164669  87.35537601 91.19275437 91.97556353
 89.30895936 89.69020817 96.43212137 57.77006369 52.19748151 66.6109271
 68.46861824 61.62100414 53.74134109 68.59974295 71.17711397 59.73011495
 66.47918314 67.77659097 83.25521645 68.2964429  59.96414802 88.70970324
 66.35886395 72.94661409 72.47093098 78.60915447 55.48148139 83.37262023
 82.17371225 92.45600075 78.23008151 73.06939363 78.72842819 68.10107338
 77.37143179 46.45432178 60.61497216 80.26153234 19.39033027 86.57395884
 73.63121581 57.15557561 68.95932116 68.4970366  34.45922599 69.50025288
 13.42879992 47.80367245]
mAP score regular 75.79, mAP score EMA 71.34
starting validation
Accuracy th:0.5 is [90.94351845 97.89720208 93.69409772 98.64713357 99.36218452 98.24351596
 99.11552931 95.75204923 98.6371677  97.61566634 99.07566584 99.31235518
 99.43941999 95.92396044 97.89720208 98.27341356 96.97535939 98.7492837
 99.38709919 98.91122904 99.56897626 99.64621172 99.78075093 99.77327653
 95.17901188 97.77262875 94.38672547 97.97942048 98.11146822 98.7268605
 99.08563171 98.93863517 97.39143434 99.34474425 99.19525625 99.32232105
 98.91621197 98.73682637 99.44689439 93.65672571 98.11645115 93.62433665
 97.43877221 96.29269751 96.76109326 95.30109375 98.76672397 98.88133144
 98.23355009 98.89877171 99.10805491 98.84146797 98.95358397 98.88631437
 99.01337918 98.24351596 91.64611207 97.62812368 96.73617859 98.20116102
 93.59443905 99.09310611 97.54341381 97.93955702 99.00590478 97.79256048
 98.89628024 95.8292847  98.85890824 98.51259436 99.81314    97.88972768
 98.46774796 96.0385679  97.65054688 97.72778235 99.28494905 98.84146797
 99.8206144  99.07815731]
Accuracy th:0.7 is [90.17863816 97.91962528 93.83860279 98.7567581  99.28245758 98.19617809
 99.08812318 95.95385804 98.59481277 97.70037621 99.11054638 99.29740638
 99.46682612 95.9189775  97.82245808 98.20863542 97.13730473 98.70942024
 99.36218452 98.91621197 99.58641652 99.63126292 99.76331066 99.77327653
 95.50788549 97.67047861 94.67075267 98.01928395 98.24102449 98.84395944
 98.97600718 98.85890824 97.266861   99.29491492 99.20273065 99.30488078
 98.86389117 98.86139971 99.45187732 93.71402945 98.06163889 93.57201585
 97.48112714 96.72621272 97.07750953 95.22634975 98.84395944 98.99593891
 98.38802103 98.88631437 99.19027331 98.87883997 99.06819144 98.8016045
 98.98846451 98.14634876 91.57136806 97.62064928 96.62904552 98.10150235
 93.04631637 99.03580238 97.66051274 97.89720208 98.92617784 97.86232155
 98.80658744 96.10583751 98.86389117 98.39051249 99.81563146 97.93955702
 98.52754316 96.05849964 97.68044448 97.68791888 99.28744052 98.8090789
 99.82559733 99.15040985]
Avg Prec: is [97.70041793 53.05663488 75.47680234 82.80923661 89.74254907 76.56517055
 90.76229251 59.65595578 76.39365672 71.33817477 66.78196361 70.81711166
 45.39244013 48.53427972 52.284651   80.89023553 56.80547254 78.32273771
 78.53858576 69.41108662 92.18862159 85.29482937 96.3855999  97.83211625
 30.5929631  65.71551982 38.8454718  66.42619494 49.0608123  69.77814763
 87.62653245 60.98965079 66.53704369 88.03069631 84.45632733 89.32660659
 84.78600752 87.0754503  95.23901907 50.84570942 45.27901071 56.85099993
 52.93313887 46.61510027 38.41469741 58.43792746 63.25461824 45.97493748
 55.98294764 54.06286143 82.37577578 56.02864579 50.77259676 85.43659997
 54.2750657  60.37975409 62.49946223 68.89017761 47.20135094 75.98687327
 70.96601952 91.78986477 73.53076838 67.14272309 70.48913417 53.27356029
 72.72569591 39.07899211 50.09446652 73.52545591  8.93089701 81.09205994
 61.37604722 49.21162578 70.00171143 58.56391139 23.51132894 62.78033333
  2.99098342 30.41751682]
Accuracy th:0.5 is [90.62461071 97.85484715 93.87846625 98.6296933  99.34972718 98.22856716
 99.05573411 95.87662257 98.5400005  97.64556394 99.08563171 99.27996612
 99.47430052 95.83426763 97.89720208 98.18621222 97.042629   98.67703117
 99.32979545 98.84645091 99.54157012 99.60136532 99.78324239 99.76580213
 95.41819269 97.69539328 94.50880733 97.96447168 98.16628049 98.6745397
 99.03580238 98.88631437 97.3939258  99.26501732 99.19027331 99.34723572
 98.83897651 98.85143384 99.40952239 93.65423425 98.06163889 93.70655505
 97.341605   96.56925032 96.92802153 95.11672522 98.83897651 98.94610957
 98.27839649 98.98597304 99.16785011 98.87634851 99.04327678 98.88880584
 99.00092184 98.16877196 91.59628273 97.68542741 96.63651992 98.15382316
 93.64675985 99.09559758 97.60320901 97.88225328 98.98846451 97.78757755
 98.90624611 96.01116177 98.82402771 98.47771383 99.81563146 97.98191195
 98.44781623 95.89904577 97.56334554 97.68542741 99.25505145 98.81904477
 99.82559733 99.14542691]
Accuracy th:0.7 is [90.13379176 97.80252635 93.72399532 98.71440317 99.37464185 98.25846476
 99.08064878 95.96880684 98.62471037 97.64307248 99.06819144 99.29242345
 99.46682612 95.7694895  97.83740688 98.10897675 96.95791913 98.66955677
 99.30986372 98.78167277 99.54904452 99.62877146 99.78822533 99.76331066
 95.51535989 97.60071754 94.69815881 97.86979595 98.19866956 98.63218477
 99.01836211 98.93614371 97.27184393 99.24757705 99.17781598 99.34474425
 98.87634851 98.80409597 99.38460772 93.64426838 98.02675835 93.71652092
 97.45372101 96.81839699 97.08996686 95.13665695 98.84146797 99.00590478
 98.35064903 98.96604131 99.15290131 98.84146797 99.04078531 98.90126317
 98.95358397 98.18122929 91.46672646 97.64058101 96.67638339 98.18621222
 93.63181105 99.08064878 97.61566634 97.87477888 98.96604131 97.81747515
 98.85890824 96.04355084 98.84395944 98.4577821  99.81563146 98.02426689
 98.50761143 95.96133244 97.57331141 97.74023968 99.27000025 98.7717069
 99.82559733 99.18279891]
Avg Prec: is [97.67210475 51.17185213 75.63617838 82.56384208 89.7149861  77.25557603
 90.36004255 60.14902544 75.45447347 70.84224217 65.16028293 69.59045697
 41.97388381 47.70658632 50.39434149 79.19438745 55.01131814 76.46432904
 76.98137203 64.84865613 90.77114685 83.02893526 96.4038471  97.41016125
 30.99100163 62.09829822 39.60076229 65.56965294 46.21125456 64.19411282
 86.54566018 60.16956369 65.5683511  85.60616756 83.89014715 89.3838493
 84.03283972 86.80537    94.78288257 50.84264939 42.67086562 57.52258275
 52.81450959 47.18864396 38.56930148 58.28986094 63.14276998 46.34632316
 55.93590456 57.50360447 82.28186561 56.10853759 47.33943592 86.21796606
 53.06636895 58.9785649  62.65656013 69.86360517 46.59517387 75.82334478
 72.11838991 92.0503299  73.1921697  65.91398255 71.508398   51.97315581
 72.68305684 37.54827324 47.4653094  73.92099097  8.97760489 81.66475176
 59.8093449  47.71207503 68.7299502  59.71903929 21.65951177 61.72967259
  3.24232706 30.19084588]
mAP score regular 64.77, mAP score EMA 64.03
Train_data_mAP: current_mAP = 75.79, highest_mAP = 75.79
Val_data_mAP: current_mAP = 64.77, highest_mAP = 64.77
lr:  [9.015813846277982e-05, 9.015813846277982e-05]
BCE Train Loss:  tensor([28.1596,  8.6532, 14.8407,  2.9097,  0.2177,  2.4250,  0.1966,  5.5937,
         1.4261,  9.0654,  0.9068,  7.7478,  1.8154,  8.4235,  1.5219, 13.1231,
        14.0876, 14.3539,  2.3121,  1.4946,  0.7433,  1.0835,  0.6554,  0.5943,
        10.2148,  5.8348, 17.1753,  3.9769,  3.4240,  3.6737,  3.2725,  2.0203,
         7.9150,  4.2050,  1.0697,  3.8714,  0.6770,  1.5823,  0.2747, 17.6988,
         6.2957, 27.4076,  6.2278,  5.7817,  9.8980, 18.1707,  1.6837,  1.5782,
         7.1442,  4.1077,  0.7171,  0.8401,  1.3674,  3.3899,  3.4100,  4.2282,
        18.1423,  7.2829, 13.8081,  5.0450,  7.9413,  1.5596,  8.2538,  2.7990,
         1.1698,  5.9178,  1.9717, 14.4758,  2.1768,  2.0715,  0.1262,  5.2129,
         3.1178, 10.6923,  7.3985, 13.4922,  5.6710,  7.3431,  0.3825,  5.6837],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [29/80], Step [000/642], LR 9.0e-05, Loss: 483.2
BCE Train Loss:  tensor([25.3795, 10.3403, 18.5424, 11.5439,  1.7504,  8.1895,  2.0801,  6.8994,
         1.3265,  4.1884,  1.9535,  6.8963,  5.9609, 12.1764,  4.0030,  4.0744,
         4.1328,  1.6507,  1.8069,  3.0374,  9.4134,  2.4192,  1.4085,  0.1278,
        19.1812,  6.3752, 11.8699,  9.3221,  5.3905,  2.7613,  3.6949,  0.6235,
         7.6431,  0.8932,  4.4711,  5.9066,  1.0657,  8.8029,  3.9733, 14.1335,
         2.5778, 18.8449,  6.4517,  9.2288, 19.5879, 17.0810,  3.1074,  1.5527,
         5.0704,  4.6488,  6.7304,  4.9620,  1.0848,  1.3607,  1.4455,  2.5754,
        16.1387,  7.9017,  8.9243,  2.3763, 24.0494,  2.7976,  3.3648,  2.2411,
         1.9630,  7.4007,  0.5261,  9.0916,  1.4176,  1.6595,  9.9386,  1.4996,
         1.0114, 13.0065, 13.5663,  5.1357,  4.0105,  0.9630,  0.1374,  1.2355],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [29/80], Step [100/642], LR 9.0e-05, Loss: 502.1
BCE Train Loss:  tensor([22.4660, 10.2828, 23.1170,  5.2412,  4.7698,  7.8908,  1.2206, 19.4530,
        11.4950, 11.4080,  0.4137,  4.6548,  4.3121, 16.5578, 14.4382,  3.6365,
         7.9357,  4.2467,  0.7855,  2.7466,  0.8849,  1.1586,  1.0775,  0.3381,
        29.4191,  7.2259, 22.6077,  4.5535,  7.0830,  3.9455,  1.7789,  0.9349,
         2.8411,  1.8823,  0.5549,  0.4098,  1.7277,  2.0208,  0.2085, 21.2296,
         3.7535, 17.4377,  3.9905, 11.2388, 11.7417, 11.5935,  3.7041,  2.1077,
         3.0784,  1.1106,  1.3930,  5.2322,  0.3354,  0.9852,  1.4982,  5.8650,
        32.6115,  7.0389, 14.7143, 14.3291, 13.1385,  2.8204,  3.6565,  8.6967,
         0.1676,  3.7863,  0.3716, 14.5697,  2.5056,  2.4982,  0.0649,  4.9247,
         2.5663, 14.2095,  8.2065,  2.5304,  0.8342,  9.4936,  0.3446,  0.8091],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [29/80], Step [200/642], LR 9.0e-05, Loss: 538.9
BCE Train Loss:  tensor([25.9739,  4.4988, 19.1636,  8.3077,  1.4253,  7.0511,  2.5061, 18.1174,
         2.7758,  3.4650,  1.3287,  3.2663, 10.1989,  7.9383,  2.9564,  3.8849,
         8.3579,  3.3514,  0.4183,  1.5279,  0.5259,  0.4217,  0.8508,  0.2306,
        19.5993,  2.6532, 19.0226, 15.2914,  7.9771,  8.1480,  2.6269,  0.8151,
         8.6782,  2.2538,  1.0167,  4.2563,  4.1629,  0.7971,  1.6061, 37.3266,
        11.1604, 21.4763,  9.2574, 14.2241,  9.3788, 13.8076,  5.5880, 10.6820,
         4.3381,  1.8737,  2.4383,  1.7700,  6.9955,  3.5792,  6.1401, 12.3959,
        23.6912, 15.3776, 14.6909,  5.3294, 17.0279,  3.3196,  7.8190,  5.7557,
         0.7571,  5.9567,  9.1190, 11.6204,  0.9948,  3.7543,  5.5372,  6.0374,
         3.1135, 11.9621,  6.3569,  6.6959, 15.8861,  6.3644,  0.1524,  5.0587],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [29/80], Step [300/642], LR 8.9e-05, Loss: 602.3
BCE Train Loss:  tensor([20.1443,  3.6899, 11.5440,  1.6434,  0.2723,  7.5217,  0.5705, 10.6755,
         5.9827,  5.7300,  8.0902,  1.7297,  1.6183,  6.7183,  5.9754,  6.4070,
        13.1831,  2.0772,  2.2298,  6.4912,  7.0970,  0.1807,  0.1601,  0.1887,
        22.7703,  4.6702, 24.9795,  3.1109,  5.3162,  5.2355,  1.2253,  5.1816,
         3.8853,  2.6582,  3.4695,  0.4313,  5.8995,  2.5725,  0.1172, 27.2520,
         7.6998, 22.2648,  9.8614, 18.2813,  5.0738, 11.9288,  5.7074,  4.8554,
         1.8954,  5.5939,  0.6184,  0.7457,  4.3775,  7.9610,  1.3811, 11.1202,
        16.0750,  9.5502,  7.2335,  1.2351, 17.0304,  1.2346,  9.7084,  5.3359,
         5.7616,  3.5323,  0.9253, 13.0726,  1.1796,  4.8906,  0.3498,  4.8223,
         2.6372,  9.7980, 15.9685,  4.0376,  0.7051,  4.0135,  0.2120,  2.7964],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [29/80], Step [400/642], LR 8.9e-05, Loss: 510.2
BCE Train Loss:  tensor([22.9041, 12.2886, 13.0851,  6.8252,  0.7117,  1.4927,  4.3544, 12.4177,
         0.7822,  4.4389,  1.5571,  0.7530,  1.9169, 18.2185,  8.4527, 12.3035,
         6.6480,  3.9728,  3.9654,  0.9170,  0.1500,  0.3473,  0.2912,  0.2447,
        16.7387,  7.2440, 13.3386, 14.8355,  6.0594,  3.5245,  0.3770,  2.0307,
        10.2390,  4.1154,  1.9048,  1.0516,  6.0769,  5.6655,  0.3388, 18.2052,
         2.1259, 16.6552,  4.4172, 11.5400,  6.5315, 17.6175,  3.3374,  2.1586,
         4.4485,  5.0635,  0.8107,  0.8182,  4.8213,  0.5424,  1.6862,  3.8372,
        22.5951,  3.5170, 22.9265,  6.7421,  9.1607,  0.5196,  4.8063,  2.5321,
         1.0274,  6.7743,  5.1446,  6.8692,  4.3564,  6.6960,  5.0145,  6.1430,
         4.5311, 16.1147,  3.0942,  8.8618,  2.5638,  4.1494,  0.1364,  5.8407],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [29/80], Step [500/642], LR 8.9e-05, Loss: 497.3
BCE Train Loss:  tensor([19.3108,  2.5919, 12.3117,  2.8847,  2.7864, 10.6624,  2.7134, 12.5717,
         1.6062,  9.9837,  1.0688, 12.6704,  3.2493,  9.8370,  6.9154,  4.2062,
         3.6505,  1.4591,  0.8421,  1.7272,  0.4737,  3.8322,  0.0595,  0.2905,
         9.4899,  6.4118, 21.3851,  2.6572, 13.0053,  8.7264,  3.0299, 10.3972,
         6.6792,  3.6677,  0.3072,  0.4432,  2.2614,  3.5259,  3.0079, 14.9001,
         8.5284, 17.3031,  5.1357,  8.5331,  4.8636,  9.3209,  2.5759,  2.0577,
         5.7206,  1.5691,  0.9921, 10.1099,  2.4102,  3.5309,  1.3921,  4.7074,
        16.8066,  5.3207,  6.5638, 11.0510, 20.7292,  0.3301,  4.5217,  5.4192,
         9.3969,  3.7351,  1.4621,  9.5446,  1.8686,  1.1030,  0.3409,  3.2240,
         3.5859,  4.5820,  8.0483,  3.1549,  5.0055, 12.8169,  0.4034,  1.1273],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [29/80], Step [600/642], LR 8.9e-05, Loss: 466.5
BCE Val Loss:  tensor([5.3973e+01, 2.1428e+01, 5.4116e+01, 2.3680e+01, 7.1460e-01, 9.7839e+00,
        7.4208e+00, 1.9346e+01, 5.7850e+00, 7.7392e+00, 6.6948e+00, 1.1365e+01,
        7.8660e+00, 1.7093e+01, 7.2534e+00, 1.8616e+01, 1.8977e+02, 5.5831e+00,
        2.0368e+00, 3.4001e+00, 4.9889e-01, 1.8142e-01, 4.7768e-02, 3.8711e-01,
        2.6717e+01, 1.5035e+01, 2.6034e+01, 7.5397e-01, 1.4186e+01, 1.8371e+01,
        1.8716e+00, 1.3341e+00, 1.0943e+01, 3.4051e-01, 1.3274e-01, 3.9126e-01,
        9.5867e+00, 3.9312e+00, 3.7570e+00, 3.6809e+01, 1.0704e+01, 2.0734e+01,
        5.8509e+00, 1.5811e+01, 1.3333e+01, 1.5885e+01, 8.3539e-01, 3.5304e+00,
        1.5570e+00, 3.4288e+00, 5.1596e-02, 1.6714e-01, 3.9441e+00, 2.8127e-01,
        1.7078e-01, 2.5298e-01, 2.1073e+01, 7.6082e+00, 9.3215e+00, 3.4105e+00,
        9.2924e+00, 6.3395e+00, 2.5223e+00, 5.2223e+00, 1.1363e-01, 1.4782e+00,
        1.6874e-01, 6.3478e+00, 8.8994e+00, 1.8841e+01, 3.4114e-01, 1.7204e+01,
        1.0823e+01, 9.6625e+00, 1.6245e+01, 4.8269e+00, 8.7230e-01, 6.1434e+00,
        7.4954e-02, 1.1709e+00], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [29/80], Step [000/314], LR 8.9e-05, Loss: 909.5
BCE Val Loss:  tensor([5.8000e+01, 1.8957e+01, 4.4032e+01, 1.1852e+01, 7.2149e+00, 3.5925e+01,
        4.5655e+01, 3.3674e+01, 2.0821e+01, 3.3369e+01, 1.7391e+01, 3.9612e+01,
        1.1610e+01, 7.8027e+00, 1.8169e+01, 3.1006e+00, 6.9664e+00, 1.4496e+01,
        5.0456e+00, 1.1937e+01, 1.1131e-01, 5.9704e-02, 1.0734e-01, 1.3531e-01,
        2.9139e+01, 2.1766e+01, 3.3266e+01, 1.4734e+01, 1.9324e+01, 5.0482e-01,
        6.5413e-01, 1.0351e-01, 9.7686e-01, 7.1037e-01, 4.1169e-01, 2.1308e-01,
        1.2117e+00, 1.0817e+00, 6.1129e-01, 2.0463e+00, 2.4117e-01, 3.9193e+00,
        9.4516e-01, 3.3727e+00, 6.9689e-01, 1.0879e+00, 2.7432e-01, 1.9422e-01,
        2.1019e-01, 7.8018e+00, 2.4398e-02, 7.9352e-02, 9.0761e-02, 3.2829e-01,
        4.4511e-02, 1.0839e+00, 1.3098e+01, 7.5383e+00, 3.5979e+00, 1.9002e-01,
        6.9129e+00, 6.1231e-02, 6.2518e-01, 1.8241e-01, 2.6875e-02, 3.7962e-02,
        3.5877e-02, 2.1372e+01, 1.1729e-01, 5.7544e+00, 1.1609e-02, 3.4979e-01,
        2.0490e+00, 3.2576e+00, 4.5824e+00, 3.2490e-01, 8.8335e-01, 1.8346e-01,
        2.2759e-03, 9.7558e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [29/80], Step [100/314], LR 8.9e-05, Loss: 664.5
BCE Val Loss:  tensor([1.1133e+01, 4.1467e-01, 4.0102e+00, 1.2475e-01, 6.5015e-02, 5.9750e-02,
        2.8979e-02, 1.7177e+01, 3.5745e-01, 2.5565e-02, 1.3121e-02, 2.6092e-02,
        7.3082e-03, 1.0932e+01, 4.0302e-01, 7.7369e-01, 1.6175e+00, 1.5242e-01,
        6.4357e-02, 5.5924e-02, 3.0272e-02, 9.3567e-03, 1.7876e-02, 2.6639e-02,
        4.4558e+00, 1.1918e+00, 2.6557e+01, 3.6958e+00, 8.6107e-02, 9.3202e-02,
        1.5319e-01, 7.2547e+00, 9.3877e+00, 3.2062e-02, 2.2981e-01, 3.0489e-01,
        1.0866e+01, 7.0223e+00, 7.0334e-02, 4.2499e+01, 1.8733e+01, 6.7629e+01,
        4.9763e+01, 5.8867e+01, 4.1979e+01, 6.0799e+01, 9.8452e+00, 7.7943e+00,
        4.4072e+01, 9.8547e+00, 2.6348e+01, 3.7687e+01, 5.0352e+01, 1.4661e+01,
        5.6221e+01, 6.8587e+01, 8.3857e+01, 1.1115e+01, 7.5419e+00, 3.0453e-01,
        7.3764e+01, 3.9239e-02, 1.2742e+01, 9.4269e+00, 1.4854e+01, 1.7519e+00,
        9.4067e+00, 1.2643e+01, 7.3982e+00, 1.4605e+00, 7.2018e-02, 1.1393e+01,
        4.6738e+00, 4.6239e+01, 2.9172e+00, 1.3989e+01, 9.5085e+00, 3.5128e-01,
        1.6821e-02, 4.0125e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [29/80], Step [200/314], LR 8.9e-05, Loss: 1120.5
BCE Val Loss:  tensor([2.5236e+01, 1.5077e+00, 1.3017e+01, 1.6654e+00, 8.3573e-01, 8.8566e+00,
        7.9782e+00, 1.6870e+01, 4.0190e+00, 1.7687e+01, 4.5871e+00, 7.7647e+00,
        1.1679e-01, 1.4728e+01, 1.8540e+01, 3.2450e-01, 2.3174e+00, 8.6584e-01,
        7.8565e-02, 5.9710e-02, 3.3866e-01, 2.3398e-02, 2.4251e-02, 2.8579e-01,
        1.8119e+01, 6.3902e+00, 2.5908e+01, 4.7373e-01, 2.0563e+01, 2.4258e-01,
        2.5616e-01, 5.4434e-02, 1.1136e-01, 1.6543e-01, 2.0135e-02, 3.9793e-02,
        2.6365e-01, 1.0894e-01, 2.1320e-02, 2.0162e+00, 1.2045e+00, 2.2515e+00,
        4.3611e-01, 1.2272e+00, 3.6235e-01, 7.0861e-01, 2.4647e-01, 1.0048e-01,
        7.1048e-02, 4.5613e-02, 1.6957e-02, 3.7213e-02, 3.6013e-02, 2.7899e-01,
        2.7726e-02, 2.8637e-01, 6.6084e+00, 3.3711e+00, 1.2296e+01, 3.3191e-01,
        8.7566e+00, 6.3222e-02, 1.8076e+00, 2.2447e-01, 2.4722e-02, 4.2832e-01,
        9.9512e-02, 6.5101e+00, 8.1893e-02, 1.4510e-01, 8.1471e-03, 1.1013e-01,
        2.0239e-01, 6.5295e+00, 6.4141e+01, 3.4788e+00, 1.0665e-01, 4.7776e+00,
        4.4488e-03, 2.6224e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [29/80], Step [300/314], LR 8.9e-05, Loss: 350.0
starting validation
Accuracy th:0.5 is [92.42821116 98.21030446 94.74787101 98.8986489  99.48221878 98.65986038
 99.33967666 96.81777756 98.82555037 98.08116373 99.22515564 99.30678232
 99.58090179 96.68010867 98.22005093 98.60747311 97.66937537 98.98758543
 99.43226813 99.17520498 99.55775393 99.65521863 99.81481707 99.71857068
 95.81023623 98.26756497 95.25590575 98.31507901 98.52584642 99.14109234
 99.14352895 99.11307123 98.01172013 99.37013438 99.3871907  99.39571886
 99.16789513 99.23002887 99.65400032 94.6638077  98.32238886 94.42258257
 97.81800904 97.06874916 97.56703744 96.08070077 99.00829668 99.12525432
 98.64036744 99.18982469 99.36769776 99.1362191  99.40181041 99.25074012
 99.21175424 98.65133222 93.81220989 98.19081152 97.44764318 98.79874758
 95.06341297 99.3177471  98.14817071 98.43325496 99.22393733 98.44543804
 99.18129652 96.78731984 99.08626844 98.78900111 99.81969031 98.49173378
 98.96200095 96.65696081 97.98126241 98.20664953 99.30190909 98.99245867
 99.84527479 99.32018372]
Accuracy th:0.7 is [90.47769886 98.13842424 93.77444232 98.81093067 99.43957798 98.4113254
 99.23612042 96.47665111 98.6903181  97.77293162 99.16789513 99.28485277
 99.55044407 96.4474117  98.10431159 98.39183246 97.64013596 98.9827122
 99.41277519 99.08383182 99.48709202 99.60648628 99.8050706  99.73928193
 95.5556097  98.11162145 94.79294843 98.14938902 98.37843106 99.07164874
 99.18860638 98.90717706 98.06167079 99.27997953 99.31043725 99.39815548
 99.0241347  99.18007822 99.64425385 94.4968994  98.43325496 94.66868094
 98.10674821 97.40622068 97.38916436 95.4301239  98.98758543 99.0801769
 98.85966302 99.08626844 99.25317674 99.03753609 99.35185975 99.13743741
 99.10454307 98.48320561 93.60875233 98.09212851 97.30753768 98.65620546
 95.19864524 99.1496205  97.9654244  98.40645216 99.1228177  98.29924099
 99.10697969 96.49492574 98.97905727 98.58067031 99.81725369 98.47467745
 98.86575456 96.32070759 97.81679073 98.01781167 99.28607108 98.89377566
 99.84405648 99.33236681]
Avg Prec: is [98.53330659 66.07666729 83.79019015 86.9292828  95.09501937 86.87669745
 94.72785201 74.71102889 82.75157407 81.27742151 75.3966675  76.34508461
 62.53849642 62.92213465 64.78820533 86.17150896 68.33690018 84.74929738
 85.7977691  79.65064155 93.2250798  84.63042235 97.41602168 97.55987058
 47.95151233 77.23611703 57.70002497 77.54089676 65.1752383  81.94085489
 92.52018233 79.35117912 80.47102455 90.71186862 93.21079025 93.41781249
 92.50201221 92.78047928 97.36086115 64.75336695 61.05236447 70.88278868
 74.3253871  68.62536065 58.9610129  74.85908511 77.8679112  68.14561218
 74.61674999 73.98761827 86.93507681 75.79527854 70.73288365 91.7737531
 74.20614521 78.92320479 77.96605971 83.08658662 65.32105791 87.23453036
 85.06873852 94.53294472 82.84799506 80.30459221 82.13101068 74.52338381
 82.73226552 56.43399976 67.45239414 83.48677266 25.15165701 89.41428367
 79.01502005 63.70193641 74.57425188 74.93274297 42.24392802 76.01030326
 24.51490707 55.62776218]
Accuracy th:0.5 is [91.68991606 98.04826939 94.61142043 98.75732508 99.46759908 98.54777598
 99.30678232 96.54974964 98.7597617  98.04217785 99.14231064 99.26048659
 99.57359194 96.33410899 98.08116373 98.47589576 97.40987561 98.85844471
 99.34698651 99.05702903 99.53460606 99.63207076 99.79654244 99.70029605
 95.60799698 98.02755814 95.10483547 98.18228335 98.54412105 98.94250801
 99.06799381 99.15205711 97.89841742 99.29703585 99.36160622 99.3591696
 99.06799381 99.10332476 99.63207076 94.26907567 98.31629732 94.3714136
 97.87648786 97.12235475 97.44398826 95.92719387 98.88646581 99.02169808
 98.68178994 99.10210646 99.30190909 99.10697969 99.30678232 99.108198
 99.17155005 98.52950135 93.2980836  97.95933285 97.13941107 98.59894494
 94.9415821  99.21784579 98.00197366 98.21761431 99.1642402  98.28218467
 99.05337411 96.56193272 99.02291639 98.73783214 99.82090861 98.38939584
 98.83651515 96.36700333 97.79973441 98.01659337 99.27023306 98.93763478
 99.84527479 99.30190909]
Accuracy th:0.7 is [90.20723432 97.89354418 94.09120259 98.72686736 99.46394415 98.46005775
 99.28607108 96.27197524 98.70493781 97.89963573 99.09845153 99.24464858
 99.55288069 96.05877121 97.93131175 98.31995224 97.20398143 98.76463493
 99.28363446 98.9546911  99.53095113 99.64912708 99.78192273 99.67592987
 95.46910978 97.87161462 94.83680754 98.01172013 98.44909297 98.81458559
 99.10210646 99.00586007 97.56338251 99.2470852  99.31165556 99.3445499
 99.03388117 99.0667755  99.56384547 93.98764635 98.15791718 93.93525907
 97.78024147 97.01270696 97.26733349 95.55073647 98.80605743 98.96687419
 98.6208745  99.05337411 99.289726   98.98027558 99.24221196 99.13865572
 99.08748675 98.37599444 92.43552101 97.8119175  97.00783373 98.52706473
 94.41770934 99.23002887 97.84481183 98.13720593 99.1228177  98.2029946
 98.98636713 96.33410899 98.97296573 98.77072648 99.818472   98.34431842
 98.82067714 96.1123768  97.71323449 97.9106005  99.23855704 98.86940949
 99.84405648 99.25439505]
Avg Prec: is [98.22281543 61.36795641 81.22808288 84.20451487 94.95284834 83.96757374
 93.18833198 71.18265856 79.89221097 77.8964923  69.54528082 74.06249843
 53.29176101 56.6471067  59.42194789 82.81647302 61.95560624 81.51350757
 81.30762196 74.81551868 91.5488011  80.87043592 97.0774584  96.8373244
 43.55212865 72.15736423 53.41640933 72.70725196 57.93850083 75.25066523
 91.14974886 76.20384264 76.38274257 88.28723676 91.54168566 92.38220617
 90.63357829 90.50120231 96.88472662 59.5027726  54.56368071 67.11618867
 69.67490349 63.67917667 54.58118464 70.22938921 73.07472093 62.05981558
 68.72924677 69.17219542 84.73110866 71.24086618 61.41134267 89.42433804
 68.20323859 74.48615536 74.16783497 79.28940857 58.88186286 83.24806252
 82.85050764 93.4326369  79.78143326 74.83847224 79.17805838 70.22564138
 78.24078677 49.06799959 62.87828244 81.29073663 23.45246091 88.10593793
 76.22808877 57.92909806 70.80191559 70.73638483 36.6148521  71.13465909
 17.13347277 49.36118205]
mAP score regular 76.81, mAP score EMA 72.84
starting validation
Accuracy th:0.5 is [90.57727284 97.90467648 93.79375638 98.70692877 99.33726985 98.26095622
 99.04327678 95.9189775  98.5773725  97.61815781 99.12798665 99.27249172
 99.48675785 95.7470663  97.96945462 98.27092209 97.06006926 98.77668984
 99.39706505 98.92119491 99.57645066 99.63375439 99.79071679 99.77576799
 95.30607669 97.81000075 94.61344894 98.04918155 98.20365249 98.75924957
 99.07566584 98.95607544 97.40638314 99.37215038 99.22266238 99.35471012
 98.91122904 98.90375464 99.43692852 93.23566784 97.81000075 93.07870543
 97.1024242  96.25283404 97.07003513 95.20143508 98.8165533  98.90873757
 98.00931809 98.97600718 99.21020505 98.90624611 99.06819144 98.90375464
 99.01088771 98.18372076 91.19266512 97.63061514 96.56426738 98.24849889
 92.93420036 99.02334504 97.52099061 97.97692902 99.00839624 97.79256048
 98.90375464 96.01116177 98.82153624 98.39300396 99.81064853 97.96696315
 98.4503077  95.95385804 97.61815781 97.63559808 99.21767945 98.86638264
 99.82559733 99.07068291]
Accuracy th:0.7 is [90.04409896 97.95699728 93.34778384 98.72436904 99.33726985 98.21610982
 98.96105838 95.97628124 98.5848469  97.51849914 99.11802078 99.31733812
 99.47430052 95.89406283 97.96198022 98.21361836 97.1995914  98.7866557
 99.37962479 98.91372051 99.54157012 99.56399332 99.79569973 99.79071679
 95.51785136 97.80003488 94.55863667 97.97443755 98.12143409 98.7941301
 99.06071704 98.86389117 97.39890874 99.32979545 99.08812318 99.37464185
 98.86638264 98.87883997 99.45187732 93.61437078 98.04918155 93.74143558
 97.45372101 96.79099086 97.10491566 94.99464335 98.88382291 98.96604131
 98.22856716 98.95856691 99.13546105 98.85143384 99.08563171 98.79911304
 98.99095598 98.16378902 91.5464534  97.71034208 96.66890899 98.18122929
 93.50723771 98.98099011 97.54839674 97.97443755 98.92866931 97.87727035
 98.87385704 96.11082044 98.7866557  98.22856716 99.81563146 97.99187782
 98.53750903 96.0161447  97.57081994 97.72778235 99.27996612 98.7791813
 99.82559733 99.13795251]
Avg Prec: is [97.62210405 53.90817325 75.22606763 82.33024219 88.66490259 77.12050794
 90.88054005 59.91850809 75.23639277 70.23556802 67.0169678  70.28740674
 44.85867018 47.90575558 52.66539974 80.71742132 58.14818793 78.77782157
 79.05465332 68.38962089 91.24798378 85.33347857 96.53137077 98.0031961
 30.08553619 64.81227458 38.31351266 66.57248969 47.85928596 69.38337749
 88.18310383 61.53259258 67.71108306 87.79869163 83.70448633 88.92409686
 85.04939437 87.73808389 94.86714759 50.32971398 46.19441576 57.37329188
 54.5553094  48.28663416 39.09891184 58.49498726 64.08382995 44.91396824
 55.86835929 58.19442554 82.96890437 56.8276249  49.93042112 85.87495763
 53.5680271  58.99516111 60.93668614 70.34870603 47.33525031 75.47896798
 70.76825405 91.57147557 72.43341115 67.72226155 70.71873322 52.29422718
 73.01424832 38.34212615 46.95640841 72.39593296  7.7780694  81.25233486
 60.93380709 48.24032411 69.30899504 59.65303361 22.57852119 62.33262883
  2.95349752 29.53043751]
Accuracy th:0.5 is [90.76662431 97.87477888 93.91085532 98.66955677 99.37713332 98.22856716
 99.08064878 95.8816055  98.56491517 97.66300421 99.09559758 99.27498318
 99.47180905 95.8816055  97.91464235 98.23604156 97.09744126 98.7119117
 99.33726985 98.86389117 99.56648479 99.63126292 99.79071679 99.77576799
 95.38082069 97.74023968 94.48638413 97.98440342 98.18870369 98.6969629
 99.05822558 98.91372051 97.42631487 99.27996612 99.18279891 99.36467598
 98.85890824 98.85641677 99.41948825 93.66420011 98.07907915 93.72399532
 97.36153674 96.59665645 96.95293619 95.16157162 98.86887411 98.94860104
 98.30331116 98.98099011 99.18279891 98.89628024 99.06071704 98.91372051
 99.02085358 98.18122929 91.613723   97.72030795 96.64897725 98.17873782
 93.66669158 99.10307198 97.61815781 97.91713382 99.01088771 97.78010315
 98.90375464 96.00617884 98.82901064 98.47023943 99.81563146 98.01180955
 98.4577821  95.92396044 97.59324314 97.70286768 99.25754292 98.85392531
 99.82559733 99.14791838]
Accuracy th:0.7 is [90.3854299  97.84238981 93.79873932 98.73931784 99.39208212 98.26344769
 99.09808905 95.97628124 98.62471037 97.65303834 99.07815731 99.29989785
 99.46931759 95.80437003 97.87976182 98.15880609 97.01023993 98.69945437
 99.32730398 98.80658744 99.55901039 99.64372026 99.79569973 99.76331066
 95.51535989 97.67795301 94.71310761 97.90965942 98.22109276 98.6745397
 99.05075118 98.93863517 97.26935247 99.27000025 99.18529038 99.34972718
 98.90624611 98.82153624 99.41201385 93.69409772 98.04669009 93.80870518
 97.46368687 96.82836286 97.09245833 95.14911428 98.86638264 99.00341331
 98.38802103 98.97849864 99.17532451 98.85392531 99.05573411 98.91372051
 98.97351571 98.23105862 91.52153873 97.67047861 96.70378952 98.19866956
 93.65672571 99.10307198 97.64307248 97.89221915 98.97849864 97.84238981
 98.88631437 96.08341431 98.84894237 98.47023943 99.81563146 98.02177542
 98.5101029  95.98873857 97.59822608 97.76266288 99.27249172 98.79163864
 99.82559733 99.17034158]
Avg Prec: is [97.72620308 51.91362604 75.94582819 82.83499749 90.04446815 77.52976736
 90.63125899 60.49008641 75.94748902 71.2459308  66.04162232 69.90163311
 43.23926229 48.45231966 51.14040614 79.95779411 56.23590115 77.3941236
 77.86885481 66.09941808 91.49239005 83.84974087 96.51841098 97.558614
 31.16786989 63.19414576 39.8287217  66.16627398 47.15370144 65.83082315
 86.92993152 60.82449641 66.17137214 86.20056256 84.16404363 89.58533376
 84.62870501 87.19468569 95.0074503  51.24973661 43.83739722 57.80761743
 53.45901587 47.67620492 38.81189047 58.622848   63.89390588 46.80411423
 56.37321513 57.96739509 82.62326016 56.72444826 48.2974624  86.39946735
 54.00982545 59.8451552  62.92662733 70.40997536 47.18054853 76.43710183
 72.31311578 92.23857831 73.64158209 66.73011669 71.83762803 52.69994105
 73.15214703 38.25058127 48.14292701 74.21050486  8.91115168 81.89397069
 60.28239939 48.25726777 69.18029739 60.10886133 22.35263546 62.686481
  3.33262545 30.6587797 ]
mAP score regular 64.66, mAP score EMA 64.58
Train_data_mAP: current_mAP = 76.81, highest_mAP = 76.81
Val_data_mAP: current_mAP = 64.66, highest_mAP = 64.77
lr:  [8.864814267402449e-05, 8.864814267402449e-05]
BCE Train Loss:  tensor([18.4060,  4.0723, 20.5023,  4.2852,  0.9319,  7.1424,  6.0698, 12.3684,
        12.9807,  5.8799,  3.1789,  0.6467,  4.5905, 14.9760,  9.5818,  5.9947,
         9.4976,  1.2053,  0.5366,  2.7252, 10.4256,  4.4120,  0.8244,  0.7631,
        20.2314,  6.4726, 20.1991,  7.3925,  2.4797,  7.9247,  1.8032,  0.8503,
         6.1523,  2.5355,  2.2285,  3.5868,  0.4152,  0.7607,  0.6733, 14.0477,
         2.6653, 14.4219,  6.7852,  5.5045, 10.1944, 13.2526,  2.8610,  2.1038,
         9.2205,  2.5673,  2.8878,  1.3158, 11.3634,  0.9917,  4.2912,  0.8130,
        13.9457,  4.2697, 16.0376,  3.7049, 12.9876,  2.7136,  7.4209,  2.6699,
         0.3758, 12.8176,  2.8913, 14.3521,  1.6257,  3.4798,  0.2216,  6.1311,
         5.4984,  4.3899, 16.5227, 12.5672,  2.9228,  2.6235,  0.1150,  5.1713],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [30/80], Step [000/642], LR 8.9e-05, Loss: 506.4
BCE Train Loss:  tensor([24.0163,  8.4110, 17.0431,  4.3767,  4.1740,  6.9376,  5.2431, 13.1159,
         2.9391,  3.6008,  4.9130, 13.6583,  0.7005,  8.1569,  7.3290,  7.2156,
        15.9797,  8.2089,  1.5316,  1.0124,  0.3898,  2.3907,  0.1802,  1.6113,
        17.5727,  8.5114, 22.7010,  6.7794,  6.1240,  5.0469,  5.9837,  4.8908,
         2.4591,  1.0548,  0.2384,  2.1516,  2.4357,  0.6398,  2.1390, 20.3242,
         9.7287, 24.5472,  5.5501, 12.3318,  7.3094, 16.8846,  1.2530,  1.6767,
         6.1739,  4.7560,  9.3664,  2.9459,  2.3365,  0.9865,  5.2609,  5.8480,
        11.9370,  4.8299,  6.7849,  9.5998, 24.0754,  0.7722,  6.4352,  4.7046,
         7.7262,  4.4058,  7.6270,  9.4486,  2.2192,  5.6853,  0.0998,  2.8530,
         5.4917, 17.6956, 10.0734,  5.1130,  4.0354,  4.1673,  0.1998,  0.4342],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [30/80], Step [100/642], LR 8.8e-05, Loss: 545.6
BCE Train Loss:  tensor([33.7130,  1.3660, 13.7987,  3.6051,  0.6687,  1.8596,  1.0728,  8.8742,
         1.7825,  7.2177,  3.6434,  0.5729,  0.4604, 10.7199,  4.7538,  7.3716,
        13.3033,  7.2151,  2.0468,  1.8490,  0.2565,  7.9612,  0.2374,  0.1972,
         7.7098,  6.5502, 20.4891,  2.9065,  2.1609,  2.8327,  1.0426,  1.8304,
         5.2090,  0.8970,  4.4467,  2.0183,  9.9071,  0.4454,  0.8569, 16.6262,
         8.4789, 18.3167,  8.1382,  7.0882,  4.6394,  7.9947,  2.5838,  3.0775,
         5.9827,  8.6182,  5.2096,  3.3246,  1.2468,  1.6563,  4.1320,  6.0987,
        28.0869,  6.0726, 17.2602,  5.9366, 15.9992,  0.9281,  4.9105,  4.4011,
         6.7911,  3.4707,  6.1289, 12.8875,  7.5025,  5.6145,  0.0898,  3.8814,
         2.1379,  9.4475, 15.2816,  8.5924,  3.6128,  2.8926,  0.0891,  4.3540],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [30/80], Step [200/642], LR 8.8e-05, Loss: 493.4
BCE Train Loss:  tensor([22.9616,  3.1118, 11.1708, 10.9617,  1.2877,  6.3191,  1.8709, 12.7990,
         1.5235,  3.4145,  0.3099,  1.3227,  5.2194, 19.0814, 18.7739, 11.1689,
         4.1965,  3.9422,  0.4869,  5.3256,  0.8146,  1.6969,  0.1715,  1.3136,
         8.5024,  2.2513, 10.8222, 13.8707,  7.8128, 12.4963,  0.2210,  3.3085,
         3.3657,  3.1265,  2.4283,  2.6866,  0.5631,  1.7304,  0.4394, 17.0521,
         1.8209, 11.5161,  8.1797,  7.5498,  3.5431, 11.4974,  8.7135,  2.9985,
         6.5745,  4.6876,  1.6446,  1.8966,  0.7398,  1.7331,  2.8912,  8.3429,
        20.2196,  4.8226,  8.6921,  3.3163, 14.6776,  1.0117,  6.1994,  3.7221,
         2.6064,  1.8172,  1.4028, 10.5563,  1.3041,  1.0390,  0.0601,  3.5903,
         2.6969,  8.7983,  8.2008, 16.6813,  4.0672,  3.9413,  0.2449,  9.2782],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [30/80], Step [300/642], LR 8.8e-05, Loss: 463.2
BCE Train Loss:  tensor([26.9910,  5.1147, 16.8162,  3.5895,  7.6659,  9.2034,  2.1344, 22.5643,
         6.1181,  6.5519,  3.4453,  6.6954,  3.4295, 16.1047, 16.0380,  6.4030,
         3.9091,  1.7965,  1.3290,  0.7662,  0.3476,  0.2785,  0.1401,  3.6592,
        15.3414,  4.0106, 10.7579,  2.3585,  2.0641,  0.8679,  1.4251,  2.8133,
         4.8185,  8.0267,  1.4282,  1.1144,  6.0684,  2.7630,  2.7713, 14.8241,
         6.6050, 14.1207, 10.0269, 10.3667,  9.7386,  7.0242,  4.4979,  0.9056,
         6.2061,  1.1981, 12.5479,  1.1118,  0.7124,  3.9796,  3.4893,  1.8257,
        18.9427,  1.5930,  7.4841,  2.3855,  8.2805,  0.7413,  1.3144,  1.8267,
         2.0731,  1.1554,  0.4519, 10.9413,  1.3280,  0.3884,  0.0449,  1.3754,
         1.0629,  4.9492,  3.9715,  3.8634,  0.3745,  1.8498,  0.1042,  2.1742],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [30/80], Step [400/642], LR 8.8e-05, Loss: 425.6
BCE Train Loss:  tensor([19.9161, 14.5508, 20.1566,  3.4583,  4.3759,  3.0013,  0.8019,  8.0929,
         2.1018,  7.3156,  3.0112,  2.8622,  0.4035,  6.5286,  6.2778,  4.1711,
         8.6295,  5.8199,  0.4138,  4.2527,  3.4674,  0.5889,  0.1423,  0.3968,
         9.6259,  2.7868, 17.6242, 12.2687,  3.4392,  1.2791,  0.5858,  0.9687,
         3.9101,  5.4314,  0.3712,  0.7057,  0.4551,  0.7790,  1.6837, 16.9794,
         4.2043, 11.7797, 10.8547,  8.9737,  3.5626,  9.7847,  0.9634,  2.4609,
         9.8538,  1.9232,  7.0078,  5.6510,  0.5998,  3.4840,  3.9613,  1.6826,
        21.0980, 12.2765,  5.5502,  4.9535, 13.2974,  1.2914,  7.1768,  1.8857,
         0.6337,  4.6420,  0.6822,  7.0372,  1.0467,  0.7206,  0.1544,  3.5272,
         1.7867, 13.2944,  5.8236,  2.4322,  2.4288,  7.5806,  0.1147,  1.3322],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [30/80], Step [500/642], LR 8.7e-05, Loss: 417.1
BCE Train Loss:  tensor([26.1669,  5.8900, 24.0560,  3.8942,  3.2130,  5.1846,  0.6912,  8.8061,
         1.0756,  6.0279,  6.7880,  0.8787,  0.2804,  9.2317,  9.1727, 13.9588,
         9.6574,  2.2455,  3.8300,  2.7039,  3.0171,  6.5498,  1.4567,  4.5797,
        17.7757,  2.1436, 19.2646,  8.9968,  1.2966,  0.4778,  2.5380,  6.2187,
         6.0809,  0.6420,  1.0892,  4.6399,  0.6553,  3.2358,  0.3435, 14.5602,
         1.7721,  7.4326,  8.6389,  6.6924,  5.0096,  7.6635,  2.7779,  3.9065,
         4.1772,  4.1069,  2.0397,  4.6447,  0.2915,  1.5870,  3.3084,  3.2763,
        22.2761,  3.4468,  5.2515,  5.9762,  9.2036,  0.7547,  3.7995,  3.7401,
         1.1757,  3.2446,  1.1506, 13.3275,  1.1011,  2.4694,  0.1613,  1.7803,
         1.2750, 13.8143,  8.3018,  8.8553,  0.5222,  0.7748,  0.1461,  1.4898],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [30/80], Step [600/642], LR 8.7e-05, Loss: 430.7
BCE Val Loss:  tensor([6.2840e+01, 2.1479e+01, 5.1956e+01, 2.2698e+01, 1.4166e-01, 1.0159e+01,
        4.8580e+00, 2.1753e+01, 6.8237e+00, 7.8113e+00, 8.9139e+00, 1.1157e+01,
        7.7280e+00, 1.7233e+01, 7.6586e+00, 2.3864e+01, 2.2036e+02, 4.2236e+00,
        3.7246e+00, 1.0389e+01, 1.7225e-01, 1.0507e+00, 4.6989e-02, 2.4479e-02,
        2.3005e+01, 1.3555e+01, 3.1207e+01, 7.4307e-01, 1.5740e+01, 1.3819e+01,
        5.1101e-01, 3.8193e+00, 9.5072e+00, 5.4916e-01, 3.9969e-01, 2.8179e-01,
        7.1063e+00, 4.1995e+00, 9.1205e-01, 3.8487e+01, 1.1316e+01, 2.2461e+01,
        5.8176e+00, 1.3089e+01, 1.4611e+01, 1.4097e+01, 8.8019e-01, 4.0570e+00,
        5.0878e-01, 3.0205e+00, 3.8353e-02, 1.5976e-01, 3.2760e+00, 2.8677e-01,
        4.4450e-01, 3.7030e-01, 2.8708e+01, 7.5107e+00, 9.3752e+00, 2.2000e+00,
        1.2014e+01, 2.0787e+00, 1.9104e+00, 7.5069e+00, 5.4505e-02, 6.7408e-01,
        2.5801e-01, 6.3447e+00, 8.9314e+00, 1.3499e+01, 4.2060e-01, 1.8963e+01,
        9.4575e+00, 8.2222e+00, 1.7260e+01, 6.6646e+00, 4.8682e-01, 8.8109e+00,
        9.2192e-02, 6.7106e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [30/80], Step [000/314], LR 8.7e-05, Loss: 957.5
BCE Val Loss:  tensor([7.2075e+01, 1.9908e+01, 4.6446e+01, 1.1708e+01, 2.7718e+00, 3.7356e+01,
        2.8899e+01, 3.2670e+01, 1.5321e+01, 3.0954e+01, 1.6648e+01, 3.4630e+01,
        1.1477e+01, 7.0815e+00, 1.8931e+01, 3.7035e+00, 7.0366e+00, 1.6392e+01,
        5.0884e+00, 9.8442e+00, 9.1679e-02, 2.3467e-01, 1.1045e-01, 5.1911e-02,
        3.2986e+01, 2.1663e+01, 3.5192e+01, 1.4556e+01, 1.7709e+01, 6.6476e-01,
        1.0764e-01, 4.0575e-01, 6.1028e-01, 5.3322e-01, 5.8011e-01, 1.6511e-01,
        9.2316e-01, 2.6421e+00, 7.9823e-02, 1.9699e+00, 1.7975e-01, 4.7425e+00,
        4.9355e-01, 2.6139e+00, 7.3275e-01, 1.6637e+00, 1.6212e-01, 1.0186e-01,
        1.4557e-01, 7.6302e+00, 2.0137e-02, 1.1540e-01, 5.4554e-02, 2.8623e+00,
        6.9252e-02, 8.3445e-01, 1.4579e+01, 9.4937e+00, 2.6859e+00, 1.8580e-01,
        6.0332e+00, 2.7618e-01, 1.0915e+00, 5.9103e-02, 1.5732e-02, 1.0735e-01,
        2.6484e-02, 2.1000e+01, 1.2860e-01, 2.5390e+00, 1.8888e-02, 2.2694e-01,
        2.8328e+00, 3.7666e+00, 5.0887e+00, 2.2051e-01, 4.8381e-01, 6.4541e-01,
        2.8840e-03, 6.9486e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [30/80], Step [100/314], LR 8.7e-05, Loss: 654.2
BCE Val Loss:  tensor([1.2919e+01, 3.7252e-01, 3.9881e+00, 3.5763e-01, 5.6739e-02, 5.9938e-02,
        8.1731e-02, 1.5621e+01, 2.5753e-01, 2.3962e-02, 2.6343e-02, 3.2970e-02,
        7.1465e-03, 1.1401e+01, 3.4802e-01, 8.9392e-01, 1.5198e+00, 2.8265e-01,
        7.1077e-02, 7.7509e-02, 3.8382e-02, 3.7277e-02, 1.1396e-02, 3.9145e-03,
        4.1825e+00, 6.4003e-01, 2.4678e+01, 2.7013e+00, 3.8309e-01, 2.8409e-01,
        3.1279e-01, 6.2804e+00, 8.9112e+00, 4.7148e-02, 3.4826e-01, 2.0786e-01,
        1.4391e+01, 7.6838e+00, 5.3188e-02, 3.6834e+01, 1.6324e+01, 6.2561e+01,
        5.3352e+01, 5.6589e+01, 4.2218e+01, 5.8414e+01, 1.1963e+01, 7.6482e+00,
        3.8881e+01, 1.0778e+01, 2.2691e+01, 3.6051e+01, 5.7823e+01, 1.4943e+01,
        4.7592e+01, 7.1243e+01, 8.5149e+01, 1.0913e+01, 6.3434e+00, 4.2009e-01,
        7.7366e+01, 2.7149e-01, 1.6333e+01, 8.7012e+00, 1.3345e+01, 3.3607e+00,
        9.3989e+00, 1.2635e+01, 7.1705e+00, 6.0478e+00, 2.0719e-01, 1.2192e+01,
        5.4563e+00, 4.3374e+01, 2.0208e+00, 1.4199e+01, 9.5693e+00, 1.7753e+00,
        2.3231e-02, 2.6685e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [30/80], Step [200/314], LR 8.7e-05, Loss: 1112.0
BCE Val Loss:  tensor([2.3963e+01, 9.7769e-01, 1.1265e+01, 1.0859e+00, 8.2525e-01, 8.9997e+00,
        8.2182e+00, 1.5879e+01, 4.1181e+00, 1.7749e+01, 3.5270e+00, 7.4945e+00,
        1.9307e-01, 1.3350e+01, 1.7763e+01, 4.1797e-01, 1.5833e+00, 6.8735e-01,
        6.3662e-02, 5.8734e-02, 3.6457e-01, 7.3853e-02, 1.7191e-02, 2.2751e-02,
        1.9263e+01, 1.9008e+00, 2.1269e+01, 4.9261e-01, 1.8020e+01, 1.6895e-01,
        1.3307e-01, 9.4051e-02, 6.8241e-02, 4.4275e-01, 3.4772e-02, 4.0048e-02,
        9.6254e-02, 1.4850e-01, 1.2517e-02, 2.3653e+00, 1.0120e+00, 1.6451e+00,
        2.7538e-01, 6.8486e-01, 2.1823e-01, 1.4994e+00, 1.2426e-01, 4.1340e-02,
        8.5189e-02, 3.3345e-02, 9.8904e-03, 3.2252e-02, 3.2576e-02, 1.6945e-01,
        3.8843e-02, 2.1821e-01, 7.6749e+00, 2.0308e+00, 1.2454e+01, 5.7417e-01,
        7.1953e+00, 4.4198e-01, 1.6900e+00, 3.7573e-02, 1.4648e-02, 5.2388e-01,
        8.7830e-02, 6.4447e+00, 1.2205e-01, 1.7296e-01, 9.9231e-03, 8.3586e-01,
        2.9995e-01, 5.7776e+00, 4.7740e+01, 3.1812e+00, 7.1625e-02, 3.8052e+00,
        2.2359e-02, 3.1311e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [30/80], Step [300/314], LR 8.7e-05, Loss: 310.6
starting validation
Accuracy th:0.5 is [91.28056432 98.2029946  95.21326495 98.9827122  99.52120466 98.67448009
 99.33724004 96.90305917 98.86819118 98.3552832  99.26901475 99.37988085
 99.63572569 96.70081992 98.1749735  98.68300825 97.70592464 99.04971918
 99.38353578 99.0801769  99.57602856 99.66740171 99.80385229 99.75633825
 95.80414469 98.20055799 95.43377883 98.15669887 98.72808567 99.12525432
 99.18007822 99.16911344 98.13720593 99.31043725 99.43592305 99.40668364
 99.08992337 99.23490211 99.65400032 94.83193431 98.47589576 94.80391321
 98.07263557 97.47566428 97.63891765 96.31827098 99.03266286 99.10697969
 98.81458559 99.0521558  99.38353578 99.19957116 99.36282453 99.25439505
 99.2617049  98.70615611 93.70743534 98.22614247 97.55119942 98.87671934
 95.44718022 99.33358512 98.01050182 98.44421973 99.29216262 98.47711407
 99.20322608 96.77635506 99.0947966  98.90352213 99.82090861 98.5368112
 98.97174742 96.67279882 98.00075535 98.18715659 99.33358512 99.07164874
 99.84527479 99.37500761]
Accuracy th:0.7 is [88.70993287 98.02755814 94.6077655  98.90474044 99.4566343  98.47589576
 99.33480343 96.59117213 98.85600809 98.11527637 99.25926828 99.32871188
 99.59673981 96.46934126 98.08238204 98.53071965 97.46713612 98.96809249
 99.45785261 99.18982469 99.50536665 99.6795848  99.81238045 99.71735237
 95.58241249 97.9800441  95.12798333 97.94593146 98.61721958 99.05824734
 98.98758543 99.21419086 98.04095954 99.17276836 99.3177471  99.35064144
 98.93641647 99.19835285 99.59308488 94.44694875 98.36137474 94.27760383
 98.09212851 97.18936173 97.34408694 95.81754608 98.97540235 98.97540235
 98.78656449 98.92910661 99.31896541 99.1215994  99.31531049 99.18860638
 99.16058528 98.50635348 93.938914   98.11649468 97.37454466 98.76463493
 94.85995541 99.35551467 98.26878328 98.14573409 99.13378248 98.49417039
 99.1496205  96.51929192 99.04850087 98.85357147 99.818472   98.45762113
 98.8986489  96.32436252 97.86674139 98.00075535 99.29216262 99.02169808
 99.84405648 99.32505696]
Avg Prec: is [98.60800229 68.48274986 85.07624323 87.61902493 96.0789041  87.03873595
 94.37403159 75.70175491 83.48228112 83.95804528 77.4411108  78.97963509
 65.78078461 65.05995395 64.42008421 86.51149341 69.44111796 85.56331153
 84.8368047  80.08427056 94.33952296 84.36809404 97.71126447 98.11277703
 48.26547903 78.40901735 58.79162143 78.41212934 67.26307431 80.73520155
 92.83888254 78.76906396 81.63707227 91.02083329 93.54681164 94.00307137
 92.22124914 93.11221731 97.64572448 66.08572812 63.66154976 71.50773825
 75.61387214 70.44926135 61.4580485  75.09961954 78.56699432 70.83307716
 74.7674885  76.1433571  86.89382236 76.03921611 70.50973012 91.87753971
 76.1783958  80.90815914 79.05137196 83.89587412 67.61593716 88.27065077
 85.69896246 94.89949862 84.16771803 81.05985472 83.50782103 76.58645146
 83.76509439 58.05717699 68.72158089 84.86392179 25.9584047  89.8977285
 80.62518184 64.29814098 75.66235623 75.62655918 47.76856173 75.31299109
 21.17679371 59.71964794]
Accuracy th:0.5 is [91.87997222 98.08603696 94.84168078 98.88646581 99.47490893 98.60016325
 99.33480343 96.61553831 98.76585324 98.1603538  99.20444439 99.31287387
 99.60404966 96.43522862 98.08847358 98.52706473 97.49272061 98.94007139
 99.37866254 99.15205711 99.58333841 99.66374679 99.8050706  99.7076059
 95.68718705 98.12380453 95.21204664 98.23832556 98.60990972 98.99367698
 99.12890925 99.18373314 98.03243138 99.32749357 99.38962732 99.35551467
 99.0947966  99.17398667 99.63572569 94.36410375 98.31995224 94.38603331
 97.92887514 97.16255894 97.53901634 95.96861637 98.93763478 99.02657131
 98.70128288 99.12890925 99.2751063  99.12647263 99.32262034 99.15205711
 99.21175424 98.61843788 93.47352006 98.02268491 97.25393209 98.69519134
 95.09143407 99.29703585 98.09334682 98.31873393 99.24830351 98.39914231
 99.11550785 96.66183404 99.03022624 98.80605743 99.81725369 98.3418818
 98.88159257 96.46812295 97.87161462 98.07019895 99.29459924 98.96565588
 99.84405648 99.30190909]
Accuracy th:0.7 is [90.61536775 97.9106005  94.27029398 98.81336728 99.44445121 98.46371267
 99.30069078 96.33654561 98.67813501 97.98979057 99.15205711 99.289726
 99.57359194 96.16476407 97.97273425 98.40279724 97.34408694 98.85966302
 99.32871188 99.05337411 99.56506378 99.6649651  99.78557766 99.68080311
 95.48738441 97.92156528 94.93305393 98.12502284 98.50269855 98.86453625
 99.11428954 99.03144455 97.64622751 99.24586689 99.35064144 99.35064144
 99.0241347  99.08139521 99.59673981 94.02175899 98.21030446 94.02054069
 97.90816389 97.12600967 97.33434047 95.62870823 98.88159257 98.98636713
 98.65986038 99.04850087 99.26048659 99.02291639 99.24952181 99.18982469
 99.13134587 98.47345914 92.68283768 97.93131175 97.09798857 98.63183928
 94.62725844 99.25926828 97.95080469 98.23467063 99.17398667 98.24929034
 99.05702903 96.3913695  98.98880374 98.77925464 99.81603538 98.29193114
 98.84869824 96.20740488 97.76927669 97.96298778 99.27145137 98.89255735
 99.84405648 99.26779644]
Avg Prec: is [98.33001725 63.07613487 82.2341283  85.32432011 95.18045625 84.59370703
 93.58672298 72.01406887 80.27247059 80.11101744 73.13763855 76.80839515
 58.93080245 58.72053072 59.17051595 83.42845855 64.14613765 83.08179065
 82.01136465 78.42460168 93.1285764  82.18392151 97.16225436 97.49282291
 44.25640773 73.31166967 55.12009536 74.43812235 59.94116834 75.97436301
 91.60650088 75.59336341 78.43117424 89.17878313 92.52437353 92.79758379
 90.94966605 91.46494943 97.28518955 60.49673217 56.36311084 67.99882632
 71.41823316 65.04889142 57.26913397 71.2597155  74.60816151 63.47332487
 69.6090601  71.42153689 84.52397889 72.58755282 63.58500209 90.2881184
 70.13788885 77.14725942 75.34275046 80.83335931 61.5309102  85.4497707
 83.68071559 93.78314252 81.2550475  76.56186939 80.50362187 73.09760793
 80.09136501 51.05114195 64.57305123 82.41200647 23.16453739 87.86692021
 77.18986906 59.71399454 72.02828839 71.1136446  41.88770335 71.36070929
 18.14306415 50.98424679]
mAP score regular 77.78, mAP score EMA 74.20
starting validation
Accuracy th:0.5 is [90.3331091  97.91962528 93.98310786 98.65709943 99.39706505 98.31825996
 99.05075118 95.79440417 98.4503077  97.67546154 99.07815731 99.19525625
 99.50170665 95.8890799  97.94204848 98.29583676 97.13481326 98.7193861
 99.29242345 98.61225303 99.52662132 99.64122879 99.80815706 99.78573386
 95.30607669 97.76266288 94.5262476  97.91215088 98.28088796 98.7642325
 99.03081944 98.85143384 97.31669034 99.32730398 99.19027331 99.36218452
 98.86887411 98.87883997 99.45436879 93.65174278 98.10897675 93.63679398
 97.3117074  96.71126392 97.0650522  95.25624735 98.8016045  98.94860104
 98.26344769 98.93863517 99.24259412 98.89877171 99.10058051 98.94860104
 99.00341331 98.13638289 90.66447418 97.74273115 96.61409672 98.18122929
 93.30792037 98.97600718 97.21952313 97.92959115 98.99593891 97.68791888
 98.88880584 96.04105937 98.85641677 98.47522236 99.8056656  97.94453995
 98.52006876 96.00368737 97.61815781 97.70535914 99.29242345 98.89129731
 99.82559733 99.12549518]
Accuracy th:0.7 is [89.21942347 97.88474475 93.82863692 98.6894885  99.37464185 98.25348182
 99.03580238 95.93641777 98.6147445  97.59324314 99.11802078 99.27498318
 99.47928345 95.89157137 97.91464235 98.22607569 97.1098986  98.70692877
 99.35221865 98.81406184 99.45686025 99.68607519 99.81812293 99.77078506
 95.48047936 97.63559808 94.66078681 97.83740688 98.26593916 98.78914717
 98.88133144 98.96105838 97.34658794 99.24757705 99.15539278 99.30238932
 98.78914717 98.89877171 99.41450532 93.72648678 98.13389142 93.78379052
 97.49856741 96.76607619 97.11488153 95.12918255 98.85890824 98.95856691
 98.34815756 98.89628024 99.16785011 98.90375464 99.13296958 98.90624611
 99.01337918 98.19119516 91.46174353 97.70785061 96.71873832 98.19866956
 93.33283504 99.06320851 97.55337967 97.79256048 98.91372051 97.91962528
 98.89129731 96.07593991 98.82901064 98.41791863 99.81563146 97.94453995
 98.52754316 96.07095697 97.64307248 97.70037621 99.27498318 98.88880584
 99.82559733 99.15539278]
Avg Prec: is [97.66521843 52.93045348 75.74485326 82.52539612 90.13744301 77.15034181
 90.53868992 59.82415993 76.30505087 70.05193912 66.40745198 69.91030962
 46.19628032 47.86073999 51.8074891  80.40084251 56.25948442 76.84498128
 79.18549629 67.24543542 91.07899419 84.30537084 96.69360082 97.87583931
 29.70809407 64.16666518 39.32489935 64.84805225 48.99509133 69.84365729
 88.19140984 64.29049837 66.48687652 87.10535581 83.70205086 89.03749726
 84.45582875 87.80063114 94.93320305 51.44721193 46.39642391 57.13754594
 54.09624275 47.45989938 38.41675879 58.02203991 62.64408031 43.58949143
 56.42609484 56.51204591 83.27802338 57.20501533 51.33659252 86.52740275
 54.5125831  59.01425631 61.95265473 69.80655941 47.88592017 76.34406069
 70.44639065 91.55310232 72.88929728 66.67642447 70.77904371 53.59479277
 73.08613178 37.79519915 47.14770336 71.3495807   8.32579696 80.44565118
 60.91470584 48.27754169 69.82559237 58.08603785 23.91361862 63.64767078
  2.96515023 29.0661083 ]
Accuracy th:0.5 is [90.90365498 97.88723622 93.89839799 98.6820141  99.39955652 98.23853302
 99.11303785 95.9040287  98.58235543 97.65802128 99.09559758 99.27498318
 99.46931759 95.89904577 97.93457408 98.27341356 97.15723647 98.7343349
 99.36965892 98.86887411 99.56648479 99.64621172 99.79071679 99.78324239
 95.38331216 97.77761168 94.44652067 98.00433515 98.21361836 98.7193861
 99.06071704 98.93365224 97.42880634 99.30737225 99.21020505 99.35969305
 98.90375464 98.88382291 99.42696265 93.64426838 98.10399382 93.77133318
 97.36153674 96.60413085 96.94546179 95.18399482 98.85143384 98.95607544
 98.30829409 98.97351571 99.19774771 98.91122904 99.07068291 98.92866931
 99.03829384 98.19119516 91.61870593 97.74023968 96.64648579 98.19119516
 93.71153798 99.10556345 97.65054688 97.98191195 99.00341331 97.80003488
 98.91621197 95.9937215  98.82901064 98.49764556 99.81064853 98.04419862
 98.4652565  95.90901164 97.60570048 97.69788474 99.27498318 98.88382291
 99.82559733 99.13296958]
Accuracy th:0.7 is [90.58474724 97.85235568 93.83112839 98.72436904 99.40453945 98.28088796
 99.13047811 95.99870444 98.63467623 97.68791888 99.10805491 99.29740638
 99.48675785 95.85669083 97.91962528 98.20365249 97.0650522  98.72935197
 99.34474425 98.84645091 99.57395919 99.65119466 99.8056656  99.77078506
 95.51286843 97.73276528 94.70563321 97.93955702 98.23105862 98.70692877
 99.05822558 98.96105838 97.2743354  99.30238932 99.20023918 99.35720158
 98.92119491 98.83150211 99.41450532 93.69160625 98.09651942 93.80372225
 97.49607594 96.82337992 97.1024242  95.18150335 98.88382291 99.00092184
 98.40795276 98.99593891 99.18279891 98.87385704 99.05822558 98.90624611
 98.98597304 98.22358422 91.60126567 97.72778235 96.71873832 98.23604156
 93.68911478 99.10556345 97.65054688 97.90965942 98.99593891 97.86232155
 98.90624611 96.09836311 98.85392531 98.4652565  99.81563146 98.02177542
 98.51508583 96.02611057 97.62563221 97.77512021 99.27249172 98.8165533
 99.82559733 99.18279891]
Avg Prec: is [97.77483723 52.52083654 76.17177097 83.00543303 90.27033414 77.78103282
 90.86423818 60.78930128 76.3135706  71.51640861 66.68985337 70.19564196
 44.10900132 49.03596449 51.83922374 80.58199371 57.22319463 78.13458328
 78.61116761 67.17186732 91.74277336 84.60628818 96.60526428 97.53667592
 31.2235091  64.10799333 40.02121909 66.58590681 47.95888601 67.16065119
 87.19226913 61.62775796 66.67580817 86.71293317 84.33057488 89.75997294
 85.06815564 87.44059137 95.12155226 51.56841979 44.81399074 57.99753537
 53.9842649  48.0711897  39.05472776 58.84394828 64.43311026 47.02717992
 56.7783841  58.47433798 82.96706228 57.31455759 49.06691123 86.69846319
 54.7988376  60.51863896 63.13856776 70.86536336 47.68453062 76.82124381
 72.43833665 92.37819054 73.96546885 67.41283468 72.10066118 53.33168047
 73.58553905 38.77799353 48.53528016 74.34473345  8.81249168 82.03150013
 60.69082401 48.64613569 69.56868633 60.38564415 22.97246572 63.51514018
  3.37493938 31.16388316]
mAP score regular 64.61, mAP score EMA 65.01
Train_data_mAP: current_mAP = 77.78, highest_mAP = 77.78
Val_data_mAP: current_mAP = 65.01, highest_mAP = 65.01
lr:  [8.704504060620746e-05, 8.704504060620746e-05]
BCE Train Loss:  tensor([17.3444,  4.8731, 14.7493,  1.7676,  1.6552,  3.0909,  2.5717, 10.1659,
         1.7196,  6.2776,  3.2405,  3.4774,  0.2450,  7.2892,  6.7371,  3.3853,
        20.0063,  8.3312,  3.8962,  4.3405,  0.5129,  0.3298,  0.1241,  0.0724,
        12.5609, 10.8797, 23.0442,  9.2539,  7.7082,  1.9907,  0.7557,  1.4937,
         1.8416,  2.4699,  0.2951,  1.4227,  7.4020,  6.3465,  0.1328, 21.4001,
         9.8288, 13.5791,  1.2912,  5.9155,  7.7066, 20.8242,  7.1697,  2.8010,
         2.2237,  2.0418,  2.8094,  2.5564,  2.7140,  0.2786,  0.7312,  7.9804,
        18.6583,  8.5578, 15.1418,  4.9127, 15.0517,  0.8080,  2.4680,  4.8695,
         5.2050, 11.3660,  1.0180,  4.3455,  1.5866,  2.6782,  0.3344,  6.4847,
         2.2011, 20.0328,  3.2844,  2.8749,  3.0456,  3.4352,  0.2519,  0.8109],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [31/80], Step [000/642], LR 8.7e-05, Loss: 465.1
BCE Train Loss:  tensor([25.1498,  4.8781, 12.3391,  5.0518,  0.2754, 10.1627,  0.8545, 12.6161,
         4.7993, 12.2882,  4.6635,  1.8513,  2.9342, 12.2677, 10.3934,  7.9928,
        10.3236,  0.8465,  8.6539,  1.5957,  0.2126,  0.9378,  0.5161,  0.2984,
        11.1399,  9.8503, 11.5811, 11.4478,  1.2973,  6.5265,  0.9311,  3.8586,
        10.9610,  0.6349,  1.6840,  5.0373,  8.7571,  2.3535,  6.1516, 12.5050,
         2.4699, 18.6150,  3.9450,  5.6532,  9.7122, 10.6402,  3.5556,  0.9405,
         8.2029,  3.5942,  2.0992,  1.9182,  0.6287,  0.7165,  4.0635,  6.7433,
        15.8960,  1.9349,  4.8627, 15.5677, 14.0274,  0.4236,  2.9429,  8.7323,
         0.8786,  3.3128,  4.8893,  7.1180,  3.0943,  4.1694,  0.3266,  6.5754,
         5.5519,  9.6968,  6.3688,  4.1308,  1.1608,  1.6151,  0.1217,  0.8303],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [31/80], Step [100/642], LR 8.7e-05, Loss: 464.3
BCE Train Loss:  tensor([28.1292, 10.6364,  9.4286,  2.6223,  4.0468,  3.7026,  0.8310, 20.3390,
         2.0001,  6.7306,  0.7650,  2.2500,  0.3169,  5.7051, 13.8713,  4.0182,
        14.3436,  6.3008,  0.3206,  4.5032,  8.0059,  0.5601,  0.1978,  0.0789,
        10.6826,  4.3291, 14.9719,  7.0759,  1.4127,  4.9220,  4.3702,  4.7615,
         4.9516,  0.9209,  0.4197,  0.5505,  1.0202, 10.4455,  0.2919, 12.0320,
         4.1653, 10.6324,  1.6820, 11.0835,  4.8742, 12.4248,  9.0866,  1.6879,
         4.0647,  2.7486,  2.8783,  0.4844,  2.5555,  3.2201,  2.6236,  0.8152,
        13.4892,  8.4711, 15.2909,  2.4738, 13.8968,  6.5329,  6.9146,  1.7094,
         1.4380,  4.7680,  5.7349,  8.4312,  1.1368,  0.8140,  0.4494,  8.7921,
         8.5981, 10.2930,  9.5730, 11.4519,  0.5631,  5.6003,  2.0661,  2.9895],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [31/80], Step [200/642], LR 8.7e-05, Loss: 459.4
BCE Train Loss:  tensor([26.0819, 14.3565, 14.5511,  8.7023,  0.9206,  3.1525,  0.3806,  8.5097,
        21.8822,  9.3160,  1.5126,  0.7651,  0.4179,  7.4418,  6.4390,  7.4060,
         7.3749, 10.0014,  0.2434,  0.4362,  0.1794,  0.2754,  0.1064,  2.4504,
        20.1030,  4.1835, 15.2202, 10.1043,  4.3816,  0.6607,  0.2063,  1.0610,
         2.3393,  1.3448,  0.5184,  0.5111,  2.9886,  0.7047,  0.4185, 12.6318,
         4.2926, 20.7659,  7.2652, 17.7147, 11.5922, 12.5244,  5.0854,  6.6994,
         8.6723,  3.8082,  5.6791, 11.3643,  0.7950,  1.7366,  2.6329,  6.9348,
        19.0729,  4.1205, 15.6102,  2.3882, 19.3001,  0.8414, 11.1123,  6.0859,
         5.9955,  9.4424,  3.5109,  7.9135,  2.3976,  2.0305,  0.3231,  5.7255,
         5.1257, 20.7854,  9.2252,  8.5787,  4.6082,  0.7376,  0.1523,  5.5937],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [31/80], Step [300/642], LR 8.6e-05, Loss: 528.5
BCE Train Loss:  tensor([30.2582,  2.6449, 23.1897,  0.8994,  0.3188,  4.3774,  1.9618, 12.3361,
         2.0684,  8.3734,  1.2151,  1.3157,  0.3647, 16.3037,  5.3358,  1.3399,
        15.3340,  8.6404,  2.4553,  0.9966,  2.1322,  0.7699,  0.2597,  0.4201,
         9.8572,  9.3514, 12.6020,  1.6102,  0.6289,  2.1566,  0.8657,  1.2178,
         8.8142,  4.9893,  0.7456,  1.1639,  2.1861,  1.0819,  0.6964, 12.7812,
         4.7213, 10.4089, 10.4019,  5.8541,  6.9000,  8.6246,  6.4915, 11.1543,
         2.6609,  0.9638,  4.2896,  4.0791,  4.1856,  0.4940,  0.8396,  3.2295,
        16.2916,  4.9949, 11.0039,  2.3980, 14.0705,  0.2882,  9.1268,  4.1509,
         4.0168,  5.4379,  4.4155, 11.4775,  0.9596,  2.1124,  0.1347,  1.8486,
         2.0577, 12.5477,  4.1912,  4.2770,  1.0646,  2.0104,  0.0907,  0.6721],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [31/80], Step [400/642], LR 8.6e-05, Loss: 419.0
BCE Train Loss:  tensor([10.4368,  7.1560, 17.5990,  0.9909,  0.1533,  3.9752,  3.8983,  9.3879,
         0.9909,  3.0838,  2.8955,  0.5815,  0.1470, 10.7053, 12.4728, 14.6630,
         5.3201,  6.8142,  0.5378,  0.6153,  5.3161,  0.7727,  0.2815,  5.7381,
        13.2318, 10.9258, 13.3082,  4.3292,  1.5429,  1.4699,  0.4393,  0.6246,
         9.2244,  1.3314,  3.2912,  0.5902,  2.8671,  0.4022,  0.2559, 20.7971,
         6.0813, 13.3340,  6.1935,  9.5564,  5.8393,  6.2355,  3.4294,  2.5723,
         3.2420,  4.2120,  0.9614, 26.5732,  0.5441,  2.2670,  2.3695,  5.1936,
        11.9603,  5.4284,  9.5163,  5.2864,  8.0414,  1.6532, 10.2961,  5.5040,
         0.4994,  2.0393,  2.2999, 11.7128,  1.9810,  1.6503,  0.2694,  2.7737,
         2.1884, 12.9865,  7.9991,  3.0711,  5.1842,  2.6371,  3.8462,  1.8703],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [31/80], Step [500/642], LR 8.6e-05, Loss: 428.5
BCE Train Loss:  tensor([33.8546,  7.6847, 14.2443,  1.4865,  1.0843,  6.7323,  2.8616,  5.5541,
        11.8527,  5.2903,  4.3552,  7.8557,  0.1848, 21.0677,  8.0067,  1.5931,
        20.2481, 14.4466,  0.4622,  7.7884,  0.3943,  0.2063,  0.3061,  0.3165,
        27.6567,  9.1996, 16.0806,  9.2452,  7.3137,  6.1275,  1.6538,  3.2606,
        10.6320,  0.7123,  0.5734,  4.3760,  0.7565,  4.4538,  0.3507, 19.7296,
         8.6696, 18.0917,  3.6957, 10.9487,  5.5695, 10.7815,  2.3597,  2.9486,
         8.9858,  3.7009,  2.5039,  6.2218,  2.0678,  0.7995,  2.1660,  9.9250,
        24.1970,  6.4556, 10.3601, 11.1416, 12.5389,  0.3292,  6.0817,  4.1904,
         0.8449,  9.5007,  3.4760, 16.6289,  2.1597,  0.9476,  0.1428,  9.1058,
         4.0762,  9.9581,  7.8835,  7.7610,  5.3479,  0.8335,  0.2272,  0.9152],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [31/80], Step [600/642], LR 8.5e-05, Loss: 554.5
BCE Val Loss:  tensor([5.4082e+01, 1.8831e+01, 4.9516e+01, 2.3559e+01, 1.6518e-01, 1.0117e+01,
        4.1950e+00, 2.0315e+01, 5.6236e+00, 8.6781e+00, 7.3532e+00, 1.2461e+01,
        7.5859e+00, 1.8002e+01, 9.5945e+00, 2.3077e+01, 2.2530e+02, 2.9189e+00,
        1.6449e+00, 1.4474e+00, 2.9126e-01, 5.2247e-01, 2.3261e-02, 1.8378e-02,
        2.2949e+01, 1.1761e+01, 3.0447e+01, 1.9024e+00, 1.2285e+01, 1.8607e+01,
        8.6206e-01, 7.8154e-01, 1.1009e+01, 3.6934e-01, 1.2436e-01, 8.2427e-02,
        1.2727e+01, 4.3162e+00, 6.6973e+00, 4.0235e+01, 1.3093e+01, 2.3137e+01,
        5.8378e+00, 1.6833e+01, 1.4926e+01, 1.6093e+01, 3.1832e-01, 4.4921e+00,
        1.4394e-01, 3.6565e+00, 7.2307e-02, 1.1642e-01, 9.3292e+00, 1.9822e-01,
        1.7343e-01, 8.4761e-02, 2.4050e+01, 8.2116e+00, 8.5743e+00, 3.3722e+00,
        1.1404e+01, 2.0950e+00, 3.6234e+00, 8.3108e+00, 7.0615e-02, 7.6797e-01,
        3.9180e-01, 7.3091e+00, 8.4419e+00, 1.6068e+01, 5.4060e-01, 2.2121e+01,
        1.0717e+01, 1.0190e+01, 1.6553e+01, 7.6140e+00, 8.0673e-01, 6.8838e+00,
        1.1549e-01, 7.4299e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [31/80], Step [000/314], LR 8.5e-05, Loss: 968.0
BCE Val Loss:  tensor([5.6410e+01, 2.0495e+01, 5.1976e+01, 1.1091e+01, 6.5751e+00, 3.3987e+01,
        2.2499e+01, 3.4705e+01, 2.5233e+01, 3.2234e+01, 1.6582e+01, 4.4405e+01,
        1.1956e+01, 7.4770e+00, 1.7316e+01, 2.8852e+00, 8.1909e+00, 1.8380e+01,
        3.5493e+00, 1.7152e+01, 1.7949e-01, 9.6874e-02, 7.2371e-02, 3.0292e-02,
        3.2380e+01, 2.0829e+01, 3.7727e+01, 1.5116e+01, 1.4897e+01, 4.8988e-01,
        1.2977e-01, 2.1307e-01, 4.1323e-01, 9.9879e-01, 2.2394e-01, 4.6300e-02,
        5.0412e+00, 1.1808e+00, 1.4348e-01, 1.3212e+00, 5.0810e-02, 4.3371e+00,
        1.8205e-01, 1.3247e+00, 1.1103e+00, 2.1010e+00, 6.6064e-02, 6.5676e-02,
        7.5036e-02, 6.6158e+00, 3.4463e-02, 6.1981e-02, 1.8593e-02, 1.0913e-01,
        7.8347e-02, 8.5386e-02, 1.3885e+01, 8.4035e+00, 3.9476e+00, 2.1769e-01,
        3.5511e+00, 1.4898e-01, 3.9782e-01, 8.0070e-02, 1.8626e-02, 6.0744e-02,
        3.0705e-02, 2.1725e+01, 1.6435e-01, 2.9100e+00, 3.1819e-02, 2.8322e-01,
        3.4440e+00, 2.9139e+00, 5.2686e+00, 2.6094e-01, 8.9174e-01, 4.4558e-01,
        5.5729e-03, 1.1205e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [31/80], Step [100/314], LR 8.5e-05, Loss: 660.1
BCE Val Loss:  tensor([1.0190e+01, 4.5248e-01, 3.4084e+00, 5.4292e-01, 4.4230e-02, 7.6227e-02,
        1.1752e-01, 1.5292e+01, 1.2420e-01, 2.7224e-02, 2.0525e-02, 3.3600e-02,
        2.2535e-02, 9.4152e+00, 7.0504e-01, 1.8072e+00, 2.3157e+00, 9.0126e-02,
        6.4699e-02, 1.9641e-02, 3.4852e-02, 2.3795e-02, 9.6394e-03, 4.6429e-03,
        4.2015e+00, 6.7184e-01, 2.8750e+01, 5.1718e+00, 4.4771e-01, 1.8173e-01,
        6.9987e-01, 5.8825e+00, 9.4917e+00, 4.6200e-02, 9.1070e-02, 5.4951e-02,
        8.6388e+00, 7.3881e+00, 8.3259e-02, 3.2899e+01, 2.0280e+01, 6.4490e+01,
        5.9283e+01, 5.7642e+01, 4.5653e+01, 6.4262e+01, 8.6203e+00, 7.2871e+00,
        3.6963e+01, 1.1883e+01, 2.4480e+01, 3.4624e+01, 7.5000e+01, 1.2776e+01,
        4.0936e+01, 8.7424e+01, 1.0202e+02, 1.2883e+01, 6.8727e+00, 1.6183e+00,
        7.9793e+01, 2.4418e-01, 1.3531e+01, 7.0255e+00, 1.0390e+01, 4.4728e+00,
        8.3913e+00, 1.5551e+01, 8.4462e+00, 5.6778e+00, 4.2328e-01, 1.4253e+01,
        5.6677e+00, 4.3174e+01, 1.2877e+00, 1.5605e+01, 1.2198e+01, 1.6694e+00,
        6.8942e-02, 9.3211e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [31/80], Step [200/314], LR 8.5e-05, Loss: 1173.3
BCE Val Loss:  tensor([2.6019e+01, 7.7950e-01, 1.4296e+01, 6.6383e-01, 4.7888e-01, 8.8898e+00,
        9.4200e+00, 1.5942e+01, 2.4837e+00, 1.8089e+01, 4.1498e+00, 7.8651e+00,
        4.0671e-01, 1.2642e+01, 1.6969e+01, 2.2210e-01, 1.5535e+00, 4.8620e-01,
        3.1465e-02, 2.5975e-02, 1.4406e-01, 3.4142e-02, 1.2343e-02, 3.7242e-02,
        2.1077e+01, 5.3378e+00, 2.4196e+01, 1.2590e+00, 1.6772e+01, 7.3275e-02,
        2.4691e-01, 4.1945e-02, 5.4385e-02, 9.4378e-02, 2.4843e-02, 3.1528e-02,
        2.4571e-01, 9.5813e-02, 3.4263e-02, 2.3431e+00, 3.0764e-01, 1.0188e+00,
        4.7156e-02, 2.0687e-01, 2.0721e-01, 1.0462e+00, 4.4092e-02, 2.8065e-02,
        2.8317e-02, 2.1129e-02, 2.1532e-02, 2.8705e-02, 7.8948e-03, 8.2871e-02,
        7.3214e-02, 6.0226e-02, 5.0842e+00, 2.7384e+00, 1.1540e+01, 5.0936e-01,
        7.2554e+00, 3.4833e-01, 7.1515e-01, 7.9414e-02, 1.9391e-02, 4.8303e-01,
        2.2593e-01, 6.1800e+00, 1.4586e-01, 1.2273e-01, 1.4390e-02, 2.0557e-01,
        2.0474e-01, 7.1724e+00, 4.7427e+01, 1.7256e+00, 1.4157e-01, 4.8073e+00,
        1.1150e-02, 4.9169e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [31/80], Step [300/314], LR 8.5e-05, Loss: 314.0
starting validation
Accuracy th:0.5 is [93.19940059 98.26634666 95.26930715 98.98880374 99.51145819 98.72321244
 99.372571   96.878693   98.82676868 98.34919165 99.26414152 99.36404284
 99.65643693 96.8238691  98.30533254 98.72808567 97.77780485 99.05459241
 99.4152118  99.21784579 99.61257782 99.71004252 99.81238045 99.75390163
 95.80414469 98.41619863 95.35946199 98.40157893 98.78047295 99.20444439
 99.16058528 99.21784579 98.17862843 99.43470474 99.43714136 99.2751063
 99.28119784 99.289726   99.66374679 94.81853291 98.2858396  94.84655401
 98.14938902 97.45617134 97.54023465 96.2524823  99.0241347  99.09114168
 98.84869824 99.19835285 99.34820482 99.22759226 99.27632461 99.26292321
 99.29216262 98.54168443 94.38237838 98.08238204 97.53536141 98.90717706
 95.6530744  99.3311485  98.3552832  98.56970553 99.30556402 98.50513517
 99.14231064 96.89940425 99.11428954 98.95103617 99.82578185 98.59650833
 98.96809249 96.51807361 97.98735396 98.25660019 99.31896541 99.12403601
 99.84527479 99.37988085]
Accuracy th:0.7 is [92.21744374 98.17862843 94.93305393 98.83042361 99.53704268 98.70250119
 99.36526114 96.78731984 98.62696605 98.1323327  99.19835285 99.31531049
 99.62597922 96.58020736 98.24076217 98.52219149 97.57800222 98.92301507
 99.32505696 99.13743741 99.61866936 99.70638759 99.8050706  99.73197208
 95.51175059 98.23345232 94.87092019 98.31020577 98.63671252 99.07286705
 98.92545169 99.06068396 97.76440346 99.35064144 99.22150071 99.05702903
 99.17398667 99.20200777 99.6649651  94.21425178 98.1323327  94.48106139
 97.86308646 97.13697445 97.59262192 96.29634142 98.89499397 99.01804315
 98.68057163 99.09966984 99.3591696  99.09601491 99.21175424 99.11916278
 99.27266968 98.32604379 93.85606901 98.29802268 97.29291797 98.94738125
 95.20230017 99.38353578 98.20786784 98.38452261 99.3031274  98.55752245
 99.21053593 96.70325654 99.10697969 98.87428272 99.82090861 98.52828304
 98.84260669 96.81899587 97.89110756 97.96420609 99.34820482 99.07286705
 99.84405648 99.40302872]
Avg Prec: is [98.71910316 69.7182256  85.30859984 88.35749945 96.38787101 87.79732085
 94.92441961 76.56183067 84.82396648 83.7039145  78.15261866 79.70734328
 68.6470059  66.9519525  66.8715198  87.48765245 70.14505557 86.90511853
 85.74386801 83.09399247 93.87484609 86.31174679 97.55471291 97.78537614
 50.86990046 79.66784732 59.94987975 79.23592001 68.99329684 84.86403481
 93.00189681 80.62079362 82.86255823 92.1588861  94.61954815 94.18094939
 93.82903236 94.04690809 97.60814311 67.61672161 65.24054467 72.15065427
 76.73068186 71.5425699  62.06228375 75.88571527 79.98650843 70.00152568
 76.36917427 75.64383638 86.53483754 76.818185   71.9693555  92.42979606
 76.20025428 80.79211971 81.12499835 85.04496481 67.17065973 89.56925842
 86.65179041 95.04292595 85.49478706 82.65892619 85.24264154 78.5663476
 84.00677981 58.91988119 71.08833672 86.32154569 29.48715297 90.62625188
 81.48625654 67.1326385  75.20474434 77.4929609  49.42015021 78.15063061
 27.06993439 62.38350403]
Accuracy th:0.5 is [92.35145771 98.12136792 94.96594827 98.90230382 99.50780327 98.63793082
 99.31652879 96.71543963 98.83164191 98.18959321 99.21784579 99.32627526
 99.62110598 96.51929192 98.18715659 98.63671252 97.53901634 98.94616294
 99.38962732 99.12038109 99.59308488 99.68202142 99.79410582 99.71369745
 95.7639405  98.16400872 95.20595509 98.24685372 98.62818435 99.08505013
 99.11428954 99.1642402  98.08481865 99.35185975 99.43714136 99.39815548
 99.1496205  99.20200777 99.65400032 94.50055433 98.37477614 94.56512469
 97.94471315 97.16621386 97.51708678 96.12455989 98.98880374 99.05824734
 98.75854339 99.1228177  99.27997953 99.15571204 99.31043725 99.21053593
 99.24099365 98.70737442 93.70621703 98.10918483 97.30510106 98.77559971
 95.276617   99.28850769 98.08238204 98.38086768 99.27023306 98.46249437
 99.12769094 96.70325654 99.07408535 98.83164191 99.82334523 98.46858591
 98.86453625 96.54243979 97.84115691 98.1603538  99.30190909 99.02291639
 99.84527479 99.35795129]
Accuracy th:0.7 is [91.11852926 97.99100888 94.3982164  98.86331794 99.47125401 98.51853657
 99.26779644 96.37309487 98.74392369 98.08360035 99.18251483 99.30678232
 99.57481025 96.26710201 98.05070601 98.51488164 97.38794605 98.85235316
 99.33845835 99.02657131 99.56506378 99.68080311 99.78435935 99.70882421
 95.52393368 97.99100888 94.93183563 98.12989608 98.55264921 98.97052911
 99.15327542 99.06555719 97.76440346 99.27754291 99.40546533 99.36647945
 99.13378248 99.14718388 99.60892289 94.18257575 98.2724382  94.21059685
 97.92156528 97.13819276 97.35992495 95.7078983  98.89377566 99.02047977
 98.68300825 99.06921212 99.30190909 99.04484594 99.28363446 99.21662748
 99.14474726 98.55021259 92.93259098 98.02268491 97.13941107 98.70128288
 94.76005409 99.28728938 97.96786102 98.27609313 99.21053593 98.31629732
 99.04119102 96.46446803 99.01682484 98.843825   99.81603538 98.43081834
 98.8292053  96.31217943 97.75222037 98.01537506 99.27632461 98.9412897
 99.84405648 99.30069078]
Avg Prec: is [98.46071513 64.31111793 83.31312992 86.23751638 95.69294242 85.43849648
 93.90892045 73.24644633 82.25993239 80.9191662  73.87054323 76.92908211
 61.69958841 60.43609266 62.46014266 84.75200367 65.26200949 83.43226057
 82.7359238  78.71109938 92.92676813 83.89080112 97.25345659 97.392762
 46.36921436 74.85856938 55.36543767 75.28119253 61.68101951 79.82554578
 91.77873546 77.25611408 79.5904532  90.17845339 93.29754725 93.1580154
 92.05912619 92.41077737 97.21080618 62.45919043 59.62146344 69.37205185
 72.34197508 66.4610461  57.76885854 72.20617225 75.89556339 64.87024005
 72.19055252 70.48545392 84.71580612 73.5090647  64.58906101 91.05818588
 72.27234664 79.38456586 76.74616407 82.07173132 62.0301032  86.69027501
 84.6401018  94.2350079  81.90441494 78.59283048 82.80867334 74.52082426
 81.3337549  52.74338093 65.9106306  83.66103366 26.37766219 89.29218277
 77.9210268  62.24456536 71.96792408 73.57017368 41.91240976 74.5591228
 20.75747663 56.00294856]
mAP score regular 78.94, mAP score EMA 75.47
starting validation
Accuracy th:0.5 is [90.82641951 97.87727035 93.55955851 98.7268605  99.38959065 98.14385729
 99.10805491 95.70720283 98.61723597 97.62563221 99.16535865 99.29989785
 99.44689439 95.8068615  97.85983008 98.32573436 97.15723647 98.82153624
 99.38211625 98.93365224 99.60136532 99.68109226 99.79569973 99.78573386
 95.48047936 97.82494955 94.6009916  97.95699728 98.26344769 98.77668984
 99.00341331 99.00590478 97.53095647 99.37713332 99.11303785 99.23013678
 98.93116077 98.92617784 99.46682612 93.68911478 98.09153649 93.75140145
 97.56583701 96.70877245 96.68634925 94.62839774 98.86887411 98.99593891
 98.36310636 98.98099011 99.23761118 98.91122904 99.07566584 98.85890824
 98.96105838 98.09153649 91.38201659 97.43628074 96.63153699 98.05167302
 93.49727184 99.04327678 97.66549568 97.98440342 98.94860104 97.68542741
 98.76174104 95.83177617 98.80658744 98.47771383 99.80068266 97.98689489
 98.49017116 94.98467748 97.66300421 97.75269701 99.12051225 98.94361811
 99.82559733 99.07566584]
Accuracy th:0.7 is [90.73423524 97.91713382 93.72399532 98.67703117 99.41699679 98.29583676
 99.11303785 95.93143484 98.5101029  97.64805541 99.13795251 99.27498318
 99.48924932 95.88658843 97.98191195 98.19119516 97.18713407 98.76921544
 99.28744052 98.90375464 99.60136532 99.66116053 99.78573386 99.77576799
 95.48546229 97.84238981 94.59600867 97.96198022 98.24351596 98.81406184
 98.83399357 98.97849864 97.3715026  99.36716745 99.05075118 99.04576824
 98.87385704 98.87883997 99.46433465 93.59443905 98.03174129 93.75389292
 97.53344794 96.84082019 97.11986446 95.20641802 98.85641677 98.94610957
 98.35314049 98.96853278 99.24508558 98.87385704 99.05075118 98.74430077
 98.99344744 98.03423275 91.66106087 97.75020555 96.68634925 98.23105862
 93.52716944 99.12549518 97.63808954 97.93706555 98.99095598 97.87228742
 98.89877171 96.11829484 98.82901064 98.4428333  99.81563146 98.03174129
 98.50761143 95.86914817 97.67795301 97.66051274 99.27249172 98.94361811
 99.82559733 99.14293545]
Avg Prec: is [97.73147003 53.19679108 74.60437481 82.01228857 90.84999547 77.38477161
 91.20364279 59.66473627 75.52988265 70.49417881 67.22637167 69.82680426
 46.08277961 48.04909687 52.47375212 80.86524089 57.53642478 78.6579297
 78.82831639 69.69359365 91.45435018 86.008632   96.59410689 97.70908818
 30.04715321 65.39960957 38.6694789  65.21482783 48.56935965 70.85472671
 88.41789053 63.84514893 68.84932195 87.90227329 83.60236343 89.14920842
 85.55892712 87.78205588 95.43847757 50.35022519 45.81946498 57.55747896
 55.3844061  47.26724497 39.3882404  58.39931943 63.12455659 45.42765488
 55.45019142 58.4775402  83.57231089 56.14791156 48.61897596 85.65907671
 55.6999294  57.21308099 61.96707652 70.71749356 46.83694078 77.05234507
 70.92487658 92.02023222 74.28619629 66.96564215 71.59600025 54.32776584
 73.70060833 38.57930412 47.62275249 72.08239031  8.37597106 81.38843123
 60.45601748 47.52711793 70.20431438 58.52259083 23.45522226 65.20116388
  2.95632497 32.17615519]
Accuracy th:0.5 is [91.03071978 97.90218502 93.87597479 98.67703117 99.39955652 98.26095622
 99.11552931 95.8666567  98.59481277 97.65802128 99.10556345 99.27996612
 99.47430052 95.9115031  97.95948875 98.31825996 97.23198047 98.75177517
 99.36218452 98.87883997 99.57146772 99.65119466 99.79320826 99.79071679
 95.34843162 97.82993248 94.4515036  98.03672422 98.20116102 98.75177517
 99.07068291 98.94361811 97.45870394 99.32481252 99.21269651 99.35720158
 98.93614371 98.88382291 99.44191145 93.65174278 98.11645115 93.70904652
 97.3565538  96.62157112 96.94297033 95.21389242 98.84395944 98.95109251
 98.31078556 98.97600718 99.20771358 98.91122904 99.10058051 98.92617784
 99.03331091 98.20116102 91.6585694  97.74023968 96.65396019 98.20863542
 93.69908065 99.11552931 97.67047861 98.00682662 98.99593891 97.82744101
 98.90873757 95.9638239  98.84395944 98.51259436 99.8056656  98.04419862
 98.47023943 95.9115031  97.60570048 97.69290181 99.28245758 98.89378877
 99.82559733 99.14293545]
Accuracy th:0.7 is [90.70184618 97.87727035 93.92082119 98.74430077 99.40952239 98.29583676
 99.12549518 96.01116177 98.6595909  97.69788474 99.12549518 99.30238932
 99.49174079 95.91399457 97.94453995 98.23355009 97.117373   98.75924957
 99.35221865 98.86389117 99.58392506 99.66365199 99.80317413 99.77825946
 95.52532576 97.76017141 94.70065027 97.98191195 98.23355009 98.73682637
 99.06569998 98.96604131 97.2967586  99.30986372 99.20023918 99.36716745
 98.92368637 98.85641677 99.42197972 93.73396118 98.11146822 93.82614545
 97.48860154 96.84580312 97.1024242  95.22136682 98.88382291 98.99344744
 98.42290156 99.00341331 99.20023918 98.88631437 99.07815731 98.92119491
 99.02583651 98.22856716 91.6660438  97.78259461 96.73119565 98.25348182
 93.72648678 99.11552931 97.64556394 97.94952288 98.99843038 97.88723622
 98.90624611 96.10832897 98.85143384 98.47023943 99.81563146 98.04419862
 98.52006876 96.04853377 97.64058101 97.77013728 99.27498318 98.84395944
 99.82559733 99.18529038]
Avg Prec: is [97.81665326 52.99917379 76.3835776  83.1081698  90.46223391 78.03840249
 91.04172412 61.04205748 76.60176232 71.71300775 67.1998368  70.42836565
 44.89976473 49.48892053 52.33803054 81.08198032 58.12765589 78.7426258
 79.27806455 68.04922576 91.94978592 85.1502956  96.6747928  97.74317996
 31.32798043 64.80631291 40.1330498  67.01401732 48.565455   68.46715132
 87.57872976 62.3110332  67.14342414 87.1325241  84.53194958 89.8902949
 85.24792956 87.37520663 95.28919616 51.90259888 45.5260229  58.17318018
 54.3308816  48.40107419 39.16997226 59.01887785 64.81918673 47.33022931
 57.08343282 58.98039304 83.1924527  57.83824925 49.88767999 86.88759282
 55.61856963 61.06847318 63.32018306 71.21034194 48.10999624 77.24302006
 72.53887752 92.45502309 74.21471469 67.97225257 72.21847532 53.88191105
 73.96524096 39.2308721  48.7808563  74.30300878  8.73161958 82.13439653
 61.09212474 49.04723161 69.92300842 60.56567702 23.42457974 64.09654269
  3.39212065 31.87625743]
mAP score regular 64.94, mAP score EMA 65.38
Train_data_mAP: current_mAP = 78.94, highest_mAP = 78.94
Val_data_mAP: current_mAP = 65.38, highest_mAP = 65.38
lr:  [8.535269427262528e-05, 8.535269427262528e-05]
BCE Train Loss:  tensor([23.8145,  3.9256, 15.2286,  1.7067,  0.6159,  2.7630,  1.6457,  6.0897,
         1.0164,  2.2312,  1.2185,  0.9852,  5.7953,  9.7433,  5.2492, 12.4704,
         7.2209,  1.5406,  0.5242,  2.7834,  0.3777,  0.2389,  0.4890,  0.2199,
        15.8712,  9.5205, 11.3068,  9.0314,  2.5532,  7.4251,  2.8816,  1.6184,
         1.5956,  0.5445,  5.2310,  0.8322,  5.7441,  4.3074,  0.4804, 17.1309,
         2.0921, 11.4731,  7.9804,  9.8392,  7.3804,  9.8165,  7.5253,  5.6111,
         2.8163,  3.3669,  4.5204,  2.9311,  2.9986,  2.7708,  1.5169,  1.6866,
        21.3362,  6.8996,  6.2257,  4.7397, 18.4448,  1.7032,  2.7880,  5.3680,
         0.4971,  3.4519,  1.4772, 14.0469,  2.4214,  3.3393,  0.1951,  2.6605,
         5.2675,  8.7625,  5.8140,  4.2266,  4.5093,  3.3504,  0.4176,  0.7914],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [32/80], Step [000/642], LR 8.5e-05, Loss: 417.0
BCE Train Loss:  tensor([21.3950,  3.0365, 12.6410,  1.4335,  0.7498,  5.0195,  1.2792, 14.0026,
         5.4250,  4.5182,  6.7290,  0.2828,  1.8482, 10.3566,  4.1660, 11.6286,
         8.4869,  6.5500,  6.7502,  7.2080,  0.4793,  0.5178,  3.7168,  5.5744,
        12.5220, 11.4277, 14.7384,  2.9258,  1.1188,  0.8106,  2.6108,  3.9992,
        11.9870,  0.6320,  6.4685,  3.6321,  0.9957,  2.7930,  0.3880, 11.8583,
         2.5579, 11.5444,  4.2880,  3.9466,  7.4358,  7.0532, 14.9690,  2.1836,
         3.2237,  2.5980,  0.9363,  0.5814,  0.2486,  1.9049,  9.7140,  6.7680,
        17.8964,  5.6392, 13.4378,  3.0248, 11.9274,  3.4698,  3.1732,  5.5724,
         3.4540, 10.3035,  0.7593, 11.6117,  3.8384,  1.3318,  0.1652,  2.4585,
         1.3149, 10.6013,  5.9315,  6.0815,  3.9075,  2.5061,  0.4779,  5.7477],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [32/80], Step [100/642], LR 8.5e-05, Loss: 447.3
BCE Train Loss:  tensor([18.6541,  7.7289, 15.5305,  2.6059,  3.9719,  8.0742,  1.9263, 10.8980,
         3.0743,  2.1135,  0.7787,  4.4166,  0.3745, 10.5992,  1.5313,  3.5969,
         6.8082,  3.9269,  1.5855,  2.9245,  3.9306,  0.2624,  0.2147,  0.3544,
        14.2606, 15.4579, 19.5780,  4.1159, 16.4384,  1.1897,  0.2391,  0.2481,
         3.3198,  1.1916,  1.2656,  0.4567,  1.5658,  1.0618,  1.1811, 14.3930,
         7.8303, 14.2376,  0.9897,  4.4022,  2.4243, 13.7820,  0.6028,  5.6720,
         4.3834,  2.0812,  0.1993,  0.2479,  0.2838,  0.1881,  0.3548,  5.0008,
        11.5488,  9.5182,  5.7383,  8.5878, 14.4171,  0.3132,  4.8143,  3.8739,
         1.7396,  3.8686,  2.3515, 13.1717,  4.1179,  1.9566,  1.6084,  4.5537,
         2.3359, 11.1659,  2.4824,  7.0102,  1.4196,  2.6963,  0.0928,  2.3516],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [32/80], Step [200/642], LR 8.5e-05, Loss: 396.3
BCE Train Loss:  tensor([37.7755,  5.2990,  8.0964,  4.3691,  2.9575,  1.5948,  4.0666,  7.5723,
         8.8427,  9.4950,  5.6067,  2.5508,  0.7749, 12.7538, 11.6233,  6.5748,
        11.1187,  0.6163,  0.9978,  2.4754,  5.5928,  0.8187,  0.0507,  0.0501,
        11.4487,  6.8350, 16.4873, 13.4141,  9.2774,  2.8854,  1.9028,  0.4487,
         6.8699,  2.0132,  0.6805,  0.8783,  0.9361,  3.6590,  0.8638, 15.4106,
         2.6125, 13.9546,  4.8287,  9.9421,  7.8866, 14.1529,  2.6716,  3.3920,
         1.5419,  3.8286,  3.6197,  0.5218,  0.6460,  0.5458,  1.8608,  5.4647,
        15.4453,  4.6341, 12.9491,  2.5709, 15.7648,  0.9719,  8.1092, 10.6715,
         4.9195,  7.7627,  1.9677,  8.5118,  1.4722,  1.2461,  0.0600,  3.1919,
         1.7986, 10.7507,  5.0135,  8.1513,  0.9517,  5.1267,  0.2228,  3.1753],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [32/80], Step [300/642], LR 8.5e-05, Loss: 458.6
BCE Train Loss:  tensor([20.3156,  3.7005, 16.1359,  1.4921,  0.3979,  3.7434,  0.3386,  6.5172,
         5.8174,  4.6965,  1.5153,  0.6027,  3.6694, 10.3634,  5.5400,  3.5040,
         5.6232, 10.6454,  3.5162,  3.3739,  0.8881,  6.5698,  0.2071,  0.4648,
        28.6417,  7.3374, 13.5574,  3.4387,  1.9535,  2.9525,  6.4500,  6.8523,
         7.5933,  0.3119,  0.5555,  0.5999,  2.5990,  1.5925,  0.1128,  9.1114,
         4.2617, 10.2300,  5.6117, 11.8335, 12.0058, 13.7967,  1.9695,  1.7165,
         7.2223,  0.9637,  0.5818,  4.7819,  5.9454,  2.5289,  1.3459,  1.5212,
        14.2417,  4.9253,  9.8868,  4.8271, 10.7859,  0.5538,  1.8856,  1.1381,
         0.9402,  1.5154,  0.4938,  7.5142,  1.3049,  6.1754,  3.0280,  2.7502,
         2.7256,  8.7902, 10.7070,  9.3965,  4.8531,  3.5408,  0.0967,  3.5207],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [32/80], Step [400/642], LR 8.4e-05, Loss: 415.2
BCE Train Loss:  tensor([26.5910,  7.9907, 14.1887,  2.2365,  3.0618,  7.0010,  0.6854, 12.0570,
         3.1599,  4.8730,  0.5035,  0.6669,  1.0246, 14.1072,  5.3780,  5.2633,
         4.7243,  0.8510,  2.8722,  1.2969,  1.2258,  0.2397,  4.5394,  1.1699,
        11.1274,  2.1420,  6.9899,  4.8773,  1.6950,  0.3023,  1.8141,  1.0623,
         6.6150,  0.2979,  4.2220,  4.0960,  2.9490,  0.9539,  0.3945, 11.9396,
         8.7492, 13.0260,  5.9589, 15.8441,  7.7436, 11.8536,  2.7875,  6.5651,
         2.7048,  1.1872,  0.5933,  2.2744,  0.6572,  3.0902,  0.8104,  3.3834,
        19.8574,  5.7997,  5.7119,  2.3166, 13.8955,  5.1832,  2.9159,  3.7371,
         2.6530,  4.3756,  2.8863,  4.8784,  5.0741,  8.4484,  1.5699,  8.3520,
        11.7375, 12.2706,  7.5810,  4.6486,  4.6980,  5.9037,  1.6593,  5.6079],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [32/80], Step [500/642], LR 8.4e-05, Loss: 426.2
BCE Train Loss:  tensor([31.2542,  4.3052, 26.0718,  2.4890,  4.6311,  8.0556,  4.1846, 13.0817,
         1.6012,  5.3024,  0.3653,  5.6594,  0.4905, 10.0930, 13.4532,  3.0804,
         7.6508,  3.2335,  0.2585,  5.6141,  2.2441,  1.0650,  0.2200,  0.0820,
        26.3985, 15.2501, 18.3773,  5.0859,  1.6032,  3.5356,  1.7830,  1.3019,
        10.6635,  0.7609,  2.3898,  0.3698,  2.8575,  1.6171,  0.6024, 23.7841,
         5.7488, 27.1314,  5.5333,  7.2561, 16.5994, 16.1717, 12.3923,  1.7098,
         6.2868,  4.8879,  2.4424,  3.5206,  8.0815,  1.2767,  5.6648,  4.7142,
        20.5291, 19.8118,  9.6289,  6.2051, 20.3444,  1.3953,  8.2951,  8.8297,
         2.6771,  6.9272,  2.9145, 19.7272,  5.3015,  7.8980,  0.1424,  2.6629,
         5.7514, 14.6091,  9.9596,  6.9825,  0.7083,  5.3153,  0.3303,  3.5868],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [32/80], Step [600/642], LR 8.4e-05, Loss: 590.8
BCE Val Loss:  tensor([5.7501e+01, 1.6649e+01, 5.1823e+01, 2.0546e+01, 1.5577e-01, 9.0723e+00,
        5.1744e+00, 2.1572e+01, 5.5646e+00, 8.5682e+00, 7.3407e+00, 1.1067e+01,
        7.8206e+00, 2.1401e+01, 7.1301e+00, 2.2130e+01, 1.9328e+02, 1.8339e+00,
        1.1616e+00, 1.8833e+00, 2.7928e-01, 4.7547e-01, 1.5130e-02, 1.6476e-02,
        2.7282e+01, 1.2039e+01, 3.0854e+01, 1.0107e+00, 1.5075e+01, 1.8043e+01,
        1.9916e+00, 1.2138e+00, 1.1369e+01, 1.0462e+00, 1.6703e-01, 2.2715e-01,
        7.6004e+00, 5.0483e+00, 5.3832e+00, 3.6907e+01, 9.6144e+00, 2.0694e+01,
        7.1491e+00, 1.9665e+01, 1.3809e+01, 1.4109e+01, 4.7093e-01, 3.9224e+00,
        1.4190e-01, 2.7083e+00, 4.8118e-02, 8.1816e-02, 4.3370e+00, 2.2830e-01,
        1.2201e-01, 5.7185e-01, 2.0264e+01, 6.7843e+00, 1.0503e+01, 2.6552e+00,
        1.0196e+01, 1.2700e+00, 2.8379e+00, 5.8130e+00, 2.2038e-01, 9.5018e-01,
        7.0556e-01, 7.3585e+00, 7.6712e+00, 1.6707e+01, 2.6862e-01, 2.1146e+01,
        1.0719e+01, 8.2463e+00, 1.6935e+01, 6.3917e+00, 7.8872e-01, 8.8703e+00,
        8.5042e-02, 9.3656e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [32/80], Step [000/314], LR 8.4e-05, Loss: 913.7
BCE Val Loss:  tensor([6.2451e+01, 1.9230e+01, 5.0625e+01, 1.0492e+01, 7.3129e+00, 3.5147e+01,
        2.3877e+01, 3.6312e+01, 2.1681e+01, 2.9474e+01, 1.6659e+01, 3.9698e+01,
        1.0082e+01, 5.9361e+00, 1.9050e+01, 3.8398e+00, 1.0898e+01, 1.6647e+01,
        6.0619e+00, 1.3767e+01, 1.7774e-01, 1.3854e-01, 4.6281e-02, 5.9215e-02,
        3.1252e+01, 2.2645e+01, 3.3041e+01, 1.5573e+01, 1.8233e+01, 3.8239e-01,
        1.7920e-01, 1.5533e-01, 1.0832e+00, 2.7157e+00, 6.4478e-01, 2.2399e-01,
        2.1025e+00, 2.4398e+00, 9.5793e-02, 2.2373e+00, 1.3888e-01, 4.1004e+00,
        8.3743e-02, 5.1732e-01, 4.1186e-01, 2.4031e+00, 1.1198e-01, 1.2496e-01,
        2.4356e-02, 7.7221e+00, 1.6840e-02, 3.2640e-02, 3.1975e-02, 2.1570e+00,
        7.6217e-02, 3.0818e+00, 1.3990e+01, 9.1190e+00, 3.9249e+00, 1.3447e-01,
        3.2741e+00, 2.7864e-01, 1.0519e+00, 2.5691e-01, 2.5155e-02, 7.8479e-02,
        2.8471e-02, 2.2695e+01, 1.5115e-01, 4.9754e+00, 9.0409e-03, 2.3624e-01,
        4.0737e+00, 3.6509e+00, 3.2870e+00, 1.9525e-01, 6.6963e-01, 1.6713e-01,
        2.9736e-03, 8.0327e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [32/80], Step [100/314], LR 8.4e-05, Loss: 666.1
BCE Val Loss:  tensor([1.1654e+01, 3.5528e-01, 3.9753e+00, 1.1455e-01, 9.6590e-02, 4.4014e-02,
        1.6970e-01, 1.4854e+01, 1.2814e-01, 1.6932e-02, 1.5042e-02, 6.5727e-02,
        1.4366e-02, 9.2955e+00, 3.1116e-01, 8.3733e-01, 1.7805e+00, 1.1544e-01,
        3.9523e-02, 2.3037e-02, 5.2741e-02, 1.8386e-02, 3.9887e-03, 3.5925e-03,
        4.9240e+00, 7.4014e-01, 2.5707e+01, 4.1661e+00, 7.8604e-01, 4.3980e-01,
        1.6566e-01, 7.0279e+00, 9.5920e+00, 6.6507e-02, 1.3872e-01, 1.1175e-01,
        1.0658e+01, 7.0432e+00, 4.8984e-02, 5.2223e+01, 1.4549e+01, 6.2723e+01,
        7.4064e+01, 6.1532e+01, 4.6252e+01, 6.2614e+01, 9.0307e+00, 7.4277e+00,
        3.6620e+01, 1.2433e+01, 2.4293e+01, 4.1706e+01, 5.7496e+01, 2.4207e+01,
        4.9835e+01, 6.7438e+01, 1.1020e+02, 1.0006e+01, 7.4453e+00, 4.0600e-01,
        8.6641e+01, 3.8731e-01, 1.4216e+01, 7.4027e+00, 1.2189e+01, 3.2739e+00,
        9.4919e+00, 1.5984e+01, 9.4611e+00, 5.5133e+00, 1.4395e-01, 1.3165e+01,
        6.4736e+00, 4.5498e+01, 2.1174e+00, 1.4316e+01, 1.1294e+01, 8.3212e-01,
        2.3340e-02, 3.1688e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [32/80], Step [200/314], LR 8.4e-05, Loss: 1206.8
BCE Val Loss:  tensor([2.7003e+01, 1.5711e+00, 1.4430e+01, 8.0976e-01, 1.2789e+00, 1.1182e+01,
        7.6285e+00, 1.6681e+01, 3.0269e+00, 2.0821e+01, 7.6509e+00, 9.9375e+00,
        4.8853e-01, 1.2868e+01, 1.8812e+01, 6.7342e-01, 2.0849e+00, 6.6824e-01,
        5.2471e-02, 4.5754e-02, 8.1039e-01, 6.6040e-02, 1.3012e-02, 3.2992e-02,
        1.9570e+01, 4.7172e+00, 2.0605e+01, 1.1489e+00, 1.5637e+01, 2.9268e-01,
        4.8942e-01, 4.8402e-02, 1.1381e-01, 6.8454e-01, 4.7694e-02, 3.7693e-02,
        1.1259e-01, 9.1850e-02, 2.7567e-02, 2.2983e+00, 8.7783e-01, 9.2490e-01,
        2.4696e-02, 1.2987e-01, 2.0182e-01, 2.0731e+00, 8.6608e-02, 8.0471e-02,
        1.6946e-02, 6.8216e-02, 1.3687e-02, 2.1717e-02, 2.4734e-02, 2.0521e-01,
        4.2411e-02, 3.1633e-01, 5.2643e+00, 2.4564e+00, 1.2908e+01, 1.3361e-01,
        8.1416e+00, 2.7455e-01, 2.4581e+00, 7.0565e-01, 3.0540e-02, 1.0685e+00,
        2.6031e-01, 6.5525e+00, 2.1894e-01, 1.2514e-01, 7.8355e-03, 7.8644e-01,
        1.5743e-01, 7.1396e+00, 6.3089e+01, 2.9340e+00, 1.8067e-01, 5.3075e+00,
        1.0653e-02, 3.4119e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [32/80], Step [300/314], LR 8.4e-05, Loss: 349.9
starting validation
Accuracy th:0.5 is [93.03127399 98.31873393 95.3326592  98.99855021 99.56019054 98.69397303
 99.41033857 97.03585483 98.9546911  98.39426908 99.31165556 99.35185975
 99.65278201 96.91767888 98.2724382  98.82555037 97.81922735 99.07895859
 99.47856386 99.27632461 99.63328907 99.73440869 99.81481707 99.72588053
 95.93694034 98.44665635 95.57022941 98.42960003 98.84017008 99.23977534
 99.3031274  99.28119784 98.31264239 99.40790195 99.43957798 99.46881739
 99.22515564 99.33602173 99.70273267 94.85751879 98.56605061 95.00493415
 97.97151594 97.41474885 97.73394574 96.41208075 99.05459241 99.16180358
 98.76950817 99.21419086 99.42130335 99.20322608 99.44566952 99.30190909
 99.31652879 98.87306441 94.53588528 98.38817753 97.43546009 98.98514882
 95.77977851 99.18982469 98.32360717 98.3833043  99.27754291 98.60381818
 99.19713454 97.0175802  99.11672616 98.96200095 99.82212692 98.46980422
 99.01926146 96.88843947 98.06045248 98.32482548 99.36647945 99.13256417
 99.84527479 99.35795129]
Accuracy th:0.7 is [92.0164228  98.27731144 94.42989242 98.86331794 99.52729621 98.52950135
 99.38597239 96.878693   98.84626162 98.25416357 99.27145137 99.34820482
 99.6235426  96.68498191 98.10065667 98.66473362 97.71810772 99.01316992
 99.41399349 99.19591623 99.63207076 99.735627   99.79532413 99.68689465
 95.76881373 98.29071283 95.28880009 98.2578185  98.8011842  99.20444439
 99.25439505 99.11063462 98.22126923 99.39450055 99.32140203 99.39937379
 99.13743741 99.22881057 99.68080311 94.93914548 98.48807885 94.42258257
 97.62064302 96.94935491 97.45982627 96.35360193 98.93276154 99.11550785
 98.58432524 99.17033175 99.33236681 99.03997271 99.37135269 99.3177471
 99.20931763 98.76463493 93.75494938 98.1603538  97.22469268 98.86088132
 94.830716   99.38231747 98.37721275 98.61356465 99.3177471  98.50148025
 99.24343027 96.84092543 99.14352895 98.85600809 99.81603538 98.63793082
 98.88281088 96.61432    97.88014279 98.19081152 99.3445499  99.04971918
 99.84405648 99.37135269]
Avg Prec: is [98.69866372 70.9325288  86.17802251 88.77578623 96.44567669 88.10300109
 95.17637421 78.21621777 85.1774749  84.65518381 78.5042674  79.28601463
 67.79033172 67.73610379 67.79292588 88.30488367 71.55141232 86.97940846
 86.748059   83.74770923 94.43949041 88.22704851 97.58410849 97.80525099
 51.33645314 80.29462535 61.29065714 79.99278971 71.32145029 85.65843271
 93.65593123 82.76395136 84.56059213 91.7799109  94.18587813 94.59618498
 93.62070046 94.04783997 97.91585621 68.54575769 67.2626627  74.03563915
 77.50871589 73.55393403 64.09318463 76.96221388 81.27565465 70.76721559
 77.89718592 76.05439804 88.19315109 78.93441505 74.13882635 92.48492303
 78.69303499 83.59098352 81.9909186  86.1711459  69.58365512 89.93131446
 87.76573715 95.5968042  86.06406003 83.23261558 85.37325607 79.18797422
 86.21685595 61.38362695 71.38769508 86.50621318 27.18054115 90.95997361
 82.37633245 68.77890861 77.50009565 77.49755598 50.37948032 79.30149088
 22.96014405 60.36304234]
Accuracy th:0.5 is [92.59024622 98.216396   95.1377298  98.95590941 99.49440187 98.65986038
 99.34211328 96.80559447 98.88890243 98.22248754 99.27997953 99.33358512
 99.61135951 96.63990448 98.15913549 98.65864207 97.63404442 98.99124036
 99.41033857 99.2190641  99.62232429 99.69176789 99.80385229 99.70882421
 95.75906726 98.24563541 95.31560288 98.33579026 98.72443075 99.12038109
 99.15693035 99.24464858 98.16522703 99.36526114 99.41033857 99.40424702
 99.16545851 99.2190641  99.68445804 94.66746263 98.43203665 94.57121624
 98.02390322 97.33312216 97.60480501 96.17329224 98.98514882 99.06555719
 98.77681802 99.15205711 99.32749357 99.18373314 99.37622592 99.23490211
 99.25439505 98.76219832 93.87678025 98.21274107 97.3940376  98.87550103
 95.4715464  99.372571   98.19202982 98.46371267 99.26901475 98.45883944
 99.17398667 96.77270014 99.05093749 98.84260669 99.82090861 98.54777598
 98.90839537 96.63503125 97.96786102 98.17984674 99.32018372 99.04850087
 99.84527479 99.32871188]
Accuracy th:0.7 is [91.35975439 98.06654402 94.58096271 98.90595875 99.49683849 98.54168443
 99.31531049 96.52903839 98.78900111 98.09822005 99.2190641  99.29703585
 99.58333841 96.35969347 98.05801586 98.54168443 97.41840377 98.91205029
 99.35307806 99.12403601 99.61257782 99.70029605 99.79897906 99.70151436
 95.57510264 98.06532571 95.05244819 98.19690306 98.62940266 99.0241347
 99.2056627  99.11916278 97.86552308 99.29216262 99.40302872 99.40424702
 99.09114168 99.15814866 99.67471157 94.31415309 98.29314945 94.22521655
 97.96298778 97.26246025 97.39769252 95.83825733 98.93276154 99.03144455
 98.72686736 99.08748675 99.31165556 99.07652197 99.32383865 99.24221196
 99.18860638 98.61112803 93.25422449 98.08238204 97.18692511 98.80362081
 94.94767364 99.36769776 98.11040314 98.39426908 99.24221196 98.37599444
 99.11307123 96.51198207 99.01560654 98.86697287 99.81725369 98.50269855
 98.87671934 96.37918641 97.85943154 98.02755814 99.28485277 98.98636713
 99.84405648 99.29703585]
Avg Prec: is [98.55289723 66.96553559 83.98792321 87.28958328 95.81009881 86.14314364
 94.2864882  74.68848589 82.93823419 81.33278684 76.21063926 77.09569704
 61.93480178 62.36544518 62.87540276 85.86156061 67.28346509 84.33683444
 83.24779134 80.39660773 93.73981927 85.12823161 97.26855193 97.32171168
 46.62697459 75.96892376 57.04968745 76.62989199 65.35182202 81.51799179
 92.57763663 80.48640502 80.98059596 90.72262011 92.90329733 93.69802956
 92.3250224  92.47268271 97.63376582 64.28384371 61.18120446 70.33088186
 73.94103585 69.44723596 59.61764215 73.63084266 77.6656105  66.15396896
 73.40420973 72.38742811 86.26157314 75.20114525 68.51752596 91.41781619
 73.27538842 80.94515587 78.16520645 83.19530335 64.1338575  87.81911504
 85.54258746 95.11347585 83.34550777 79.81432455 84.03652609 75.23838972
 83.50443139 55.34264879 66.28529026 84.47129137 23.9528896  89.97452477
 79.23768768 63.51761213 74.16859726 73.90528147 43.94960231 75.29716198
 19.35417308 55.90709394]
mAP score regular 79.72, mAP score EMA 76.59
starting validation
Accuracy th:0.5 is [90.79403045 97.85484715 93.75887585 98.7119117  99.38959065 98.31327703
 99.10556345 95.72215163 98.61972743 97.66549568 99.13296958 99.19027331
 99.46682612 95.83925057 97.99436929 98.28587089 97.0949498  98.75177517
 99.40952239 98.91870344 99.53409572 99.65617759 99.81314    99.78573386
 95.08931908 97.82245808 94.33440466 98.02426689 98.16378902 98.75177517
 99.13795251 99.00590478 97.44873807 99.33228692 99.15040985 99.37713332
 98.92617784 98.95358397 99.47430052 92.9018113  98.07658769 93.58696465
 97.50105887 96.80095672 96.99030819 94.71809054 98.86139971 98.93863517
 98.39798689 98.97600718 99.18778185 98.91870344 99.11802078 98.91870344
 99.02085358 98.13887436 91.35211899 97.77013728 96.68136632 98.21610982
 93.59194758 98.89378877 97.52099061 97.76017141 98.99843038 97.79256048
 98.84146797 95.7844383  98.80409597 98.4727309  99.81064853 97.80003488
 98.48518823 95.94389217 97.59324314 97.54590527 99.14542691 98.89628024
 99.82310586 99.05822558]
Accuracy th:0.7 is [90.62959364 97.92460822 93.59443905 98.69197997 99.41201385 98.29085383
 99.12051225 95.99621297 98.63965917 97.69788474 99.13795251 99.25754292
 99.50419812 95.92894337 97.97194608 98.22856716 97.24692927 98.73682637
 99.38709919 98.92119491 99.58392506 99.67112639 99.78822533 99.76081919
 95.49293669 97.81996661 94.60597454 98.02426689 98.23105862 98.85392531
 99.08563171 98.99344744 97.46617834 99.35720158 99.09310611 99.33976132
 98.93863517 98.86389117 99.47679199 93.58198171 98.15382316 93.66669158
 97.40389167 96.75611032 97.12235593 95.07686175 98.86638264 98.99095598
 98.33071729 98.98597304 99.15290131 98.85641677 99.09061464 98.92617784
 98.99344744 98.27341356 91.52652166 97.73027381 96.68634925 98.19119516
 93.30542891 99.03331091 97.67047861 97.99187782 98.98846451 97.88225328
 98.89378877 96.06099111 98.87634851 98.38303809 99.81563146 97.97692902
 98.50511996 96.02860204 97.54590527 97.71781648 99.27996612 98.82651917
 99.82559733 99.15290131]
Avg Prec: is [97.66837221 52.90475355 74.92356034 81.94166714 90.74154781 77.71071071
 90.92148129 59.9767866  76.78917656 70.88453142 66.59136263 70.28004309
 46.07428462 48.6661381  52.69277692 80.68860325 58.1800305  77.92610573
 79.49461198 69.69922706 91.25472169 85.78446814 96.91757455 97.65272031
 29.61719359 65.80775827 38.2171734  65.94701063 48.42839086 72.26720142
 87.90894435 63.19973714 67.74728154 88.17713588 84.06392389 89.3679273
 85.47088799 87.88588054 95.16958347 49.86910963 47.17619725 56.74605445
 54.72426353 46.3412353  37.73924102 56.89926007 63.53858279 45.92224901
 55.8195575  58.4682637  82.3366705  56.01695935 50.33976108 86.16384939
 54.65553111 61.11943217 61.04642919 70.7247229  47.1015818  76.05522453
 70.62546026 91.44710148 73.56709723 68.37078737 71.71885578 52.99435732
 73.05164171 38.23306236 50.09859174 70.88881786  8.06567125 80.96697416
 59.41721281 48.03542817 68.55710471 58.63049941 24.12438659 64.29293028
  2.67413569 29.63102675]
Accuracy th:0.5 is [91.11044672 97.92211675 93.93078705 98.7119117  99.40952239 98.28587089
 99.13296958 95.87662257 98.5997957  97.65802128 99.10805491 99.28494905
 99.47430052 95.9414007  97.96696315 98.32075143 97.2220146  98.76921544
 99.37464185 98.89129731 99.57645066 99.66116053 99.79320826 99.78822533
 95.32849989 97.84238981 94.4664524  98.04419862 98.21860129 98.7642325
 99.07815731 98.94361811 97.44375514 99.35471012 99.21767945 99.36716745
 98.97351571 98.90873757 99.45935172 93.64925131 98.13139996 93.70157212
 97.4014002  96.62157112 96.93549593 95.20890949 98.84645091 98.95607544
 98.30331116 98.97849864 99.22515385 98.92368637 99.10805491 98.92368637
 99.02832798 98.20614396 91.65358647 97.76266288 96.67140045 98.20863542
 93.71901238 99.10805491 97.70785061 98.00682662 99.00341331 97.83740688
 98.90624611 95.9638239  98.83648504 98.5175773  99.8056656  98.02177542
 98.4802053  95.9264519  97.60570048 97.69539328 99.28494905 98.91372051
 99.82559733 99.14293545]
Accuracy th:0.7 is [90.79403045 97.90716795 94.01300546 98.7492837  99.41699679 98.30331116
 99.11552931 96.0385679  98.66457383 97.69290181 99.13047811 99.31235518
 99.49672372 95.93641777 97.97443755 98.26095622 97.17467673 98.78914717
 99.36467598 98.88133144 99.60136532 99.66863493 99.80815706 99.78573386
 95.53778309 97.78010315 94.72058201 97.98938635 98.26095622 98.7791813
 99.06569998 98.96853278 97.35904527 99.32730398 99.19774771 99.37962479
 98.93863517 98.88133144 99.43941999 93.80123078 98.11894262 93.84109425
 97.49109301 96.87570073 97.12983033 95.24129855 98.89129731 98.99843038
 98.4054613  99.00092184 99.20023918 98.90126317 99.07815731 98.93614371
 99.02085358 98.23355009 91.74327927 97.79505195 96.70378952 98.27092209
 93.76635025 99.12300371 97.68044448 97.99436929 99.01088771 97.88225328
 98.91122904 96.11331191 98.85392531 98.4802053  99.81563146 98.04170715
 98.53003463 96.06846551 97.66300421 97.76266288 99.27498318 98.87385704
 99.82559733 99.18279891]
Avg Prec: is [97.84614866 53.35325382 76.54781745 83.17714178 90.65029524 78.23620156
 91.21293991 61.22089955 76.8316614  71.79905704 67.54862893 70.56423827
 45.52628541 49.86493139 52.78894174 81.44503925 58.77671631 79.16919404
 79.77585476 68.832757   92.01582466 85.62873397 96.74043154 97.71909755
 31.2988487  65.44340543 40.19884077 67.27726729 49.11869191 69.54092199
 87.84046372 62.79511579 67.49965796 87.50397004 84.7037984  90.02578246
 85.68818251 87.91580821 95.37928338 52.0980112  46.08169118 58.3257571
 54.78646356 48.66176274 39.3827711  59.16011192 65.0884225  47.51784658
 57.10444027 59.33103642 83.39690157 58.16991993 50.51181393 86.95640144
 56.2950896  61.50556761 63.43416761 71.42849571 48.4593589  77.3945688
 72.51843159 92.51949529 74.49801203 68.43272323 72.42244236 54.38839753
 74.18099989 39.52575767 49.08201843 74.30070097  8.62594856 82.20352467
 61.45695781 49.37935307 70.18889012 60.6148722  23.82668653 64.72052741
  3.36484087 32.24522771]
mAP score regular 64.87, mAP score EMA 65.66
Train_data_mAP: current_mAP = 79.72, highest_mAP = 79.72
Val_data_mAP: current_mAP = 65.66, highest_mAP = 65.66
lr:  [8.357518068382753e-05, 8.357518068382753e-05]
BCE Train Loss:  tensor([26.7582,  6.7545, 20.9073,  7.9690,  0.2821,  6.0798,  4.8243,  5.5057,
        14.4338, 10.4485,  0.6467,  1.7842,  0.4766, 15.7273,  2.1754, 12.3274,
         8.6923,  2.0031,  0.4673,  2.0043,  6.2145,  6.3154,  1.8837,  0.5341,
        14.5549,  4.0252, 13.3198,  4.4805,  9.8812,  3.9517,  1.7629,  0.2706,
         8.0956,  0.7013,  0.2769,  1.8883,  1.8979,  2.8615,  1.7116, 12.5671,
         7.0677, 16.9731,  5.3160,  4.5671,  4.3705, 15.2152,  5.6952,  7.2823,
         5.3272,  4.5467,  1.9117,  1.8724,  0.3338,  0.3042,  5.3429,  2.8992,
        25.1244,  4.7685,  9.9455,  2.7927, 22.7919,  1.6438,  6.0296,  4.2054,
         3.2030,  3.0848,  2.5845, 13.6402,  5.0099,  2.1552,  5.1308, 14.6107,
         2.8985,  9.1739, 15.0244,  4.5238,  2.7793,  2.4824,  0.0879,  1.3718],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [33/80], Step [000/642], LR 8.4e-05, Loss: 501.6
BCE Train Loss:  tensor([22.2972,  1.5938, 10.7855,  3.1736,  0.8014,  3.3616,  3.5670,  9.5265,
         0.7423,  5.0200,  3.8799,  5.1834,  0.5443,  6.9221,  4.7626,  7.4795,
        10.6130,  5.7076,  1.1595,  1.2482,  0.4472,  0.2001,  0.0744,  0.1062,
        10.4462,  2.1450,  9.8144,  1.1118,  5.2558,  2.9385,  0.5565,  2.3626,
        12.3088,  1.6535,  1.6460,  7.7502,  4.4261,  1.1864,  1.3702, 12.0300,
         4.5331, 13.5847,  5.0074,  4.4486,  2.5879, 12.0224,  4.7417,  6.7554,
         2.7455,  4.3154,  1.5180,  1.0979,  2.6856,  4.8301,  5.7311,  5.0849,
        17.5708,  6.8801, 13.3127,  2.9121, 10.5749,  1.8782,  3.8880,  4.5834,
         0.3591,  9.6345,  0.7553, 10.4859,  3.9160,  0.9253,  0.0492,  1.9468,
         2.4832, 15.1497, 14.3603, 11.8624,  0.5972, 15.3777,  0.1391,  1.1692],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [33/80], Step [100/642], LR 8.3e-05, Loss: 418.7
BCE Train Loss:  tensor([20.5404,  9.2393, 16.2257,  1.2473,  3.1558,  3.6878,  3.2017, 10.7591,
        11.1004, 10.7390,  4.9790,  1.6521,  1.5330,  7.0082,  7.1070,  7.3277,
        10.3640,  1.6911,  0.4035,  5.4070,  5.3136,  1.6457,  0.2998,  2.7392,
        12.0437,  6.2609, 23.0592,  1.5953,  1.2587,  4.9682,  3.1133,  4.7747,
         5.0722,  3.6490,  1.3255,  0.5733,  3.2010,  0.9967,  1.5245,  9.8158,
         6.6439, 12.0819,  3.3115,  8.6038,  6.1361, 18.7811,  2.9506,  1.8552,
         2.3609,  3.4049,  2.5593,  2.4466,  0.8765,  1.5501,  0.6099,  1.8092,
        15.0188,  6.1974,  3.3456,  2.1431, 12.8597,  1.5617,  8.0812,  2.4344,
         2.0694,  7.3025,  2.2003,  7.4720,  3.1470,  7.5070,  0.2249, 13.7837,
         5.4090, 11.9987,  2.1403,  7.2728,  0.4528,  1.0938,  0.2097,  1.9076],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [33/80], Step [200/642], LR 8.3e-05, Loss: 432.4
BCE Train Loss:  tensor([26.1540, 11.3277, 16.8526,  6.3210,  0.4406,  6.7663,  6.3282,  8.1296,
         4.2535,  2.7338,  9.7570,  2.4971,  0.5592, 13.2922,  5.0169, 10.4098,
         4.3206,  0.4524,  0.8301,  7.3938,  0.4482,  0.5948,  0.1268,  0.7640,
        12.3144,  5.9487, 12.5810,  3.9348,  1.2815, 10.2857,  2.4353,  2.4877,
         5.1727,  0.5581,  2.0928,  0.6175,  2.9688,  0.9554,  0.8918, 18.3231,
         2.7891, 14.8754,  4.9777,  9.4393, 10.3901, 12.9415,  8.2170,  4.5002,
         1.8569,  3.1513,  4.9847,  7.1641,  0.6789,  6.9909,  0.4744,  3.2616,
        28.8703,  6.7349, 13.0862,  1.2931, 13.3463,  6.5871,  3.0974,  4.8330,
         1.9169,  6.1255,  9.1239,  7.1275,  1.4258,  4.1485,  0.2799,  8.7523,
         7.4824, 13.2445,  8.6781,  7.4567,  4.5589,  3.3828,  6.5687,  1.7729],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [33/80], Step [300/642], LR 8.3e-05, Loss: 495.2
BCE Train Loss:  tensor([17.0863, 15.9650, 14.6760, 10.5713,  0.5435,  1.7843,  1.1878, 13.4267,
         1.3046,  1.4768,  0.9855,  9.4031,  1.0016,  8.4302,  1.3986,  9.4099,
        10.6621,  3.8866,  4.6221,  2.6023,  3.0492,  0.2337,  0.3625,  0.1055,
        15.3597, 14.8156, 18.8973,  2.3191,  1.7364,  3.3193,  1.8539,  5.9738,
        13.9474,  1.0959,  0.4455,  0.4267,  8.0601,  0.7197,  6.5323, 17.0806,
         0.7886, 17.2496,  4.9777,  3.0105,  6.1447, 11.1863,  2.5189,  2.6049,
         5.7671,  4.0913,  0.7426,  2.3573,  1.6519,  2.5552,  3.9432,  1.3597,
        16.9786,  5.9482,  4.9130,  2.1252, 14.7970,  4.1374,  4.8507,  5.7040,
         0.6274,  3.7086,  4.3557, 11.0809,  3.0670,  4.0479,  0.2682,  4.1896,
         6.5786,  6.5091, 11.0305,  2.4601,  0.7976,  2.4367,  4.5900,  1.7528],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [33/80], Step [400/642], LR 8.2e-05, Loss: 444.7
BCE Train Loss:  tensor([19.9447,  9.9615,  7.2201,  7.3658,  0.5141,  8.3312,  4.2742, 10.5184,
         0.9709, 12.4669,  2.1376,  7.7298,  2.2052, 18.8076, 13.2214,  5.0588,
        10.9474, 12.4945, 11.1922,  1.0567,  0.5432,  0.4982,  0.1121,  0.8014,
        28.1932,  9.9092, 16.8932,  7.9556,  7.8892,  0.2791,  6.7777,  1.5000,
         3.2089,  4.0507,  1.2628,  4.2602,  1.1129,  3.3464, 12.7850, 24.0521,
         5.8429, 18.3513,  6.6602,  5.6708,  8.9424, 11.7815,  2.8172,  0.6739,
         5.1232,  3.4030,  3.5410,  4.6158,  6.1176,  4.9632,  6.4308,  9.2086,
        19.4672, 12.4338, 14.1106,  2.1835, 13.5821,  0.8389,  6.5499,  2.2089,
         3.2159,  6.4429,  3.3379,  8.1774,  0.8704,  1.5788,  0.0937,  3.0954,
         1.5306, 16.4625,  4.9099,  7.1595,  3.8659,  8.8654,  0.3152,  1.0734],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [33/80], Step [500/642], LR 8.2e-05, Loss: 548.4
BCE Train Loss:  tensor([25.6995,  6.6881, 15.3555,  1.4156,  1.0751, 11.7995,  7.2124, 15.6565,
         5.4021,  5.6258,  1.7327,  3.0318,  0.5563, 13.7765,  9.0706,  6.3020,
         9.0826,  3.8491,  4.5107,  5.1895,  1.9716,  0.2265,  0.0763,  0.1640,
        20.3269,  4.3651, 13.1737,  7.8158,  2.7212,  1.7735,  1.8889,  3.2807,
        10.6363,  8.4441,  2.2865,  0.9615,  4.4061,  4.2511, 11.1647, 15.1761,
         5.4062, 18.4337,  3.8993,  5.6607,  7.7239, 16.0343,  8.2558,  9.8894,
         1.2554,  0.7829,  2.3181,  1.6268,  0.7875,  0.7306,  5.4099,  2.1449,
        21.9519,  7.1488,  9.5167,  7.1278,  9.3786,  0.3530,  5.5304,  3.9402,
         3.2282,  2.8560,  4.0623,  6.5226,  4.1137,  3.9677,  0.2949,  1.4887,
         1.4637, 21.0915,  4.4205,  7.8151,  1.3192,  3.0039,  4.8299,  0.5577],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [33/80], Step [600/642], LR 8.2e-05, Loss: 494.5
BCE Val Loss:  tensor([5.7715e+01, 1.9265e+01, 5.7677e+01, 2.1640e+01, 3.1130e-01, 1.0311e+01,
        4.0702e+00, 2.3400e+01, 7.0653e+00, 6.9788e+00, 8.5050e+00, 1.2632e+01,
        8.0602e+00, 1.7705e+01, 7.6171e+00, 2.1970e+01, 2.1084e+02, 5.0800e+00,
        2.3062e+00, 3.4780e+00, 2.3689e-01, 5.6078e-01, 4.0568e-02, 6.2204e-02,
        2.5979e+01, 1.4723e+01, 2.9906e+01, 1.6426e+00, 1.3448e+01, 1.9492e+01,
        5.5599e-01, 4.2530e+00, 8.2541e+00, 6.5187e-01, 3.0757e-01, 1.9311e-01,
        1.2045e+01, 5.0390e+00, 4.8903e+00, 4.1116e+01, 1.1326e+01, 2.6970e+01,
        7.8865e+00, 2.0787e+01, 1.6208e+01, 1.6691e+01, 4.0161e-01, 5.1830e+00,
        1.1342e-01, 3.8743e+00, 1.8893e-02, 8.1085e-02, 1.6830e+00, 1.1343e-01,
        1.8335e-01, 2.2269e-01, 2.4377e+01, 9.2188e+00, 9.0012e+00, 3.7781e+00,
        1.0785e+01, 7.5729e+00, 2.9060e+00, 7.6301e+00, 1.5180e-01, 6.6272e-01,
        4.7533e-02, 6.8989e+00, 8.3678e+00, 1.7569e+01, 3.1498e-01, 1.8535e+01,
        1.2079e+01, 9.6562e+00, 1.8929e+01, 7.9934e+00, 1.8950e-01, 9.1206e+00,
        8.9098e-02, 6.7483e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [33/80], Step [000/314], LR 8.2e-05, Loss: 988.3
BCE Val Loss:  tensor([5.4772e+01, 1.9205e+01, 4.5634e+01, 1.0108e+01, 6.1079e+00, 3.9974e+01,
        2.4111e+01, 3.2003e+01, 1.9872e+01, 2.8575e+01, 1.7055e+01, 4.0689e+01,
        1.2584e+01, 6.8328e+00, 1.9511e+01, 3.1052e+00, 7.3297e+00, 1.6427e+01,
        5.9431e+00, 1.2704e+01, 1.9073e-01, 9.6067e-02, 1.1420e-01, 6.2166e-02,
        3.4335e+01, 2.3070e+01, 3.7551e+01, 1.5736e+01, 1.6604e+01, 2.9389e-01,
        1.2041e-01, 3.1351e-01, 1.2698e+00, 1.0125e+00, 4.4013e-01, 1.4334e-01,
        4.0886e+00, 1.8152e+00, 3.6354e-01, 6.4287e-01, 5.3545e-02, 4.6643e+00,
        3.0160e-02, 4.3867e-01, 2.1741e-01, 1.2486e+00, 1.1720e-01, 3.4927e-02,
        4.7869e-02, 9.5311e+00, 1.2368e-02, 4.7372e-02, 3.5213e-02, 5.4671e-02,
        9.9603e-02, 1.9842e+00, 1.3415e+01, 1.0037e+01, 3.5405e+00, 6.5900e-02,
        1.7789e+00, 7.6517e-02, 1.5063e+00, 7.2144e-02, 3.0290e-02, 6.5399e-02,
        9.0327e-03, 2.2447e+01, 7.5880e-02, 4.7337e+00, 1.4186e-02, 1.0943e-01,
        3.7723e+00, 2.9158e+00, 3.7925e+00, 1.2111e-01, 2.0803e-01, 4.6736e-01,
        2.2451e-03, 5.8980e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [33/80], Step [100/314], LR 8.2e-05, Loss: 648.7
BCE Val Loss:  tensor([1.2763e+01, 1.6435e-01, 4.7821e+00, 1.0051e-01, 8.2355e-02, 3.0151e-02,
        1.0247e-01, 1.7796e+01, 1.3593e-01, 1.7872e-02, 1.8571e-02, 2.5292e-02,
        8.3296e-03, 1.1943e+01, 2.6112e-01, 4.6094e-01, 1.2217e+00, 4.7327e-02,
        2.7375e-02, 1.3681e-02, 2.1873e-02, 1.2396e-02, 5.6023e-03, 8.0363e-03,
        3.8091e+00, 5.2666e-01, 2.9360e+01, 8.8472e+00, 3.5588e-01, 8.9015e-02,
        2.6090e-01, 6.0955e+00, 1.1362e+01, 8.7809e-02, 5.0308e-01, 2.4474e-01,
        1.1511e+01, 8.2512e+00, 2.9456e-02, 3.4128e+01, 1.5982e+01, 7.3752e+01,
        7.7853e+01, 6.8124e+01, 4.8547e+01, 6.0793e+01, 9.5360e+00, 8.7744e+00,
        4.1162e+01, 1.0435e+01, 2.7399e+01, 4.1363e+01, 5.8058e+01, 1.3358e+01,
        4.2089e+01, 7.8631e+01, 1.2457e+02, 1.4707e+01, 6.3956e+00, 3.6493e-01,
        9.2679e+01, 1.0539e-01, 1.7289e+01, 9.6491e+00, 1.4682e+01, 5.6488e+00,
        1.1234e+01, 1.5474e+01, 7.4408e+00, 2.9805e+00, 2.9355e-01, 1.5624e+01,
        6.4197e+00, 4.2148e+01, 2.3779e+00, 1.5805e+01, 9.7033e+00, 1.3227e+00,
        3.4109e-02, 5.6079e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [33/80], Step [200/314], LR 8.2e-05, Loss: 1258.9
BCE Val Loss:  tensor([3.1906e+01, 4.3530e-01, 1.1971e+01, 1.5107e+00, 8.1634e-01, 7.9257e+00,
        9.4235e+00, 1.4814e+01, 1.9800e+00, 2.0833e+01, 5.5081e+00, 7.3484e+00,
        4.5436e-01, 1.1215e+01, 1.8501e+01, 2.5441e-01, 3.0846e+00, 4.1419e-01,
        5.9427e-02, 4.9768e-02, 1.0917e+00, 3.6553e-02, 2.8017e-02, 1.2628e-01,
        2.3155e+01, 3.4403e+00, 2.6455e+01, 1.0074e+00, 1.6425e+01, 9.0552e-02,
        9.1543e-02, 6.8943e-02, 4.1907e-02, 3.1251e-01, 3.3275e-02, 2.0195e-02,
        2.3942e-01, 6.1804e-02, 1.4297e-02, 1.4014e+00, 1.0424e+00, 4.4984e-01,
        1.3600e-02, 6.9940e-02, 7.5800e-02, 3.8708e-01, 6.7293e-02, 1.9067e-02,
        1.6267e-02, 2.1470e-02, 5.5159e-03, 1.4378e-02, 2.3845e-02, 7.2993e-02,
        5.9542e-02, 5.9350e-02, 5.9101e+00, 3.5434e+00, 1.2037e+01, 1.8042e-01,
        9.0632e+00, 4.5216e-02, 1.3883e+00, 4.9724e-01, 2.5400e-02, 9.1042e-01,
        1.6809e-01, 7.0278e+00, 6.4515e-02, 4.2879e-02, 7.5530e-03, 2.5981e-01,
        1.0920e-01, 6.7131e+00, 5.7450e+01, 1.8747e+00, 3.2903e-02, 5.8530e+00,
        1.0299e-02, 2.6080e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [33/80], Step [300/314], LR 8.2e-05, Loss: 338.3
starting validation
Accuracy th:0.5 is [93.23716816 98.28340298 94.86970188 99.02291639 99.5406976  98.7597617
 99.43470474 97.16012232 99.03509947 98.44056481 99.28485277 99.37622592
 99.67592987 96.88478454 98.3004593  98.8852475  97.90572727 99.04728256
 99.48100048 99.30556402 99.64059892 99.72588053 99.818472   99.76852134
 95.90039108 98.41376202 95.5275886  98.43812819 98.83773346 99.22515564
 99.25317674 99.29581755 98.3833043  99.44566952 99.52242297 99.52485959
 99.25195843 99.29703585 99.69542281 95.08777914 98.58188862 94.69670204
 97.91791036 97.28804474 97.77658654 96.57167919 99.14840219 99.09966984
 98.87550103 99.25561336 99.39084563 99.24464858 99.44810614 99.19957116
 99.38231747 98.86575456 94.55050499 98.23223401 97.64013596 98.86819118
 95.83703902 99.27632461 98.36259305 98.61478296 99.33236681 98.56361399
 99.1496205  96.97493939 99.17642329 99.00098683 99.82578185 98.63305759
 99.07043043 97.02610836 98.06898064 98.29924099 99.32262034 99.19591623
 99.84892972 99.37988085]
Accuracy th:0.7 is [91.95550736 98.133551   93.81951974 98.90230382 99.56506378 98.5648323
 99.42252166 96.7946297  98.88646581 98.13476931 99.25317674 99.34698651
 99.64912708 96.56071442 98.21030446 98.68909979 97.74003728 98.90595875
 99.48587371 99.23612042 99.60161304 99.68323973 99.81725369 99.75755656
 95.58484911 98.15913549 95.07559606 98.41985356 98.74879692 99.06068396
 99.03388117 99.1922613  98.13111439 99.3871907  99.43470474 99.43470474
 99.26779644 99.18495145 99.63572569 94.52735712 98.39183246 93.88774503
 97.53779803 96.878693   97.4915023  96.28659495 99.06190227 98.98027558
 98.79021942 99.1642402  99.29459924 99.18738807 99.44688783 99.07408535
 99.31287387 98.78412787 93.80611835 98.34066349 97.43911502 98.7743814
 95.1791523  99.10576138 98.40767047 98.36015643 99.29216262 98.579452
 99.03266286 96.65817912 99.11428954 98.88646581 99.82090861 98.58798017
 98.95712772 96.69472838 97.89963573 98.14817071 99.29094431 99.12403601
 99.8464931  99.372571  ]
Avg Prec: is [98.79361707 71.68774077 86.67158974 89.46730763 96.60171028 88.21936195
 95.53141431 78.73291423 86.19652241 85.32970881 78.94926813 80.63313943
 72.25850605 69.32622096 67.98017907 89.31829737 73.6835152  87.22787684
 87.06184732 84.33314115 94.65203981 87.35384438 97.74764632 98.14485003
 53.06366792 81.00724871 62.26035554 81.28738881 72.22042246 86.58760181
 93.7986019  81.64490957 85.14726463 92.08345979 94.85624768 95.46599558
 94.1905063  94.33737174 97.89906066 69.86286425 69.7200731  74.49827857
 80.15398511 73.27827124 66.18169681 78.30691707 81.80229372 72.12320755
 77.08760962 78.87873131 88.47942549 78.61097978 75.13275469 92.75919776
 79.40882981 84.1599971  82.2130171  85.54305585 70.17547063 89.04247878
 87.81004741 95.34434464 86.55657239 84.35616088 86.33862187 79.06148064
 85.83551127 63.54725306 73.28133781 87.71036352 30.14965118 90.94807168
 83.08635576 69.79895095 78.45564345 77.73550726 50.78210722 79.67784766
 25.48983367 62.73074595]
Accuracy th:0.5 is [92.8521826  98.26391004 95.21204664 98.96687419 99.53460606 98.72808567
 99.41764842 96.96031968 98.90839537 98.29802268 99.24464858 99.3591696
 99.63207076 96.72762271 98.21883262 98.78534618 97.73394574 99.06555719
 99.45297937 99.21540917 99.60039473 99.66374679 99.81481707 99.73928193
 95.86262351 98.29924099 95.34484229 98.36746628 98.73417722 99.16180358
 99.22393733 99.28363446 98.22492416 99.37135269 99.48343709 99.4286132
 99.21540917 99.22271902 99.66740171 94.77711042 98.4953887  94.76249071
 98.13720593 97.35627003 97.65597398 96.3353273  99.0947966  99.12647263
 98.78169126 99.22515564 99.35064144 99.21053593 99.39815548 99.29581755
 99.32871188 98.75610677 94.11800538 98.23588894 97.41231223 98.86575456
 95.57388433 99.34333159 98.29680438 98.53559289 99.28241615 98.53559289
 99.19469792 96.90184086 99.08992337 98.90839537 99.82456354 98.51244502
 98.97052911 96.76295367 97.98248072 98.21395938 99.31531049 99.10576138
 99.8464931  99.34942313]
Accuracy th:0.7 is [91.64362033 98.11527637 94.68086402 98.95834602 99.52120466 98.59650833
 99.34089497 96.60822846 98.83773346 98.21030446 99.20809932 99.31896541
 99.60648628 96.47055957 98.10187498 98.64402237 97.55972759 98.97662066
 99.40302872 99.15936697 99.60161304 99.68202142 99.82334523 99.73440869
 95.62261668 98.1469524  95.12798333 98.21883262 98.66595193 99.04484594
 99.22271902 99.11672616 97.93496668 99.31652879 99.44079629 99.40424702
 99.14474726 99.18251483 99.65521863 94.38725162 98.37233952 94.41649103
 98.12989608 97.31484753 97.48662906 95.99054592 98.99855021 99.06921212
 98.73295891 99.16545851 99.32018372 99.09235999 99.35673298 99.26048659
 99.25804998 98.63793082 93.3675272  98.11649468 97.23687577 98.76098001
 95.13894811 99.33236681 98.16400872 98.41863525 99.25439505 98.42229018
 99.12038109 96.5997003  99.04971918 98.90474044 99.81725369 98.48807885
 98.8852475  96.41329906 97.88014279 98.09456512 99.28241615 99.0387544
 99.84527479 99.30800063]
Avg Prec: is [98.6360302  68.37158858 84.6970051  88.0110983  96.15194335 86.85204865
 94.76501886 76.12668856 83.91227477 83.06369074 76.38922824 78.56432111
 66.62125384 64.29078997 63.75867131 87.43445235 69.41495684 85.42386772
 84.78402924 81.65715637 93.75838189 85.05066214 97.42649711 97.75658827
 49.07926087 77.5932167  58.26112949 77.9641368  66.45390649 82.92080742
 92.79650131 80.6676026  82.08646353 90.93574787 93.88268992 94.31880808
 93.28341582 93.03103304 97.56612685 65.72709676 64.00118084 71.42719336
 76.69872126 69.8802155  62.28903781 75.3606929  79.32909129 68.40654122
 73.6285789  75.38467431 86.95102304 75.82832333 70.06874797 91.84842366
 76.44008056 81.41253377 79.13671681 83.7736697  65.87151226 87.83689596
 86.21388431 95.060702   84.78630316 81.33328772 84.19922432 76.9914347
 83.6811719  57.66929807 69.1402946  85.77473422 27.38052432 89.80644248
 80.33241376 64.91213326 75.23624354 74.88957552 44.07024538 76.18763413
 20.11894833 57.70700145]
mAP score regular 80.47, mAP score EMA 77.76
starting validation
Accuracy th:0.5 is [90.76164138 97.98440342 93.73645265 98.7044373  99.40204799 98.32822583
 99.10307198 95.92146897 98.57238957 97.69041034 99.07566584 99.26501732
 99.48426639 95.8591823  97.96198022 98.36310636 97.1622194  98.74430077
 99.37464185 98.88880584 99.54655306 99.67860079 99.80068266 99.79569973
 95.47051349 97.79754341 94.60348307 97.93955702 98.23604156 98.82651917
 99.07317438 98.95109251 97.48611007 99.36965892 99.20273065 99.36218452
 98.91870344 98.93365224 99.45436879 93.68662332 98.17375489 93.81119665
 97.53593941 96.81839699 97.07501806 95.09181055 98.81904477 98.96604131
 98.35563196 98.99593891 99.24010265 98.93116077 99.06071704 98.79911304
 98.97600718 98.19866956 91.46672646 97.46866981 96.61658819 98.21610982
 93.42501931 99.01587064 97.46368687 98.01679249 98.98099011 97.69041034
 98.88880584 96.06597404 98.83150211 98.5175773  99.81314    97.96198022
 98.5101029  95.9488751  97.60819194 97.60819194 99.28744052 98.83150211
 99.82559733 99.10556345]
Accuracy th:0.7 is [90.48010564 97.92959115 93.31041184 98.72436904 99.42447119 98.30081969
 99.11802078 95.92146897 98.58733837 97.66300421 99.13296958 99.29989785
 99.50918105 95.8890799  97.99436929 98.30081969 97.22699753 98.69945437
 99.39955652 98.90624611 99.57645066 99.65119466 99.8056656  99.78822533
 95.49791963 97.71781648 94.6308892  98.06163889 98.27092209 98.76174104
 98.92617784 98.99843038 97.42133194 99.36716745 99.15040985 99.31484665
 98.92617784 98.84146797 99.41201385 93.67167451 98.15880609 93.49727184
 97.38894287 96.72372125 97.1472706  95.20890949 98.84645091 98.94860104
 98.38552956 98.98099011 99.14791838 98.93614371 99.12051225 98.7044373
 99.02583651 98.25099036 91.5987742  97.74522261 96.75611032 98.23604156
 93.31290331 98.88880584 97.68044448 97.92460822 98.94610957 97.87727035
 98.78914717 96.11829484 98.87634851 98.46027356 99.81563146 97.95948875
 98.49764556 96.03607644 97.58327728 97.69539328 99.27498318 98.86389117
 99.82559733 99.20522211]
Avg Prec: is [97.67539537 53.65424993 75.15505748 82.68930846 90.68177804 78.13726342
 91.21930065 59.45347397 75.48729589 70.88631747 65.74888978 70.75053706
 47.02208383 48.13665159 53.11819148 80.97233076 57.48274742 78.19388233
 79.77703357 69.05635345 91.882822   86.72329127 96.6770825  97.79574444
 29.48854657 64.74969116 38.55599668 65.80541528 49.00248268 71.06744708
 88.17318526 63.45172362 68.0192514  87.97937685 84.13852341 89.60957821
 85.44970784 87.40016404 94.86051443 50.32216643 46.77326927 56.41535503
 56.04863547 47.20980313 38.6976139  57.96483174 64.79701226 44.04820422
 56.74352477 58.46783425 82.6785124  58.20151996 51.21341471 85.31523626
 57.22078594 61.43632533 61.06505892 70.63708467 47.63838371 75.7596373
 69.85467545 91.72637863 73.56374477 67.02857971 70.80949657 53.47748064
 72.69267974 37.80286982 49.50710201 73.80231461  8.28096731 80.84023044
 60.49659186 47.79835833 69.33087204 57.81934672 23.69090226 62.99570163
  2.91090716 33.39884051]
Accuracy th:0.5 is [91.19017366 97.92211675 93.94822732 98.7119117  99.41450532 98.30829409
 99.14791838 95.89157137 98.60228717 97.67546154 99.10556345 99.28245758
 99.48177492 95.93641777 98.00433515 98.33071729 97.21204873 98.78167277
 99.40703092 98.90375464 99.57645066 99.66116053 99.80068266 99.79320826
 95.31105962 97.84737275 94.46396093 98.05914742 98.23105862 98.78416424
 99.08563171 98.95109251 97.47365274 99.35720158 99.22017091 99.35969305
 98.96354984 98.92617784 99.47180905 93.62931958 98.14634876 93.71652092
 97.38146847 96.63402845 96.95044473 95.20392655 98.86139971 98.96604131
 98.28587089 98.96354984 99.23262825 98.92119491 99.13047811 98.93365224
 99.04078531 98.21610982 91.60874007 97.78259461 96.67389192 98.22607569
 93.72399532 99.14044398 97.70037621 98.01430102 99.01587064 97.83740688
 98.91870344 95.91399457 98.83897651 98.50761143 99.8056656  97.99935222
 98.45279916 95.9563495  97.61815781 97.68293594 99.28494905 98.92119491
 99.82310586 99.13795251]
Accuracy th:0.7 is [90.88372325 97.92211675 94.05286892 98.75924957 99.43194559 98.32075143
 99.13047811 96.06099111 98.6521165  97.69041034 99.12549518 99.31982958
 99.49423225 95.9488751  97.99436929 98.28836236 97.23945487 98.80658744
 99.38211625 98.90126317 99.60136532 99.67361786 99.80815706 99.78573386
 95.53778309 97.79505195 94.68819294 98.01180955 98.26593916 98.8090789
 99.08064878 98.97102424 97.3864514  99.33976132 99.20522211 99.38709919
 98.94860104 98.88631437 99.44191145 93.82116252 98.13638289 93.85106012
 97.51351621 96.85576899 97.14976206 95.25624735 98.88631437 99.01587064
 98.39549543 98.99095598 99.20023918 98.90375464 99.09559758 98.94860104
 99.03331091 98.24351596 91.76071954 97.80252635 96.73368712 98.25846476
 93.75887585 99.12798665 97.72778235 98.00931809 99.01337918 97.87976182
 98.90873757 96.11829484 98.86139971 98.49764556 99.81563146 98.05416449
 98.54249197 96.06348257 97.67795301 97.75020555 99.27747465 98.88382291
 99.82559733 99.17034158]
Avg Prec: is [97.85753621 53.62484755 76.64246757 83.27659176 90.80929816 78.47360628
 91.33759036 61.33558892 76.97334746 71.91232707 67.68831992 70.78883219
 45.89150384 50.0501731  53.16513719 81.62235668 59.30500017 79.07951099
 80.12230681 69.51870644 92.34848424 86.2143797  96.80103439 97.71425313
 31.24313737 65.87888069 40.19818108 67.53578402 49.55830638 70.57637197
 88.02896366 63.18816247 67.83796177 87.83116703 84.90996427 90.1174671
 85.81066598 88.00578239 95.44567451 52.25024061 46.69284142 58.42468686
 55.18429864 48.73128517 39.51471062 59.21773773 65.3302716  47.51737326
 57.21488806 59.56348369 83.57602346 58.39599308 51.03767341 87.12458047
 56.83352721 61.93853202 63.49903126 71.66936209 48.76321534 77.60106992
 72.45527302 92.55381934 74.69357676 68.88802045 72.55746562 54.71060545
 74.31301271 39.68942854 49.41310737 74.39606804  8.68389205 82.23104928
 61.75494514 49.56428679 70.43447861 60.70676718 24.2944848  65.12969217
  3.35219993 32.56920057]
mAP score regular 65.03, mAP score EMA 65.89
Train_data_mAP: current_mAP = 80.47, highest_mAP = 80.47
Val_data_mAP: current_mAP = 65.89, highest_mAP = 65.89
lr:  [8.171678202574147e-05, 8.171678202574147e-05]
BCE Train Loss:  tensor([18.8462,  7.1793, 14.8555,  8.7685,  6.5070,  7.3013,  4.0451,  8.5440,
         0.8956,  4.1585,  1.0813,  3.3199,  0.4795, 11.0477,  4.2798,  8.5096,
        10.0235,  1.3323,  5.7791,  2.4345,  1.1828,  1.4033,  0.5536,  0.4908,
         7.1461, 18.6619, 18.7928,  3.3982,  7.8475,  1.9601,  8.2987,  6.8189,
         5.1048,  2.2845,  1.0520,  0.6237,  6.7020,  7.6797,  1.1450, 14.2901,
         3.0570, 17.3731,  2.1211,  4.9810,  4.6152, 12.0575,  1.6302,  0.7817,
         6.6164,  1.0689,  3.7525,  2.4457,  0.9964,  6.1974,  5.2412,  8.4084,
        19.0156,  8.1053,  5.1443,  1.2964, 12.0679,  7.0675,  4.4783,  5.8729,
         2.4266,  1.7662,  1.2785,  7.5434,  1.2236,  0.8525,  0.3299,  5.4853,
         6.1298,  7.1086,  8.0397,  7.6330,  0.3195, 11.0647,  0.2160,  9.0602],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [34/80], Step [000/642], LR 8.2e-05, Loss: 459.7
BCE Train Loss:  tensor([28.3014,  2.7487, 14.7038,  3.7225,  0.2781,  7.6261,  1.5688,  9.3283,
         9.9108,  5.9343,  3.6793,  0.5467,  0.3769,  7.5979,  3.8297,  8.6616,
        12.7359,  2.0592,  0.4595,  1.3921,  0.5767,  0.1002,  0.7398,  1.1715,
         7.1951,  1.4574, 12.9936,  3.0885,  2.9595,  0.7471,  0.4981,  3.7482,
         3.3541,  0.2448,  0.3029,  0.6753,  0.6114,  4.1009,  8.0946, 20.0479,
         1.6380, 19.8877,  5.9543,  9.6381, 18.9005,  8.5802,  0.9915,  0.4293,
         2.6580,  0.6329,  1.6896,  7.1230,  2.1312,  0.6770,  0.4951,  4.7973,
        13.2561,  3.7220, 12.6935,  3.3427, 13.4012,  0.6005, 14.0716,  3.7386,
         0.3187,  5.5430,  0.7537, 16.6592,  1.4863,  3.1720,  4.7316,  2.8946,
         2.1519,  6.8680,  8.6452,  7.5772,  0.6387,  4.9018,  1.8054,  0.7298],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [34/80], Step [100/642], LR 8.1e-05, Loss: 418.1
BCE Train Loss:  tensor([28.4831, 12.4904, 15.5850,  1.6231,  0.4612,  7.8338,  2.1582, 10.8959,
         0.9635,  4.5216,  0.9449,  0.3649,  0.2583, 17.9797, 10.2190,  3.7792,
         6.8231,  4.8579,  0.3921,  4.0252,  1.0553,  0.8531,  0.1546,  0.4142,
         7.4036, 16.9373, 17.6559,  3.2574,  3.0821,  3.9757,  0.1349,  0.6464,
         7.5783,  0.3398,  3.7553,  4.3633,  3.1798,  1.4477,  0.3527, 20.4303,
         4.7729, 13.3843,  3.1136, 12.8327, 10.1564, 12.3599,  1.0196, 13.7221,
         6.6502,  2.6285,  1.8930,  5.1285,  2.4163,  1.5237,  3.4719,  5.1581,
        23.0865,  4.0622,  3.1744,  3.1044, 23.2911,  2.1725,  3.8755,  2.7278,
         4.3796,  5.2859,  1.4764,  3.4664, 13.2649,  1.5656,  3.6267,  6.2914,
         4.3349, 12.7646,  7.6553,  6.0157,  0.8899,  6.6566,  0.0819,  0.5311],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [34/80], Step [200/642], LR 8.1e-05, Loss: 475.7
BCE Train Loss:  tensor([17.8938,  4.4294,  7.7877,  6.2362,  1.5413,  2.0374,  5.4021,  5.8844,
         1.5831,  3.1395,  4.5836,  0.9804,  0.2902, 10.2592,  7.4621,  1.0126,
         7.8882,  1.6180,  6.2051,  3.7799,  6.8389,  0.4279,  0.1586,  2.8355,
        14.2850, 12.4309, 12.5860,  4.5562,  1.4798,  0.3687,  5.0053,  3.6213,
         3.2009,  1.4544,  0.4660,  0.1640,  4.0862,  2.0804,  0.5820, 15.7480,
         4.4482, 10.4607,  6.3903,  4.9289,  8.0297,  7.7030,  0.5863,  0.5703,
         8.7603,  0.6299,  0.6290,  0.9398,  0.4251,  0.3381,  0.5735,  3.8082,
        14.7291,  4.0028,  5.0178,  3.3232,  8.9193,  3.0983, 14.4513,  3.3135,
         2.7361,  3.9377,  1.0026, 11.4257,  2.2874,  3.4532,  0.1470,  6.3131,
         3.7863,  6.8975, 11.4205, 11.0980,  0.5476,  3.2837,  0.0847,  5.1309],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [34/80], Step [300/642], LR 8.1e-05, Loss: 382.0
BCE Train Loss:  tensor([15.9597, 11.1579, 15.0750,  7.2698,  0.6604,  1.7331,  1.6627,  6.6258,
         3.7418,  4.5027,  3.2012,  6.6447,  0.3233, 17.7478, 10.2151,  2.8695,
         9.1723,  0.7481,  1.8896,  2.5542, 12.3928,  1.7946,  0.1418,  0.0985,
        20.4374,  8.4159, 22.3150,  3.6978,  1.3663,  0.5266,  0.8051,  1.6154,
         3.5213,  0.2104,  3.9625,  1.0134,  0.6257,  1.7950,  1.5548, 19.0000,
         2.7849, 20.3207,  3.5612,  7.3559, 10.7280,  5.7852,  4.4422,  6.0280,
         4.4182,  1.0946,  2.5527,  0.3651,  1.7547,  0.3010,  9.2778,  7.3711,
        13.2177,  8.4984,  6.5699,  4.1361,  6.9349,  1.2096,  2.5181,  7.5641,
         2.2318,  3.4157,  2.0651,  8.1264,  3.9770,  5.9470,  0.1542,  5.6965,
         3.2999, 11.0491,  6.5674, 12.0891,  2.1688, 11.5385,  3.4366,  3.7559],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [34/80], Step [400/642], LR 8.1e-05, Loss: 453.4
BCE Train Loss:  tensor([23.4255,  6.3153, 12.8194,  0.6794,  5.9045,  3.8864,  1.2404, 10.6004,
         6.5986,  5.2630,  5.9337,  0.8107,  3.4968,  9.4528,  6.6749,  1.3762,
        12.0943,  5.9638,  2.7613,  3.1256,  0.4025,  0.5056,  0.2265,  0.2089,
        16.9192, 10.0031, 16.6857,  7.2960,  4.6606,  1.0241,  2.1696,  3.7818,
         5.2889,  0.7483,  0.3213,  3.8604,  7.1645,  0.3096,  0.6547, 14.4231,
         1.4631, 12.4574,  6.5235,  4.7421,  9.2726, 11.8108,  1.1279,  2.3972,
         3.4917,  1.3377,  3.0502,  0.3994,  0.4075,  0.6464,  0.9627,  4.5042,
        12.1713,  6.4796,  7.2880,  2.6823, 14.5105,  0.3423,  6.4391,  3.9628,
         1.2512, 10.3260,  0.3598, 15.3653,  1.5586,  1.4845,  0.1602,  3.1528,
         0.8764, 14.7938,  5.7232,  9.6978,  7.6571,  5.6943,  0.0648,  3.0206],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [34/80], Step [500/642], LR 8.0e-05, Loss: 424.7
BCE Train Loss:  tensor([15.4934,  7.0532,  9.6113,  0.8635,  1.3893,  3.9863,  1.6504,  6.4826,
         2.0282,  1.8176,  7.7516,  0.4463,  0.1503,  9.9232,  1.1093,  4.4377,
         5.4191,  0.8431,  1.1314,  2.9226,  4.6791,  0.3713,  0.1907,  0.0550,
        19.9073,  2.5649, 25.2956,  4.4518,  8.5426,  5.4680,  5.8652,  1.8491,
         6.4077,  1.5486,  1.7813,  0.4842,  3.2569,  1.5914,  4.3344, 17.0390,
         5.5757, 16.5210,  5.1479,  6.3208,  9.4129, 15.2286,  1.6099,  1.5057,
         1.3581,  0.9645,  1.3289,  1.8512,  3.5672,  3.0567,  2.8817,  1.9115,
        19.1568,  6.7268, 20.5272,  6.5718, 17.4007,  0.7856, 16.4482,  8.0687,
         1.1695,  3.1914,  4.8018,  7.0954,  8.7204,  3.0405,  0.3510,  3.7734,
         2.7044,  9.1061,  7.2923,  5.2735,  6.3498,  5.2454,  0.3374,  2.4084],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [34/80], Step [600/642], LR 8.0e-05, Loss: 445.0
BCE Val Loss:  tensor([5.6931e+01, 1.5308e+01, 4.8529e+01, 2.2070e+01, 1.8164e-02, 8.5568e+00,
        1.6823e+00, 2.1463e+01, 6.2633e+00, 9.9700e+00, 9.1381e+00, 1.3596e+01,
        8.4354e+00, 1.7037e+01, 7.2196e+00, 3.4208e+01, 2.7635e+02, 1.7783e+00,
        9.3038e-01, 2.6977e+00, 5.1887e-01, 5.8209e-01, 1.5851e-02, 1.5841e-02,
        2.8609e+01, 1.6895e+01, 2.8218e+01, 1.3371e+00, 1.5558e+01, 2.0616e+01,
        2.0944e+00, 1.6012e+00, 1.1992e+01, 5.2103e-01, 1.9166e-01, 2.1408e-01,
        6.5057e+00, 3.4347e+00, 1.0483e+01, 4.1482e+01, 9.6387e+00, 2.3417e+01,
        6.1713e+00, 1.7090e+01, 1.6417e+01, 1.6769e+01, 3.9377e-01, 3.4341e+00,
        1.6644e-01, 4.1157e+00, 2.4036e-02, 9.3386e-02, 5.2948e+00, 2.4560e-01,
        6.9752e-02, 3.5155e-01, 2.3034e+01, 7.4938e+00, 9.6746e+00, 8.7975e-01,
        1.1938e+01, 3.8026e+00, 3.6263e+00, 7.2122e+00, 7.7136e-02, 1.0017e+00,
        3.9462e-02, 5.5584e+00, 9.4804e+00, 1.5506e+01, 5.1336e-01, 1.9618e+01,
        1.1613e+01, 8.4434e+00, 1.8064e+01, 5.7115e+00, 2.5659e-01, 8.9455e+00,
        1.1805e-01, 1.2945e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [34/80], Step [000/314], LR 8.0e-05, Loss: 1029.5
BCE Val Loss:  tensor([6.0318e+01, 1.7187e+01, 5.3518e+01, 1.1907e+01, 4.0052e-01, 3.3980e+01,
        1.7475e+01, 3.9053e+01, 2.2772e+01, 3.8453e+01, 1.5340e+01, 3.8987e+01,
        1.2272e+01, 7.9096e+00, 1.8620e+01, 1.4956e+00, 5.6153e+00, 1.7759e+01,
        3.1128e+00, 1.3096e+01, 1.5110e-01, 7.1956e-02, 3.2748e-02, 2.9461e-02,
        3.1188e+01, 2.5438e+01, 3.4670e+01, 1.3720e+01, 1.7374e+01, 8.3929e-01,
        3.4401e-01, 1.9620e-01, 4.2310e-01, 1.8823e+00, 1.3625e-01, 3.7994e-02,
        2.2688e+00, 8.6776e-01, 3.4313e-02, 8.0955e-01, 1.2404e-01, 4.6545e+00,
        1.4224e+00, 4.0547e+00, 1.0080e+00, 1.6792e+00, 7.0108e-02, 4.5150e-02,
        6.9261e-02, 7.7587e+00, 1.3899e-02, 3.6934e-02, 3.2631e-02, 1.1365e+00,
        1.7558e-02, 4.9559e+00, 1.3227e+01, 1.0288e+01, 4.0988e+00, 1.2700e-01,
        7.3576e+00, 4.0142e-02, 9.6361e-01, 2.7594e-02, 1.2370e-02, 3.9177e-02,
        3.9935e-03, 2.3226e+01, 5.2657e-02, 4.0144e+00, 1.2313e-02, 9.5204e-02,
        2.6064e+00, 3.0899e+00, 4.5389e+00, 2.9319e-01, 4.0286e-01, 9.5134e-01,
        3.2375e-03, 1.4042e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [34/80], Step [100/314], LR 8.0e-05, Loss: 662.4
BCE Val Loss:  tensor([1.1697e+01, 3.6790e-01, 3.9268e+00, 4.8476e-01, 3.0270e-02, 3.1440e-02,
        1.0294e-01, 1.8625e+01, 1.8531e-01, 2.9797e-02, 1.1864e-02, 3.7156e-02,
        8.9787e-03, 1.1392e+01, 3.6448e-01, 3.6072e+00, 7.6011e-01, 6.2994e-02,
        2.2778e-02, 1.9724e-02, 2.8695e-02, 1.5041e-02, 3.2732e-03, 3.4023e-03,
        5.3766e+00, 9.2913e-01, 2.9102e+01, 6.7757e+00, 8.6137e-01, 2.4980e-01,
        1.5059e-01, 5.8633e+00, 1.0344e+01, 5.2901e-02, 1.2113e-01, 7.7101e-02,
        1.0300e+01, 7.8669e+00, 2.3419e-02, 3.8136e+01, 1.8947e+01, 7.7876e+01,
        5.9564e+01, 5.8412e+01, 4.4431e+01, 5.6684e+01, 1.1262e+01, 8.5320e+00,
        4.0139e+01, 1.0437e+01, 2.6958e+01, 4.0068e+01, 5.3464e+01, 1.9371e+01,
        6.2272e+01, 7.6586e+01, 1.1708e+02, 1.1386e+01, 6.3942e+00, 3.6800e-01,
        7.7198e+01, 1.1240e-01, 1.3982e+01, 7.3817e+00, 1.3291e+01, 2.6112e+00,
        1.1358e+01, 1.3496e+01, 8.4404e+00, 4.2091e+00, 1.7469e-01, 1.3162e+01,
        4.8257e+00, 4.6798e+01, 1.8253e+00, 1.3589e+01, 1.0096e+01, 1.2185e+00,
        6.4027e-02, 1.0110e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [34/80], Step [200/314], LR 8.0e-05, Loss: 1212.2
BCE Val Loss:  tensor([2.8685e+01, 8.9975e-01, 1.4515e+01, 1.4853e+00, 4.4216e-01, 8.8467e+00,
        1.1694e+01, 1.8236e+01, 1.5105e+00, 1.8757e+01, 6.1092e+00, 7.4656e+00,
        2.3426e-01, 9.9284e+00, 1.7128e+01, 3.4558e-01, 2.4105e+00, 3.2469e-01,
        1.6524e-02, 2.4182e-02, 4.1893e-01, 3.1004e-02, 7.6931e-03, 3.0581e-02,
        1.8092e+01, 2.7016e+00, 2.1440e+01, 7.1305e-01, 1.6294e+01, 1.4761e-01,
        9.2602e-01, 5.0220e-02, 2.4670e-02, 4.1373e-02, 5.7756e-03, 7.0275e-03,
        3.5170e-01, 5.1136e-02, 1.1487e-02, 1.3158e+00, 7.6433e-01, 1.3910e+00,
        8.9620e-02, 2.2405e-01, 7.9000e-02, 5.1412e-01, 4.9983e-02, 3.0298e-02,
        1.8382e-02, 2.2416e-02, 1.0030e-02, 1.6822e-02, 1.4825e-02, 1.7165e-01,
        2.0174e-02, 1.1568e-01, 2.8956e+00, 1.8914e+00, 1.3669e+01, 2.7052e-01,
        7.5473e+00, 1.0610e-01, 1.3052e+00, 3.2518e-02, 1.5082e-02, 7.0717e-01,
        3.1318e-02, 5.7312e+00, 3.9521e-02, 7.8587e-02, 9.3996e-03, 7.3362e-02,
        7.3573e-02, 7.6369e+00, 3.3468e+01, 4.5000e+00, 4.1380e-02, 5.0229e+00,
        7.2789e-03, 3.8658e-03], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [34/80], Step [300/314], LR 8.0e-05, Loss: 300.4
starting validation
Accuracy th:0.5 is [93.48448484 98.40279724 95.80779961 99.01560654 99.53582437 98.83286022
 99.38962732 97.06874916 99.01195161 98.41254371 99.3177471  99.4005921
 99.68080311 96.95422814 98.39426908 98.72199413 97.81922735 99.02657131
 99.53216944 99.31165556 99.63450738 99.73440869 99.81969031 99.74537347
 95.87358828 98.47955069 95.72617293 98.56361399 98.74148707 99.31896541
 99.26414152 99.31531049 98.45518451 99.49318356 99.46881739 99.47369062
 99.28363446 99.30190909 99.70029605 95.31438457 98.62452943 95.02442709
 98.05314263 97.56338251 97.83506536 96.67645375 99.15083881 99.19469792
 98.96565588 99.28119784 99.42130335 99.28119784 99.46272584 99.372571
 99.30678232 98.90230382 94.59680072 98.44543804 97.71323449 98.99367698
 95.8614052  99.41643011 98.50391686 98.66717023 99.36160622 98.73783214
 99.12403601 97.04438299 99.21053593 99.07774028 99.82090861 98.69397303
 99.0947966  97.03950975 98.14573409 98.3699029  99.36769776 99.19469792
 99.85380295 99.372571  ]
Accuracy th:0.7 is [92.60364762 98.32117055 95.21813818 98.98636713 99.40181041 98.70128288
 99.46394415 96.6009186  98.843825   98.54533936 99.29825416 99.36891607
 99.64303554 96.62893971 98.28218467 98.8572264  97.55607266 98.8852475
 99.45054276 99.26414152 99.63328907 99.73197208 99.81238045 99.72466222
 95.99541916 98.3138607  95.3046381  98.45762113 98.88402919 99.29094431
 99.31043725 99.20809932 98.0628891  99.37988085 99.28728938 99.34211328
 99.22393733 99.15571204 99.67105664 94.75518086 98.60381818 95.00493415
 98.37843106 97.6450092  97.52196002 96.19522179 99.04971918 99.108198
 98.85235316 99.20809932 99.38231747 99.22515564 99.43226813 99.35673298
 99.22393733 98.83895177 93.37971029 98.24076217 97.5341431  98.86819118
 95.44230699 99.38840901 98.44300143 98.59894494 99.30921894 98.68788148
 98.93641647 96.70934808 99.10332476 98.96078264 99.82090861 98.52219149
 98.92667    96.67523544 98.11649468 98.28096636 99.32505696 99.17033175
 99.84892972 99.30556402]
Avg Prec: is [98.85184967 72.71309138 87.77250018 89.00584473 97.01535881 89.04238452
 95.92157751 79.72337487 87.36631067 86.22383443 80.08412889 82.02234172
 73.84974936 71.29018525 70.63059579 89.24392727 76.10996622 87.71788071
 88.26515774 85.29104063 94.50393968 88.54317377 97.24823648 97.91030473
 54.42184067 81.76658496 64.04901643 82.26635709 73.93664015 88.30597264
 94.35886436 83.5150891  86.77776423 93.34123995 95.66817678 95.67669656
 94.06167102 95.03200994 97.90666026 71.83655078 69.92971896 75.42531739
 79.94395465 74.54776839 67.13866415 79.28444771 82.69751903 73.89112853
 79.51666483 79.94750684 89.47705542 80.41097478 77.15037227 93.28763518
 81.21991754 85.41502301 83.80225627 86.80576273 71.47553383 90.53133686
 88.18278781 95.82264939 87.68111187 85.16886369 87.7571132  82.08777317
 87.17822976 66.0571991  74.3764369  87.84660111 30.55657498 92.18290731
 84.39883434 72.01404418 78.58373673 78.91956239 52.98335996 81.25777936
 31.16360146 65.24636735]
Accuracy th:0.5 is [93.14335839 98.28340298 95.36189861 98.96200095 99.55531731 98.77072648
 99.42983151 96.96397461 98.97662066 98.40157893 99.28485277 99.38109916
 99.65765524 96.79219308 98.28096636 98.77803633 97.80826257 99.04240933
 99.50049342 99.21175424 99.62963414 99.71491575 99.80628891 99.735627
 95.95277835 98.39548738 95.43865206 98.42716341 98.75732508 99.25439505
 99.22150071 99.2751063  98.36624797 99.43592305 99.50536665 99.45541599
 99.22150071 99.289726   99.68811296 94.88553989 98.53071965 94.8721385
 98.1883749  97.43789671 97.68886831 96.39502443 99.06799381 99.14352895
 98.87671934 99.20200777 99.36891607 99.23612042 99.41886673 99.31652879
 99.33845835 98.84504331 94.30562493 98.30167761 97.49028399 98.90717706
 95.72860954 99.36647945 98.33822687 98.57457877 99.29094431 98.63793082
 99.2202824  96.93108027 99.12525432 98.96200095 99.82578185 98.61234634
 98.99367698 96.83970712 98.00441028 98.26756497 99.33602173 99.15571204
 99.84892972 99.37013438]
Accuracy th:0.7 is [91.98352847 98.14451578 94.82584277 98.92667    99.54678915 98.64036744
 99.3871907  96.69594669 98.8998672  98.24563541 99.22150071 99.33358512
 99.61623275 96.5168553  98.17862843 98.67326178 97.64135427 98.98636713
 99.43592305 99.16545851 99.6101412  99.71613406 99.80263398 99.72588053
 95.72008138 98.21761431 95.18524384 98.26878328 98.69884626 99.11550785
 99.23733873 99.14840219 98.07507218 99.35064144 99.46272584 99.43104982
 99.18373314 99.26292321 99.66862002 94.53954021 98.3565015  94.47496985
 98.17131858 97.40743899 97.49515722 96.1123768  99.00098683 99.08139521
 98.78534618 99.15693035 99.32749357 99.15205711 99.37622592 99.29825416
 99.25195843 98.69397303 93.59900586 98.19568475 97.34652356 98.82798699
 95.21691987 99.35307806 98.20543122 98.49295208 99.27754291 98.480769
 99.18616976 96.69472838 99.05824734 98.95834602 99.818472   98.57214215
 98.97174742 96.5022356  97.93374837 98.12989608 99.29094431 99.06068396
 99.84405648 99.34698651]
Avg Prec: is [98.73489078 69.27345749 85.67687047 87.83196991 96.54342059 87.45345123
 95.17456674 76.95451557 85.43798254 84.03076347 76.96147655 80.56169871
 68.42304715 65.84119739 66.66244373 87.74915716 71.60056722 86.31908256
 86.06999483 82.60844229 94.00544279 86.38192842 97.09950952 97.71029816
 50.97866754 78.62223858 59.62906746 79.20941965 68.46067407 85.36346366
 93.30483115 80.970372   84.3406586  91.90889879 94.6154187  94.82282117
 93.1304535  93.89775916 97.76475534 66.84686958 64.55757538 72.66616175
 77.48800162 71.09879313 63.58102693 75.89623614 79.83967534 69.91107675
 76.41683501 75.91791083 87.51614233 77.41870601 72.34738983 92.22374097
 77.84497841 82.97093375 80.66674464 84.95136023 66.43806764 88.89941851
 87.15660114 95.27717802 85.46435912 82.33788541 85.63764182 79.2635566
 85.14013327 59.81839709 70.76560687 86.14251947 28.96355596 91.0231855
 82.09094287 66.70113557 76.08438104 76.10438378 47.26108061 78.55051973
 27.2389656  60.07301193]
mAP score regular 81.63, mAP score EMA 78.98
starting validation
Accuracy th:0.5 is [90.90863792 97.72030795 93.84856865 98.6147445  99.40453945 98.31576849
 99.03331091 95.8890799  98.60228717 97.41385754 99.13296958 99.24508558
 99.50419812 95.91648604 97.97194608 98.20116102 97.25440367 98.75177517
 99.42696265 98.88631437 99.59887386 99.71846426 99.81064853 99.78324239
 94.76293694 97.83740688 94.53123054 97.95948875 97.86232155 98.81157037
 99.07317438 98.95358397 97.49856741 99.35221865 99.16286718 99.35720158
 98.98099011 98.89129731 99.44191145 93.61187931 98.05416449 93.32536064
 97.08498393 96.50198072 97.0650522  95.10426788 98.85890824 98.96354984
 98.4054613  98.96354984 99.23511971 98.90126317 99.07068291 98.93863517
 99.02832798 98.17126342 91.40194833 97.76266288 96.56177592 98.25348182
 93.34778384 99.08314024 97.57331141 98.07907915 98.91870344 97.75767995
 98.7492837  96.02860204 98.83150211 98.50511996 99.8056656  97.94703142
 98.5026285  96.01863617 97.43129781 97.43378927 99.30488078 98.87883997
 99.81563146 99.18030745]
Accuracy th:0.7 is [90.62959364 97.89471062 93.88843212 98.70692877 99.34474425 98.33819169
 99.08812318 95.90901164 98.54996637 97.64556394 99.14044398 99.28744052
 99.49174079 95.8666567  98.00184369 98.35314049 97.12983033 98.6446421
 99.37215038 98.95358397 99.59389092 99.68358373 99.80317413 99.75832773
 95.34594015 97.78010315 94.6383636  98.06662182 98.18122929 98.88133144
 99.08064878 98.99843038 97.43378927 99.34225278 99.06819144 99.25006852
 98.94361811 98.76174104 99.44440292 93.69409772 98.13389142 93.72150385
 97.416349   96.74863592 97.12983033 95.06191295 98.88631437 98.97351571
 98.38303809 98.93863517 99.19525625 98.91122904 99.10307198 98.87385704
 99.00839624 98.21112689 91.26491766 97.72030795 96.66641752 98.20116102
 93.44744251 99.08563171 97.61815781 98.11645115 98.86887411 97.84986422
 98.6595909  96.10832897 98.85890824 98.45279916 99.81314    97.80501781
 98.5101029  96.02611057 97.63061514 97.65552981 99.31235518 98.88880584
 99.82559733 99.17283305]
Avg Prec: is [97.66094088 53.03918752 75.65016112 82.02370489 90.41689134 77.79376297
 91.07842352 58.08746666 75.38063513 70.92427882 66.50862549 71.25492411
 46.9521663  47.69558666 52.52709371 81.39147173 57.13828901 77.89621423
 80.60907729 69.81915281 92.14168973 86.27128196 96.86768627 97.88380822
 28.44751257 65.16835826 38.0585512  67.1403556  49.50613274 72.87882112
 87.84810923 63.6237579  68.53993282 88.49297247 84.38627415 90.13527011
 85.70612681 88.16100176 95.53228376 50.34328619 46.58506817 56.4543786
 55.51807198 47.80104377 38.48784929 56.81369752 63.90900213 45.26215848
 56.87025064 57.3696958  83.1615256  56.68941825 50.88016199 86.02131917
 56.44820498 60.97529621 59.63472336 70.63694605 46.55745291 76.05821453
 69.90629872 92.03047007 72.7408508  69.08244789 68.58832654 53.77489516
 71.54667537 38.07879671 49.44451656 72.99751466  9.17218931 80.18859569
 60.98759274 48.40569562 70.02430906 58.15185977 24.3983529  64.0839767
  3.14868275 30.88082041]
Accuracy th:0.5 is [91.28484939 97.91713382 93.98061639 98.7044373  99.42696265 98.31327703
 99.15539278 95.89157137 98.60976157 97.67047861 99.10805491 99.28245758
 99.47679199 95.9040287  98.00931809 98.33071729 97.26187807 98.8090789
 99.43443705 98.90375464 99.58392506 99.67112639 99.80317413 99.80068266
 95.30109375 97.84986422 94.47890973 98.07409622 98.25099036 98.8090789
 99.09310611 98.94610957 97.48611007 99.34225278 99.23761118 99.36467598
 98.99344744 98.94112664 99.48924932 93.64426838 98.14634876 93.69409772
 97.40389167 96.65894312 96.98532526 95.21887535 98.85890824 98.95856691
 98.33570023 98.96354984 99.25006852 98.93614371 99.11802078 98.93863517
 99.05075118 98.22358422 91.613723   97.80252635 96.68634925 98.23604156
 93.66918305 99.14542691 97.69788474 98.05167302 99.01836211 97.84238981
 98.91870344 95.89406283 98.84645091 98.5325261  99.80815706 97.97443755
 98.46774796 95.96880684 97.63808954 97.66051274 99.28245758 98.93614371
 99.82310586 99.13546105]
Accuracy th:0.7 is [90.94102698 97.93208262 94.06034332 98.7492837  99.44191145 98.32324289
 99.12300371 96.07344844 98.6521165  97.70785061 99.12300371 99.31982958
 99.49921519 95.9862471  98.00184369 98.32075143 97.26935247 98.82402771
 99.38959065 98.93365224 99.59638239 99.67610933 99.80317413 99.78573386
 95.54525749 97.81498368 94.67822707 98.04669009 98.27341356 98.83150211
 99.09310611 98.97849864 97.41136607 99.36218452 99.20023918 99.38959065
 98.96853278 98.90375464 99.45436879 93.82365399 98.13638289 93.89590652
 97.52597354 96.86822632 97.15225353 95.26621322 98.87634851 99.00839624
 98.39300396 99.00092184 99.20023918 98.91122904 99.12300371 98.96105838
 99.05324264 98.24600742 91.77566834 97.80750928 96.75361886 98.27092209
 93.73894412 99.13047811 97.71532501 98.05167302 99.01337918 97.87727035
 98.89628024 96.11082044 98.85641677 98.49764556 99.81563146 98.04669009
 98.54996637 96.05600817 97.68293594 97.75767995 99.28744052 98.90126317
 99.82559733 99.17532451]
Avg Prec: is [97.86989956 53.79747361 76.73285052 83.34097635 90.91080841 78.59704469
 91.42618095 61.36718595 77.01595231 71.96220119 67.82364041 70.92791524
 46.14550055 50.13747126 53.54543605 81.9118002  59.78373898 79.82434556
 80.52523845 70.07791764 92.3452241  86.66019118 96.84379692 97.77958521
 31.17877354 66.18926058 40.17395993 67.62088832 50.18197024 71.41563272
 88.10566484 63.63758033 68.22481333 88.13255617 85.04343501 90.18125123
 85.98734403 88.21316596 95.53895933 52.38306821 47.10708628 58.48510278
 55.5339811  48.82377911 39.53122753 59.2503849  65.53257603 47.56075672
 57.55376006 59.8406908  83.66272284 58.55280394 51.52490299 87.25197487
 57.27124303 62.42811639 63.51246762 71.92747051 48.96431704 77.84796146
 72.35346279 92.57606372 74.80199822 69.22761263 72.4899009  54.94787467
 74.33853998 39.77855248 49.53808233 74.39975669  8.73351431 82.22927566
 62.02776273 49.6772816  70.59942395 60.69195092 24.62024284 65.43510339
  3.34718189 32.84719994]
mAP score regular 65.01, mAP score EMA 66.08
Train_data_mAP: current_mAP = 81.63, highest_mAP = 81.63
Val_data_mAP: current_mAP = 66.08, highest_mAP = 66.08
lr:  [7.978197534351091e-05, 7.978197534351091e-05]
BCE Train Loss:  tensor([21.4559,  5.1505,  7.7822,  8.9835,  0.3311,  1.4873,  1.1079,  4.3204,
         0.9446,  7.0922,  1.5077,  3.8194,  0.2302,  8.8882, 10.3735,  5.6228,
        22.1170,  3.3486,  0.1908,  1.5408,  0.2749,  0.2039,  4.2956,  4.8565,
        21.9769,  5.0565, 10.9224, 14.2561,  3.6126,  2.6239,  0.9203,  2.7217,
         4.7438,  1.4366,  0.8752,  1.6723,  6.9284,  3.5320,  1.5681, 21.4911,
         4.2155, 12.0414,  8.6578,  9.1629, 10.0024, 11.3929,  7.1363,  7.5609,
         4.0839,  4.2052,  0.3776,  0.8702,  4.4755,  1.7886,  1.4271,  6.4861,
        21.5924,  4.5116,  7.9587,  0.8637, 16.4692,  3.3550,  7.9824,  3.9031,
         0.9378,  8.5672,  5.9503, 11.0751,  5.0727,  2.3005,  0.1515,  5.6093,
         1.5912, 10.3377, 14.4886,  2.9778,  1.2962,  0.8193,  0.2870,  0.7309],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [35/80], Step [000/642], LR 8.0e-05, Loss: 463.0
BCE Train Loss:  tensor([19.9815,  4.2273, 19.5952,  3.0800,  0.2293, 10.1554,  0.7063, 11.4508,
         1.8061,  8.3663,  1.7791,  2.1747,  0.7614,  7.3243,  1.6027, 14.2853,
        11.0207,  4.3743,  2.1007,  2.3908,  0.5327,  1.2028,  0.1141,  0.1556,
        10.2331,  2.7386, 18.9299,  4.9917, 11.6853,  5.1661,  0.5517,  1.2957,
         4.6316,  1.5120,  1.4019,  0.5296,  0.5193,  0.7167,  0.1759, 16.0159,
         1.3155, 12.7427,  7.3212,  6.6658,  5.8555, 12.0276,  0.9712,  1.6145,
         1.0244,  2.9835,  0.3786,  0.3579,  2.0279,  2.1614,  0.6760,  7.2062,
        15.6974,  1.8801,  6.2194,  2.6434,  4.5281,  1.3552,  1.2033,  4.7973,
         1.7059,  2.6864,  1.1183, 10.3764,  2.8983,  2.7056,  4.3577,  4.4782,
        15.4471,  6.3497, 11.7170,  6.6847,  2.3648,  1.7159,  0.1161,  5.1315],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [35/80], Step [100/642], LR 7.9e-05, Loss: 394.0
BCE Train Loss:  tensor([12.5651,  2.2915, 14.8989,  1.6149,  0.8370,  1.0558,  2.2344,  5.1667,
         2.2581,  4.2411,  1.3750,  1.6747,  1.9152, 14.2586,  6.2670,  5.4283,
        13.3205,  0.7981,  1.0188,  5.7397,  5.5900,  3.1203,  1.4229,  0.1947,
         8.5803,  4.6774, 16.4453,  4.6156,  4.0466,  7.5461,  2.4514,  1.5446,
         5.8396,  1.0709,  0.7660,  1.5152,  1.2404,  5.3760,  1.1063, 29.0416,
         4.7647, 17.4751,  5.7385,  9.8478,  6.1412, 11.0542,  8.8386,  2.4716,
         8.4129,  3.8460,  3.6896,  2.6794,  5.3779,  3.1813,  3.9838,  9.0812,
        21.6867,  6.8704,  7.7454,  1.7822, 11.5723,  2.4632,  8.8674,  4.6469,
         1.7892,  5.7478,  3.5659, 11.4578,  1.7913,  2.3920,  0.2083,  3.4519,
         7.2753, 10.4854,  8.4499,  6.1321,  7.7835,  0.5600,  0.1002,  0.6055],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [35/80], Step [200/642], LR 7.9e-05, Loss: 449.2
BCE Train Loss:  tensor([14.4113,  3.3832,  8.4871,  0.8792,  0.3959,  4.6178,  1.3994,  4.7837,
         9.4310,  0.7057,  0.3555,  1.0141,  0.3492, 11.9241,  7.6258,  1.6332,
         7.0732,  0.2766,  0.4836,  0.3735,  0.1516,  0.0730,  0.1868,  0.4126,
         9.1727,  7.4979, 14.7928,  7.4065,  1.0825,  7.1561,  2.0010,  1.7109,
         2.1419,  5.6642,  0.5484,  1.2469,  2.4191,  1.0784,  1.0702, 23.0555,
        12.0892, 17.2901,  2.9300, 11.2838,  5.1200, 13.7152,  7.2707,  0.5502,
         2.9040,  1.3619,  0.6850,  7.4597,  0.6005,  1.2879,  0.7203,  4.9152,
        22.0947, 11.0932,  5.0934,  6.4708, 16.3890,  1.9847,  6.2225, 11.6139,
         9.9687,  7.1804,  1.8164,  9.2559,  2.0469,  1.2433,  0.2757,  5.0228,
         8.3893,  8.2777, 21.3730,  5.2483,  0.7194,  3.4790,  0.2219,  1.1235],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [35/80], Step [300/642], LR 7.9e-05, Loss: 425.3
BCE Train Loss:  tensor([24.1059,  1.5893, 17.5386,  7.4721,  0.2794,  5.1640,  8.8585, 12.2213,
         1.1435,  5.7770,  0.7043,  6.5241,  0.3980,  5.1267, 14.8790,  0.6886,
        12.8441,  9.0385,  1.0266,  2.5442,  1.6184,  0.0968,  0.2826,  2.5507,
        11.0327,  9.3122, 15.3421,  1.5644,  5.6518,  2.7611,  1.6018,  1.5964,
         1.6764,  0.5487,  0.6286,  2.3182,  2.0039,  2.3418,  0.7235, 14.5298,
         4.6646, 15.3970,  6.5441, 10.1584,  2.9610, 13.3464,  4.6014,  6.9658,
         3.2534,  1.1404,  2.3368,  4.5331,  1.0971,  2.8483,  2.9373,  6.8842,
        21.0308,  7.8319, 11.9695,  9.9067, 20.9217,  1.5794,  5.8702,  6.6866,
         4.8223,  3.4605,  0.6616, 10.1920,  5.7560,  9.9935,  4.6711,  3.2291,
         3.5840, 19.4041, 13.5298,  6.5020,  2.2819,  3.2614,  2.2487,  0.5031],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [35/80], Step [400/642], LR 7.9e-05, Loss: 485.7
BCE Train Loss:  tensor([13.9197,  9.0183, 11.6659,  0.9015,  1.8871,  2.2654,  4.7436,  9.4316,
         2.1902,  0.8047,  0.6154,  0.5528,  1.3611,  8.2596,  8.8572,  6.3057,
         8.8905,  5.4363,  2.9480,  0.6637,  0.4765,  0.4939,  5.6753,  0.2341,
        20.5612,  2.9604, 11.6148,  5.2800,  1.7664,  2.8015,  0.2435,  0.5014,
        13.1805,  2.2692,  1.8241,  0.8613,  3.6026,  2.9150,  1.1160, 18.7993,
         6.3412, 14.6329,  7.4290,  5.7290,  6.9956,  9.1074,  4.4940,  9.0042,
         2.4576,  7.0724,  0.7850,  1.1684,  1.2142, 14.0953,  3.8291,  5.8185,
        15.2627,  5.8556, 16.7114,  1.9629, 26.5278,  0.8020,  6.9380,  5.8527,
         1.0208,  4.3853,  1.3295,  4.9471,  0.8525,  7.1883,  0.0625,  1.4879,
         9.4092,  7.5045, 18.5246, 12.6858,  0.9854,  1.7071,  0.1818,  0.4041],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [35/80], Step [500/642], LR 7.8e-05, Loss: 450.7
BCE Train Loss:  tensor([18.2539,  8.4219, 21.0692,  5.1444,  0.2654,  4.6837,  0.2237,  6.1785,
         0.5351,  9.0730,  1.1646,  2.0606,  0.7123, 11.3530, 11.2851,  3.0128,
         9.7390,  3.8612,  2.6437,  1.8303,  1.1953,  1.2037,  0.0406,  0.1226,
        12.6372,  9.9303,  9.1570,  6.1379,  2.1142,  1.8008,  5.4285,  1.1974,
         3.7394,  3.8480,  1.4040, 12.6641,  1.4439,  8.7025,  0.2090, 21.1578,
         3.7096, 18.5535,  3.3266,  6.6237,  6.2711, 11.4300,  0.8467,  0.3763,
         1.4323,  0.4069,  3.8463,  0.8311,  3.4130,  0.5322,  0.6372,  1.5599,
        13.9995,  6.4684, 12.8952,  1.4477,  9.3194,  0.2059,  4.9322,  2.5805,
         1.3723,  2.4452,  1.6362,  7.3530,  7.1580,  3.3473,  0.0599,  3.2314,
         1.0506,  6.9290,  2.7009,  9.6940,  4.3100,  3.3517,  0.1044,  0.9493],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [35/80], Step [600/642], LR 7.8e-05, Loss: 397.0
BCE Val Loss:  tensor([5.8418e+01, 1.7044e+01, 4.5363e+01, 2.4783e+01, 3.1920e-02, 1.0258e+01,
        5.6193e+00, 2.1761e+01, 6.4726e+00, 8.9214e+00, 8.8405e+00, 1.1988e+01,
        8.7697e+00, 2.3992e+01, 7.7352e+00, 2.5030e+01, 2.0445e+02, 6.8696e+00,
        9.9708e-01, 2.2370e+00, 3.8273e-01, 3.0105e-01, 3.7859e-02, 4.2463e-02,
        2.9267e+01, 1.0369e+01, 3.5167e+01, 1.1712e+00, 1.3711e+01, 1.2136e+01,
        4.7515e-01, 5.1853e+00, 1.1058e+01, 2.8262e-01, 4.4936e-01, 1.2601e-01,
        1.0286e+01, 3.6013e+00, 3.9909e+00, 3.8942e+01, 1.1378e+01, 2.2497e+01,
        6.8063e+00, 1.7622e+01, 1.6281e+01, 1.7399e+01, 1.5221e-01, 3.8287e+00,
        1.2436e-01, 3.6445e+00, 2.2214e-02, 1.7378e-01, 4.5269e+00, 2.6940e-01,
        8.0260e-01, 2.0204e-01, 2.0699e+01, 9.1533e+00, 8.0855e+00, 7.2299e-01,
        1.0116e+01, 5.3918e+00, 2.4978e+00, 8.6950e+00, 5.0912e-02, 4.8040e-01,
        3.3732e-01, 1.0813e+01, 9.3318e+00, 1.7379e+01, 3.8362e-01, 2.0740e+01,
        1.2326e+01, 1.1145e+01, 1.5895e+01, 7.2093e+00, 2.2402e-01, 1.1935e+01,
        1.4066e-01, 4.7343e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [35/80], Step [000/314], LR 7.8e-05, Loss: 966.5
BCE Val Loss:  tensor([6.3663e+01, 1.5613e+01, 6.3999e+01, 1.1385e+01, 7.4558e-01, 4.0199e+01,
        3.4518e+01, 4.2126e+01, 1.4122e+01, 3.4624e+01, 1.6557e+01, 4.5115e+01,
        1.1151e+01, 7.3421e+00, 1.8236e+01, 2.6646e+00, 6.1841e+00, 1.4202e+01,
        4.8932e+00, 1.1474e+01, 1.4867e-01, 4.8108e-02, 1.1884e-01, 3.7956e-02,
        3.3225e+01, 2.2615e+01, 3.4659e+01, 1.5657e+01, 1.7808e+01, 4.9074e-01,
        1.3475e-01, 2.6838e-01, 7.8786e-01, 5.7408e-01, 5.1252e-01, 7.2924e-02,
        2.1701e+00, 2.1542e+00, 3.0236e-01, 3.2709e+00, 8.2994e-02, 4.0111e+00,
        2.6213e-01, 1.3404e+00, 8.6792e-01, 2.0841e+00, 4.4735e-02, 7.3264e-02,
        5.3523e-02, 6.6162e+00, 1.5931e-02, 8.7184e-02, 3.0846e-02, 1.0631e+00,
        1.7941e-01, 2.6762e+00, 1.7499e+01, 9.9837e+00, 5.6096e+00, 4.5368e-02,
        4.1725e+00, 4.9864e-02, 8.7862e-01, 5.8612e-02, 3.0086e-02, 4.3762e-02,
        5.9869e-02, 2.2141e+01, 4.1745e-01, 3.2982e+00, 3.0596e-02, 1.5367e+00,
        4.5770e+00, 3.9392e+00, 3.9642e+00, 4.1244e-01, 2.7141e-01, 1.6699e+00,
        4.1097e-03, 4.8131e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [35/80], Step [100/314], LR 7.8e-05, Loss: 694.1
BCE Val Loss:  tensor([1.1558e+01, 3.6766e-01, 5.4892e+00, 3.2836e-01, 3.5466e-02, 6.5327e-02,
        6.3567e-02, 1.6964e+01, 2.7405e-01, 2.3556e-02, 1.8280e-02, 2.3374e-02,
        1.1619e-02, 9.5327e+00, 4.0290e-01, 1.4359e+00, 1.0934e+00, 9.5573e-02,
        3.4929e-02, 1.3651e-02, 1.7422e-02, 6.7257e-03, 3.4999e-03, 4.2588e-03,
        4.9144e+00, 1.3265e+00, 2.9849e+01, 3.6171e+00, 1.0201e+00, 1.4282e-01,
        9.3729e-01, 8.0490e+00, 1.0415e+01, 3.9446e-02, 6.0949e-01, 9.1277e-02,
        1.0429e+01, 6.9731e+00, 4.4232e-02, 6.4036e+01, 1.3903e+01, 7.0958e+01,
        5.7957e+01, 5.4854e+01, 4.7066e+01, 6.5758e+01, 1.0077e+01, 5.7987e+00,
        4.1822e+01, 1.1272e+01, 2.7654e+01, 3.9517e+01, 6.4925e+01, 1.7273e+01,
        5.1416e+01, 8.2758e+01, 1.1746e+02, 1.0709e+01, 8.7932e+00, 1.6874e-01,
        9.1310e+01, 9.8952e-02, 1.4430e+01, 7.7256e+00, 1.4130e+01, 2.6983e+00,
        1.0102e+01, 1.9790e+01, 8.4867e+00, 2.3503e+00, 1.8806e-01, 1.6185e+01,
        6.0732e+00, 4.4932e+01, 3.2474e+00, 1.6104e+01, 1.0155e+01, 1.0992e+00,
        6.0437e-02, 3.9196e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [35/80], Step [200/314], LR 7.8e-05, Loss: 1260.1
BCE Val Loss:  tensor([2.9596e+01, 7.2964e-01, 1.3725e+01, 4.6344e-01, 5.1645e-01, 8.8339e+00,
        8.3741e+00, 1.8002e+01, 4.9904e+00, 1.8506e+01, 7.1396e+00, 8.3045e+00,
        4.3299e-01, 9.4126e+00, 1.6587e+01, 3.9183e-01, 1.4716e+00, 9.7580e-01,
        3.5020e-02, 3.7171e-02, 4.4304e-01, 2.0691e-02, 1.6493e-02, 4.9051e-02,
        2.1400e+01, 8.3013e+00, 2.3054e+01, 2.2369e-01, 2.0378e+01, 3.8664e-01,
        6.9269e-01, 6.5728e-02, 7.6289e-02, 1.7903e-01, 7.1221e-02, 3.5760e-02,
        3.4177e-01, 1.5954e-01, 2.4797e-02, 2.2798e+00, 4.3197e-01, 1.3293e+00,
        1.0852e-01, 1.6678e-01, 1.1381e-01, 3.7268e-01, 2.0851e-02, 5.3542e-02,
        2.4008e-02, 4.4943e-02, 1.2536e-02, 1.2380e-01, 1.0871e-02, 2.0140e-01,
        2.1772e-01, 4.7646e-02, 7.3902e+00, 3.3148e+00, 1.6683e+01, 2.0185e-01,
        6.5007e+00, 4.1681e-02, 1.4570e+00, 1.1249e-01, 1.5838e-02, 5.4698e-01,
        4.2823e-01, 6.8323e+00, 1.0421e-01, 1.0987e-01, 8.9971e-03, 1.5371e-01,
        6.7950e-01, 7.6922e+00, 4.3312e+01, 5.5056e+00, 5.3353e-02, 5.0457e+00,
        9.7982e-03, 2.7175e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [35/80], Step [300/314], LR 7.8e-05, Loss: 336.2
starting validation
Accuracy th:0.5 is [93.29564698 98.32482548 95.83703902 98.97905727 99.54922576 98.82555037
 99.37988085 97.13819276 98.98880374 98.51609995 99.36160622 99.36404284
 99.67836649 97.14550261 98.40888878 98.90230382 98.0068469  99.20931763
 99.54922576 99.32749357 99.63694399 99.71978899 99.81481707 99.77583119
 96.0295318  98.52828304 95.78830667 98.41863525 98.90108551 99.32383865
 99.18129652 99.23977534 98.45518451 99.46759908 99.54800746 99.51876805
 99.2617049  99.36769776 99.71613406 94.77101887 98.68057163 95.36677185
 98.35284658 97.68886831 97.87892448 96.6557425  99.14231064 99.23124718
 98.98880374 99.28607108 99.44079629 99.19835285 99.46638077 99.38840901
 99.35551467 98.88768412 94.91356099 98.51609995 97.50124877 98.96200095
 95.96983468 99.40912026 98.51731826 98.70250119 99.37135269 98.74757861
 99.26535983 97.15524908 99.1922613  99.03631778 99.82821847 98.7037195
 99.0107333  97.19301665 98.17010027 98.31751562 99.34820482 99.2336838
 99.85014802 99.4566343 ]
Accuracy th:0.7 is [91.52544438 98.1749735  95.55804632 98.8024025  99.46759908 98.71224766
 99.33358512 96.64599603 99.02169808 98.31507901 99.35551467 99.32749357
 99.67105664 97.03707314 98.29558607 98.78534618 97.81557242 99.15936697
 99.49074695 99.26901475 99.66009186 99.71613406 99.80872553 99.75755656
 95.75175741 98.53802951 95.50931397 98.25538188 98.78412787 99.3177471
 98.88646581 99.29094431 98.1055299  99.38109916 99.47856386 99.44932445
 99.25195843 99.30678232 99.69054958 95.40453942 98.50391686 94.94889195
 98.09334682 97.2831715  97.58409376 96.04658813 99.0387544  99.14474726
 98.89012073 99.25561336 99.3591696  99.28728938 99.39815548 99.25926828
 99.40424702 98.65742376 94.20694192 98.27974805 97.80704426 98.75367016
 95.09874392 99.31165556 98.33700856 98.49904363 99.28485277 98.65376884
 99.35673298 97.0736224  99.16180358 98.90474044 99.82212692 98.68422656
 99.10088815 96.97981262 98.09578343 98.38086768 99.31531049 99.18738807
 99.84527479 99.41399349]
Avg Prec: is [98.87914292 72.79407939 87.79753281 90.4486912  96.78409826 89.23975237
 95.95766889 80.44838607 86.68531303 86.14698239 80.12295683 79.93107534
 72.19282918 71.52092514 71.87994219 89.65125146 75.94022224 88.80698199
 88.98554527 85.79767874 94.70094901 88.98293969 97.58617157 98.24859331
 55.72023314 82.94903188 65.21047764 82.58059713 74.47991193 88.07285915
 94.67446655 83.20763326 86.40472187 93.0966145  95.54218893 95.70945966
 94.06901435 94.86998022 98.1293916  72.15245759 72.75085209 76.9506162
 81.06244221 76.49559611 68.13390772 80.25081279 84.6440828  74.09383514
 79.94418646 78.96861485 89.75292691 80.17326777 77.74099344 94.15454268
 81.13681224 86.71118162 84.24218818 87.87963208 73.00684328 91.16481493
 88.87023947 95.92091352 88.18560595 85.83584503 87.33783158 82.89963152
 88.66157962 65.49738923 75.52773362 87.92787212 32.88109755 91.98865747
 84.40531714 73.13046473 79.63796652 79.83396363 54.5813159  82.67176055
 39.30664547 67.19971435]
Accuracy th:0.5 is [93.31635823 98.29071283 95.53246184 99.02900793 99.59064826 98.76585324
 99.40181041 97.04316468 98.98393051 98.41498032 99.31896541 99.34333159
 99.64547216 96.8933127  98.34066349 98.79996589 97.87039632 99.11428954
 99.51511312 99.27754291 99.64303554 99.7210073  99.80872553 99.76242979
 96.02222195 98.4259451  95.54220831 98.44421973 98.83164191 99.24099365
 99.30069078 99.31896541 98.38086768 99.46759908 99.51511312 99.45176107
 99.24952181 99.29216262 99.72953546 94.99640599 98.5928534  94.97813136
 98.18471997 97.46713612 97.75100206 96.53878486 99.13378248 99.18129652
 98.91205029 99.22759226 99.41399349 99.24464858 99.42373996 99.34211328
 99.34211328 98.91083198 94.48593463 98.41619863 97.58409376 98.98149389
 95.80779961 99.42983151 98.35040996 98.66107869 99.32505696 98.6342759
 99.28363446 96.95666476 99.13500079 98.97052911 99.82943678 98.70128288
 99.08626844 96.91889719 98.02877645 98.32604379 99.34089497 99.16911344
 99.84527479 99.38353578]
Accuracy th:0.7 is [92.28688734 98.14207917 95.00249753 98.98027558 99.54800746 98.65498715
 99.37744423 96.77270014 98.88037426 98.19202982 99.2751063  99.32627526
 99.6235426  96.59117213 98.20055799 98.68666317 97.71079787 99.04362764
 99.4566343  99.19713454 99.61988767 99.70882421 99.80141567 99.74781009
 95.71520815 98.26512835 95.32291273 98.32117055 98.74148707 99.14718388
 99.24464858 99.17033175 98.133551   99.39937379 99.4700357  99.45541599
 99.21297255 99.26414152 99.69054958 94.61873028 98.44665635 94.63213167
 98.18350166 97.38916436 97.54267126 96.18060209 99.08992337 99.08261352
 98.84138838 99.16911344 99.41277519 99.1642402  99.40302872 99.32505696
 99.29581755 98.80727574 93.77444232 98.29436776 97.38794605 98.91083198
 95.37042677 99.38840901 98.27852975 98.53924782 99.31652879 98.5234098
 99.21540917 96.72396779 99.0801769  98.93154323 99.81969031 98.60990972
 98.99367698 96.5862989  97.93862161 98.20543122 99.3031274  99.09235999
 99.84527479 99.33602173]
Avg Prec: is [98.76878986 69.52329247 86.4511679  89.22834846 96.74158749 88.0992044
 95.38428287 77.78553397 85.69936401 83.93869278 78.2799948  78.36800302
 68.607712   67.03688644 68.11422165 88.14256639 72.80653042 87.40764473
 87.23708462 83.94163993 94.13425156 87.31259364 97.48290006 98.10785908
 51.92212447 80.17422826 61.24447602 79.88219164 70.02991548 85.98087165
 93.90442748 83.08229997 84.64892934 92.05216406 94.87519487 95.03201097
 93.79053416 93.81931537 97.9966934  68.04991812 67.21983052 73.72176873
 77.96843024 72.32660651 64.50390618 77.56363815 81.92331875 70.68733796
 77.48590901 75.93551151 88.54969391 78.24347538 73.33688805 93.16576742
 78.05278188 85.34585415 81.75484013 86.60432812 68.63557885 89.83005222
 87.63630118 95.44656446 86.3044723  83.94696325 86.58159375 79.60466061
 86.58621877 60.07934849 71.7925377  86.53979698 32.18765947 91.528481
 83.09589351 68.5193701  76.43990371 77.71069458 48.24197852 79.6031729
 25.73732938 62.04991419]
mAP score regular 82.22, mAP score EMA 79.84
starting validation
Accuracy th:0.5 is [90.80648778 97.86730448 93.43000224 98.69447144 99.43443705 98.30580263
 99.14791838 95.8591823  98.30580263 97.58078581 99.05573411 99.29242345
 99.46931759 95.54774896 97.95699728 98.32324289 97.19460847 98.73931784
 99.40703092 98.92368637 99.57146772 99.68358373 99.79569973 99.79071679
 95.28614495 97.66051274 94.4141316  98.04918155 98.27839649 98.73184344
 98.95109251 98.83897651 97.50105887 99.35221865 99.22266238 99.36965892
 98.94112664 98.89877171 99.49672372 92.19921768 98.15631462 93.51222064
 97.61317488 96.68385779 97.04013753 95.06938735 98.88880584 98.93614371
 98.31576849 98.93116077 99.22515385 98.78416424 99.09061464 98.92866931
 98.83399357 98.21860129 91.25246032 97.83491541 96.0161447  98.19617809
 93.37020704 99.11552931 97.61317488 98.00433515 98.98846451 97.74771408
 98.84645091 95.27119615 98.81157037 98.48269676 99.80317413 97.89969355
 98.34068316 95.76699803 97.55587114 97.24692927 99.29242345 98.89628024
 99.82559733 99.14293545]
Accuracy th:0.7 is [90.2284675  97.91215088 93.88344919 98.64962503 99.41699679 98.37307223
 99.07317438 95.87911403 98.54249197 97.68791888 99.11552931 99.30986372
 99.47679199 95.84921643 97.96696315 98.28088796 97.2444378  98.79163864
 99.40453945 98.94860104 99.58143359 99.66116053 99.80815706 99.77576799
 95.44809029 97.83740688 94.5935172  97.98191195 98.26843063 98.84395944
 98.77668984 98.93863517 97.38894287 99.34225278 99.20023918 99.33477838
 98.97600718 98.88133144 99.45686025 93.35774971 98.15382316 93.83361985
 97.55088821 96.74614446 97.09993273 94.97969455 98.88133144 98.96604131
 98.37058076 98.98597304 99.14542691 98.92617784 99.10307198 98.87883997
 98.98348158 98.17126342 91.6211974  97.78010315 96.49699778 98.13638289
 93.19829584 99.05324264 97.54341381 97.97443755 98.96604131 97.85983008
 98.92368637 95.89157137 98.84395944 98.46276503 99.81812293 97.94952288
 98.47771383 96.01116177 97.66798714 97.60320901 99.30986372 98.89378877
 99.82559733 99.17781598]
Avg Prec: is [97.65264413 52.98058815 74.86505783 82.12800866 90.71871448 77.93775244
 91.060566   58.47018114 75.51164436 70.26543303 66.76231868 70.14167182
 46.5057245  48.55942705 53.07989973 79.88318276 57.69892118 79.10523768
 80.06058294 70.15754163 92.15341493 86.11955523 97.07885678 97.57095515
 28.9749299  65.95864005 37.65079387 66.01159836 48.84709361 72.91365843
 88.14042498 62.40871657 68.35443389 88.59430072 83.90905288 89.44578693
 85.45552148 87.82063808 95.22918079 50.90737014 47.7681978  57.67069224
 56.1817982  45.82107221 35.97019523 56.23203172 64.27636056 44.95764916
 56.23971821 58.41179829 82.63713554 57.77537334 49.18991425 85.98947437
 57.18467822 59.71523558 60.19825475 70.72051712 47.30432435 76.25778146
 68.52418635 92.25325515 72.93781226 68.01072353 70.03849101 53.971747
 72.36366364 38.54018408 47.49240259 72.56503731  9.7889118  79.81053771
 62.02336195 47.95640933 69.58141872 58.10583507 24.6556777  65.28007505
  3.19200351 32.8052563 ]
Accuracy th:0.5 is [91.23003712 97.90716795 93.99058226 98.7044373  99.43692852 98.34815756
 99.16037571 95.92894337 98.6072701  97.68044448 99.11552931 99.28245758
 99.47679199 95.91399457 98.00931809 98.37307223 97.24942073 98.82153624
 99.44440292 98.92119491 99.58641652 99.68358373 99.8056656  99.80317413
 95.26372175 97.86730448 94.4739268  98.07409622 98.25846476 98.82901064
 99.11802078 98.95856691 97.47365274 99.35969305 99.24010265 99.36218452
 98.99344744 98.97600718 99.49672372 93.60440491 98.13389142 93.70406358
 97.38894287 96.66392605 96.95791913 95.20143508 98.86389117 98.94860104
 98.33320876 98.97600718 99.24757705 98.94112664 99.11303785 98.95358397
 99.05075118 98.23105862 91.6286718  97.79256048 96.68385779 98.24849889
 93.63679398 99.15539278 97.71034208 98.04918155 99.00590478 97.82744101
 98.90126317 95.90901164 98.83897651 98.51259436 99.80815706 98.00184369
 98.4727309  95.9563495  97.64556394 97.64805541 99.28744052 98.94610957
 99.8206144  99.15290131]
Accuracy th:0.7 is [90.93106112 97.93208262 94.06532626 98.75924957 99.45187732 98.32573436
 99.13546105 96.05102524 98.64962503 97.74023968 99.13296958 99.31484665
 99.48675785 95.98873857 98.02177542 98.34068316 97.2818098  98.83648504
 99.39706505 98.94361811 99.59638239 99.68109226 99.80815706 99.78573386
 95.55024043 97.83242395 94.65829534 98.04918155 98.28587089 98.86139971
 99.09310611 98.98099011 97.43628074 99.36467598 99.21020505 99.40204799
 98.99344744 98.92119491 99.46433465 93.81368812 98.14136582 93.90587239
 97.54590527 96.88068366 97.16720233 95.26372175 98.89129731 99.00341331
 98.40047836 98.99843038 99.20771358 98.92119491 99.13546105 98.96354984
 99.06320851 98.27590503 91.78065127 97.83491541 96.74614446 98.28587089
 93.74392705 99.13795251 97.72529088 98.07658769 99.00341331 97.87727035
 98.91372051 96.11829484 98.86139971 98.4876797  99.81563146 98.02924982
 98.53750903 96.06597404 97.67795301 97.76515435 99.29491492 98.90375464
 99.82559733 99.18030745]
Avg Prec: is [97.88020417 54.10092887 76.7499557  83.38042366 91.04384241 78.65609911
 91.51355411 61.33886785 77.02893993 72.09244947 67.98813117 71.02343642
 46.4537462  50.20015106 53.84941281 82.08087905 60.15702872 80.08112727
 80.87452597 70.58264122 92.1487816  86.91065167 96.8965217  97.88848209
 31.08048616 66.56077055 40.08153016 67.6641901  50.40362021 72.16456011
 88.25317414 63.99919108 68.44361688 88.38727538 85.1341328  90.25261354
 86.36026141 88.1711646  95.45317484 52.41337536 47.51507414 58.54035122
 55.88146055 48.88138816 39.52591732 59.24875057 65.71308949 47.3374648
 57.63144754 59.80570945 83.67255982 58.79750958 51.88802783 87.23147326
 57.61979895 62.66602492 63.51929132 72.13864376 49.16183785 77.9556621
 72.29003858 92.61679209 74.88520185 69.4452544  72.40077056 55.11475265
 74.40139474 39.90231808 49.59811527 74.37578652  8.87805023 82.20893406
 62.23079521 49.75685883 70.77149111 60.72374479 25.04176551 65.57456292
  3.37486996 32.95771648]
mAP score regular 64.97, mAP score EMA 66.21
Train_data_mAP: current_mAP = 82.22, highest_mAP = 82.22
Val_data_mAP: current_mAP = 66.21, highest_mAP = 66.21
lr:  [7.777542175590241e-05, 7.777542175590241e-05]
BCE Train Loss:  tensor([16.4693,  3.1411, 11.3641,  2.8053,  0.3134,  3.3462,  0.2975,  5.6301,
         3.1968,  4.5142,  0.9442,  0.3696,  0.4014,  6.9093,  8.5638,  2.1462,
         7.5235,  2.1699,  1.0656,  6.3017,  0.5593,  2.9549,  0.3124,  3.2971,
        18.9606,  4.9827, 10.2114,  8.6519,  2.1956,  1.0122,  0.5782,  2.3980,
         4.8034,  0.3429,  1.5745,  6.3735,  8.0502,  0.8222,  0.6215, 19.6340,
         5.8424, 27.3376,  1.6508,  7.1480,  8.3864, 22.9643,  0.3117,  6.8742,
         1.0125,  0.3010,  3.0080,  5.8212,  0.2387,  1.3640,  0.6808,  0.7155,
        17.2113,  2.5654, 11.7337,  6.5690,  6.2324,  2.7281,  5.9295,  6.7500,
         0.3099,  3.5404,  0.5524, 12.1460,  1.4468,  6.3572,  2.1141,  2.7625,
         6.0846,  7.5685, 11.1247,  5.9264,  0.2793,  0.6300,  0.2291,  3.5222],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [36/80], Step [000/642], LR 7.8e-05, Loss: 403.8
BCE Train Loss:  tensor([15.4012,  3.4554, 10.1271,  1.8489,  2.0296,  2.9947,  1.0668,  5.7917,
         4.0851,  3.8712,  3.9791,  0.6206,  0.6825, 10.8761,  3.0605,  2.6643,
         9.4311,  2.5480,  0.3662,  1.1718,  2.2602,  0.1693,  0.2715,  1.0990,
        21.3560,  6.6620,  8.5485,  9.0890,  1.0391,  0.5486,  2.9622,  0.8447,
         5.3063,  0.5381,  2.3399,  6.8633,  0.5604,  0.7862,  2.9371, 13.1191,
         1.5054, 14.2910,  2.5908,  7.5876,  8.2092,  7.2952,  0.8828,  3.1398,
         5.1689,  1.2599,  1.7948,  3.1403,  0.8507,  2.1506,  0.3366,  3.1031,
        24.7919, 12.8889,  1.4459,  2.2255, 12.8377,  1.5622,  3.5641,  0.8612,
         0.4281,  5.9052,  5.3469, 13.6032,  1.1179,  1.7353,  0.1747,  5.6732,
         0.6659,  5.5483,  2.0796,  2.3314,  0.9146,  0.7642,  2.6461,  2.3789],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [36/80], Step [100/642], LR 7.7e-05, Loss: 348.2
BCE Train Loss:  tensor([27.0091,  1.7653, 24.5906,  4.7870,  1.4756,  9.3545,  9.3462, 12.2927,
         4.5472,  7.0387,  0.8491,  4.2958,  5.4337,  7.7826,  8.9414,  6.2691,
        13.0239, 21.8069,  0.3992,  1.1478,  1.0156,  0.2583,  0.1699,  0.0579,
        13.2898,  5.1145, 20.7585,  5.1830,  8.1295,  3.1380,  7.8750,  2.7330,
         4.0993,  0.5429,  0.4967,  0.7095,  0.6818,  0.5977,  0.1677, 20.0156,
         5.2449, 16.7988,  5.2183,  5.1385,  3.6983, 15.2031,  1.0906,  2.4103,
         4.3506,  4.4836,  0.3450,  2.8282,  5.5595,  0.5171,  0.6191,  9.9641,
        14.7146,  1.7223, 15.1735,  1.6136, 10.3605,  1.4545,  4.9605,  7.5355,
         0.5201,  1.4034,  1.0900,  4.2281,  3.5569,  3.5362,  0.3160,  6.4317,
         9.6535, 10.4531,  9.3135,  5.5941,  0.6764,  4.7314,  0.1269,  1.1546],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [36/80], Step [200/642], LR 7.7e-05, Loss: 471.0
BCE Train Loss:  tensor([19.6657,  4.1872,  8.1622,  7.5185,  0.2738,  1.2660,  0.3879,  6.2455,
         6.6994,  4.6038,  0.9770,  0.5813,  0.2936, 17.7896,  6.1987,  6.4336,
        14.9933,  0.8604,  3.2998,  3.9144,  0.5150,  0.4583,  0.1923,  0.4183,
        24.2092,  4.4549, 16.8531,  7.7497,  0.7715,  1.5767,  2.9037,  1.0612,
         6.4424,  0.5665,  3.6272,  0.4114,  0.5353,  1.2878,  0.1887, 11.9971,
         2.5306, 15.2346,  5.4273,  8.0125,  6.0652,  7.4276,  2.7139,  4.2440,
         5.0906,  4.6636,  3.0603,  3.5108,  6.6229, 12.5484,  2.5870,  5.1629,
        21.1232,  2.9576,  5.3965,  1.6362, 14.2595,  4.9769,  3.2174,  1.3171,
         0.8958,  8.0540,  1.1039,  7.0122,  4.5294,  7.8281,  0.1613,  6.4484,
         1.1893,  4.7630,  2.8241,  5.2728,  2.1922,  1.2561,  0.1384,  1.9567],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [36/80], Step [300/642], LR 7.7e-05, Loss: 406.0
BCE Train Loss:  tensor([21.3428,  3.4511, 13.9006,  7.4910, 10.5495,  2.7822,  5.5797, 10.3116,
         2.4165,  1.4695,  3.0396,  5.5716,  0.1518,  8.1054, 22.3887,  1.6849,
         9.2620,  1.9661,  0.8933,  1.7292,  3.6719,  0.0934,  0.3534,  0.0959,
         7.4152,  9.2965,  9.1704,  1.6493,  1.0544,  1.5137,  4.7337,  4.0952,
         3.1641,  1.2548,  0.2980,  0.5650,  1.7768,  3.5443,  0.1697, 16.7919,
         5.9426, 14.5029, 10.3760,  6.6553, 13.3033,  8.8894,  3.9280,  7.6423,
         1.5269,  6.5278,  2.4085,  7.7681,  4.9988,  2.2969,  2.6781,  4.1697,
        20.3629,  6.4037,  5.8243,  1.0309, 15.0217,  0.6910,  4.6052,  3.6845,
         2.0246,  8.5400,  4.5711, 10.8251,  4.2031,  1.0442,  2.2561,  5.3804,
         2.3362, 16.0806, 11.8007,  4.2676,  5.5903,  3.7732,  0.1208,  3.3162],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [36/80], Step [400/642], LR 7.6e-05, Loss: 452.2
BCE Train Loss:  tensor([10.5860, 11.3404, 17.6141,  4.4470,  0.3848,  4.9397,  4.2886,  7.9746,
         7.3290,  3.4794,  0.9715,  0.8315,  0.3161,  7.3982,  4.6201,  3.8924,
         4.9220,  9.0295,  2.0462,  1.0156,  0.2890,  0.2552,  0.1334,  0.2110,
        15.2246, 19.2061, 14.6580,  2.5252,  1.3077,  2.3303,  0.5184,  0.7127,
         2.7778,  5.9688,  0.6004,  1.2882, 11.0795,  0.9788,  0.4074, 17.9707,
         4.4320, 15.2562,  3.7864,  4.2932,  6.8337, 12.2089,  7.0119,  1.2595,
         3.2465,  5.4490,  0.7648,  3.5292, 10.6720,  1.1979,  1.1708,  9.1244,
        16.1717,  3.2646,  6.0489,  5.2456, 11.6544,  1.0358,  7.6338,  4.3595,
         3.0059,  2.4074,  1.7212, 13.6205,  2.6917,  2.6692,  0.3408,  2.1647,
         2.8395,  7.6287,  9.1114,  2.5190,  7.5301,  4.3645,  0.0777,  0.4236],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [36/80], Step [500/642], LR 7.6e-05, Loss: 414.6
BCE Train Loss:  tensor([21.9393,  4.6883, 24.0488,  7.1926,  3.4048,  2.2760,  1.6267, 13.2490,
         3.6657,  4.0540,  2.4996,  1.2642,  0.2965, 15.0427, 14.2488,  0.9591,
        15.2630,  6.6912,  5.0655,  5.3291,  3.3234,  5.2301,  9.9337,  5.6481,
        17.8537,  9.2078, 12.5034,  7.9862,  1.4788,  0.5903,  0.2196,  1.5438,
         7.2371,  1.1246,  0.8282,  0.6250,  2.5987,  2.5149,  0.8798, 11.5408,
         4.5085, 11.5010, 10.6925,  8.8064,  5.4920,  9.7815,  1.3931,  0.8928,
         6.5280,  0.6719,  1.3873,  1.8664,  1.1868,  0.8382,  0.4102,  3.9053,
        14.4129,  9.9498,  7.0448,  3.3640,  9.0856,  0.3739,  2.0232,  6.6566,
         0.7474,  1.9977,  1.0405, 10.6438,  0.7679,  3.4475,  0.1181,  4.5612,
         1.4997,  9.8123,  8.4211,  1.0571,  0.4632,  4.9055,  0.1235,  1.8598],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [36/80], Step [600/642], LR 7.6e-05, Loss: 429.9
BCE Val Loss:  tensor([6.0172e+01, 1.6607e+01, 4.8718e+01, 2.1236e+01, 4.6568e-02, 9.6722e+00,
        6.0420e+00, 2.4163e+01, 5.1493e+00, 8.1098e+00, 6.4295e+00, 1.4085e+01,
        7.9678e+00, 1.7609e+01, 7.5362e+00, 1.7435e+01, 2.6439e+02, 1.3435e+00,
        1.4240e+00, 3.0206e+00, 9.9612e-02, 3.1142e-01, 3.9664e-02, 1.5763e-02,
        2.3017e+01, 1.3759e+01, 3.4062e+01, 2.1246e+00, 1.6358e+01, 1.8126e+01,
        1.3581e+00, 2.6141e+00, 1.0814e+01, 5.1868e-01, 1.1717e-01, 2.2393e-01,
        1.2178e+01, 4.3189e+00, 7.9458e+00, 4.5699e+01, 1.2814e+01, 2.1467e+01,
        7.7964e+00, 2.0205e+01, 1.7710e+01, 1.7039e+01, 2.9851e-01, 3.9193e+00,
        2.3350e-01, 4.2941e+00, 3.2578e-02, 1.0031e-01, 2.6940e+00, 2.2497e-01,
        3.0377e-01, 2.4630e-01, 2.3037e+01, 8.1253e+00, 1.0117e+01, 1.1369e+00,
        9.9938e+00, 3.3404e+00, 3.4356e+00, 7.1294e+00, 7.4509e-02, 7.2443e-01,
        1.5633e-01, 7.3587e+00, 1.0169e+01, 1.5405e+01, 3.8338e-01, 1.7882e+01,
        1.1632e+01, 9.7821e+00, 1.9072e+01, 9.0854e+00, 3.3222e-01, 1.1075e+01,
        1.7768e-01, 3.6437e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [36/80], Step [000/314], LR 7.6e-05, Loss: 1024.2
BCE Val Loss:  tensor([6.5265e+01, 1.6634e+01, 5.3046e+01, 1.0677e+01, 8.6601e-01, 4.2488e+01,
        2.7765e+01, 3.6233e+01, 2.5527e+01, 3.8639e+01, 1.5834e+01, 4.4620e+01,
        1.0817e+01, 5.9256e+00, 1.8476e+01, 1.5000e+00, 9.2528e+00, 1.9015e+01,
        5.8622e+00, 1.3490e+01, 6.9028e-02, 5.9853e-02, 1.2806e-01, 1.5978e-02,
        3.3371e+01, 2.3989e+01, 4.4943e+01, 1.6521e+01, 1.6615e+01, 8.0516e-01,
        8.6509e-02, 1.3493e-01, 5.7569e-01, 1.1188e+00, 2.9600e-01, 9.7454e-02,
        1.1152e+00, 1.4906e+00, 5.0348e-01, 5.7237e-01, 2.7977e-02, 2.9687e+00,
        1.0991e-01, 8.9842e-01, 1.0239e+00, 1.5799e+00, 2.0470e-01, 8.0545e-02,
        5.8387e-02, 8.0263e+00, 1.7379e-02, 5.8574e-02, 3.5512e-02, 6.9545e-01,
        4.8747e-02, 1.7520e+00, 1.2488e+01, 8.5272e+00, 4.7014e+00, 8.5349e-02,
        1.5229e+00, 1.3924e-01, 4.5253e-01, 3.9461e-02, 1.2188e-02, 5.2681e-02,
        1.4830e-02, 2.2365e+01, 6.5099e-02, 4.4334e+00, 1.5147e-02, 2.1537e-01,
        2.4874e+00, 3.1521e+00, 2.1497e+00, 5.1077e-02, 7.4195e-01, 6.3465e-01,
        4.7532e-03, 4.4045e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [36/80], Step [100/314], LR 7.6e-05, Loss: 686.4
BCE Val Loss:  tensor([1.2279e+01, 2.6910e-01, 3.4650e+00, 1.1361e-01, 2.0154e-02, 2.0450e-02,
        3.6665e-02, 1.6780e+01, 5.5656e-02, 1.4596e-02, 1.0402e-02, 2.4815e-02,
        5.0580e-03, 1.0685e+01, 2.9428e-01, 4.0155e-01, 7.9116e-01, 5.4525e-02,
        2.6466e-02, 1.2652e-02, 1.1618e-02, 1.2867e-02, 7.0210e-03, 3.7712e-03,
        4.5630e+00, 1.2171e+00, 3.1909e+01, 5.5510e+00, 4.6740e-01, 6.0177e-01,
        1.0712e-01, 6.7921e+00, 1.0851e+01, 4.9922e-02, 1.4040e-01, 2.5808e-01,
        9.6589e+00, 6.0134e+00, 1.0746e-01, 3.5879e+01, 1.5712e+01, 6.7591e+01,
        6.1087e+01, 5.1748e+01, 4.9203e+01, 6.4176e+01, 1.0778e+01, 6.7810e+00,
        4.0897e+01, 9.7794e+00, 2.9713e+01, 4.0303e+01, 5.7145e+01, 2.4819e+01,
        5.2887e+01, 9.8651e+01, 1.4202e+02, 9.8584e+00, 7.7659e+00, 1.8302e-01,
        7.9127e+01, 2.7933e-01, 1.4204e+01, 7.7407e+00, 1.5049e+01, 2.9376e+00,
        1.1379e+01, 1.7774e+01, 7.5422e+00, 3.8761e+00, 2.3135e-01, 1.5437e+01,
        5.4306e+00, 4.4697e+01, 1.8132e+00, 1.6828e+01, 1.1226e+01, 1.6811e+00,
        8.4881e-02, 1.8609e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [36/80], Step [200/314], LR 7.6e-05, Loss: 1258.2
BCE Val Loss:  tensor([3.2863e+01, 9.1899e-01, 1.2422e+01, 4.9603e-01, 4.5595e-01, 9.2020e+00,
        8.2464e+00, 1.6980e+01, 8.4532e-01, 1.9172e+01, 5.3448e+00, 8.2243e+00,
        2.9195e-01, 1.0109e+01, 1.6933e+01, 9.6903e-02, 5.8318e-01, 3.8888e-01,
        2.5486e-02, 6.0777e-02, 1.0988e-01, 3.8874e-02, 1.7670e-02, 3.5208e-02,
        2.1863e+01, 7.1457e+00, 2.9995e+01, 1.8593e+00, 1.8819e+01, 2.6319e-01,
        2.0929e-01, 4.4635e-02, 3.9055e-02, 1.5618e-01, 1.8091e-02, 3.4306e-02,
        1.7286e-01, 4.5922e-02, 3.4554e-02, 1.5285e+00, 5.2729e-01, 1.0780e+00,
        4.0077e-02, 1.0461e-01, 7.7914e-02, 3.3504e-01, 3.2847e-02, 5.0057e-02,
        2.6565e-02, 2.2997e-02, 3.3334e-02, 4.4512e-02, 1.8932e-02, 1.6681e-01,
        5.3259e-02, 7.3932e-02, 4.3114e+00, 3.2953e+00, 1.2139e+01, 1.4814e-01,
        7.5516e+00, 3.5085e-01, 1.3043e+00, 2.9716e-02, 2.7719e-02, 8.9437e-01,
        1.8719e-01, 6.2943e+00, 5.3455e-02, 1.0006e-01, 9.8683e-03, 1.6864e-01,
        1.4191e-01, 5.8681e+00, 3.8316e+01, 1.7602e+00, 4.7187e-02, 4.8795e+00,
        1.2828e-02, 9.5262e-03], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [36/80], Step [300/314], LR 7.6e-05, Loss: 316.7
starting validation
Accuracy th:0.5 is [93.79028033 98.4673676  96.00516563 99.05459241 99.54191591 98.85966302
 99.43226813 97.39160098 98.99124036 98.64280406 99.33967666 99.42373996
 99.67349326 97.13453783 98.42472679 98.88646581 98.02877645 99.17033175
 99.56506378 99.33236681 99.6649651  99.75268333 99.80019737 99.76242979
 96.16232746 98.58188862 95.26565222 98.64036744 98.94981786 99.28241615
 99.37013438 99.36647945 98.42350849 99.54313422 99.51145819 99.5126765
 99.36160622 99.40912026 99.69420451 95.31438457 98.57579708 95.44474361
 98.30655085 97.85333999 97.8959808  96.88722116 99.18616976 99.23612042
 99.0107333  99.27023306 99.44688783 99.28241615 99.49927511 99.42008504
 99.40546533 98.99245867 94.58339933 98.44300143 97.49759384 99.10332476
 96.22933444 99.45541599 98.54899429 98.76707155 99.34211328 98.73783214
 99.32018372 97.3660165  99.21662748 99.09723322 99.82578185 98.79631096
 99.11672616 97.30510106 98.24076217 98.25294526 99.39084563 99.26779644
 99.85258464 99.44810614]
Accuracy th:0.7 is [92.11997905 98.33335364 95.42037743 98.9412897  99.43592305 98.73295891
 99.36526114 97.11260828 98.83529684 98.42107187 99.27876122 99.39206394
 99.65034539 96.89696763 98.27852975 98.76219832 97.81557242 99.03144455
 99.49927511 99.32018372 99.62719752 99.71369745 99.80750722 99.75024671
 95.81754608 98.51488164 94.70279358 98.579452   98.8158039  99.33480343
 99.18129652 99.27266968 97.92522021 99.4846554  99.39084563 99.48709202
 99.33602173 99.34089497 99.70882421 94.48349801 98.39061415 94.86604695
 98.01172013 97.61211486 97.83506536 96.47665111 99.08261352 99.22150071
 98.87428272 99.25926828 99.43592305 99.15814866 99.47856386 99.40668364
 99.36404284 98.79387434 93.3395061  98.47345914 97.20885467 99.00707837
 95.67865889 99.40912026 98.27609313 98.58798017 99.32140203 98.70250119
 99.25195843 97.13575614 99.11063462 99.00951499 99.82334523 98.57579708
 99.03388117 96.93717182 98.15669887 97.9800441  99.36526114 99.23490211
 99.85014802 99.34942313]
Avg Prec: is [99.00334811 75.06175364 88.81681256 90.58789164 96.77398843 89.80891299
 95.96726076 82.01958652 87.16980506 87.70422624 82.14887427 83.46768715
 72.59333539 72.38111881 73.49537689 90.30623506 78.0435104  89.78745232
 89.42170353 86.01424462 95.52964114 90.12424203 97.85556095 98.11885738
 57.40205531 83.73977731 65.72819567 83.83566116 75.39055432 88.28541184
 95.13161412 85.44919802 87.92363908 94.17286436 96.04024528 96.01748349
 94.88438307 95.59246339 98.04852024 74.75745396 73.00011868 77.64283165
 81.61168928 78.04540887 69.24567958 81.51847143 84.32391109 76.50113474
 81.34339122 80.13558808 89.78477293 81.66941008 78.95460091 94.50968624
 82.23097133 88.05277061 85.56815765 88.19202874 73.19418911 91.97931143
 89.70393505 96.04353212 88.91098275 86.56572047 87.30906269 83.02948167
 88.33755538 68.71768617 75.74578638 89.08052901 35.35881408 92.92490681
 85.87075427 75.46807303 80.48533197 80.89338772 55.50604492 83.3739931
 33.08884533 70.28653264]
Accuracy th:0.5 is [93.6599213  98.32604379 95.722518   99.02900793 99.55897223 98.80727574
 99.44810614 97.15159416 98.97783896 98.48320561 99.32993019 99.37988085
 99.6661834  96.96397461 98.38208599 98.83895177 97.93862161 99.14840219
 99.52851452 99.30434571 99.66009186 99.74293686 99.81481707 99.75024671
 96.03440504 98.43812819 95.61530683 98.52097319 98.8292053  99.25561336
 99.33845835 99.33967666 98.43569157 99.49683849 99.52364128 99.46272584
 99.34089497 99.37013438 99.70273267 95.30098318 98.61234634 95.15478613
 98.25903681 97.68886831 97.80826257 96.61675662 99.14718388 99.20688101
 98.97418404 99.25195843 99.40912026 99.26535983 99.45054276 99.36404284
 99.36526114 98.92545169 94.66624432 98.43447326 97.6316078  99.01560654
 95.90039108 99.41643011 98.46493098 98.67813501 99.31896541 98.65864207
 99.25926828 97.09189703 99.16667682 99.0241347  99.82212692 98.7463603
 99.01804315 97.03463652 98.12502284 98.35284658 99.36891607 99.20200777
 99.8464931  99.42252166]
Accuracy th:0.7 is [92.48668998 98.19081152 95.24615928 99.0107333  99.5406976  98.71590258
 99.42252166 96.81655925 98.90108551 98.38817753 99.28850769 99.35673298
 99.64059892 96.66548897 98.2578185  98.75854339 97.78633301 99.07164874
 99.46028923 99.24221196 99.64912708 99.71613406 99.80994384 99.74415516
 95.75663065 98.31629732 95.31925781 98.45518451 98.75245185 99.17033175
 99.29216262 99.20444439 98.16400872 99.42008504 99.48831033 99.44932445
 99.28119784 99.32627526 99.68202142 94.83193431 98.45031128 94.63822322
 98.20421291 97.51830509 97.62673457 96.28050341 99.07286705 99.12525432
 98.84260669 99.20322608 99.37500761 99.18738807 99.42008504 99.36282453
 99.29947247 98.82311375 93.98642804 98.32238886 97.44764318 98.94494463
 95.50687735 99.37988085 98.32482548 98.58554355 99.31409218 98.52462811
 99.22150071 96.85554513 99.11794447 98.9961136  99.81969031 98.67326178
 98.96565588 96.66792559 97.99466381 98.19446644 99.32383865 99.13987403
 99.84405648 99.37988085]
Avg Prec: is [98.87394434 71.362758   87.26984976 89.39565873 96.32767628 88.65226538
 95.43132827 79.22774036 85.82735264 85.66696474 79.72602853 81.35217437
 69.00781316 68.38223583 69.68582207 89.12168879 74.42267075 88.28383157
 88.01909003 83.94970061 94.88606172 87.93690521 97.79557957 97.96318887
 53.16532093 80.96284919 62.25127482 81.51333827 70.77169161 86.03798937
 94.32149877 83.80009695 85.74328834 92.96041473 95.23431815 95.1045689
 94.38152791 94.72545026 97.90081098 70.40945347 68.68258891 74.6231362
 79.20266819 75.1726696  66.29696244 78.63308978 82.3283152  73.44643805
 78.95390892 77.91717263 88.92596804 79.2465228  75.2915055  93.76452042
 78.98562524 85.57254734 82.91702804 86.71941145 69.37629286 90.58644177
 88.38446934 95.67050952 86.88056938 84.53158058 86.21365182 80.59793331
 86.34976349 63.45652829 72.6412142  87.40765571 31.97777316 92.16179745
 83.04474715 70.36783849 77.9948039  78.37145745 50.88677866 81.24143947
 25.3590175  65.18519611]
mAP score regular 83.11, mAP score EMA 80.79
starting validation
Accuracy th:0.5 is [90.88621471 97.85733862 93.91832972 98.75924957 99.42447119 98.32822583
 99.17781598 95.80437003 98.62720183 97.67795301 99.17532451 99.25754292
 99.47430052 95.80935297 98.00433515 98.35064903 97.26187807 98.8090789
 99.42696265 98.87385704 99.62627999 99.67361786 99.80317413 99.78573386
 95.34843162 97.82993248 94.62590627 98.06662182 98.23355009 98.72187757
 99.11552931 98.89628024 97.48112714 99.36965892 99.20273065 99.34723572
 98.92617784 98.97102424 99.51167252 93.67665745 98.16129756 93.62184518
 97.52846501 96.51942098 96.83583726 95.01706655 98.82153624 98.87634851
 98.35314049 99.02832798 99.23511971 98.91621197 99.01088771 98.95358397
 99.04327678 98.24849889 91.5090814  97.62064928 96.75361886 98.25348182
 93.51222064 99.07815731 97.66300421 98.11645115 99.00341331 97.73027381
 98.88133144 95.70720283 98.84894237 98.49764556 99.80317413 97.98191195
 98.50761143 95.92146897 97.55836261 97.79505195 99.20771358 98.89129731
 99.82310586 99.17781598]
Accuracy th:0.7 is [90.4302763  97.93208262 93.96317612 98.74430077 99.36716745 98.31576849
 99.11054638 95.95385804 98.58982983 97.69539328 99.15788425 99.29491492
 99.48177492 95.9339263  98.01430102 98.28337943 97.2743354  98.76174104
 99.39457359 98.94610957 99.61133119 99.65866906 99.81314    99.79071679
 95.50788549 97.87727035 94.53621347 98.07409622 98.27590503 98.83648504
 99.00092184 98.95358397 97.34409647 99.37215038 99.15539278 99.33228692
 98.94610957 98.88880584 99.51914692 93.61686225 98.11395969 93.80372225
 97.52597354 96.72621272 97.04761193 95.06440441 98.84894237 98.99843038
 98.38552956 99.00839624 99.21518798 98.91870344 99.08563171 98.94860104
 99.07317438 98.22607569 91.20512246 97.78010315 96.68884072 98.22109276
 93.53215238 99.10805491 97.56832847 98.03174129 98.99843038 97.87477888
 98.88133144 96.0011959  98.88133144 98.43785036 99.81314    97.86481302
 98.5175773  96.04853377 97.69041034 97.74273115 99.29491492 98.92866931
 99.82559733 99.18279891]
Avg Prec: is [97.69548138 52.98404148 75.88598584 82.34105978 91.16666558 77.99085274
 91.23804318 59.79682972 75.91200486 70.87427196 67.55586569 70.36407781
 46.95209113 47.86426362 54.19548075 81.67264443 58.86853888 79.54300625
 80.46209632 70.85222552 92.17430934 85.52745112 96.65034495 97.74223364
 28.91584808 65.82094727 37.35089944 66.67687088 49.26680063 73.65732479
 88.24021906 63.26162359 68.56023285 88.96409714 84.68684164 89.55943095
 85.5297519  87.92324218 95.70981606 49.65986495 47.21098744 57.32715607
 55.82141184 45.87506253 38.01347719 56.98704478 63.57282049 46.94971101
 55.8037368  59.39565154 82.90740751 56.36525619 50.77361603 86.30395786
 56.83365059 61.0276326  60.73271304 70.7094149  47.68940471 76.79579504
 70.69998458 91.98102682 73.56757181 68.70235592 71.73918439 53.98595566
 73.4755868  38.29445757 50.18735235 72.7493838   9.06556939 80.1382635
 61.01925008 48.20924126 69.55580038 58.98560673 25.22091057 65.3235293
  3.21474976 31.86741553]
Accuracy th:0.5 is [91.22256272 97.89969355 93.99058226 98.71689464 99.44689439 98.35064903
 99.17532451 95.9339263  98.60976157 97.68542741 99.13795251 99.27747465
 99.48426639 95.8890799  98.01430102 98.4054613  97.26935247 98.82651917
 99.45686025 98.92368637 99.58641652 99.68358373 99.80815706 99.80068266
 95.23631562 97.86730448 94.42409747 98.08406209 98.26593916 98.83897651
 99.11552931 98.96105838 97.49607594 99.35969305 99.24259412 99.36716745
 98.99843038 98.97849864 99.50170665 93.60938785 98.14884022 93.68911478
 97.40638314 96.66392605 96.96539353 95.17901188 98.85143384 98.95856691
 98.33819169 98.99344744 99.25006852 98.94112664 99.09559758 98.97351571
 99.05075118 98.23853302 91.64611207 97.80501781 96.67389192 98.27092209
 93.60440491 99.14293545 97.70286768 98.07160475 99.00341331 97.83491541
 98.90375464 95.9040287  98.83150211 98.52754316 99.80815706 98.01679249
 98.48269676 95.98873857 97.65552981 97.62314074 99.28494905 98.93365224
 99.8206144  99.14044398]
Accuracy th:0.7 is [90.98338192 97.93457408 94.11017266 98.76921544 99.45187732 98.33071729
 99.13047811 96.04105937 98.65460797 97.72778235 99.14791838 99.30488078
 99.48426639 95.99621297 98.02177542 98.36559783 97.28430127 98.84894237
 99.41201385 98.93365224 99.59389092 99.68607519 99.80317413 99.78573386
 95.54276603 97.83989835 94.67822707 98.06413035 98.29085383 98.85641677
 99.09808905 98.98348158 97.42880634 99.37464185 99.23262825 99.39706505
 99.00092184 98.92368637 99.47928345 93.83361985 98.14884022 93.90587239
 97.55587114 96.86324339 97.15972793 95.24379002 98.90375464 99.00590478
 98.40047836 99.00092184 99.20771358 98.92866931 99.13546105 98.96105838
 99.06819144 98.28836236 91.7482622  97.84986422 96.74365299 98.29832823
 93.71901238 99.14542691 97.72279941 98.08904502 99.00341331 97.87976182
 98.90873757 96.08839724 98.85143384 98.50013703 99.81563146 98.02177542
 98.53003463 96.06846551 97.68044448 97.76515435 99.30986372 98.93116077
 99.82559733 99.17781598]
Avg Prec: is [97.88642329 54.21044755 76.6928826  83.41709615 91.08026272 78.67826488
 91.59888377 61.24943466 77.10143673 72.16142465 68.17249105 71.0427302
 46.76200689 50.22271311 54.11267137 82.16536214 60.39514458 80.33775286
 81.20208819 70.9107061  92.22283136 87.0068663  96.93586403 97.88912631
 30.97008446 66.77669172 39.97966265 67.86898062 50.60360213 72.81645732
 88.3627917  64.15592988 68.58912749 88.6419678  85.10429359 90.25981472
 86.19151346 88.59451996 95.56478654 52.38265883 47.9245493  58.56138416
 56.21482296 48.79565899 39.40982982 59.22080032 65.84596154 47.40063747
 57.74401148 60.02595336 83.6179747  58.92607131 52.09950118 86.99295722
 57.73568151 62.87048488 63.48323372 72.30935785 49.2556373  78.0487159
 72.20858548 92.62690234 74.93632701 69.72159757 72.30798331 55.28150217
 74.4359278  39.98509545 49.84105723 74.31163929  8.94002951 82.13814232
 62.4096873  49.76812308 70.82357074 60.53577085 25.29218392 65.74356498
  3.33167069 33.1320645 ]
mAP score regular 65.31, mAP score EMA 66.31
Train_data_mAP: current_mAP = 83.11, highest_mAP = 83.11
Val_data_mAP: current_mAP = 66.31, highest_mAP = 66.31
lr:  [7.570195522626184e-05, 7.570195522626184e-05]
BCE Train Loss:  tensor([15.4837, 10.8311, 15.1475,  6.5943,  2.8547,  4.7478,  3.4564,  7.7497,
         3.6123,  5.4993,  5.3246,  4.8555,  0.6634, 12.0658,  2.5703,  4.2083,
         7.0964,  0.4161,  0.4559,  0.4390,  2.2593,  0.3096,  0.0546,  0.3521,
        10.6672,  5.9086, 16.1897,  2.6472,  6.1669,  1.0366,  0.5098,  2.2089,
         3.6021,  0.7203,  0.2942,  3.3563,  0.4239,  0.8380,  0.3883, 16.2983,
         1.3890, 18.2278,  6.9964, 13.8113, 12.1610, 11.2580,  6.9809,  0.5981,
        11.6891,  2.0515,  4.2307,  2.0134,  6.0232,  4.5388,  1.1003,  2.5004,
        15.8542,  2.3709,  4.7177,  6.1672, 11.6196,  1.0053,  5.7637,  3.3079,
         1.1245,  5.2927,  5.5589, 17.5051,  3.1736,  7.6529,  0.1873,  4.2783,
         2.6280,  5.9765,  5.3620,  4.0641,  5.0022, 10.6271,  0.9077,  2.1960],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [37/80], Step [000/642], LR 7.6e-05, Loss: 426.2
BCE Train Loss:  tensor([11.5893,  7.6783, 13.1225,  0.9451,  0.4602,  5.8572,  5.0527,  5.7712,
         2.6918,  4.1559,  0.6611,  2.5885,  0.1980, 15.0405,  9.5355,  5.6612,
        13.0320,  1.9832,  3.4754,  2.0861,  0.4847,  8.8249,  0.1015,  0.1877,
         9.6959,  7.6469,  8.7727,  3.7670,  4.7740,  0.9025,  2.3186,  3.8817,
         4.0413,  0.3718,  4.3137,  0.3321,  1.3528,  0.4411,  0.0674, 36.1705,
         2.1191, 15.5722,  5.8647, 14.0393,  7.5939, 11.8634,  2.1069,  3.5563,
         2.7043,  6.7610,  3.0936,  1.2439,  0.7331,  0.5601,  0.7123,  3.6440,
        15.6928,  6.5735,  7.1861,  2.7346, 13.4124,  1.9565,  2.7429,  1.5578,
         1.2312,  6.5257,  2.5227,  7.6956,  2.5425,  4.2387,  0.7538,  4.2761,
         2.7425, 13.1281, 20.1225,  6.1372,  1.8434,  4.0413,  1.7659,  5.3415],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [37/80], Step [100/642], LR 7.5e-05, Loss: 429.0
BCE Train Loss:  tensor([24.8768,  6.4926, 13.9374,  5.7487,  0.5659,  6.5571,  1.6357,  3.1053,
         1.7732,  1.9477,  1.3073,  3.9837,  5.8038, 13.5196,  8.1040,  2.3332,
         7.2671,  5.5989,  0.3925,  1.9203,  0.2900,  0.1574,  1.3218,  0.3976,
        24.0226,  7.5498,  9.9245,  3.9212,  2.6849,  1.2783,  0.7515,  5.6157,
         4.4775,  6.3747,  1.4412,  0.3122,  2.3258,  2.3422,  0.5584, 16.1923,
         1.3317, 10.4367,  2.6785,  4.4106,  3.3971, 13.4065,  0.9521,  9.0600,
         4.1906,  4.3368,  0.4323,  3.2321,  0.5221,  3.2477,  1.3382,  1.4971,
        18.0813,  4.5545,  5.4869,  4.9096,  5.2798,  0.3516,  5.8867,  1.5798,
         0.5989,  3.4167,  1.5671, 10.9198,  2.2617,  3.4464,  0.1332,  1.4889,
         1.3410,  7.1998,  7.7363,  9.4336,  0.5655,  6.3379,  0.1169,  4.7983],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [37/80], Step [200/642], LR 7.5e-05, Loss: 380.8
BCE Train Loss:  tensor([14.6972,  1.8474,  6.2358,  5.3561,  1.5975,  1.0161,  0.4249, 13.2936,
         1.9339,  1.1111,  4.2320,  1.1727,  0.4537,  4.6221,  1.4527,  1.6778,
         6.0838,  4.4486,  0.5499,  5.1048,  0.1817,  2.3580,  0.1538,  0.1335,
        10.9872,  6.6922,  9.2911,  3.4327,  2.7079,  1.6432,  3.0502,  2.3731,
         2.3820,  2.0206,  6.2321,  3.9806,  0.9640,  1.2288,  6.6318, 12.2819,
         7.1106, 16.2600, 10.4682,  9.5783, 10.3741, 10.7827,  5.8755,  0.6381,
         6.2521,  3.2919,  1.6264,  0.5024,  6.9650,  3.8831,  0.6437,  5.6953,
        18.7058,  1.4522,  3.4659,  1.5484, 13.6363,  7.2136,  4.8559,  6.2075,
         1.1116,  1.9280,  0.6400,  3.9076,  3.8881,  0.9000,  0.2267,  4.8956,
         2.7977, 10.6938,  3.3889,  4.6152,  3.3686,  1.4303,  0.3129, 10.6958],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [37/80], Step [300/642], LR 7.5e-05, Loss: 367.9
BCE Train Loss:  tensor([18.2379,  5.8157, 41.3623,  5.6807,  0.2032, 12.5222,  0.7919, 24.5956,
         7.5669,  1.5118,  0.3641,  6.5124,  0.2024, 13.6664,  1.5548,  2.0860,
        17.4780,  5.5693,  3.9160,  4.6933,  1.0660,  0.3555,  0.1241,  0.5957,
         9.6276,  8.3284, 13.1290,  9.0423,  2.2531,  1.3344,  0.7571,  3.5263,
         3.8825,  0.4480,  0.6665,  4.8617,  9.6632,  0.9191,  0.2203, 16.3927,
         8.3785, 12.5371, 11.9874, 15.6420,  7.0362, 12.0268,  9.3579,  2.2743,
         5.1398,  0.3321,  4.9316,  6.0077,  4.4775,  1.3903,  1.5735,  4.8779,
        14.9262,  3.8227, 13.9238,  3.3116,  9.4678,  8.3188,  0.8772,  3.3792,
         0.3565,  6.6521,  0.6272,  3.6721,  1.3540,  0.8087,  3.8758,  2.9951,
         4.1778,  9.7391,  2.8493,  5.5448,  1.0754,  8.7606,  2.1222,  3.3319],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [37/80], Step [400/642], LR 7.4e-05, Loss: 485.5
BCE Train Loss:  tensor([25.9366,  8.7515, 23.9203,  8.3551,  1.7586,  1.4990,  0.3434,  7.0191,
         0.8088,  2.0805,  5.1902,  0.9372,  0.9161, 15.0877,  4.4355,  1.8192,
         3.8344,  0.9875,  2.9904,  9.1146,  0.3242,  0.6033,  0.2367,  1.7220,
        18.7533,  6.2528,  9.5185,  4.4404,  6.9114, 12.2440,  0.6836,  0.8505,
         1.7025,  2.1508,  0.9403,  0.4896,  1.3282,  0.3697,  1.8822, 22.5663,
         3.1700,  7.7226,  2.3761,  5.7725,  6.2168, 11.5255,  1.2017,  1.0641,
         1.5998,  0.7780,  1.0515,  1.0502,  0.5060,  1.1801,  6.5355,  5.6026,
        12.7046,  3.0825,  4.3149,  1.3259,  7.4405,  0.1042,  5.1895,  8.7105,
         2.9447,  6.1617,  1.9937, 11.9395,  3.2074,  2.0974,  0.6343,  5.4361,
         1.4592,  8.4730,  8.7212,  1.5198,  0.8401,  0.8917,  0.0716,  1.6122],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [37/80], Step [500/642], LR 7.4e-05, Loss: 378.0
BCE Train Loss:  tensor([12.1073,  9.9384, 21.9278,  2.5810,  2.0691,  4.7201,  0.6482, 12.3783,
         6.1899,  5.6529,  2.9623,  0.6058,  0.9144,  6.6452,  6.8033,  2.8310,
         6.6148,  0.5740,  4.4065,  0.7897,  4.6618,  0.9816,  0.0785,  0.2800,
         7.6336,  2.7270, 12.2117,  4.1423,  2.2760,  0.5308,  1.1763,  1.0521,
         2.6567,  0.3067,  0.7073,  0.4651,  1.7450,  2.6957,  0.2373, 14.8243,
         9.6675, 15.9596,  3.5424,  8.7725,  9.8996, 11.7487,  2.2215,  5.4750,
         7.3614,  5.1692,  4.7721,  1.2436,  5.5316,  1.5355,  2.4109,  1.6458,
        18.2268,  3.2789, 23.3153,  3.5694, 11.8592,  2.8257,  2.2396,  4.3131,
         2.0630,  3.8825,  1.9272,  6.2733,  1.3706,  0.9652,  0.1829,  8.3943,
         3.5837,  5.3130,  6.5252,  6.9689,  0.8049,  1.0061,  3.7995,  2.5766],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [37/80], Step [600/642], LR 7.4e-05, Loss: 395.0
BCE Val Loss:  tensor([5.9823e+01, 1.9017e+01, 6.2594e+01, 2.5162e+01, 4.6336e-02, 9.4460e+00,
        4.9402e+00, 2.0866e+01, 6.3594e+00, 9.9422e+00, 7.7775e+00, 1.4450e+01,
        7.6466e+00, 2.1429e+01, 8.3150e+00, 2.1319e+01, 2.1255e+02, 3.1595e+00,
        3.1202e+00, 2.1801e+00, 8.7372e-02, 1.2414e-01, 9.7983e-03, 1.5387e-02,
        2.2108e+01, 1.5680e+01, 3.1222e+01, 2.7002e+00, 1.4760e+01, 1.5341e+01,
        4.7664e-01, 3.2693e+00, 1.1042e+01, 7.8469e-01, 3.8735e-01, 1.5650e-01,
        5.5604e+00, 3.5976e+00, 4.0287e+00, 4.6374e+01, 9.4947e+00, 2.0715e+01,
        6.7278e+00, 1.9387e+01, 1.4934e+01, 1.2791e+01, 2.3428e-01, 3.1889e+00,
        2.3802e-01, 3.8472e+00, 8.2657e-02, 9.6237e-02, 2.7187e+00, 7.3827e-02,
        4.7876e-01, 3.3249e-01, 2.5734e+01, 5.6974e+00, 8.0303e+00, 1.0995e+00,
        8.8503e+00, 4.8922e+00, 4.8766e+00, 7.5310e+00, 3.5238e-02, 3.1391e-01,
        8.2359e-02, 7.6748e+00, 8.6161e+00, 1.6769e+01, 4.0830e-01, 2.3165e+01,
        1.1942e+01, 9.9027e+00, 2.0170e+01, 5.5806e+00, 7.0088e-01, 1.0315e+01,
        1.0153e-01, 1.6013e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [37/80], Step [000/314], LR 7.4e-05, Loss: 975.9
BCE Val Loss:  tensor([5.5175e+01, 2.0740e+01, 5.5430e+01, 1.3971e+01, 4.5190e-01, 3.6820e+01,
        2.7127e+01, 3.4177e+01, 1.7369e+01, 4.0819e+01, 1.8357e+01, 3.9914e+01,
        1.2045e+01, 5.8977e+00, 1.9109e+01, 4.0943e+00, 8.7827e+00, 2.5732e+01,
        8.7973e+00, 1.5208e+01, 5.2735e-02, 7.3492e-02, 4.6498e-02, 2.3375e-02,
        3.6109e+01, 2.6700e+01, 3.6814e+01, 1.6598e+01, 1.6841e+01, 2.1626e-01,
        7.0877e-02, 1.0455e-01, 1.4064e+00, 1.8900e+00, 7.1781e-01, 1.2473e-01,
        1.1233e+00, 1.0615e+00, 7.3164e-01, 5.7640e-01, 1.6826e-01, 4.4001e+00,
        1.7921e-01, 6.6982e-01, 7.7971e-01, 1.9323e+00, 1.1116e-01, 1.0145e-01,
        3.4172e-02, 8.0801e+00, 3.4262e-02, 5.4609e-02, 1.9025e-02, 1.4137e+00,
        6.2771e-02, 7.9255e-01, 1.3205e+01, 9.6143e+00, 4.1032e+00, 3.7842e-02,
        2.9867e+00, 2.0596e-02, 7.9574e-02, 7.0445e-02, 5.0893e-03, 1.7010e-02,
        6.3366e-03, 2.5125e+01, 2.3694e-02, 5.1216e+00, 1.4233e-02, 7.7737e-02,
        2.0040e+00, 3.8672e+00, 3.2799e+00, 1.7893e-01, 1.3811e+00, 5.4665e-01,
        2.3008e-03, 1.6416e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [37/80], Step [100/314], LR 7.4e-05, Loss: 691.9
BCE Val Loss:  tensor([1.2895e+01, 3.8393e-01, 4.9311e+00, 2.4182e-01, 4.9571e-02, 3.7799e-02,
        2.7309e-02, 1.6670e+01, 2.6213e-01, 1.7238e-02, 5.9321e-03, 1.6970e-02,
        1.3499e-02, 9.8776e+00, 4.4559e-01, 1.3592e+00, 1.1836e+00, 7.1472e-02,
        1.4415e-01, 2.1818e-02, 1.0863e-02, 1.1730e-02, 1.5644e-03, 4.2905e-03,
        4.3247e+00, 9.2024e-01, 2.9517e+01, 5.7243e+00, 4.5587e-01, 6.5523e-02,
        2.6626e-01, 6.6683e+00, 1.1287e+01, 6.9889e-02, 2.1084e-01, 3.5786e-02,
        1.2266e+01, 6.3072e+00, 2.3440e-02, 3.6755e+01, 2.1914e+01, 7.2621e+01,
        5.9589e+01, 5.5074e+01, 4.3698e+01, 6.2442e+01, 1.0167e+01, 5.0935e+00,
        4.3969e+01, 1.1677e+01, 2.9303e+01, 4.0929e+01, 6.4971e+01, 1.3650e+01,
        5.6431e+01, 8.6709e+01, 1.3940e+02, 6.2911e+00, 6.0745e+00, 1.3583e-01,
        7.9262e+01, 6.5066e-02, 1.4450e+01, 6.3036e+00, 1.5535e+01, 1.2289e+00,
        1.1106e+01, 1.6980e+01, 7.6367e+00, 3.4004e+00, 2.4123e-01, 1.7105e+01,
        5.1152e+00, 4.4668e+01, 2.6752e+00, 1.6259e+01, 1.0744e+01, 4.7520e-01,
        5.7373e-02, 7.6950e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [37/80], Step [200/314], LR 7.4e-05, Loss: 1247.1
BCE Val Loss:  tensor([2.5975e+01, 4.3335e-01, 1.2265e+01, 2.6442e+00, 2.4833e-01, 7.9492e+00,
        8.8964e+00, 1.5884e+01, 4.6344e+00, 2.0684e+01, 5.6452e+00, 1.0493e+01,
        7.2881e-01, 1.2781e+01, 1.6823e+01, 8.7841e-02, 1.8399e+00, 3.0638e-01,
        3.6081e-02, 2.6395e-02, 3.8205e-01, 2.4031e-02, 5.8573e-03, 6.2480e-02,
        2.1991e+01, 4.7556e+00, 2.4957e+01, 1.3228e+00, 1.8915e+01, 6.1432e-02,
        1.3628e-01, 2.8779e-02, 3.7613e-02, 1.3415e-01, 1.7423e-02, 1.3575e-02,
        1.4815e-01, 3.4338e-02, 4.1127e-03, 1.5451e+00, 1.2835e+00, 8.5026e-01,
        4.7209e-02, 8.6221e-02, 5.3564e-02, 3.2439e-01, 3.4015e-02, 3.9417e-02,
        2.3717e-02, 2.6487e-02, 2.1781e-02, 3.8080e-02, 1.4640e-02, 4.5836e-02,
        4.8009e-02, 1.5493e-01, 2.8765e+00, 2.1820e+00, 1.4535e+01, 1.1373e-01,
        9.6008e+00, 1.9508e-01, 1.3610e-01, 3.7429e-02, 5.2351e-03, 1.5742e-01,
        5.0927e-02, 6.4035e+00, 1.9042e-02, 6.7652e-02, 9.0054e-03, 8.3508e-02,
        6.4470e-02, 6.2294e+00, 3.9754e+01, 2.6600e+00, 6.2905e-02, 4.1422e+00,
        5.2333e-03, 4.6197e-03], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [37/80], Step [300/314], LR 7.4e-05, Loss: 315.4
starting validation
Accuracy th:0.5 is [94.29222354 98.52097319 95.99663747 99.1215994  99.62232429 98.95225448
 99.48952864 97.44033333 99.11063462 98.59163509 99.36891607 99.43714136
 99.71369745 97.19423496 98.47833238 98.87550103 98.19202982 99.19591623
 99.53947929 99.37013438 99.63938061 99.77583119 99.83796494 99.78070443
 96.18913025 98.59772664 95.94912343 98.66838854 98.94981786 99.39937379
 99.30069078 99.38231747 98.6208745  99.5687187  99.58942995 99.56993701
 99.37866254 99.43226813 99.70516928 95.51053228 98.58554355 95.73104616
 98.49417039 97.90572727 97.96420609 96.9907774  99.22271902 99.24464858
 99.07164874 99.33236681 99.39328225 99.36404284 99.52364128 99.39815548
 99.46028923 99.03388117 95.19377201 98.62818435 97.93374837 99.07043043
 96.30608789 99.49440187 98.31142408 98.82311375 99.37988085 98.7743814
 99.32262034 97.37454466 99.23612042 99.12403601 99.82700016 98.8998672
 99.15449373 97.37210804 98.29436776 98.53071965 99.4152118  99.21175424
 99.84771141 99.4700357 ]
Accuracy th:0.7 is [93.44671727 98.37112121 95.45327177 99.15083881 99.55653562 98.80849405
 99.43957798 97.19058004 99.06190227 98.34553673 99.30800063 99.43226813
 99.67592987 96.92377042 98.43203665 98.70250119 98.01659337 99.04971918
 99.56140885 99.29703585 99.58942995 99.75024671 99.81481707 99.76121149
 95.7919616  98.48442392 95.51175059 98.61234634 98.83895177 99.30556402
 99.08748675 99.34211328 98.51488164 99.50658496 99.53338775 99.44566952
 99.27023306 99.35795129 99.66983833 94.81000475 98.74757861 95.14260304
 98.40767047 97.75953022 97.80826257 96.76539029 99.13500079 99.24464858
 98.91448691 99.26292321 99.4566343  99.21540917 99.48343709 99.33236681
 99.46516246 98.94494463 94.21547008 98.48564223 97.63648104 98.93397985
 96.04780644 99.42617658 97.95811455 98.62209281 99.30800063 98.53559289
 99.26292321 97.04681961 99.08139521 99.02900793 99.82090861 98.60990972
 98.98149389 96.92620704 98.1883749  98.37477614 99.40302872 99.14840219
 99.84527479 99.4152118 ]
Avg Prec: is [99.0726728  76.34807042 88.88982398 91.52661125 97.55186586 90.57271259
 96.73915181 82.33036916 88.40986794 87.80515892 83.64191462 83.4368583
 77.4249729  73.93301768 73.79801848 90.66004283 78.89163507 89.91153134
 89.404285   87.62234176 95.18462368 90.46428811 98.10329644 98.40899068
 59.74317175 83.27217838 67.54998805 84.84357525 77.37473632 89.91598841
 95.37401177 84.64887252 88.50775382 94.49193665 95.79316084 96.2462066
 95.61529199 95.64390637 98.19646994 75.59123506 73.39140048 79.84331708
 83.10549845 79.26719192 69.80294301 83.00593598 84.76903113 76.51484303
 82.79429681 81.38235344 90.04097214 83.32613431 80.53039664 94.17663197
 84.04981869 87.90530305 86.66853102 89.42533044 77.89498047 92.43021646
 90.26566288 96.522362   89.35411973 87.95329506 88.06435422 84.93216397
 88.97147333 70.22516673 77.42631868 90.44886021 35.93088736 94.13710797
 87.18642135 76.27471378 81.34746622 82.35537592 59.10935264 83.46935614
 26.76747593 72.06202291]
Accuracy th:0.5 is [93.82439298 98.4393465  95.77246866 99.11307123 99.60892289 98.83895177
 99.47490893 97.20398143 99.06190227 98.5087901  99.33845835 99.40668364
 99.68811296 97.03098159 98.39670569 98.88646581 97.98979057 99.17520498
 99.51511312 99.32018372 99.6235426  99.74781009 99.83552832 99.76608472
 96.15014437 98.49173378 95.74688418 98.59772664 98.86209963 99.32505696
 99.34942313 99.35795129 98.50757179 99.55166238 99.56993701 99.51511312
 99.34820482 99.37135269 99.71126083 95.29610994 98.65133222 95.28392685
 98.33213533 97.70957956 97.89354418 96.73493257 99.16302189 99.18982469
 98.97052911 99.29216262 99.42373996 99.28241615 99.48587371 99.39084563
 99.43104982 98.96200095 94.93305393 98.49660701 97.84968507 98.99245867
 96.10750356 99.44079629 98.52828304 98.76585324 99.34698651 98.75488846
 99.30434571 97.20763636 99.19835285 99.05824734 99.82090861 98.82676868
 99.0947966  97.05900269 98.12624115 98.42107187 99.38840901 99.18982469
 99.84892972 99.47369062]
Accuracy th:0.7 is [92.77786577 98.30533254 95.18280723 99.03753609 99.59308488 98.74026876
 99.44566952 96.91158733 98.9693108  98.39305077 99.29338093 99.37500761
 99.66252848 96.77148183 98.28462129 98.78900111 97.82288227 99.12647263
 99.47856386 99.2751063  99.62597922 99.74050024 99.82334523 99.7490284
 95.84434887 98.34919165 95.4435253  98.45762113 98.78900111 99.25561336
 99.30921894 99.23977534 98.21761431 99.47856386 99.51145819 99.4980568
 99.29825416 99.32383865 99.69176789 94.90868776 98.54412105 94.82218784
 98.29924099 97.59627685 97.6864317  96.40355259 99.10454307 99.12403601
 98.87671934 99.23977534 99.40546533 99.1922613  99.4420146  99.35185975
 99.35673298 98.86940949 94.25323766 98.40645216 97.62673457 98.95590941
 95.69084197 99.42373996 98.40279724 98.66473362 99.3457682  98.63183928
 99.24830351 96.90793241 99.13012756 99.02900793 99.82090861 98.78656449
 99.04606425 96.72396779 98.00441028 98.28096636 99.35307806 99.12769094
 99.84527479 99.42373996]
Avg Prec: is [98.96155784 73.54696423 87.42455375 90.62717026 97.19676426 89.17696852
 96.1289917  79.98942426 86.86980789 85.9836888  81.24599825 81.94676999
 73.38045441 70.84123941 70.68158146 89.38479399 75.15795698 88.60979782
 87.91861729 85.51639849 94.50483512 88.81885849 98.0518808  98.20986226
 55.66277433 81.29520098 63.82492546 82.98701051 73.09612674 88.09714215
 94.55658089 83.37285442 86.46961402 93.94419959 95.18837804 95.60430435
 94.90155813 94.91471595 97.99089562 71.23126546 69.38231502 76.28165949
 80.82835939 76.05555116 67.49470862 80.16221782 82.70123204 73.53049819
 79.81480806 78.86956202 88.94871418 80.29259915 78.23601275 93.77563044
 81.18423027 86.51431915 84.00242451 87.73715205 73.70886887 91.20535662
 89.00583778 96.08813139 87.78397621 85.92632021 86.73926976 82.71010411
 87.29447818 65.06070317 73.94864798 89.02799109 31.6487039  93.1426188
 84.77021297 71.2486311  78.65615029 79.85307161 53.78837498 81.24429876
 22.75565767 68.15052579]
mAP score regular 83.95, mAP score EMA 81.79
starting validation
Accuracy th:0.5 is [90.51747764 97.76764581 93.80123078 98.5250517  99.46682612 98.32075143
 99.16785011 95.76699803 98.49764556 97.64556394 99.15539278 99.17781598
 99.46931759 95.68228816 97.80003488 98.31078556 97.1024242  98.7866557
 99.36467598 98.91122904 99.56897626 99.68358373 99.81064853 99.78324239
 95.33846575 97.74522261 94.4440292  97.97194608 98.32822583 98.87136557
 99.07566584 98.93863517 97.45870394 99.40204799 99.22266238 99.34225278
 98.98099011 98.96354984 99.47928345 93.68413185 97.74273115 93.44245958
 97.45372101 96.56177592 96.87819219 95.01706655 98.80658744 98.85890824
 98.37307223 98.94112664 99.17283305 98.90624611 99.08314024 98.91621197
 98.92617784 98.14884022 91.61123153 97.70286768 96.66890899 98.18870369
 93.23566784 99.08812318 97.51600767 98.00433515 98.97849864 97.86232155
 98.90873757 95.77945537 98.86139971 98.5250517  99.80068266 97.91713382
 98.54498343 95.81184443 97.51102474 97.50853327 99.16785011 98.90126317
 99.81563146 99.18030745]
Accuracy th:0.7 is [90.78655605 97.89471062 93.89590652 98.67952263 99.46931759 98.34815756
 99.10556345 95.92894337 98.61225303 97.62064928 99.16535865 99.23262825
 99.49423225 95.8367591  97.99686075 98.21112689 97.2743354  98.72935197
 99.42447119 98.94361811 99.54157012 99.66116053 99.80068266 99.77078506
 95.50788549 97.78757755 94.62839774 98.05416449 98.31327703 98.87385704
 98.94361811 99.01337918 97.49607594 99.37464185 99.17283305 99.28744052
 98.91372051 98.93116077 99.43443705 93.71153798 98.06662182 93.66420011
 97.55836261 96.71624685 97.06754366 95.13416548 98.85641677 98.94610957
 98.39051249 98.95109251 99.26003438 98.93863517 99.10058051 98.87883997
 99.02583651 98.22607569 91.58133393 97.73276528 96.72122979 98.16877196
 93.48232304 99.04327678 97.29177567 98.02924982 98.92368637 97.86232155
 98.86139971 96.06597404 98.83150211 98.44034183 99.81314    97.77013728
 98.51508583 95.9638239  97.64307248 97.63061514 99.27498318 98.88880584
 99.82559733 99.18778185]
Avg Prec: is [97.61453416 52.11852752 75.53202974 81.82453505 91.18968195 77.57977659
 91.40717414 58.85276368 76.09488381 69.44302305 67.2835262  70.43149135
 45.97735223 46.12814045 53.40498484 80.83702784 57.3503251  78.83102156
 79.9021871  69.68440583 91.62253633 85.05247489 96.82814285 97.78820181
 28.33174987 63.43860539 37.73404018 67.2113806  50.05843264 73.19619447
 87.50212923 63.82163503 68.04522248 89.31012733 84.24285075 89.22350002
 86.04858404 88.0511976  95.2986823  49.28065917 47.64172919 56.20018544
 56.08437136 46.22643533 36.52202732 56.89564866 63.76214187 45.13685066
 56.03652655 57.77745548 82.85284848 56.49985283 50.14203316 86.21399367
 55.21781909 59.56880219 61.40172229 70.29743279 46.6877931  75.65812339
 70.25571784 91.8675396  72.77957434 67.86876384 71.30613906 52.52051147
 73.50987682 37.04205573 50.12352534 72.99611305  9.00258098 80.12104583
 60.68660396 46.89010701 69.17432724 57.62360833 24.63501871 64.11893609
  2.85371434 30.69847273]
Accuracy th:0.5 is [91.26491766 97.87976182 93.94822732 98.7418093  99.44191145 98.34317463
 99.18030745 95.94638364 98.60228717 97.65802128 99.13795251 99.27747465
 99.48426639 95.8591823  97.99935222 98.40795276 97.2593866  98.83150211
 99.45686025 98.93116077 99.59638239 99.69105813 99.80068266 99.80068266
 95.22884122 97.87228742 94.40167427 98.08655355 98.25846476 98.85890824
 99.12051225 98.94610957 97.51102474 99.36965892 99.24508558 99.38709919
 99.02583651 98.98099011 99.50170665 93.60689638 98.14634876 93.69160625
 97.41884047 96.67887485 96.97286793 95.18150335 98.84395944 98.95109251
 98.35812343 98.98099011 99.25255998 98.92368637 99.08812318 98.98348158
 99.03331091 98.22856716 91.62368887 97.82993248 96.64897725 98.28088796
 93.59443905 99.14542691 97.70785061 98.07160475 98.99593891 97.84737275
 98.91870344 95.89157137 98.82651917 98.54498343 99.80815706 98.02177542
 98.49266263 95.96880684 97.64805541 97.61068341 99.28993198 98.94361811
 99.8206144  99.15788425]
Accuracy th:0.7 is [91.05563445 97.94453995 94.10269826 98.75426664 99.45686025 98.33071729
 99.13546105 96.02860204 98.65460797 97.71283355 99.16286718 99.30488078
 99.48924932 96.00617884 98.01928395 98.39549543 97.32167327 98.85641677
 99.42447119 98.95856691 99.61133119 99.69105813 99.80815706 99.78573386
 95.52532576 97.86979595 94.68071854 98.06662182 98.30580263 98.87634851
 99.11054638 98.97849864 97.42133194 99.37962479 99.22764531 99.40204799
 99.00341331 98.91372051 99.48426639 93.84856865 98.16628049 93.88344919
 97.55337967 96.82836286 97.15723647 95.27368762 98.90126317 98.99843038
 98.40047836 99.00341331 99.21020505 98.94361811 99.13296958 98.95109251
 99.06071704 98.29583676 91.76071954 97.85235568 96.72870419 98.29583676
 93.72399532 99.14542691 97.74023968 98.10897675 99.00092184 97.89221915
 98.91122904 96.10334604 98.86389117 98.50511996 99.81563146 98.03423275
 98.5400005  96.06846551 97.68542741 97.77013728 99.31484665 98.93365224
 99.82559733 99.17532451]
Avg Prec: is [97.87480937 54.37631275 76.73499713 83.37713936 91.16937369 78.73066687
 91.67192904 61.17674583 77.15080304 72.173827   68.30865991 71.08693121
 46.91236888 50.17892441 54.31276201 82.39650534 60.53380894 80.52419688
 81.33044884 71.22283452 92.11685743 87.15887892 96.96712702 97.8482858
 30.81663587 66.90194301 39.96905572 67.78159878 50.90684761 73.3860587
 88.34844881 64.35094393 68.7506238  88.8754688  85.16803514 90.24395326
 86.26011135 88.31532136 95.64269872 52.27498934 48.18639586 58.52735792
 56.50162673 48.68372057 39.24588186 59.17522456 65.88361012 47.37225453
 57.88278176 60.20871166 83.56290362 59.05012787 52.33453024 87.00934701
 58.02323402 62.86237342 63.47842365 72.37815685 49.27841574 78.06040188
 72.13344155 92.64430993 74.99913554 69.98654986 72.22663108 55.56807113
 74.53775113 40.06652111 50.21013059 74.26855533  8.92234263 82.05644992
 62.46431703 49.6512125  70.76313374 60.52413955 25.47129138 65.9215235
  3.33714979 32.97952166]
mAP score regular 64.83, mAP score EMA 66.37
Train_data_mAP: current_mAP = 83.95, highest_mAP = 83.95
Val_data_mAP: current_mAP = 66.37, highest_mAP = 66.37
lr:  [7.356657091707334e-05, 7.356657091707334e-05]
BCE Train Loss:  tensor([18.1264,  2.8436, 11.4003,  2.3048,  1.4128,  8.3629,  1.2190,  6.5379,
         1.6728,  2.2176,  2.4803,  1.6162,  1.3519, 13.4862,  2.0184,  2.8621,
        11.8990,  0.7890,  2.6059,  0.9878,  1.4863,  0.2712,  5.5504,  2.8314,
        11.1593,  4.3752, 17.3381,  3.4221,  8.0163,  2.8040,  0.8745,  4.1353,
         5.2033,  0.2934,  1.5047,  4.5561,  0.5000,  0.4499,  0.2578, 13.4085,
         2.4731, 18.4337,  6.8386,  3.3956,  3.1682, 11.8357,  0.5043,  0.8190,
         6.5246,  0.5308,  0.4345,  0.7710,  4.5384,  0.2387,  1.6524,  1.8337,
        13.7016,  4.2532, 11.7997,  4.2034,  9.5930,  7.5101,  2.1173,  3.9839,
         3.3032,  3.6605,  1.8744, 23.1464,  0.7056,  1.2130,  0.1503,  1.9751,
         0.5723, 13.4660, 10.7884,  8.0404,  1.2742,  3.5202,  8.0860,  0.4849],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [38/80], Step [000/642], LR 7.4e-05, Loss: 388.0
BCE Train Loss:  tensor([28.2700,  7.0873, 16.5755,  3.0599,  1.7151,  7.7766,  0.0829,  8.2944,
         9.2065,  3.9400,  0.8008,  3.1987,  5.3139,  5.7037, 14.0101,  1.4717,
         7.1125,  1.1736,  0.3309,  0.6543,  9.0788,  0.2369,  1.1020,  0.3104,
         8.3382,  6.8817, 16.7462,  5.3379,  2.9379,  0.9494,  0.2034,  1.6138,
         3.2241,  3.0412,  0.3061,  0.3379,  4.7688,  5.0688,  0.9414,  9.1010,
         6.2369,  8.9320, 14.7247, 10.7905, 11.4542, 10.7740,  7.4019,  1.5514,
         2.8405,  2.4553,  0.3440,  2.6068,  0.6438,  1.1380,  4.8804,  3.5395,
         8.0265,  6.1569, 11.6227,  5.2571, 11.4025,  0.8699,  1.6818,  5.0290,
         0.6176,  7.4896,  0.6911,  7.1008,  1.8141,  3.7996,  0.0809,  1.8816,
         2.9405, 12.5264, 11.1488,  2.1130,  0.8444,  8.3712,  0.2359,  2.3027],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [38/80], Step [100/642], LR 7.3e-05, Loss: 410.6
BCE Train Loss:  tensor([17.2589,  4.1275, 15.9345,  2.4490,  0.8107,  6.1931,  0.9322, 15.8811,
         3.4345,  6.0702,  1.6801,  1.8571,  0.0583,  9.7560,  3.6399,  1.2574,
        13.2762,  9.0673,  3.4207,  5.7315,  1.2781,  0.1131,  0.1626,  0.4245,
         6.5810,  2.8077,  7.1156,  5.4895,  0.6732,  1.1132,  2.9857,  1.8283,
         2.6777,  0.1148,  3.0140,  0.5038,  5.7735,  1.0176,  1.3273, 14.9693,
         8.2084, 22.7027, 11.4782,  3.4262,  4.8394,  6.6193,  1.8509,  4.7502,
         3.5377,  0.5502,  0.3981,  6.1094,  2.3323,  1.8065,  1.0835,  2.3348,
        25.5662,  5.9401,  5.8068,  0.8459, 14.2151,  4.7500,  6.0634,  2.2613,
         1.6830,  2.5069,  6.1609,  7.3427,  1.2808,  2.1993,  1.1296,  6.9453,
         3.0666, 14.8828,  4.7877,  2.4281,  5.6846,  1.1528,  0.0931,  3.1766],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [38/80], Step [200/642], LR 7.3e-05, Loss: 394.8
BCE Train Loss:  tensor([19.5162, 13.6886, 11.4074,  1.9676,  1.0763,  3.3146,  0.6846,  8.5337,
         3.3039,  4.3418,  0.6835,  4.8991,  0.2425, 10.0990, 12.6746,  7.1758,
         5.4098,  1.4982,  6.2086,  0.7941,  0.1317,  1.1357,  0.1481,  0.0840,
        12.1367,  4.1664,  6.8778,  8.7338,  1.5560,  2.1082,  2.0522,  3.1236,
         1.1109,  2.0258,  0.5044,  0.8076,  3.9768,  0.7596,  6.2659, 19.7328,
         2.7693, 18.1277,  3.9063,  7.7358,  2.3996,  8.4279,  0.8250,  0.6748,
         3.0219,  0.6610,  0.2075,  0.8734,  3.0945,  0.4419,  3.6534,  0.6871,
        12.1673,  2.7767,  5.4509,  1.6219,  4.6274,  2.0308,  6.0892,  6.5093,
         0.4554,  5.4085,  2.5976, 12.9592,  0.1928,  1.1268,  0.0331, 10.5221,
         0.3757, 11.7401,  4.3290, 11.3520,  6.1243, 18.5570,  0.0757,  0.9278],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [38/80], Step [300/642], LR 7.3e-05, Loss: 380.5
BCE Train Loss:  tensor([16.9305,  7.6286, 13.3839,  2.1808,  0.2187,  3.0341,  1.2991, 11.5837,
         6.3150,  4.3271,  0.9786,  1.9564,  0.4092,  6.0357,  4.4118,  1.0313,
        13.2464,  6.4756,  0.4864,  0.5665,  2.6186,  2.1257,  0.4243,  0.4854,
        17.9777,  3.1534, 15.2821,  8.3328, 14.1059,  4.3764,  1.0100,  2.2380,
         4.4986,  1.8442,  0.6251,  0.2186,  1.1001,  0.6834,  1.9350, 16.4234,
         5.0449, 17.8847,  4.5405,  9.0915, 11.9398, 18.8680,  0.7517,  0.7356,
         0.7231,  5.2940,  1.8109,  1.5562,  0.3127,  1.1722,  3.4113,  5.7284,
        28.0275, 10.8816,  4.2688,  8.2862, 17.2148,  0.4164,  2.5613,  2.8255,
         0.4773,  2.6847,  0.9530,  6.6095,  3.0984,  1.5050,  1.2852,  4.2158,
         6.2993, 13.5141, 10.2030,  7.7039,  5.6605,  0.6168,  0.5245,  1.5348],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [38/80], Step [400/642], LR 7.2e-05, Loss: 432.2
BCE Train Loss:  tensor([14.5182,  1.3808, 10.9477,  1.2776,  0.3855,  1.9850,  1.1496,  7.7881,
         4.7578,  1.9779,  4.9988,  0.3592,  7.5277, 14.8130,  4.6572,  3.7476,
         6.7259,  3.4625,  5.0447,  2.7151,  0.4212,  1.3448,  0.1762,  0.7196,
         6.8928,  5.7039, 10.3813,  5.2692,  0.9995,  1.0464,  4.1293,  5.2318,
         2.9209,  1.9585,  0.3063,  0.3522,  1.3005,  0.7706,  0.9693, 16.5660,
         2.4117,  9.3319,  4.7113,  4.0768,  5.0231, 10.9273,  5.7621,  0.5713,
         2.6780,  3.9874,  1.4437,  1.7619,  0.5930,  1.2349,  2.7148,  3.5699,
        13.1935,  4.6188, 11.8306,  1.6305, 20.2985,  0.6516,  4.4812,  1.5875,
         3.7454,  6.0907,  3.3715, 13.9381,  4.0198,  6.0580,  0.1149,  2.9610,
         2.3015,  4.6109,  7.1703,  8.1814,  6.2379,  3.9212,  0.1324,  3.8809],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [38/80], Step [500/642], LR 7.2e-05, Loss: 363.5
BCE Train Loss:  tensor([14.3290,  1.3557, 11.5165,  4.0571,  1.5944,  2.7567,  1.8043,  4.2740,
         2.1260,  0.9380,  0.6042,  0.6439,  0.0931,  5.1827,  4.6542,  4.1698,
        13.9444, 10.4301,  5.9147,  1.7774,  1.9175,  0.3073,  0.2610,  1.2014,
         8.9807,  2.7949, 16.7748,  7.1338,  2.2095,  3.8075,  0.1812,  0.2871,
         9.1749,  1.1871,  0.4457,  1.6663,  1.2507,  1.4048,  1.0302, 14.4209,
         3.7027, 20.1388,  9.7983,  6.7156,  4.3838, 17.1874,  1.2324,  1.0649,
         9.5068,  3.7367,  1.2352,  7.8272,  5.0719,  2.9151,  1.4941,  4.9077,
        22.2237,  2.6195,  5.7124,  3.1655, 12.2966,  0.5341,  9.8552,  3.6302,
         0.6880,  3.6936,  1.1129, 10.8744,  2.6747,  0.6833,  0.1590,  1.1189,
         4.6658, 19.7211,  3.0776,  4.9460,  0.4602,  1.6770,  0.1390,  0.5055],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [38/80], Step [600/642], LR 7.2e-05, Loss: 385.8
BCE Val Loss:  tensor([6.5607e+01, 1.7055e+01, 5.0141e+01, 2.1111e+01, 9.7046e-02, 1.0337e+01,
        3.0375e+00, 2.4029e+01, 5.4357e+00, 9.7646e+00, 6.6774e+00, 1.3386e+01,
        7.3522e+00, 2.4857e+01, 8.0836e+00, 4.1799e+01, 1.9514e+02, 4.9625e+00,
        2.1212e+00, 1.9463e+00, 2.1047e-01, 6.2482e-01, 1.4480e-02, 1.2219e-02,
        2.4403e+01, 1.6681e+01, 3.0282e+01, 1.4934e+00, 1.2918e+01, 2.2583e+01,
        2.2658e+00, 2.5116e+00, 9.7122e+00, 7.7114e-01, 3.3711e-01, 1.3682e-01,
        9.3254e+00, 2.6387e+00, 3.7658e+00, 4.3179e+01, 1.0695e+01, 2.2216e+01,
        7.7299e+00, 2.2992e+01, 1.6280e+01, 1.6528e+01, 1.4409e-01, 5.8068e+00,
        9.5190e-02, 4.0545e+00, 2.6842e-02, 9.1310e-02, 3.0503e+00, 5.3693e-01,
        2.9839e-01, 1.2466e-01, 3.3829e+01, 8.0793e+00, 6.8558e+00, 3.1499e+00,
        8.8043e+00, 7.7794e+00, 3.6980e+00, 9.8568e+00, 7.3228e-02, 5.3996e-01,
        2.9951e-01, 8.5167e+00, 1.0310e+01, 2.2235e+01, 1.2399e-01, 2.1214e+01,
        1.3280e+01, 1.3266e+01, 1.8120e+01, 5.1169e+00, 4.6943e-01, 1.0123e+01,
        1.4803e-01, 2.3729e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [38/80], Step [000/314], LR 7.1e-05, Loss: 1013.6
BCE Val Loss:  tensor([6.4794e+01, 1.9192e+01, 5.5965e+01, 9.8965e+00, 4.7975e+00, 4.4314e+01,
        2.3852e+01, 3.6930e+01, 2.2893e+01, 3.6629e+01, 1.6484e+01, 4.1703e+01,
        1.2473e+01, 9.8774e+00, 2.2136e+01, 2.2164e+00, 6.1545e+00, 2.1219e+01,
        7.5809e+00, 1.4349e+01, 1.2384e-01, 1.3893e-01, 3.8832e-02, 1.4165e-02,
        3.2312e+01, 2.5434e+01, 3.1636e+01, 1.8768e+01, 1.7223e+01, 9.5456e-01,
        4.3229e-01, 2.2253e-01, 7.1386e-01, 1.1237e+00, 7.1991e-01, 7.0977e-02,
        6.6245e-01, 1.7740e+00, 6.2611e-02, 1.0685e+00, 8.3204e-02, 4.2384e+00,
        2.1217e-01, 1.0768e+00, 8.7208e-01, 3.4472e+00, 3.7778e-02, 3.2847e-02,
        2.8574e-02, 5.8963e+00, 1.7322e-02, 3.9562e-02, 2.2856e-02, 5.5185e-01,
        7.8312e-02, 1.5218e+00, 1.3260e+01, 1.0313e+01, 3.7804e+00, 5.8080e-01,
        6.2232e+00, 1.2322e-02, 2.4669e-01, 8.3829e-02, 7.4679e-03, 2.7809e-02,
        2.3209e-02, 2.3045e+01, 1.9729e-02, 5.9234e+00, 5.5719e-03, 2.2493e-01,
        2.0666e+00, 3.3064e+00, 3.5997e+00, 2.1182e-01, 5.7791e-01, 7.8472e-01,
        3.2989e-03, 2.5477e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [38/80], Step [100/314], LR 7.1e-05, Loss: 699.5
BCE Val Loss:  tensor([1.1890e+01, 2.4679e-01, 5.0365e+00, 1.0350e-01, 1.1243e-01, 1.8377e-02,
        2.9618e-02, 1.8993e+01, 9.2867e-02, 1.4721e-02, 4.2468e-03, 1.8893e-02,
        7.3644e-03, 8.9307e+00, 1.8391e-01, 5.6062e+00, 1.4696e+00, 1.8845e-01,
        4.9619e-02, 7.8968e-03, 1.5589e-02, 1.2138e-02, 1.8625e-03, 1.6065e-03,
        4.1871e+00, 7.4169e-01, 3.0261e+01, 5.2381e+00, 3.2986e-01, 2.5082e-01,
        7.2654e-02, 5.1765e+00, 1.1425e+01, 8.7377e-02, 3.7643e-01, 4.1282e-02,
        1.0765e+01, 7.2697e+00, 4.2983e-02, 4.9489e+01, 1.5636e+01, 7.8939e+01,
        7.0506e+01, 5.4885e+01, 5.0025e+01, 7.3756e+01, 1.0949e+01, 1.0467e+01,
        3.9916e+01, 1.1967e+01, 3.0181e+01, 4.1806e+01, 6.3971e+01, 3.3487e+01,
        6.3896e+01, 1.2897e+02, 1.1680e+02, 7.2263e+00, 8.7186e+00, 7.6101e-01,
        8.6128e+01, 2.3442e-02, 1.1879e+01, 5.0568e+00, 1.3743e+01, 6.1847e+00,
        9.7857e+00, 1.8252e+01, 8.1995e+00, 2.5257e+00, 6.2214e-02, 1.6945e+01,
        4.8241e+00, 4.8901e+01, 2.3415e+00, 1.6369e+01, 1.1344e+01, 2.2275e+00,
        2.3745e-01, 2.2394e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [38/80], Step [200/314], LR 7.1e-05, Loss: 1356.9
BCE Val Loss:  tensor([2.7049e+01, 1.0671e+00, 1.4721e+01, 8.4663e-01, 1.8146e+00, 9.7007e+00,
        8.0623e+00, 1.7262e+01, 3.2045e+00, 2.1341e+01, 5.5323e+00, 1.0599e+01,
        2.1476e-01, 1.1833e+01, 1.7920e+01, 4.3716e-01, 1.7340e+00, 6.4335e-01,
        3.3542e-02, 3.1471e-02, 3.6902e-01, 4.8614e-02, 8.5994e-03, 1.9761e-02,
        1.8825e+01, 4.2716e+00, 2.1695e+01, 2.3965e+00, 1.9023e+01, 2.7597e-01,
        2.6331e+00, 4.2343e-02, 4.4668e-02, 4.0393e-01, 1.1874e-02, 2.1607e-02,
        7.2550e-02, 8.9237e-02, 1.1062e-02, 1.0745e+00, 1.1924e+00, 9.0691e-01,
        1.6943e-01, 2.7083e-01, 8.8779e-02, 3.5166e-01, 1.8453e-02, 2.6210e-02,
        2.6158e-02, 5.5743e-02, 3.9828e-02, 3.3000e-02, 2.6740e-02, 4.6390e-01,
        5.6387e-02, 1.9086e-02, 2.7037e+00, 3.1658e+00, 1.4963e+01, 3.0810e-01,
        9.6552e+00, 9.7468e-03, 1.3666e+00, 1.2662e-01, 1.6047e-02, 1.0673e+00,
        4.3695e-01, 6.6388e+00, 2.0740e-02, 9.1965e-02, 4.0593e-03, 7.2758e-02,
        1.6365e-01, 6.6528e+00, 4.3085e+01, 5.7298e+00, 3.4135e-02, 4.5738e+00,
        9.7320e-03, 4.7751e-03], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [38/80], Step [300/314], LR 7.1e-05, Loss: 330.0
starting validation
Accuracy th:0.5 is [94.10947722 98.56605061 96.31948928 99.11428954 99.6235426  98.89255735
 99.5406976  97.49759384 99.11672616 98.6208745  99.33236681 99.44688783
 99.70395098 97.37332635 98.4539662  98.90474044 98.20177629 99.25804998
 99.54435253 99.35185975 99.68567634 99.68933127 99.83552832 99.78679597
 96.34020053 98.66838854 95.94303188 98.65011391 98.97296573 99.40424702
 99.35795129 99.37744423 98.63549421 99.554099   99.64303554 99.49683849
 99.35551467 99.44079629 99.71004252 95.722518   98.81093067 95.66282087
 98.52828304 97.96055116 98.06654402 97.08458718 99.15936697 99.25683167
 99.11185293 99.35551467 99.47612724 99.31165556 99.52851452 99.41155688
 99.45907092 98.80483912 95.4155042  98.61965619 98.02755814 99.07286705
 96.39258781 99.43714136 98.6769167  98.843825   99.40181041 98.78900111
 99.29216262 97.43789671 99.18616976 99.17520498 99.81481707 98.84626162
 99.18495145 97.34286863 98.39670569 98.52706473 99.44566952 99.31165556
 99.86476773 99.44688783]
Accuracy th:0.7 is [94.05952657 98.46980422 96.0015107  99.02900793 99.63450738 98.7183392
 99.49562018 97.09189703 98.98514882 98.4113254  99.24343027 99.40424702
 99.6649651  97.27098841 98.31264239 98.98027558 98.07629049 99.22637395
 99.52973282 99.24343027 99.65521863 99.74537347 99.81969031 99.76852134
 96.10263033 98.47711407 95.7785602  98.62331112 98.85478978 99.37013438
 99.38231747 99.25074012 98.27974805 99.48831033 99.60648628 99.43348643
 99.2336838  99.31531049 99.71857068 95.41063096 98.69640964 95.23641281
 98.3004593  97.80704426 97.70836125 96.62041154 99.05093749 99.15205711
 99.00707837 99.31409218 99.48100048 99.20078946 99.49318356 99.43104982
 99.43104982 98.58554355 95.52637029 98.3552832  97.93374837 99.12890925
 96.18791194 99.26657814 98.65864207 98.81824052 99.40302872 98.74270538
 99.36160622 97.23931239 99.05459241 99.10454307 99.81359876 98.7317406
 99.06799381 97.02976328 98.27121989 98.47467745 99.38597239 99.24464858
 99.85502126 99.39328225]
Avg Prec: is [99.05739945 77.40156514 90.17679035 91.09313976 97.39357081 90.52318894
 96.74907795 83.33358417 88.46926509 87.67876671 82.85066493 84.19333765
 77.80185029 76.33618183 74.97587969 90.90485455 79.15521319 90.21960804
 89.89227469 87.55351949 95.81075977 89.5456598  98.09858623 98.59490074
 60.25578072 85.3972598  67.85036253 84.43073325 77.77462163 89.69500136
 95.25911132 85.34039275 89.11767222 94.5861421  96.71896987 96.03398772
 95.58809325 96.0992384  98.18605337 76.32669323 75.21304966 79.74962814
 83.68494184 79.5374749  73.56983699 83.7096791  84.89415269 77.98487125
 84.15433725 81.52582902 90.89762393 83.6014815  80.79073808 94.77865228
 84.49500064 88.20427953 87.59685203 89.92856248 77.68659345 92.12934613
 90.76404884 96.91494757 90.05971561 88.17390806 88.58641187 84.44638049
 89.25184005 71.05132887 76.91386337 90.19839669 29.87245354 93.45494457
 87.46518987 76.37267758 82.98349385 82.57954624 60.98373846 85.09527031
 36.88164573 69.0445288 ]
Accuracy th:0.5 is [94.05708995 98.42960003 96.06120783 99.0947966  99.62963414 98.89377566
 99.49440187 97.29291797 99.07895859 98.54533936 99.33358512 99.42008504
 99.6929862  97.08702379 98.4259451  98.89743059 98.06167079 99.1922613
 99.54435253 99.31409218 99.6649651  99.7636481  99.82456354 99.77461288
 96.20496826 98.57092384 95.75419403 98.58432524 98.90717706 99.3311485
 99.36526114 99.35185975 98.58310693 99.52973282 99.60161304 99.50293003
 99.35185975 99.40424702 99.74293686 95.41794081 98.67082516 95.35702538
 98.41741694 97.80704426 97.95933285 96.86894653 99.18129652 99.21540917
 99.07652197 99.29216262 99.47490893 99.29947247 99.50049342 99.43714136
 99.38231747 99.01560654 95.10118054 98.5234098  97.83872029 99.07774028
 96.11359511 99.47734555 98.53802951 98.73052229 99.38840901 98.72808567
 99.3457682  97.23322084 99.19591623 99.08870506 99.82212692 98.82555037
 99.11550785 97.14672092 98.2297974  98.39914231 99.40790195 99.24221196
 99.85258464 99.4432329 ]
Accuracy th:0.7 is [93.047112   98.3284804  95.46789147 99.04606425 99.5955215  98.76707155
 99.47734555 96.9907774  98.99855021 98.33822687 99.29825416 99.38962732
 99.67227495 96.82143249 98.32117055 98.79143773 97.89232587 99.12769094
 99.4700357  99.26657814 99.65887355 99.74537347 99.82578185 99.75268333
 95.89917277 98.40523385 95.46910978 98.45762113 98.83164191 99.23977534
 99.34089497 99.23977534 98.2724382  99.4846554  99.54800746 99.47612724
 99.289726   99.3457682  99.71735237 94.94889195 98.54655767 94.90503283
 98.29436776 97.65841059 97.74369221 96.44253847 99.13743741 99.15814866
 98.94859955 99.26657814 99.42983151 99.22881057 99.46272584 99.38597239
 99.36282453 98.90839537 94.48593463 98.3699029  97.65110074 98.96565588
 95.7359194  99.46881739 98.43812819 98.65133222 99.31165556 98.63305759
 99.28485277 97.0175802  99.13865572 99.03509947 99.81359876 98.72443075
 99.08505013 96.86407329 98.09456512 98.27974805 99.34698651 99.19104299
 99.84527479 99.40181041]
Avg Prec: is [99.01913736 74.28271899 88.67714502 90.3255186  97.29937073 89.6842051
 96.42169286 81.03196188 87.15077276 86.21061882 80.8108035  82.40642619
 73.76968284 72.02527702 71.81551865 89.78378371 76.69596015 89.36618061
 88.75439675 85.58011539 95.32598722 89.23791636 98.01130107 98.35117968
 56.21964804 83.40289528 64.49354054 82.70370555 73.92138661 88.0049183
 94.98043107 83.99673499 87.03558183 93.89982497 96.36470257 95.60352553
 95.05677166 95.42216681 98.10320376 72.17032396 71.16645284 76.64428263
 81.37369966 77.16105581 69.69599666 81.12681353 82.98287436 74.74490362
 81.99850435 79.13319649 90.0350185  81.51112576 78.13837256 94.28869699
 81.69135013 87.41552694 85.14725587 88.09206105 73.85476136 91.06810773
 89.49358368 96.48335773 88.30032426 86.15964683 87.08700147 82.63800937
 88.33549905 66.42434532 74.84282172 88.71519741 28.41388576 92.95632997
 85.74476151 72.63792833 80.20685863 79.74183053 55.02064867 82.62848683
 31.26375884 65.54646003]
mAP score regular 84.40, mAP score EMA 82.42
starting validation
Accuracy th:0.5 is [90.3630067  97.73774821 93.62682811 98.7567581  99.35969305 98.28836236
 99.12798665 95.82430177 98.62720183 97.51102474 99.14293545 99.22515385
 99.47928345 95.38331216 98.00433515 98.21610982 97.01522286 98.8165533
 99.38211625 98.96354984 99.60385679 99.66614346 99.81064853 99.8056656
 95.09181055 97.76515435 94.05785186 97.96945462 98.22109276 98.7791813
 99.08563171 98.96105838 97.44624661 99.40453945 99.20771358 99.36965892
 98.95109251 98.93863517 99.48675785 93.19829584 98.06911329 93.46986571
 97.50604181 96.59665645 96.98781673 95.12170815 98.85890824 98.97351571
 98.35563196 98.95856691 99.23761118 98.91122904 99.08314024 98.89378877
 98.94860104 98.25846476 90.86130005 97.75269701 96.38239031 98.10897675
 93.2306849  99.01836211 97.52846501 97.88225328 99.00839624 97.73525675
 98.83897651 95.6424247  98.88631437 98.50761143 99.81314    97.94204848
 98.52006876 95.9264519  97.57580288 97.43378927 99.23262825 98.91122904
 99.80317413 99.17283305]
Accuracy th:0.7 is [90.97092458 97.90467648 93.90587239 98.7642325  99.40952239 98.32075143
 99.12798665 95.9862471  98.6446421  97.62064928 99.10805491 99.27249172
 99.49672372 95.78194683 98.01430102 98.37058076 97.21703167 98.78914717
 99.40952239 98.92617784 99.59389092 99.69853253 99.8206144  99.77576799
 95.44061589 97.81249221 94.5187732  98.01679249 98.26095622 98.90624611
 99.08064878 99.00092184 97.41136607 99.38211625 99.15539278 99.30238932
 98.88880584 98.88631437 99.48924932 93.67914891 98.18621222 93.75140145
 97.53095647 96.72122979 97.1024242  95.14662282 98.85890824 98.97849864
 98.39549543 98.99593891 99.22017091 98.91372051 99.10805491 98.92617784
 99.03829384 98.18372076 91.45177766 97.70535914 96.65396019 98.21112689
 93.50474624 98.91372051 97.62314074 98.02924982 99.02085358 97.91215088
 98.92617784 96.00368737 98.86389117 98.5175773  99.81563146 97.87477888
 98.52256023 95.98873857 97.64556394 97.63310661 99.29989785 98.91372051
 99.82559733 99.20522211]
Avg Prec: is [97.58212338 52.72060367 75.73177249 82.38905851 90.77452767 77.28213751
 91.3719661  59.48818258 76.61684475 69.11709591 66.62587102 70.86357759
 45.78483314 46.78240356 53.05720098 81.2108383  55.15556615 79.31616215
 80.1428007  70.73855261 91.96135326 87.31913936 96.88631286 97.94498892
 28.05649385 63.97000264 37.28076671 64.65520238 47.6366093  73.53341916
 87.2077812  62.68098543 67.56843936 89.20262164 83.46149099 89.13153434
 85.30952923 87.96500063 94.89914349 49.12466775 46.90395121 56.28958935
 54.79878656 46.11514861 37.42734039 56.75318131 63.57135937 45.51674988
 57.27823814 57.79383222 82.44351373 56.17840344 50.46883799 86.46799517
 53.99281437 59.58897411 61.21288675 70.59479233 46.30263762 75.48274579
 69.78031189 91.83380253 73.10835602 67.59624882 72.11790993 53.64191344
 72.92418043 35.80427381 51.30390419 73.72955048  9.01414037 79.93081879
 60.8269935  46.5110694  69.0065332  57.88621055 24.07535754 63.78460065
  3.12099739 33.3698959 ]
Accuracy th:0.5 is [91.22256272 97.84737275 93.94573585 98.75426664 99.43443705 98.32075143
 99.19276478 95.9488751  98.61225303 97.63808954 99.14044398 99.27747465
 99.48675785 95.84921643 98.00184369 98.41542716 97.2743354  98.85143384
 99.45187732 98.95358397 99.60136532 99.70600693 99.80815706 99.80068266
 95.21140095 97.86979595 94.39669133 98.09901089 98.26843063 98.86887411
 99.12798665 98.96604131 97.52099061 99.36467598 99.23761118 99.39208212
 99.03829384 98.96604131 99.50170665 93.55457558 98.16129756 93.69160625
 97.41385754 96.65645165 96.95791913 95.20392655 98.85641677 98.95607544
 98.35064903 98.98597304 99.26003438 98.93863517 99.07566584 98.97600718
 99.04078531 98.23105862 91.61621447 97.85235568 96.65396019 98.28836236
 93.56454145 99.16286718 97.71283355 98.06911329 99.01088771 97.83740688
 98.93365224 95.89406283 98.84395944 98.54249197 99.8056656  98.01430102
 98.5101029  95.9563495  97.65303834 97.61566634 99.28494905 98.94112664
 99.81812293 99.16535865]
Accuracy th:0.7 is [91.08304059 97.93955702 94.10020679 98.74679224 99.44938585 98.34815756
 99.15539278 96.02860204 98.6521165  97.71781648 99.17034158 99.30737225
 99.49423225 95.99123004 98.02177542 98.41044423 97.35406234 98.86638264
 99.41450532 98.95358397 99.61631412 99.68856666 99.80815706 99.79320826
 95.52781723 97.87976182 94.67822707 98.06413035 98.29583676 98.88382291
 99.12300371 98.99095598 97.43877221 99.38460772 99.21767945 99.40703092
 99.00092184 98.92866931 99.48426639 93.84607719 98.18122929 93.92580412
 97.58576874 96.82587139 97.13730473 95.27867055 98.89129731 99.00590478
 98.39798689 99.00341331 99.20273065 98.94860104 99.12300371 98.96604131
 99.05573411 98.29334529 91.76570247 97.84488128 96.71624685 98.30331116
 93.74392705 99.15040985 97.73525675 98.13139996 98.99843038 97.90218502
 98.92617784 96.09338017 98.86887411 98.49266263 99.81563146 98.03423275
 98.54249197 96.05351671 97.68293594 97.76764581 99.31235518 98.93365224
 99.82559733 99.18030745]
Avg Prec: is [97.89023371 54.45339889 76.73625781 83.31972994 91.25313846 78.72101311
 91.74002334 61.11343974 77.25392963 72.18577451 68.40985241 71.18232151
 47.06563625 50.10234394 54.39667089 82.54009664 60.64872723 80.61432328
 81.39288675 71.47857221 92.50569362 87.37958986 96.97225953 97.94189681
 30.65140652 66.94346695 39.87434788 67.90896407 51.03317391 73.82333719
 88.35574531 64.49113106 68.81853506 89.1213274  85.17743425 90.1613769
 86.5819813  88.48797163 95.69965026 52.10769954 48.38672379 58.49586611
 56.78598692 48.67332689 39.10142895 59.09491932 65.98650389 47.33694138
 58.01792228 60.22626045 83.46665912 59.11104222 52.41167884 86.85510776
 58.04811829 63.0689936  63.39900605 72.39026511 49.25735886 78.05744037
 72.03577229 92.68018001 75.01316118 70.01963693 72.24130157 55.61355288
 74.54251874 40.04066332 50.52147105 74.38804194  9.06909328 81.96891152
 62.45215356 49.51776097 70.51558788 60.56530525 25.54011965 66.10322961
  3.34527388 33.03889169]
mAP score regular 64.79, mAP score EMA 66.42
Train_data_mAP: current_mAP = 84.40, highest_mAP = 84.40
Val_data_mAP: current_mAP = 66.42, highest_mAP = 66.42
lr:  [7.13744131561753e-05, 7.13744131561753e-05]
BCE Train Loss:  tensor([16.4736,  2.0090, 15.8266, 14.9079,  0.4094,  2.7887,  7.4060,  3.4644,
         7.5285,  2.4252,  0.4951,  1.4106,  3.0710,  9.5943, 10.6572,  1.9708,
         6.7994,  4.3129,  1.2023,  3.4677,  1.7564,  3.3709,  0.1409,  0.1531,
         9.1195,  2.9671, 14.9682,  4.1704,  1.7934,  1.4624,  1.0679,  1.3841,
         4.8778,  0.9305,  0.5344,  1.1464,  0.4527,  4.2665,  0.2045, 10.9871,
         4.1275, 10.7204,  7.2644, 10.9217,  3.5086, 12.9884,  4.8849,  8.5193,
         7.0163,  2.1307,  5.4986,  3.8532,  6.8106,  2.6863,  4.3744,  3.1114,
        24.7918,  7.7206,  9.8040,  2.9484, 10.3347,  0.1569, 10.5384,  4.7786,
         4.0283,  3.6359,  0.9007, 13.2165,  1.6486,  0.6760,  5.6720, 11.5211,
         4.9013, 15.2565,  8.9564,  4.4768,  0.8616,  1.0898,  0.2025,  0.9506],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [39/80], Step [000/642], LR 7.1e-05, Loss: 429.5
BCE Train Loss:  tensor([24.3083,  5.0105,  8.2591,  4.2069,  0.5177,  3.3069,  3.3654,  4.4998,
         5.4582,  3.5069,  1.4917,  4.3193,  1.0907,  7.5832,  3.6580,  6.0829,
         7.7008,  0.9777,  0.2831,  1.6442,  0.1252,  0.1077,  0.0926,  0.2497,
        23.8611,  3.3495, 10.6852, 10.4705,  2.1929,  1.2519,  0.2516,  0.3042,
         2.1625,  3.4932,  1.4289,  1.3751,  3.7669,  1.6036,  0.4476, 15.8976,
         8.5451, 25.6888,  5.1839,  4.9874, 11.7093,  6.3039,  6.8719,  1.9596,
         1.4821,  3.5517,  1.6403, 10.4634,  0.7210,  8.8003,  3.0146, 13.5976,
        11.8977,  7.7492,  5.3942,  2.9215, 15.7376,  1.2076,  6.2738,  5.3223,
         1.7536,  6.0862,  1.4608,  8.0733,  5.8664,  5.7026,  0.0904,  4.6162,
         3.7642, 13.5970,  2.2928,  3.6206,  1.5268,  3.3479,  0.2204,  1.3095],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [39/80], Step [100/642], LR 7.1e-05, Loss: 414.7
BCE Train Loss:  tensor([20.1352,  6.7971, 16.0394,  0.7939,  0.5696,  1.5266,  1.1523,  9.2558,
         2.3204,  4.0196,  5.7075,  4.5041,  0.1681,  5.9123,  3.8335,  7.4468,
         1.7645,  6.4158,  0.8506,  0.8082, 10.1789,  0.1171,  0.2759,  1.6466,
        14.3171,  6.2123, 17.7688, 10.4782,  1.4043,  0.4741,  2.9336,  1.8383,
        12.7459,  0.3856,  3.0227,  1.0248,  1.1429,  5.7174,  0.1420, 16.8716,
         5.2103, 10.5399,  3.9533,  5.4387,  3.7683,  7.9619,  6.9844,  3.5859,
         1.3858,  4.2085,  1.3338,  0.2683,  1.5089,  0.2961, 10.3667,  6.4734,
         8.5746,  2.5926,  8.3969,  0.7580, 15.6528,  0.1407,  1.8110,  3.1684,
         2.0182,  3.9318,  4.7618, 13.2643,  1.0306,  2.0456,  0.2396,  1.8861,
         1.8467,  8.3521, 10.1572,  1.5088,  1.9503,  4.4700,  0.1388,  0.5814],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [39/80], Step [200/642], LR 7.1e-05, Loss: 381.3
BCE Train Loss:  tensor([17.5627,  9.2946,  9.2379,  1.6300,  0.5757,  5.8653,  1.3978,  3.6941,
         4.6003,  2.5231,  1.9164,  2.2935,  0.2030,  4.4269,  3.8638,  2.4632,
         9.0074,  3.6766,  0.2685,  1.0044,  3.0181,  0.2033,  0.4599,  0.3281,
         7.7248,  3.8358, 10.9890, 10.5134,  5.3342,  0.3897,  1.3338,  0.3430,
         3.7749,  1.2683,  3.4786,  2.6273,  7.4845,  0.4856,  0.6227, 15.8142,
         2.6074, 13.6551,  2.8362,  4.7912,  7.0404,  7.0487,  5.0561,  0.5453,
         1.6443,  0.7757,  0.9475,  0.3852,  0.6467,  1.0657,  1.0531,  5.1585,
        10.4688,  5.9321,  4.9334,  1.5168,  9.5961,  0.2340,  7.8011,  2.2373,
        12.1946, 10.0468,  2.3005,  6.5974,  0.5181,  5.2098,  0.1145,  1.7429,
         0.4913, 10.0741,  4.5924,  7.2281,  0.7655,  1.3878,  0.1114,  2.7153],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [39/80], Step [300/642], LR 7.0e-05, Loss: 329.6
BCE Train Loss:  tensor([20.5689,  5.3271,  8.5689,  2.7951,  0.3939,  0.9489,  4.5207,  7.5517,
         1.0604,  3.5397,  2.4616,  5.0083,  0.3573,  6.7885,  7.0222,  2.8998,
         3.4304,  1.4881,  1.7569,  0.8577,  0.5164,  0.5494,  0.7003,  0.3914,
        10.3712,  2.3819,  6.1676,  2.9017,  1.8046,  2.4205,  5.4201,  1.1266,
         6.7411,  1.7394,  6.0298,  1.0103,  2.3752,  0.3896,  2.3265, 21.1207,
         7.5072, 19.9933,  4.4280,  7.3197,  8.0011, 10.3227,  3.8822,  1.7616,
         6.3741,  6.6970,  0.9347,  0.4943,  0.3390,  4.6971,  2.9984,  3.5853,
        17.7925, 10.3804,  8.9003,  3.6026,  8.0875,  1.7338,  2.0939,  2.0498,
         0.8427,  2.4885,  1.8587, 13.3238,  0.5632,  7.3703,  0.1804,  5.7125,
         1.9578, 18.6390,  7.7453,  7.7366,  1.9769,  1.7636,  0.0721,  1.1029],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [39/80], Step [400/642], LR 7.0e-05, Loss: 381.1
BCE Train Loss:  tensor([16.3585,  5.0733,  6.6514,  1.7120,  0.9408,  1.3617,  5.5171, 20.5915,
         1.6801,  4.5953,  0.5906,  0.9153,  2.6697, 10.4796,  5.4512,  1.0284,
         3.8129,  3.2206,  0.0701,  4.9706,  5.3765,  0.0540,  0.2877,  2.3876,
        18.3914,  3.3510, 12.6988,  2.2596,  9.2061,  4.5473,  1.5583,  3.7284,
         2.2944,  0.4855,  1.7378,  2.6314,  0.6852,  2.1890,  2.2128, 19.1124,
         4.0597, 14.6006,  5.6568,  7.4111,  4.4037,  8.0467, 15.0740,  0.9881,
         9.5014,  0.3644,  0.2718,  0.2480,  2.6092,  7.6402,  0.5468,  2.4862,
        16.0152,  9.0008,  9.7432,  4.9056,  9.5059,  3.8993,  9.0917, 13.9774,
         0.8715, 15.8466,  3.0996,  6.1063,  4.5137,  3.5784,  0.4103,  4.5904,
         4.6352,  8.8911, 12.6240, 12.8604,  3.2954,  1.6782,  0.0710,  2.7865],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [39/80], Step [500/642], LR 7.0e-05, Loss: 438.8
BCE Train Loss:  tensor([16.0830,  2.2436,  9.8301,  1.6998,  0.3110,  1.5176,  0.5445,  6.9391,
         2.4204,  6.5516,  2.4107,  1.4419,  2.4982,  7.5499,  3.1421, 10.3711,
         3.3453,  3.2768,  0.3843,  2.0911,  4.2773,  0.2460,  9.5632,  0.1056,
        11.5099,  7.2417, 11.7142,  6.8925,  4.2938,  3.5686,  0.7600,  1.4998,
         1.6410,  0.1787,  0.3299,  1.9300,  3.9292,  1.4002,  0.1328, 19.7220,
         2.6809,  7.8856,  6.4879,  8.0454,  6.0674, 16.6441,  5.2957,  5.3194,
         1.6153,  1.3245,  0.5589,  0.5062,  4.8401,  3.2324,  3.1004,  5.8672,
        22.6315,  3.4256, 11.0786,  2.4520, 18.1778,  1.4957,  4.5176,  4.2629,
         4.0604,  2.4609,  0.5236, 10.6622,  4.4649,  1.7978,  0.1934,  3.0192,
         9.5997,  4.6593, 11.7179, 10.1136,  4.4294,  0.5915,  2.2463,  1.9772],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [39/80], Step [600/642], LR 6.9e-05, Loss: 395.6
BCE Val Loss:  tensor([7.1588e+01, 1.9047e+01, 4.6246e+01, 2.0676e+01, 1.9485e-02, 1.0015e+01,
        5.6427e+00, 2.1211e+01, 4.8960e+00, 1.2622e+01, 7.5374e+00, 1.3082e+01,
        9.0155e+00, 2.5657e+01, 7.5513e+00, 3.1386e+01, 2.2392e+02, 2.0758e+00,
        1.1151e+00, 6.6522e-01, 1.6392e-01, 1.5061e-01, 1.8053e-02, 1.2487e-02,
        2.4843e+01, 1.7657e+01, 3.3431e+01, 1.3220e+00, 1.3235e+01, 1.5779e+01,
        1.9801e+00, 1.5254e+00, 1.0659e+01, 6.8237e-01, 1.0597e-01, 1.6316e-01,
        1.0481e+01, 2.8685e+00, 4.3058e+00, 4.9584e+01, 1.2468e+01, 2.3322e+01,
        7.0746e+00, 2.5532e+01, 1.7322e+01, 1.5841e+01, 6.7723e-01, 4.3290e+00,
        2.2356e-01, 3.2198e+00, 4.6056e-02, 5.9148e-02, 1.3967e+00, 1.9951e-01,
        3.4465e-01, 2.2533e-01, 2.9217e+01, 4.5976e+00, 8.6016e+00, 1.7702e+00,
        9.0851e+00, 7.2769e+00, 4.0706e+00, 8.1930e+00, 1.5581e-02, 4.7561e-01,
        1.7215e-01, 6.4226e+00, 1.1449e+01, 2.2131e+01, 1.9572e-01, 2.4116e+01,
        1.5384e+01, 1.1572e+01, 1.7360e+01, 7.6454e+00, 2.4726e-01, 1.5398e+01,
        1.0104e-01, 1.4407e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [39/80], Step [000/314], LR 6.9e-05, Loss: 1040.9
BCE Val Loss:  tensor([5.6892e+01, 1.7858e+01, 5.3180e+01, 1.1281e+01, 1.0221e+00, 3.9468e+01,
        3.4515e+01, 3.9054e+01, 2.8080e+01, 4.2549e+01, 1.6622e+01, 4.5764e+01,
        1.1914e+01, 6.2126e+00, 1.9135e+01, 1.6325e+00, 5.0007e+00, 2.4433e+01,
        5.5486e+00, 1.6309e+01, 8.0776e-02, 6.0251e-02, 3.5865e-02, 1.7190e-02,
        2.8255e+01, 2.6366e+01, 3.2350e+01, 1.9484e+01, 1.5922e+01, 3.0876e-01,
        2.2742e-01, 1.0204e-01, 9.6037e-01, 1.2527e+00, 2.5264e-01, 8.0553e-02,
        2.0432e+00, 1.2176e+00, 2.3730e-01, 1.2425e+00, 4.3963e-02, 3.8724e+00,
        1.6426e-01, 5.7720e-01, 1.1915e+00, 1.8276e+00, 5.0287e-01, 5.3025e-02,
        7.2995e-02, 6.4864e+00, 2.6131e-02, 3.9841e-02, 4.1588e-02, 1.7192e+00,
        3.5344e-02, 1.4446e+00, 1.6564e+01, 9.9497e+00, 3.7892e+00, 7.2069e-02,
        4.9719e+00, 3.0135e-02, 2.0068e-01, 5.2389e-02, 1.9990e-03, 5.8050e-03,
        1.2481e-02, 2.1955e+01, 1.8382e-02, 5.6940e+00, 6.9173e-03, 4.8646e-02,
        3.0901e+00, 4.1973e+00, 3.3737e+00, 5.1122e-02, 2.2627e-01, 8.1210e-01,
        1.3903e-03, 1.2196e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [39/80], Step [100/314], LR 6.9e-05, Loss: 700.2
BCE Val Loss:  tensor([1.0976e+01, 2.2473e-01, 5.0362e+00, 1.1092e-01, 2.0385e-02, 5.4455e-02,
        1.6771e-02, 1.7289e+01, 8.1077e-02, 1.7188e-02, 7.2344e-03, 2.4879e-02,
        6.6878e-03, 1.1281e+01, 5.4870e-01, 6.9760e+00, 8.1344e-01, 7.2842e-02,
        2.9206e-02, 6.9524e-03, 1.5933e-02, 7.1307e-03, 3.2602e-03, 3.2907e-03,
        4.6931e+00, 5.0454e-01, 2.7945e+01, 3.7735e+00, 8.0677e-01, 1.1739e-01,
        2.2370e-02, 5.8389e+00, 1.1244e+01, 5.9689e-02, 1.1161e-01, 1.0027e-01,
        1.3420e+01, 7.2154e+00, 1.4017e-01, 4.3623e+01, 1.8963e+01, 7.5155e+01,
        6.7428e+01, 6.2080e+01, 4.4737e+01, 6.7967e+01, 1.1546e+01, 9.1267e+00,
        4.3297e+01, 1.2757e+01, 2.8589e+01, 4.3324e+01, 5.5071e+01, 1.6461e+01,
        7.0481e+01, 1.0878e+02, 1.1496e+02, 8.6865e+00, 9.1109e+00, 1.5243e-01,
        8.7234e+01, 3.3543e-02, 1.3431e+01, 8.1721e+00, 1.8697e+01, 2.6234e+00,
        1.0803e+01, 1.4915e+01, 7.0763e+00, 1.5081e+00, 1.0782e-01, 1.6442e+01,
        5.1988e+00, 4.6051e+01, 1.8297e+00, 1.7404e+01, 1.1165e+01, 2.0399e+00,
        4.3655e-02, 8.4290e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [39/80], Step [200/314], LR 6.9e-05, Loss: 1306.8
BCE Val Loss:  tensor([3.0102e+01, 6.1719e-01, 1.3930e+01, 1.0261e+00, 2.5692e-01, 5.6687e+00,
        8.9591e+00, 1.7943e+01, 1.5138e+00, 2.3331e+01, 8.1314e+00, 8.4298e+00,
        3.5645e-01, 1.1857e+01, 1.7499e+01, 1.1970e+00, 1.1094e+00, 3.0841e-01,
        2.9761e-02, 1.8347e-02, 2.5538e-01, 1.6620e-02, 1.0085e-02, 4.7596e-02,
        1.9885e+01, 6.4215e+00, 2.2138e+01, 3.3856e-01, 2.1812e+01, 1.0914e-01,
        9.0604e-01, 4.7179e-02, 7.8208e-02, 1.0269e-01, 6.7739e-03, 1.5303e-02,
        6.5396e-01, 4.0326e-01, 3.0531e-02, 1.2899e+00, 1.5225e+00, 7.8097e-01,
        3.8848e-02, 3.9309e-02, 9.6708e-02, 2.1478e-01, 9.5517e-02, 2.7792e-02,
        4.2390e-02, 2.9719e-02, 1.5347e-02, 2.4922e-02, 3.3306e-02, 1.7527e-01,
        3.7105e-02, 5.7008e-02, 3.5555e+00, 1.8625e+00, 1.4331e+01, 1.6441e-01,
        9.3009e+00, 4.7028e-02, 6.3128e-01, 6.3028e-02, 1.5334e-02, 1.1558e-01,
        2.7786e-01, 6.3007e+00, 1.4915e-02, 6.7997e-02, 4.9108e-03, 3.4565e-02,
        2.8893e-02, 6.1249e+00, 4.1132e+01, 2.1225e+00, 1.5751e-02, 4.6783e+00,
        7.7217e-03, 3.3494e-03], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [39/80], Step [300/314], LR 6.9e-05, Loss: 321.0
starting validation
Accuracy th:0.5 is [94.61873028 98.56848723 96.2658837  99.10576138 99.61866936 98.97662066
 99.48100048 97.52805156 98.99002205 98.56970553 99.39815548 99.43592305
 99.72588053 97.42936855 98.55508583 98.93154323 98.23345232 99.27266968
 99.57115532 99.35795129 99.69176789 99.74415516 99.83431001 99.78923259
 96.39380612 98.72930398 96.05146136 98.65620546 98.96809249 99.41155688
 99.39815548 99.38353578 98.44543804 99.52120466 99.46638077 99.59308488
 99.37988085 99.47490893 99.71004252 95.98079945 98.78656449 95.78708836
 98.50513517 97.78633301 98.09943836 97.07849563 99.26535983 99.30921894
 99.12525432 99.39084563 99.45785261 99.36769776 99.52851452 99.44932445
 99.47612724 99.04119102 95.53855338 98.65620546 97.99953704 99.14231064
 96.59848199 99.4700357  98.62452943 98.80971236 99.32993019 98.75854339
 99.34942313 97.49028399 99.14840219 99.06799381 99.82456354 98.93032492
 99.04119102 97.34652356 98.38939584 98.49051547 99.39815548 99.21175424
 99.85136633 99.46759908]
Accuracy th:0.7 is [93.90601966 98.44787466 95.93572203 98.9693108  99.55044407 98.96443757
 99.4152118  97.08946041 98.86331794 98.68544487 99.36038791 99.40302872
 99.70395098 97.14062938 98.4259451  98.99976852 98.01293844 99.20322608
 99.54922576 99.20322608 99.67714818 99.70395098 99.83674663 99.74781009
 96.17085562 98.58432524 95.75663065 98.42350849 98.83651515 99.28607108
 99.33480343 99.23855704 98.64036744 99.4700357  99.30556402 99.55166238
 99.24343027 99.42252166 99.73928193 95.53977169 98.70615611 95.04757496
 98.1883749  97.32703062 97.93983991 96.65208757 99.29825416 99.23855704
 99.09723322 99.29947247 99.49440187 99.29216262 99.54435253 99.38231747
 99.38353578 98.84504331 95.64576455 98.46127606 97.80826257 98.93032492
 96.08070077 99.34942313 98.38452261 98.55874076 99.16180358 98.55021259
 99.289726   97.12722798 98.99245867 98.83042361 99.82090861 98.64280406
 98.79752927 96.85189021 98.21517769 98.22126923 99.35064144 99.30069078
 99.84527479 99.39937379]
Avg Prec: is [99.16302185 77.60082926 90.12457086 91.6371609  97.4090707  91.28275625
 96.58860668 84.49141248 88.81589019 88.91995843 84.28845678 84.17389398
 77.57632952 77.22247677 76.29191465 91.35270023 81.4301477  90.76201061
 90.31816727 89.05477028 96.00800836 90.78647561 97.99380477 98.60591049
 61.53901871 86.05498643 69.12496372 86.30309217 78.70105351 90.70849154
 95.47140122 87.31873071 89.12236302 94.14558918 96.56683483 96.54161287
 95.65041788 96.13093944 98.54503434 78.35471033 76.02468278 81.03989346
 84.66904386 80.97999959 74.16465715 84.19100972 87.49521086 79.49588116
 84.92595709 82.90929968 91.06979766 83.32761603 82.28934717 94.97490938
 85.60824712 90.20867089 88.19019969 90.26296617 78.09321969 93.98392216
 91.23869218 96.79681164 89.75655893 88.59758915 88.88669746 85.92319284
 89.34927879 73.31203952 79.37505789 90.25951618 41.20077126 94.39761444
 87.4436634  78.85697334 83.41307331 83.7495412  60.53456498 84.25662146
 40.49002019 71.89913499]
Accuracy th:0.5 is [94.19232222 98.47711407 96.0015107  99.09357829 99.66009186 98.97783896
 99.49440187 97.39281929 99.0667755  98.61721958 99.35551467 99.40790195
 99.68811296 97.28682643 98.46127606 98.94250801 98.09578343 99.27388799
 99.54557084 99.34942313 99.70516928 99.76242979 99.82456354 99.78679597
 96.22202459 98.67082516 95.76637712 98.66107869 98.93885308 99.36647945
 99.36282453 99.36891607 98.59163509 99.50414834 99.59186657 99.54557084
 99.37135269 99.43592305 99.74050024 95.50078581 98.68788148 95.44474361
 98.50757179 97.86674139 97.94593146 96.93351689 99.22271902 99.24099365
 99.08261352 99.33845835 99.46028923 99.34333159 99.53338775 99.4152118
 99.44688783 99.13012756 95.26077899 98.61721958 97.85212168 99.2056627
 96.29999635 99.48343709 98.59772664 98.80971236 99.40424702 98.79631096
 99.31409218 97.30753768 99.21540917 99.10088815 99.82700016 98.90352213
 99.13256417 97.27464334 98.21517769 98.46980422 99.38475408 99.26414152
 99.84892972 99.45785261]
Accuracy th:0.7 is [93.25544279 98.35893812 95.55073647 99.02900793 99.61623275 98.79752927
 99.45785261 97.11748151 98.99002205 98.50269855 99.33236681 99.37988085
 99.67105664 96.95300983 98.34553673 98.86697287 97.93253006 99.19347961
 99.49074695 99.27754291 99.67349326 99.75146502 99.82212692 99.75755656
 95.90282769 98.53924782 95.49834919 98.52462811 98.85478978 99.26901475
 99.33724004 99.29703585 98.34066349 99.44079629 99.54922576 99.51998635
 99.31896541 99.36891607 99.7210073  95.12554672 98.58798017 95.05122988
 98.37721275 97.72054434 97.74003728 96.54609471 99.14352895 99.18373314
 98.96200095 99.29094431 99.43104982 99.25439505 99.47612724 99.4005921
 99.36282453 98.96565588 94.64553307 98.44909297 97.6596289  99.09845153
 95.93815865 99.46638077 98.47955069 98.6769167  99.36160622 98.70981104
 99.29216262 97.05291115 99.15083881 99.08261352 99.81969031 98.83164191
 99.08992337 96.93839013 98.10918483 98.33944518 99.34820482 99.20809932
 99.84527479 99.41277519]
Avg Prec: is [99.06001412 74.84533499 88.96391836 90.58534721 97.36364669 90.5412747
 96.30840167 82.00100926 87.58123495 87.56688913 82.53887206 82.43275179
 73.75955435 74.18315838 73.03914451 90.54933575 78.23919506 90.19061923
 89.17132794 86.91652626 95.75461171 89.51182983 97.96758069 98.39885751
 57.82496157 84.45634891 65.46359437 84.11646621 75.37503146 88.85069813
 95.12383619 85.94564403 87.77422578 93.53995617 96.27878013 96.18907989
 95.09624649 95.7206794  98.48734211 73.85398469 72.27716826 77.81996712
 82.94933211 78.36491609 70.71152679 81.94654312 85.32328501 76.32287124
 82.87109256 80.61293254 89.98053897 81.13386795 80.3505326  94.2949152
 83.78961458 88.8857152  85.91544616 89.04339047 74.74942382 93.13876782
 89.98337517 96.54189331 88.6782313  86.95712004 87.61107588 84.05609317
 88.15565521 68.62815559 75.75308757 89.61507415 36.62285033 93.66197332
 85.61505048 74.43245909 80.79037138 81.46858442 54.61837961 83.00448957
 30.91583288 68.37347721]
mAP score regular 85.32, mAP score EMA 83.34
starting validation
Accuracy th:0.5 is [90.79652191 97.83242395 93.59194758 98.75924957 99.45686025 98.13638289
 99.13546105 95.9414007  98.60976157 97.2967586  99.17283305 99.29242345
 99.45686025 95.63993323 97.95201435 98.09153649 97.2519122  98.84645091
 99.41948825 98.95358397 99.56897626 99.64372026 99.81064853 99.79569973
 94.84266388 97.77013728 94.18740813 98.03672422 98.22856716 98.88133144
 99.07566584 99.00092184 97.2743354  99.41450532 99.08812318 99.40952239
 98.95109251 98.94112664 99.46682612 93.39512171 98.16378902 93.60689638
 97.47614421 96.70877245 96.83583726 95.20890949 98.6371677  98.93365224
 98.20863542 98.99593891 99.20522211 98.91870344 99.00092184 98.92119491
 99.02334504 98.29334529 90.53990084 97.86232155 96.58170765 98.22109276
 93.15344944 99.06071704 97.61566634 98.11894262 98.93614371 97.91962528
 98.90375464 95.87662257 98.83648504 98.45529063 99.80815706 97.93706555
 98.52754316 95.9563495  97.57331141 97.70785061 99.28494905 98.7044373
 99.8206144  99.16037571]
Accuracy th:0.7 is [91.03570272 97.90218502 93.80621372 98.72436904 99.42945412 98.32075143
 99.08314024 95.94638364 98.59481277 97.55587114 99.15539278 99.31484665
 99.48177492 95.82679323 98.00433515 98.32324289 97.26436953 98.84645091
 99.42197972 98.92368637 99.59389092 99.64372026 99.81812293 99.77825946
 95.31853402 97.80003488 94.55863667 97.94453995 98.24351596 98.84894237
 98.99344744 99.03580238 97.48611007 99.38211625 98.99344744 99.35720158
 98.89378877 98.88880584 99.51914692 93.73146972 98.17375489 93.66669158
 97.47614421 96.72372125 97.07003513 95.21638389 98.80658744 98.95109251
 98.39300396 99.00341331 99.22266238 98.97102424 99.07068291 98.87385704
 99.02334504 98.24600742 91.40942273 97.81498368 96.67389192 98.11395969
 93.38266437 98.99095598 97.54341381 98.00433515 98.85392531 97.90218502
 98.89877171 96.04853377 98.81904477 98.35064903 99.81563146 97.77761168
 98.46276503 95.91648604 97.60819194 97.69539328 99.29740638 98.87136557
 99.82559733 99.17781598]
Avg Prec: is [97.64129928 53.37114935 75.58806561 81.85907429 91.08739477 77.56485103
 91.28359875 58.71921275 76.1289152  70.19042506 67.28854896 71.14703837
 46.10818818 46.30694091 52.86111512 80.82766562 58.37458697 80.64119218
 80.4266237  70.75753127 91.76416069 86.30249965 96.73118271 97.82702744
 28.4925243  64.31771798 37.65700801 64.68652593 47.95801232 72.90583301
 87.64205237 65.73903183 68.34422733 89.39653146 83.21188746 89.30000527
 85.80360915 88.02123101 95.66353181 49.57788254 47.59235623 56.29811031
 53.60542592 45.88884635 37.6564743  57.57204198 64.38017444 44.55663422
 57.65582515 59.11336341 83.13214341 57.7101144  49.86616345 86.38488744
 55.54265344 59.9119962  61.33774274 71.84654151 46.69709206 76.07353032
 69.43759531 91.85157329 73.25487521 68.27898503 70.68942381 53.80742606
 72.68887957 36.11202599 49.01861399 73.83615699  7.98184516 80.48763295
 61.11222912 45.72899909 69.25942324 58.18589342 24.86237465 65.56385981
  3.04554448 32.40385594]
Accuracy th:0.5 is [91.27239206 97.85235568 93.94324439 98.74679224 99.43941999 98.33320876
 99.18529038 95.8965543  98.5923213  97.65054688 99.13546105 99.27249172
 99.47928345 95.8218103  97.98938635 98.4428333  97.2967586  98.87385704
 99.44440292 98.95109251 99.59389092 99.69853253 99.81064853 99.7981912
 95.18648628 97.87727035 94.3543364  98.08406209 98.25348182 98.87634851
 99.12549518 98.97102424 97.53344794 99.37962479 99.24508558 99.39706505
 99.04327678 98.97600718 99.51416399 93.52467798 98.16378902 93.65174278
 97.43877221 96.66392605 96.95044473 95.20890949 98.85890824 98.95607544
 98.36559783 98.98348158 99.26252585 98.93863517 99.06569998 98.97849864
 99.03331091 98.25846476 91.56389366 97.84737275 96.62655405 98.28337943
 93.55457558 99.16785011 97.70535914 98.07658769 99.00839624 97.83491541
 98.93116077 95.90153723 98.85143384 98.57238957 99.8056656  98.01180955
 98.50511996 95.89157137 97.63559808 97.61566634 99.27498318 98.94610957
 99.81812293 99.16037571]
Accuracy th:0.7 is [91.09549792 97.94453995 94.11764706 98.7717069  99.44938585 98.35812343
 99.14542691 96.03607644 98.65709943 97.71034208 99.17532451 99.31484665
 99.49174079 95.98873857 98.02426689 98.39051249 97.3565538  98.86389117
 99.42945412 98.97600718 99.61880559 99.69354959 99.81563146 99.78573386
 95.53280016 97.88474475 94.68819294 98.06662182 98.29832823 98.89628024
 99.12300371 98.99344744 97.45122954 99.38959065 99.21269651 99.40952239
 99.00341331 98.93863517 99.48426639 93.84607719 98.18372076 93.91832972
 97.60071754 96.81590552 97.1248474  95.27119615 98.88382291 98.99095598
 98.4278845  99.01088771 99.20771358 98.96105838 99.12051225 98.96354984
 99.04825971 98.30331116 91.78314274 97.85484715 96.72372125 98.31576849
 93.73894412 99.13795251 97.73276528 98.13638289 99.01088771 97.89969355
 98.93116077 96.11082044 98.87136557 98.5026285  99.81563146 98.01180955
 98.5624237  96.04105937 97.68542741 97.78757755 99.30986372 98.93863517
 99.82559733 99.17283305]
Avg Prec: is [97.87538609 54.38016363 76.5644076  83.32073732 91.26101394 78.69897598
 91.76655028 61.01200943 77.35781431 72.10132127 68.46673991 71.27111861
 47.2216728  49.95106462 54.50031352 82.35374217 60.63782682 80.60627301
 81.40970948 71.76907577 92.40091534 87.61392143 96.96242868 97.95083179
 30.47586102 66.94415192 39.66271713 67.6288346  50.96398871 74.19057379
 88.35284253 64.69116207 68.87105549 89.35484066 85.22415008 90.14683651
 86.61051118 88.57596637 95.71424356 51.92241904 48.54941974 58.41469756
 56.92634971 48.52517819 38.94968947 58.96689764 66.03356729 47.31264637
 58.16971782 60.27443252 83.43363019 59.09933627 52.52446422 87.16600968
 57.90144403 62.88374371 63.36734616 72.40127063 49.13425157 78.03092748
 71.89684283 92.67581281 75.01007983 70.23686107 72.38921926 55.63726051
 74.57372332 40.04379495 50.84414825 74.50543849  9.07317694 81.85220778
 62.43544054 49.40318411 70.57848796 60.39833975 25.56925883 66.22715773
  3.32246828 33.18478084]
mAP score regular 65.00, mAP score EMA 66.43
Train_data_mAP: current_mAP = 85.32, highest_mAP = 85.32
Val_data_mAP: current_mAP = 66.43, highest_mAP = 66.43
lr:  [6.913076304362405e-05, 6.913076304362405e-05]
BCE Train Loss:  tensor([22.3605,  3.3258, 17.1105,  4.4495,  0.2094, 10.4859,  0.3305,  5.3439,
         6.4149,  7.4417,  0.5928,  0.4969,  0.6545,  4.1384, 12.5428,  4.3975,
         9.2867,  2.1280,  3.4893,  2.5337,  3.5785,  0.0767,  1.6200,  5.1337,
        11.1399,  7.9214, 16.8606,  1.1772,  8.8820,  1.2357,  0.3564,  1.0215,
         4.8130,  2.0282,  0.6775,  0.3285,  3.5732,  1.2456,  2.5214, 16.5970,
         6.0713, 17.7646, 12.9711,  6.8702,  4.9719, 14.3927,  1.1309,  2.1958,
         1.8236,  3.8229,  1.3023,  2.2078,  0.8713,  1.7912,  1.5536,  2.1562,
        12.0458,  4.5838,  8.8919,  1.4923, 22.2548,  1.3574,  3.6525,  4.1523,
         1.7326,  3.2283,  1.6902,  5.3543,  3.7570,  0.9887,  0.0516,  1.4545,
         0.4649,  9.5424,  4.1093,  2.7343,  0.9550,  2.0968,  0.2091,  2.0188],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [40/80], Step [000/642], LR 6.9e-05, Loss: 389.2
BCE Train Loss:  tensor([13.7530, 11.7813, 22.8160,  0.6388,  1.1439,  6.5481,  2.8612,  7.5250,
         1.2264,  4.1476,  2.8007,  0.5014,  1.0981, 13.6794,  2.2675,  4.1551,
         5.9165,  7.3022,  3.3844,  2.7159,  0.4265,  0.1819,  0.2183,  0.2207,
        12.1901,  5.4576, 13.7342,  3.5186,  1.5692,  1.2366,  0.6996,  1.9114,
         2.3965,  1.0638,  0.3169,  0.0774,  1.2659,  3.4576,  0.1825, 16.0240,
         2.8580,  8.8142,  5.0358, 10.7173,  3.2453, 11.2029,  1.4798,  1.3301,
         1.1558,  0.5763,  0.3964,  2.6324,  0.5891,  3.0673,  1.5479,  6.9826,
        13.2813,  8.0143,  7.2046,  3.7951, 15.9725,  3.9546,  1.5699,  2.9633,
         1.7246,  3.4575,  2.4853, 10.1065,  0.6260,  0.7241,  0.0951,  1.0574,
         0.9250,  6.2816,  2.3069,  7.0288,  0.9179,  3.3368,  0.3831,  1.4181],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [40/80], Step [100/642], LR 6.9e-05, Loss: 343.7
BCE Train Loss:  tensor([18.7745,  3.1324, 14.5224,  2.4957,  0.6225,  2.8055,  1.9826,  6.3413,
         1.6340,  1.8596,  0.6494,  3.9041,  0.3708,  7.6069,  6.8585,  3.1388,
         8.4697,  0.8776,  1.1691,  1.3503,  1.6426,  0.0823,  0.0378,  0.1434,
        11.0601, 13.1700, 16.3573, 13.2910,  4.0305,  8.8706,  2.9417,  2.2706,
         6.1727,  0.2282,  1.8440,  1.5979,  2.6274,  4.1818,  0.2347, 16.5030,
         6.9023,  9.0811,  2.3811,  2.7054,  4.2929,  6.3922,  4.4406,  0.5283,
         0.9787,  0.6442,  0.8772,  2.3504,  0.6058,  0.8217,  9.3675,  1.7963,
        13.9889,  3.9458,  4.6878,  2.7448, 11.4069,  2.7127, 12.8921,  9.7845,
         4.7538,  7.7791,  7.7323,  7.6090,  1.3767,  2.5315,  2.1593,  1.8529,
         6.6330,  9.3484,  6.3580,  4.0077,  4.6544,  3.2870,  0.0685,  0.6769],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [40/80], Step [200/642], LR 6.8e-05, Loss: 383.0
BCE Train Loss:  tensor([23.0853, 10.5938, 13.2634,  2.7978,  0.3217,  5.3858,  1.8432,  6.2464,
         1.1225,  7.6164,  9.5725,  3.0478,  0.3793, 14.8201,  6.2964, 11.9414,
        13.3383,  0.5531,  9.3400,  1.2164,  1.5305,  0.1063,  0.9282,  0.4181,
         8.9195,  4.1547, 13.4124,  6.5611,  9.0973,  1.5558,  0.4084,  5.3784,
         2.1878,  0.3535,  1.0480,  0.7103,  1.2654,  6.9294,  1.6693, 11.2935,
         7.3355, 19.2535,  2.2842,  9.0885, 13.2292,  9.2255,  4.0012,  1.4515,
        11.1837,  1.3195,  5.7949,  5.4809,  3.3445,  5.6220,  1.0466,  2.8187,
        15.5998,  2.7912,  5.8835,  1.0968, 13.1328,  1.0956,  3.6579,  3.4989,
         0.9436,  1.5159,  5.2377, 16.3755,  1.2394,  2.4797,  0.1513,  3.0751,
         4.1341, 11.1003,  6.3947,  6.8888,  4.4677,  9.4154,  0.8906,  1.2877],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [40/80], Step [300/642], LR 6.8e-05, Loss: 445.5
BCE Train Loss:  tensor([11.2595,  4.2835, 12.1578,  4.0233,  4.2940,  5.2426,  4.1393,  9.1422,
         2.7958,  2.4423,  4.3338,  0.8059,  1.0289, 16.5310,  3.6092,  2.7675,
         8.9560,  4.6207,  4.7068,  0.9247,  8.7935,  0.5677,  0.6008,  0.1444,
         8.6150,  1.0924, 10.8344,  2.1141,  5.2813,  3.6185,  4.1412,  6.2173,
         9.2861,  0.6546,  8.6319,  2.2514,  6.8693,  0.7561,  2.3879, 12.0945,
         1.6146, 14.0732,  6.7103,  7.9785,  4.4356,  6.3474,  0.7985,  4.1521,
         3.5088,  0.6328,  1.4105,  5.1636,  4.8697, 10.2936,  4.1184,  3.6502,
        12.1308,  6.6179,  6.4777,  4.9290, 10.8803,  6.0210,  2.1154,  5.4612,
         1.2885,  2.5060,  0.3333, 10.0707,  0.8190,  2.1692,  0.1164,  2.6660,
         2.6584,  5.6445,  6.2624,  3.4262,  0.9774,  4.9837,  0.0728,  0.6322],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [40/80], Step [400/642], LR 6.8e-05, Loss: 382.0
BCE Train Loss:  tensor([18.5922, 13.0417,  8.3961,  0.4616,  0.5438,  1.0046,  0.2838, 11.2343,
         3.8863,  3.5430,  2.0720,  1.8649,  0.2409,  7.5086,  6.4144,  3.9405,
         5.5065,  3.3646,  5.5775,  1.3353,  0.6653,  1.5807,  0.1302,  0.1323,
        15.7613,  6.6499, 10.8775,  1.8395,  1.9506,  0.8238,  4.0024,  2.0986,
         3.9081,  1.1808,  0.7646,  3.4170,  1.8043,  1.2392,  0.2002, 13.2634,
         7.0497, 21.9415,  8.8375,  6.6770,  6.2320,  5.4602,  0.4636,  1.6567,
         5.1552,  4.2427,  1.4903,  2.4071,  0.3754,  0.9755,  3.9623,  0.4966,
        14.1698,  4.6413,  8.9772,  1.9309,  8.7123,  2.2182,  1.9979,  4.6675,
         3.5566,  4.7312,  5.1748,  2.5502,  2.6096,  6.3856,  0.3769,  7.6144,
         1.2747,  3.9613,  6.2419,  3.1334,  3.0060,  0.6390,  0.0799,  0.5140],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [40/80], Step [500/642], LR 6.7e-05, Loss: 347.7
BCE Train Loss:  tensor([19.2923,  5.5729, 18.8422,  3.1762,  0.8694,  0.9021,  6.0211, 13.0712,
         4.0283,  4.0024,  0.4993,  0.6487,  0.2563,  8.3747,  8.5351,  1.1106,
         3.1718,  0.6792,  0.3371,  5.8456,  0.4880,  7.7502,  1.8052,  0.4233,
         9.8534,  6.1033, 14.9852,  4.4650,  6.5671,  0.9307,  4.7525,  0.6370,
        14.3267,  0.5822,  0.9985,  1.0963,  3.7530,  4.7512,  3.8175, 13.4169,
         4.7020,  6.0297,  1.7686,  4.6244,  3.7685,  5.9457,  4.2285,  0.6687,
         2.6108,  1.3525,  0.3979,  2.1540,  3.6078,  4.0026,  2.2617,  2.2704,
        13.1714,  5.6097,  6.0055,  5.4511,  7.4691,  0.3293,  4.1781,  2.8037,
         2.4342,  6.0818,  4.7847,  5.3262,  2.6631,  0.8929,  0.1089,  2.2681,
         1.6312, 11.6934,  6.7719,  6.4064,  0.9723,  5.3018,  0.0577,  3.9581],
       device='cuda:0', grad_fn=<NegBackward0>)
Epoch [40/80], Step [600/642], LR 6.7e-05, Loss: 363.5
BCE Val Loss:  tensor([6.7051e+01, 1.8841e+01, 5.4566e+01, 2.5108e+01, 3.3722e-02, 9.1085e+00,
        4.6540e+00, 2.6220e+01, 5.2885e+00, 7.2080e+00, 7.3583e+00, 1.3675e+01,
        8.9973e+00, 2.0736e+01, 8.2843e+00, 2.1542e+01, 2.2894e+02, 1.2573e+00,
        1.7945e+00, 5.1119e-01, 7.0157e-02, 1.7860e-01, 6.1382e-03, 1.1394e-02,
        2.3794e+01, 1.8895e+01, 3.2281e+01, 1.8896e+00, 1.2684e+01, 2.0713e+01,
        1.3796e+00, 3.1662e+00, 1.1454e+01, 4.2140e-01, 2.6422e-01, 1.0127e-01,
        1.4801e+01, 3.4106e+00, 2.3605e+00, 4.2119e+01, 1.1380e+01, 1.6127e+01,
        6.1271e+00, 2.0615e+01, 1.4725e+01, 1.5952e+01, 2.1204e-01, 4.3816e+00,
        1.8659e-01, 3.8725e+00, 2.3817e-02, 6.8481e-02, 5.7450e+00, 5.5324e-01,
        6.6841e-01, 1.2735e-01, 2.6945e+01, 7.2811e+00, 8.2634e+00, 1.4970e+00,
        9.9008e+00, 6.1741e+00, 5.6901e+00, 7.2465e+00, 1.5394e-01, 2.1709e+00,
        2.3539e-01, 5.9447e+00, 1.0749e+01, 2.3428e+01, 1.0018e-01, 2.3221e+01,
        1.3657e+01, 1.2621e+01, 1.7953e+01, 7.0837e+00, 2.4448e-01, 1.3524e+01,
        1.0064e-01, 1.8870e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [40/80], Step [000/314], LR 6.7e-05, Loss: 1026.3
BCE Val Loss:  tensor([6.0889e+01, 1.8617e+01, 5.6902e+01, 9.0223e+00, 5.5238e-01, 4.5719e+01,
        3.1102e+01, 3.4299e+01, 2.1335e+01, 3.3780e+01, 1.7874e+01, 4.3693e+01,
        1.2537e+01, 5.1967e+00, 1.8247e+01, 5.1935e+00, 6.9813e+00, 2.3801e+01,
        8.0406e+00, 1.9921e+01, 2.8109e-02, 3.3411e-02, 3.6372e-02, 1.3414e-02,
        3.3540e+01, 2.8603e+01, 3.6971e+01, 1.6830e+01, 1.7647e+01, 7.5033e-01,
        1.1573e-01, 1.1977e-01, 4.5370e-01, 5.6747e-01, 4.1835e-01, 1.2798e-01,
        2.6937e+00, 2.0319e+00, 1.8113e-02, 1.7597e+00, 6.0436e-02, 5.6816e+00,
        2.4723e-01, 2.0628e+00, 2.1642e+00, 4.1957e+00, 3.1632e-01, 3.9343e-02,
        4.4510e-02, 7.7542e+00, 1.0561e-02, 3.2994e-02, 1.7371e-02, 2.9101e+00,
        4.0402e-02, 2.1398e+00, 1.3629e+01, 1.0652e+01, 2.1778e+00, 1.4319e-01,
        9.2831e+00, 3.0668e-02, 4.3765e-01, 5.4005e-02, 8.6041e-03, 2.6060e-02,
        1.8222e-02, 2.4664e+01, 7.6166e-02, 7.2028e+00, 5.4785e-03, 6.7235e-02,
        2.2303e+00, 3.6379e+00, 2.5996e+00, 1.5078e-01, 5.9673e-01, 1.6324e+00,
        1.7792e-03, 3.0183e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [40/80], Step [100/314], LR 6.7e-05, Loss: 723.5
BCE Val Loss:  tensor([1.2749e+01, 1.8436e-01, 4.0529e+00, 1.7529e-01, 2.6917e-02, 2.3463e-02,
        1.6520e-02, 1.7532e+01, 1.5703e-01, 1.6143e-02, 1.3983e-02, 2.2409e-02,
        6.1849e-03, 1.1002e+01, 2.7474e-01, 1.4682e+00, 9.7100e-01, 6.8962e-02,
        5.0856e-02, 6.0393e-03, 1.0926e-02, 7.0707e-03, 1.4071e-03, 2.5740e-03,
        4.1630e+00, 2.2739e-01, 3.2020e+01, 4.1036e+00, 2.7137e-01, 2.1439e-01,
        1.4654e-01, 5.6730e+00, 1.1194e+01, 8.6927e-02, 2.2634e-01, 8.7292e-02,
        8.5585e+00, 5.6458e+00, 6.9367e-03, 4.5130e+01, 1.6968e+01, 9.6315e+01,
        6.3790e+01, 5.7025e+01, 4.8494e+01, 8.0399e+01, 9.6809e+00, 7.8561e+00,
        3.5316e+01, 1.0132e+01, 3.0463e+01, 3.7895e+01, 8.1351e+01, 3.4274e+01,
        6.8993e+01, 1.0537e+02, 1.1509e+02, 9.0934e+00, 8.7431e+00, 1.5154e-01,
        7.4526e+01, 1.8112e-01, 1.1513e+01, 6.7179e+00, 1.3546e+01, 5.1386e+00,
        1.0003e+01, 1.8520e+01, 8.8399e+00, 1.8556e+00, 5.1694e-02, 1.4701e+01,
        5.9505e+00, 4.6561e+01, 1.9581e+00, 1.6216e+01, 1.1110e+01, 3.0961e+00,
        3.9058e-02, 1.1015e-01], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [40/80], Step [200/314], LR 6.7e-05, Loss: 1334.6
BCE Val Loss:  tensor([3.0160e+01, 4.7531e-01, 1.3772e+01, 4.4840e-01, 1.0245e+00, 7.9741e+00,
        8.2923e+00, 1.5583e+01, 3.4696e+00, 2.4280e+01, 5.6715e+00, 8.5643e+00,
        2.4800e-01, 1.0431e+01, 1.7097e+01, 4.0267e-01, 1.2938e+00, 4.5479e-01,
        4.2656e-02, 1.6445e-02, 1.4604e-01, 1.9145e-02, 7.2654e-03, 4.8034e-02,
        2.1619e+01, 1.5315e+00, 2.7022e+01, 1.7158e+00, 2.1584e+01, 6.3134e-02,
        1.9225e-01, 4.3458e-02, 2.1414e-02, 1.4433e-01, 9.0915e-03, 1.0133e-02,
        4.7933e-01, 8.4855e-02, 3.2279e-03, 7.2858e-01, 1.1720e+00, 2.0930e+00,
        5.2470e-02, 1.8094e-01, 1.5093e-01, 7.2760e-01, 1.2365e-01, 2.3391e-02,
        3.4075e-02, 1.7931e-02, 1.5699e-02, 2.7460e-02, 8.9991e-03, 2.2894e-01,
        4.3145e-02, 7.4977e-02, 2.5187e+00, 2.6272e+00, 1.2545e+01, 1.7986e-01,
        1.1224e+01, 7.4696e-02, 1.7580e+00, 5.6650e-02, 1.2507e-02, 1.3094e+00,
        7.8815e-02, 7.0611e+00, 6.2624e-02, 1.2108e-01, 3.2027e-03, 1.6746e-01,
        1.1091e-01, 6.5164e+00, 4.6363e+01, 4.9137e+00, 2.1715e-02, 4.5804e+00,
        5.1386e-03, 1.5043e-02], device='cuda:0', grad_fn=<NegBackward0>)
Val loss valEpocw [40/80], Step [300/314], LR 6.7e-05, Loss: 332.5
starting validation
Accuracy th:0.5 is [94.47496985 98.56117737 96.50345391 99.16180358 99.62476091 99.03997271
 99.53338775 97.51465016 99.16789513 98.72564905 99.44445121 99.43348643
 99.71978899 97.42084039 98.57092384 99.03509947 98.27000158 99.23612042
 99.60648628 99.33358512 99.66983833 99.77095796 99.81116214 99.81969031
 96.34263715 98.68300825 96.12090496 98.82676868 99.09235999 99.47490893
 99.43226813 99.42983151 98.71712089 99.57115532 99.60770458 99.60892289
 99.38109916 99.44566952 99.64912708 96.2524823  98.82555037 95.3606803
 98.5648323  98.15426225 98.11040314 97.25271378 99.3457682  99.25195843
 99.15083881 99.35429637 99.48831033 99.38597239 99.52364128 99.45785261
 99.50049342 99.10697969 95.84191226 98.74026876 98.0775088  99.21419086
 96.38162303 99.54435253 98.75367016 98.95956433 99.43957798 98.94250801
 99.38840901 97.53901634 99.29459924 99.16302189 99.82090861 98.94981786
 99.14718388 97.59384023 98.38452261 98.63914913 99.42008504 99.32383865
 99.85502126 99.48587371]
Accuracy th:0.7 is [93.24082309 98.44178312 95.80292638 99.03022624 99.554099   98.96078264
 99.45785261 97.58043883 99.1362191  98.46005775 99.40302872 99.38962732
 99.70395098 97.06753085 98.38695922 98.85966302 98.10674821 99.1496205
 99.57481025 99.18860638 99.61501444 99.73319039 99.77217626 99.79288751
 95.86384181 98.5234098  95.52880691 98.71590258 98.95590941 99.45785261
 99.31896541 99.42739489 98.51731826 99.49196525 99.51023988 99.56140885
 99.37866254 99.38231747 99.55288069 95.73470109 98.71102935 95.92232063
 98.54899429 97.84237521 98.0909102  97.0041788  99.2470852  99.16058528
 99.00951499 99.25926828 99.44810614 99.33602173 99.46028923 99.45907092
 99.47856386 98.92423338 95.28758178 98.63062097 97.83141044 99.09723322
 96.54122148 99.44566952 98.5648323  98.75367016 99.38962732 98.90717706
 99.289726   97.19788989 99.18251483 99.00098683 99.81725369 98.85113485
 98.94007139 97.26367856 98.21030446 98.45883944 99.36526114 99.31043725
 99.84892972 99.4432329 ]
Avg Prec: is [99.18372613 79.01105445 91.05147975 92.0810335  97.75322128 92.14309947
 96.95010566 84.76701962 89.64358275 89.76323134 85.37356121 84.58052522
 80.03553413 78.59684006 77.57306777 92.21123642 81.88833831 90.87024157
 90.66490682 89.89771463 95.77041824 91.18228749 97.67204812 98.65708422
 62.99158024 86.17898068 71.11720037 87.42195933 81.22432535 91.92317551
 95.98580841 88.31600643 90.13802248 94.80399887 96.72741391 96.71932715
 95.75852711 96.22740735 98.61518137 80.04237807 78.38387663 81.35961018
 84.6794301  83.14731536 75.06876659 84.94820315 88.85077423 79.8754843
 85.00918788 82.97379635 90.87779694 84.70966044 84.34019517 95.14888875
 86.19808174 90.37855006 88.65392283 90.96929159 79.35176939 93.90529249
 91.39557014 97.17982206 90.77719546 89.3184889  89.9817645  87.19835631
 90.35395237 75.07022173 80.04546306 90.8767209  36.22201305 94.3348864
 88.33237822 79.37038952 83.86905603 84.52192363 65.62419435 85.73761253
 36.19064906 74.04670776]
Accuracy th:0.5 is [94.33730096 98.50269855 96.20374995 99.12525432 99.63572569 98.98880374
 99.52485959 97.48297414 99.1228177  98.6769167  99.42252166 99.42008504
 99.69785943 97.33190385 98.51731826 99.01195161 98.19812137 99.25195843
 99.5675004  99.36404284 99.69664112 99.78070443 99.80994384 99.81116214
 96.29512311 98.61234634 96.0015107  98.72199413 99.01560654 99.4432329
 99.39693717 99.43714136 98.65620546 99.54191591 99.61623275 99.55044407
 99.40546533 99.42130335 99.75999318 95.77368697 98.77194479 95.56657448
 98.46858591 97.95689624 98.03974123 97.0175802  99.29947247 99.25804998
 99.10332476 99.34089497 99.44445121 99.32749357 99.54922576 99.4432329
 99.46272584 99.13743741 95.42646898 98.63305759 97.96055116 99.19591623
 96.45350325 99.50049342 98.67082516 98.87550103 99.4286132  98.86088132
 99.34211328 97.40500238 99.24343027 99.14474726 99.82700016 98.90961367
 99.16545851 97.35505172 98.28096636 98.51853657 99.42008504 99.29338093
 99.85136633 99.4700357 ]
Accuracy th:0.7 is [93.30295684 98.37964937 95.67378565 99.06312058 99.59917642 98.90961367
 99.48709202 97.16255894 99.04484594 98.480769   99.36160622 99.37622592
 99.67836649 97.04194637 98.37112121 98.90108551 97.99831873 99.16667682
 99.51876805 99.31896541 99.68811296 99.75390163 99.7904509  99.7904509
 96.02222195 98.47467745 95.5970322  98.57579708 98.90961367 99.36038791
 99.34698651 99.3311485  98.40279724 99.45785261 99.57846517 99.53095113
 99.35795129 99.38840901 99.73319039 95.33753244 98.62331112 95.13894811
 98.42838172 97.80460764 97.84724845 96.67158051 99.20931763 99.18860638
 98.97662066 99.28850769 99.40181041 99.27145137 99.49318356 99.40546533
 99.42130335 99.02169808 94.83558924 98.50513517 97.77536823 99.06555719
 96.11846834 99.49562018 98.53559289 98.77194479 99.40181041 98.73783214
 99.30069078 97.09677026 99.20078946 99.09845153 99.82090861 98.85478978
 99.11307123 96.9907774  98.13598762 98.32238886 99.37378931 99.24221196
 99.84892972 99.43104982]
Avg Prec: is [99.10344949 76.00903292 89.6550385  90.9842907  97.68528672 91.35671638
 96.60933188 82.93053177 88.51875795 88.19068738 84.00561894 82.98831788
 75.83716387 75.39058316 74.39644498 91.14870207 79.25678974 90.12654909
 89.74233307 88.19465643 95.42137584 90.52080693 97.57950466 98.51613779
 59.37241633 84.17975078 67.65364973 85.23759384 77.74571602 90.90826279
 95.4566123  87.24161867 88.4440429  94.2919128  96.14749141 96.15832544
 95.42603891 95.67918902 98.44913931 75.79327238 74.55343421 78.64842681
 83.06755219 80.11225592 71.96072547 82.57757479 86.85837738 77.06087672
 82.69883249 81.26876173 89.76507248 83.19412144 81.63140997 94.70063488
 84.29169945 89.19711912 86.89393664 89.63042874 76.49118911 93.14135637
 90.70042229 96.76361637 89.69162771 87.78546946 89.14326292 85.22310517
 89.56643655 70.39810298 76.98890007 90.20600553 34.3493334  93.87711488
 86.4895766  75.3844703  81.63364637 82.25777788 60.43347643 84.29961877
 30.38630569 70.49422938]
mAP score regular 86.01, mAP score EMA 84.20
starting validation
Accuracy th:0.5 is [90.85631711 97.76515435 93.76136732 98.76921544 99.43941999 98.23604156
 99.18030745 95.49293669 98.50761143 97.62812368 99.09559758 99.27000025
 99.47180905 95.79689563 97.94453995 98.34317463 97.2369634  98.75426664
 99.40453945 98.96354984 99.54157012 99.65368613 99.80815706 99.81064853
 95.32351695 97.84986422 94.43406333 98.01928395 98.23355009 98.81157037
 99.10058051 98.85641677 97.47614421 99.40453945 99.19525625 99.39706505
 98.88631437 98.92866931 99.37215038 93.18832997 98.09651942 92.25901288
 97.3490794  96.63153699 96.76358472 94.83768094 98.84395944 98.97849864
 98.40795276 98.99344744 99.22515385 98.91122904 99.11303785 98.86389117
 98.98597304 98.25597329 91.20263099 97.75767995 96.52938685 98.21361836
 92.70996836 99.06071704 97.62563221 98.06413035 98.99843038 97.46866981
 98.92368637 95.90652017 98.83399357 98.50761143 99.81314    97.87976182
 98.51259436 95.70720283 97.61815781 97.56832847 99.27747465 98.85392531
 99.82310586 99.15539278]
Accuracy th:0.7 is [90.51996911 97.87976182 93.92829559 98.73931784 99.44440292 98.28836236
 99.13296958 95.81931883 98.60976157 97.65303834 99.11552931 99.30737225
 99.51416399 95.84921643 97.97692902 98.26593916 97.3490794  98.69945437
 99.41201385 98.90624611 99.49423225 99.63624586 99.80815706 99.7981912
 95.44809029 97.82494955 94.57358547 98.01180955 98.28088796 98.86139971
 98.99095598 98.94112664 97.4088746  99.40453945 99.11303785 99.38211625
 98.92368637 98.90375464 99.31235518 93.60440491 98.14634876 93.30293744
 97.50853327 96.75860179 97.0501034  95.10925082 98.89378877 98.97600718
 98.41044423 98.98348158 99.22017091 98.96604131 99.10805491 98.93116077
 99.05324264 98.24849889 91.55891073 97.80501781 96.64150285 98.22856716
 93.39013877 99.02334504 97.62812368 98.07907915 98.99344744 97.75269701
 98.90126317 96.06099111 98.87136557 98.46027356 99.81563146 97.88723622
 98.49266263 95.98126417 97.67047861 97.71532501 99.30488078 98.91870344
 99.82559733 99.17532451]
Avg Prec: is [97.63544005 52.10584569 75.16914601 82.30680184 90.99579857 77.4613408
 91.70681863 59.4274398  76.76864513 70.16175678 66.98129736 70.82699597
 45.30918788 46.30364005 52.5058784  81.05489558 59.59980486 79.15743918
 80.55443375 70.41893875 91.18359149 85.36699423 96.73247769 97.89614508
 27.35491763 64.82668934 36.22861603 66.25717755 48.64159814 73.2282254
 88.08012207 64.45716102 67.97795348 89.51481686 83.26042661 89.09041865
 85.72366645 87.7206796  95.2120007  47.79708633 45.81408421 56.48935029
 55.79115513 45.81272093 38.17591402 55.83392006 64.42124835 44.64092423
 56.8013072  58.39411863 82.92366936 58.60377261 48.97373722 85.944642
 55.7056083  60.09809923 60.76345078 71.42502538 45.26464064 76.4729978
 69.85452404 91.83168892 72.97449303 68.65110525 71.38255028 51.42280309
 72.71062585 36.62565597 49.67487847 73.32039764  7.69144183 79.99109269
 60.53667423 46.70352034 68.74162993 57.03861035 23.72673544 64.73937218
  2.86803785 28.64657752]
Accuracy th:0.5 is [91.21259686 97.85484715 93.89590652 98.74430077 99.43692852 98.33570023
 99.18778185 95.8890799  98.6072701  97.64307248 99.15040985 99.25754292
 99.48426639 95.8292847  97.99187782 98.43286743 97.30174154 98.87136557
 99.44689439 98.96105838 99.59389092 99.70351546 99.81314    99.8056656
 95.19396068 97.87727035 94.346862   98.09402795 98.25597329 98.86638264
 99.11552931 98.97351571 97.52099061 99.38959065 99.25006852 99.40952239
 99.03081944 98.97102424 99.51665546 93.50972918 98.16628049 93.60938785
 97.45372101 96.65146872 96.96041059 95.17153748 98.85890824 98.95607544
 98.36061489 98.97351571 99.26501732 98.94361811 99.05822558 98.97600718
 99.01337918 98.24351596 91.57884246 97.86232155 96.61658819 98.27839649
 93.53215238 99.16286718 97.69041034 98.09651942 99.00341331 97.85484715
 98.93863517 95.8741311  98.84645091 98.5773725  99.80317413 98.00931809
 98.50761143 95.89904577 97.64556394 97.61317488 99.26252585 98.95109251
 99.81812293 99.15290131]
Accuracy th:0.7 is [91.14283579 97.94703142 94.13259586 98.76921544 99.44938585 98.36808929
 99.15290131 96.03607644 98.6521165  97.74273115 99.18279891 99.30737225
 99.49423225 95.96880684 98.02924982 98.40047836 97.3640282  98.86389117
 99.42197972 98.97351571 99.62877146 99.69105813 99.81812293 99.79071679
 95.52034283 97.89720208 94.67075267 98.06662182 98.30331116 98.90624611
 99.11802078 99.01337918 97.47116127 99.39955652 99.20023918 99.41201385
 99.00092184 98.94361811 99.49423225 93.82863692 98.18621222 93.92331265
 97.59573461 96.80843112 97.12235593 95.26123029 98.88382291 98.99344744
 98.44034183 99.00590478 99.21020505 98.96604131 99.12300371 98.96354984
 99.04576824 98.32324289 91.78065127 97.85484715 96.72372125 98.29583676
 93.72150385 99.13546105 97.72778235 98.12890849 99.01088771 97.91713382
 98.91870344 96.10085457 98.86887411 98.50761143 99.81563146 97.97443755
 98.55993223 96.04105937 97.69290181 97.77013728 99.30986372 98.94860104
 99.82559733 99.16535865]
Avg Prec: is [97.86945328 54.30087202 76.75453282 83.29612664 91.27349605 78.69189702
 91.80138264 60.74932207 77.46180766 71.94083459 68.43894144 71.28358798
 47.20893828 49.80328274 54.43198371 82.67035539 60.63414393 80.82545922
 81.3851918  71.96815625 92.22081332 87.47985585 96.95550106 97.96820797
 30.32259243 66.98256628 39.44284763 67.55618878 50.91386266 74.41848588
 88.41508695 64.94319026 68.95887586 89.51823168 85.22029474 90.00172121
 86.69178296 88.71457232 95.79628292 51.66918104 48.32223734 58.34030533
 56.97159661 48.31725672 38.90322565 58.9231296  66.00078325 47.05573383
 58.40864076 60.24760211 83.48934336 59.18438631 52.63552078 87.23165352
 57.91255533 63.03222155 63.27420821 72.58543261 49.01846285 78.0516709
 71.72631656 92.66426263 75.04990435 70.32611238 72.37532571 55.60625611
 74.53786311 40.05766926 50.94427943 74.44486775  8.93942582 81.7251392
 62.52379173 49.17912398 70.56158722 60.24814975 25.67419296 66.33273333
  3.28716139 33.30728613]
mAP score regular 64.76, mAP score EMA 66.43
Train_data_mAP: current_mAP = 86.01, highest_mAP = 86.01
Val_data_mAP: current_mAP = 66.43, highest_mAP = 66.43
